{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"about","text":"AboutE-mail: 469608976@qq.com","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"24小时之内，如何找到有毒的那瓶水？","text":"你带着手表被关在小房子里，找到有毒的瓶子，毒药十小时后发作，只有24消失时间 重要条件： 10 小时后,毒药 发作 每隔一小时 喂一瓶毒药发作时，十小时前喝的那瓶就是有毒的。 参考文章","link":"/2021/11/01/algorithm/algorithm-2/"},{"title":"1000瓶酒找1毒酒","text":"某酒主人要宴请客人，他共有1000瓶酒，其中1瓶有毒。一旦喝了毒酒后，会在一天后发作，现在如果我们用小白鼠进行检测，问一天内最少需要多少只小白鼠才可以检测出哪瓶有毒？ 此题的常规思路是10只老鼠按从左到右的顺序一字排好，每桶酒也编上号1到1000，并把编号转换成二进制形式(也就是只有0和1的二进制，但是为了方便，每个二进制都写满10位，不够十位数的前面添0补满(比如1100110就写成0001100110)，数位和老鼠的位置一一对应，把酒给相应位置上是1的老鼠喝(每一桶都要喝)。最后按死掉的老鼠是哪几只，然后排成二进制，再转成十进制就是第几桶酒。比如:第70桶酒，70转换成二进制就是0001000110，那么就给第四、八、九只老鼠喝。如果最后死掉第三、七、八只老鼠，那么就是0010001100，转换成十进制就是140，即140桶酒有毒。理论上这10只老鼠可以检测1024桶酒。 并行二分法 简单理解（8瓶为例） 黄色的 取一点混在一起喂给 第一只小白鼠 蓝色的 取一点混在一起喂给 第二只小白鼠 红色的 取一点混在一起喂给 第三只小白鼠 1000瓶 python 1234567891011121314151617181920212223242526272829303132333435363738394041x=int(input('请输入哪瓶酒有毒:'))if x%2 in range(1,2): print(&quot;1dead&quot;)else: print(&quot;1alive&quot;)if x%4 in range(1,3): print(&quot;2dead&quot;)else: print(&quot;2alive&quot;)if x%8 in range(1,5): print(&quot;3dead&quot;)else: print(&quot;3alive&quot;)if x%16 in range(1,9): print(&quot;4dead&quot;)else: print(&quot;4alive&quot;)if x%32 in range(1,17): print(&quot;5dead&quot;)else: print(&quot;5alive&quot;)if x%64 in range(1,33): print(&quot;6dead&quot;)else: print(&quot;6alive&quot;)if x%128 in range(1,65): print(&quot;7dead&quot;)else: print(&quot;7alive&quot;)if x%250 in range(1,126): print(&quot;8dead&quot;)else: print(&quot;8alive&quot;)if x%500 in range(1,251): print(&quot;9dead&quot;)else: print(&quot;9alive&quot;)if x%1000 in range(1,501): print(&quot;10dead&quot;)else: print(&quot;10alive&quot;) 相关文章 8瓶酒一瓶有毒 参考文章 https://zhuanlan.zhihu.com/p/268350907","link":"/2021/11/01/algorithm/algorithm-1/"},{"title":"二分查找","text":"给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。 递归123456789101112131415161718192021class Solution { public int search(int[] nums, int target) { return searchTarget(nums, 0, nums.length - 1, target); } public static int searchTarget(int[] nums, int from, int to, int target) { int mid = (to + from) / 2; if (target &lt; nums[from] || target &gt; nums[to] || to &lt; from) { return -1; } if (nums[mid] == target) { return mid; } if (nums[mid] &lt; target) { return searchTarget(nums, mid + 1, to, target); } else { return searchTarget(nums, from, mid - 1, target); } }} while循环123456789101112131415161718class Solution { public int search(int[] nums, int target) { int low = 0, high = nums.length - 1; while (low &lt;= high) { int mid = (high - low) / 2 + low; int num = nums[mid]; if (num == target) { return mid; } else if (num &gt; target) { high = mid - 1; } else { low = mid + 1; } } return -1; }} 相关题目你是产品经理，目前正在带领一个团队开发新的产品。不幸的是，你的产品的最新版本没有通过质量检测。由于每个版本都是基于之前的版本开发的，所以错误的版本之后的所有版本都是错的。 假设你有 n 个版本 [1, 2, …, n]，你想找出导致之后所有版本出错的第一个错误的版本。 你可以通过调用 bool isBadVersion(version) 接口来判断版本号 version 是否在单元测试中出错。实现一个函数来查找第一个错误的版本。你应该尽量减少对调用 API 的次数。 示例 1： 输入：n = 5, bad = 4输出：4解释：调用 isBadVersion(3) -&gt; false调用 isBadVersion(5) -&gt; true调用 isBadVersion(4) -&gt; true所以，4 是第一个错误的版本。 示例 2： 输入：n = 1, bad = 1输出：1 123456789101112131415161718192021/* The isBadVersion API is defined in the parent class VersionControl. boolean isBadVersion(int version); */public class Solution extends VersionControl { public int firstBadVersion(int n) { int left = 1, right = n; while (left &lt; right) { // 循环直至区间左右端点相同 int mid = left + (right - left) / 2; // 防止计算时溢出 if (isBadVersion(mid)) { right = mid; // 答案在区间 [left, mid] 中 } else { left = mid + 1; // 答案在区间 [mid+1, right] 中 } } // 此时有 left == right，区间缩为一个点，即为答案 return left; } } 相关题目ref: https://leetcode-cn.com/problems/search-insert-position/给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 请必须使用时间复杂度为 O(log n) 的算法。 示例 1: 输入: nums = [1,3,5,6], target = 5输出: 2 示例 2: 输入: nums = [1,3,5,6], target = 2输出: 1 示例 3: 输入: nums = [1,3,5,6], target = 7输出: 4 示例 4: 输入: nums = [1,3,5,6], target = 0输出: 0 示例 5: 输入: nums = [1], target = 0输出: 0 1234567891011121314151617class Solution { public int searchInsert(int[] nums, int target) {int low = 0, high = nums.length - 1; while (low &lt;= high) { int mid = (high - low) / 2 + low; int num = nums[mid]; if (num == target) { return mid; } else if (num &gt; target) { high = mid - 1; } else { low = mid + 1; } } return nums[Math.min(low, nums.length - 1)] &lt; target ? Math.min(low, nums.length - 1) + 1 : low; }} 参考文章 https://leetcode-cn.com/problems/binary-search/","link":"/2021/11/04/algorithm/algorithm-3/"},{"title":"有序数组的平方","text":"给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。 示例 1：1234输入：nums = [-4,-1,0,3,10]输出：[0,1,9,16,100]解释：平方后，数组变为 [16,1,0,9,100]排序后，数组变为 [0,1,9,16,100] 示例 2：12输入：nums = [-7,-3,2,3,11]输出：[4,9,9,49,121] 暴力排序最直观的相反，莫过于：每个数平方之后，排个序 12345678910class Solution {public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) { for (int i = 0; i &lt; A.size(); i++) { A[i] *= A[i]; } sort(A.begin(), A.end()); // 快速排序 return A; }}; 这个时间复杂度是 O(n + nlogn)， 可以说是O(nlogn)的时间复杂度，但为了和下面双指针法算法时间复杂度有鲜明对比，我记为 O(n + nlogn)。 双指针法数组其实是有序的， 只不过负数平方之后可能成为最大数了。 那么数组平方的最大值就在数组的两端，不是最左边就是最右边，不可能是中间。 此时可以考虑双指针法了，i指向起始位置，j指向终止位置。 定义一个新数组result，和A数组一样的大小，让k指向result数组终止位置。 如果A[i] * A[i] &lt; A[j] * A[j] 那么result[k–] = A[j] * A[j]; 。 如果A[i] * A[i] &gt;= A[j] * A[j] 那么result[k–] = A[i] * A[i]; 。 如动画所示： ref 12345678910111213141516171819202122232425262728293031323334class Solution { public int[] sortedSquares(int[] nums) { int right = nums.length - 1; int left = 0; int[] result = new int[nums.length]; int index = result.length - 1; while (left &lt;= right) { if (nums[left] * nums[left] &gt; nums[right] * nums[right]) { result[index--] = nums[left] * nums[left]; ++left; } else { result[index--] = nums[right] * nums[right]; --right; } } return result; }}class Solution { public int[] sortedSquares(int[] nums) { int l = 0; int r = nums.length - 1; int[] res = new int[nums.length]; int j = nums.length - 1; while(l &lt;= r){ if(nums[l] * nums[l] &gt; nums[r] * nums[r]){ res[j--] = nums[l] * nums[l++]; }else{ res[j--] = nums[r] * nums[r--]; } } return res; }} 12345678910111213141516class Solution { public int[] sortedSquares(int[] nums) { int start = 0, end = nums.length - 1; int[] result = new int[nums.length]; for (int i = nums.length - 1; i &gt;= 0; i--) { if (Math.pow(nums[start], 2) &gt; Math.pow(nums[end], 2) ) { result[i] = (int)Math.pow(nums[start], 2) ; start++; } else { result[i] = (int)Math.pow(nums[end], 2) ; end--; } } return result; }} 参考文章 https://leetcode-cn.com/problems/squares-of-a-sorted-array/submissions/","link":"/2021/11/05/algorithm/algorithm-4/"},{"title":"骆驼运输香蕉问题","text":"总共有3000只香蕉，有一只骆驼每一次只能带1000只香蕉，每1公里吃1只香蕉，没有香蕉吃它是不肯走的，A-B 点距离1000公里， 如果这个骆驼要从A点到B点有什么办法可以让更多的香蕉剩下来？如何做到？如何最有效率的运最多的香蕉到B点？ 思路如果直接运送 1000只 香蕉， 从 A 到 B 点， 到达后， 剩余香蕉为 ０.设置一个中转站， 从Ａ到中转站需要消耗５００个香蕉，再回到A点又消耗了５００个， －－＞ 至少需要２个中转站 中转站 把香蕉放到中转站，再回去取香蕉 中转站越少越好 （每多设置一个中转站，消耗越多，骆驼吃的越多） 中转站至少两个 设置两个中转站， 每次从A 到中转站 M， 运送1000只， 需要走3次， 返回A点需要2 次 ，一共走五次。此时M中转站，应该有 2000 只香蕉。为什么？ A 到 M 的距离未知，是变化的， 设为 x. 为了让骆驼物尽其用，每一次都需要运送1000 只香蕉。 M中转站 可能有 1000 或 2000 香蕉 （损耗多少是不知道的） 假设M 有 1000 只 香蕉， 直接从M到B点就可以了。 但是此时只有一个中转站，已分析过，一个中转站是不行的。 所以，M 剩余 2000 是最划算的。 从M 到 N , 需要2次， 返回 1 次, 总共 3次.中转站N,剩余1000 香蕉是最划算的， 可一次从N 到 B. 计算x + y + z = 10005x=1000 –&gt; x=2003y=100 —&gt; x=333.3剩余距离：z=1000-x-y=467 转载https://blog.csdn.net/guanliangliang/article/details/6534761分析这个问题，我们先从初始情况开始，假设走X公里后停下，将剩余香蕉运输过来。 则可以得出剩余香蕉数量为 3000 – 5X，为什么是5呢，因为骆驼往返，总共需要走5次。 同时，由于骆驼一次运输1000只香蕉，所以这个5，只有在剩余香蕉超过2000只的时候才成立，那很容易得出一个不等式，就是3000-5X&lt;2000，求出X=200,。 也就是说，骆驼拖着香蕉，走了200公里，还剩2000只。 等到只剩2000只的时候，骆驼只要一个来回就可以把香蕉全部拖走，所以，走X公里后，剩余香蕉数量为 2000 – 3X，2000-3X &gt; 1000 得出 X = 333 还剩1000只的时候，骆驼一直拖着就行了，目前已经走了200+333=533公里，剩余距离为1000-533=447，所需再消耗447只香蕉，就能到达目的地，剩余香蕉数量为553. 参考文章 https://blog.csdn.net/guanliangliang/article/details/6534761","link":"/2021/10/29/algorithm/algorithm-camel-banana/"},{"title":"轮转数组","text":"给你一个数组，将数组中的元素向右轮转 k 个位置，其中 k 是非负数。 12345678910111213141516示例 1:输入: nums = [1,2,3,4,5,6,7], k = 3输出: [5,6,7,1,2,3,4]解释:向右轮转 1 步: [7,1,2,3,4,5,6]向右轮转 2 步: [6,7,1,2,3,4,5]向右轮转 3 步: [5,6,7,1,2,3,4]示例 2:输入：nums = [-1,-100,3,99], k = 2输出：[3,99,-1,-100]解释: 向右轮转 1 步: [99,-1,-100,3]向右轮转 2 步: [3,99,-1,-100] 方法一：使用额外的数组我们可以使用额外的数组来将每个元素放至正确的位置。用 nn 表示数组的长度，我们遍历原数组，将原数组下标为 ii 的元素放至新数组下标为 (i+k)\\bmod n(i+k)modn 的位置，最后将新数组拷贝至原数组即可。 1234567891011class Solution { public void rotate(int[] nums, int k) { int n = nums.length; int[] newArr = new int[n]; for (int i = 0; i &lt; n; ++i) { newArr[(i + k) % n] = nums[i]; } System.arraycopy(newArr, 0, nums, 0, n); }} 复杂度分析 时间复杂度： O(n)O(n)，其中 nn 为数组的长度。空间复杂度： O(n)O(n)。 方法二：环状替换方法一中使用额外数组的原因在于如果我们直接将每个数字放至它最后的位置，这样被放置位置的元素会被覆盖从而丢失。因此，从另一个角度，我们可以将被替换的元素保存在变量 \\textit{temp}temp 中，从而避免了额外数组的开销。 我们从位置 00 开始，最初令 \\textit{temp}=\\textit{nums}[0]temp=nums[0]。根据规则，位置 00 的元素会放至 (0+k)\\bmod n(0+k)modn 的位置，令 x=(0+k)\\bmod nx=(0+k)modn，此时交换 \\textit{temp}temp 和 \\textit{nums}[x]nums[x]，完成位置 xx 的更新。然后，我们考察位置 xx，并交换 \\textit{temp}temp 和 \\textit{nums}[(x+k)\\bmod n]nums[(x+k)modn]，从而完成下一个位置的更新。不断进行上述过程，直至回到初始位置 00。 容易发现，当回到初始位置 00 时，有些数字可能还没有遍历到，此时我们应该从下一个数字开始重复的过程，可是这个时候怎么才算遍历结束呢？我们不妨先考虑这样一个问题：从 00 开始不断遍历，最终回到起点 00 的过程中，我们遍历了多少个元素？ 由于最终回到了起点，故该过程恰好走了整数数量的圈，不妨设为 aa 圈；再设该过程总共遍历了 bb 个元素。因此，我们有 an=bkan=bk，即 anan 一定为 n,kn,k 的公倍数。又因为我们在第一次回到起点时就结束，因此 aa 要尽可能小，故 anan 就是 n,kn,k 的最小公倍数 \\text{lcm}(n,k)lcm(n,k)，因此 bb 就为 \\text{lcm}(n,k)/klcm(n,k)/k。 这说明单次遍历会访问到 \\text{lcm}(n,k)/klcm(n,k)/k 个元素。为了访问到所有的元素，我们需要进行遍历的次数为其中 \\text{gcd}gcd 指的是最大公约数。 我们用下面的例子更具体地说明这个过程： 12nums = [1, 2, 3, 4, 5, 6]k = 2 如果读者对上面的数学推导的理解有一定困难，也可以使用另外一种方式完成代码：使用单独的变量 \\textit{count}count 跟踪当前已经访问的元素数量，当 \\textit{count}=ncount=n 时，结束遍历过程。 12345678910111213141516171819202122class Solution { public void rotate(int[] nums, int k) { int n = nums.length; k = k % n; int count = gcd(k, n); for (int start = 0; start &lt; count; ++start) { int current = start; int prev = nums[start]; do { int next = (current + k) % n; int temp = nums[next]; nums[next] = prev; prev = temp; current = next; } while (start != current); } } public int gcd(int x, int y) { return y &gt; 0 ? gcd(y, x % y) : x; }} 复杂度分析 时间复杂度：O(n)O(n)，其中 nn 为数组的长度。每个元素只会被遍历一次。空间复杂度：O(1)O(1)。我们只需常数空间存放若干变量。 方法三：数组翻转该方法基于如下的事实：当我们将数组的元素向右移动 kk 次后，尾部 k\\bmod nkmodn 个元素会移动至数组头部，其余元素向后移动 k\\bmod nkmodn 个位置。 该方法为数组的翻转：我们可以先将所有元素翻转，这样尾部的 k\\bmod nkmodn 个元素就被移至数组头部，然后我们再翻转 [0, k\\bmod n-1][0,kmodn−1] 区间的元素和 [k\\bmod n, n-1][kmodn,n−1] 区间的元素即能得到最后的答案。 我们以 n=7n=7，k=3k=3 为例进行如下展示： 123456789101112131415161718class Solution { public void rotate(int[] nums, int k) { k %= nums.length; reverse(nums, 0, nums.length - 1); reverse(nums, 0, k - 1); reverse(nums, k, nums.length - 1); } public void reverse(int[] nums, int start, int end) { while (start &lt; end) { int temp = nums[start]; nums[start] = nums[end]; nums[end] = temp; start += 1; end -= 1; } }} 复杂度分析 时间复杂度：O(n)O(n)，其中 nn 为数组的长度。每个元素被翻转两次，一共 nn 个元素，因此总时间复杂度为 O(2n)=O(n)O(2n)=O(n)。空间复杂度：O(1)O(1)。 动画演示 ## 参考文章","link":"/2021/11/10/algorithm/algorithm-reverse-array/"},{"title":"16辆摩托车，每辆最多可以跑100km，如果他们可以相互配合，朝同一个方向直线行驶，那么一起最多可以跑多远？","text":"1 辆车 100 km. 2 辆车假设只有两辆车， 最多行驶 100 * 1/2 + 100 = 150 km (两辆车同时出发，行驶50 km后， 将一辆车的油加到另一辆，则这辆车可以在行使100 km) 3 辆车假设有a,b,c三辆车， 行驶 1/3 * 100后， 三辆车都剩下 2/3 的油， 将C的油加到a,b, 则 a,b 满状态，重新出发（问题转化为两辆车）。总路程为： 100 * 1/3 + 100 * 1/2 + 100 4 辆车a, b, c, d 4辆车， 行驶 1/4 后， d 的油加到 a,b,c, 转化为 3辆车。总路程为：100 * 1/4 + 100 * 1/3 + 100 * 1/2 + 100 16 辆车总路程为：100 * （1/16 + 1/15 +…+ 1/3 + 1/2 + 1 ） 转载 https://www.zhihu.com/question/494793411/answer/2192292359这应该是一个程序算法题，按照算法去写逻辑列式子比较费劲。我是这样思考的，一辆车可以用绳子牵引着其余车子行驶，直到这辆车的燃油耗尽，接着是下一辆继续按照这个模式行驶。 这样就出现了，可以每次都用1辆车去牵引剩余的车，也可以同时2辆、3辆。。。去牵引剩余的车，但是只要出现有2辆以上车在同一段路上同时耗费燃油行驶，那必然有一段路程是重复行走的，也就是说有燃油浪费在了“不必要”的路程上，那么从能量转化的角度，路程必然不是最大化的。 所以答案就只能是每次都是1辆车去牵引剩余的车。最多可以行驶：（1/16+1/15+…+1/3+1/2+1）*100=338.07km 参考文章 https://www.zhihu.com/question/494793411/answer/2192292359","link":"/2021/10/29/algorithm/algorithm-motorcycles/"},{"title":"找出数组中超过一半的数","text":"给你一个有N（N是奇数 &amp;&amp; 1&lt;=N&lt;=999999）个数的序列，而且保证这N个数中有一个数M的数量 &gt;= （N + 1)/2 ，让你找出这个数M。Sample Input:51 3 2 3 3Sample Output:3 一、DP思想：1、把一个大的问题分解成一个一个的子问题。2、如果得到了这些子问题的解，然后经过一定的处理，就可以得到原问题的解。3、如果这些子问题与原问题有着结构相同，即小问题还可以继续的分解。4、这样一直把大的问题一直分下去，问题的规模不断地减小，直到子问题小到不能再小，最终会得到最小子问题。5、最小子问题的解显而易见，这样递推回去，就可以得到原问题的解。 二、DP的具体实现：1、分析问题，得到状态转换方程（递推方程）。2、根据状态转换方程，从原子问题开始，不断的向上求解，知道得到原问题的解。3、在通过递推方程不断求解的过程，实际上是一个填表的过程。 按照DP的思想，把这个大问题先分解成若干个小问题。所以呢当N为N时，至少有（N + 1）/ 2个M，另外的数就先不管他； ……然后当N为5得时候，依据题意那么一定至少有3个M，另外两个数就先不管他；当N为3的时候，根据题意得，一定有两个数为M，另外一个数就先不管他；先 来看当N为1的时候，那么这个数一定是M。所以就可以把这个序列中得两个不同的数删去（只要有两个数不同就删去），最后剩下的一定是M；举个栗子：intput: 93 6 9 3 3 3 8 6 3loc ： 1 2 3 4 5 6 7 8 91、2位置删去 3、4位置删去 6、7位置删去 8、9位置删去，，还剩一个5位置，那么5位置的 3 就是要找的M . 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;string&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;using namespace std;int arr[1000006];int dp[1000006];int main(){ int n; while(scanf(&quot;%d&quot;, &amp;n) != EOF){ memset(arr, 0, sizeof(arr)); memset(dp, 0, sizeof(dp)); for(int i = 0; i &lt; n; i++) scanf(&quot;%d&quot;, &amp;arr[i]); int i = 0, j = 1; while(j &lt; n){ if(dp[i] == 1){ while(dp[i] == 1) i++; } if(arr[i] != arr[j]){ i++; dp[j++] = 1; } else if(arr[i] == arr[j]){ while(arr[i] == arr[j]) j++; } } while(dp[i] == 1) i++; printf(&quot;%d\\n&quot;, arr[i]); } return 0;} 参考文章 https://blog.csdn.net/ltrbless/article/details/81318935","link":"/2021/11/24/algorithm/algorithm-7/"},{"title":"最长上升子序列问题（LIS）","text":"给定n个整数A1,A2….An,按从左到右的顺序选出尽量多的整数，组成一个上升子序列（子序列可以理解为：删除0或多个数，其他树的顺序不变）。 例如： 序列1，6，2，3，7，5，可以选出1，2，3，5，也可以选出1，6，7，但是前者更长。 选出的上升子序列中相邻元素不能相等。 关于求LIS有两种常用的算法： 暴力找a[j] O（n2） 用二分来找a[j] O（nlogn） 视频图解 最长上升子序列 视频图解 最长上升子序列 动态规划表格 力扣官方分析 1234567891011121314151617181920class Solution { public int lengthOfLIS(int[] nums) { if (nums.length == 0) { return 0; } int[] dp = new int[nums.length]; dp[0] = 1; int maxans = 1; for (int i = 1; i &lt; nums.length; i++) { dp[i] = 1; for (int j = 0; j &lt; i; j++) { if (nums[i] &gt; nums[j]) { dp[i] = Math.max(dp[i], dp[j] + 1); } } maxans = Math.max(maxans, dp[i]); } return maxans; }} 123456789101112131415161718192021222324252627282930public class Test7 { public static void main(String[] args) { int[] a = {0, 1, 6, 2, 3, 7, 5}; maxIncreaseList(a); int[] b = {0, 10, 9, 2, 5, 3, 7, 101, 18}; maxIncreaseList(b); } private static void maxIncreaseList(int[] a) { int[] dp = new int[a.length]; dp[1] = 1; // dp[i] = max{dp[j] + 1} 0 &lt;= j&lt; i for (int i = 2; i &lt;= a.length - 1; i++) { dp[i] = 1; for (int j = 1; j &lt; i; j++) { if (a[i] &gt; a[j]) { dp[i] = Math.max(dp[j] + 1, dp[i]); } } } int max = 1; for (int i = 1; i &lt;= a.length - 1; i++) { if (dp[i] &gt; max) { max = dp[i]; } } System.out.println(max); }} 最长不下降子序列 https://www.pianshen.com/article/6551264924/ https://www.cnblogs.com/itlqs/p/5743114.html 参考文章 https://blog.csdn.net/ltrbless/article/details/81318935 https://blog.csdn.net/weixin_43731933/article/details/96179727 https://www.cnblogs.com/GodA/p/5180560.html","link":"/2021/11/22/algorithm_dynamic/algorithm-dynamic-lis/"},{"title":"【动态规划】 n个矩阵连乘问题","text":"递归算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.example.demo;public class Test5 { static int[] r = {0, 5, 20, 50, 1, 100}; //r1,r2,r3,r4,r5 static int[][] dp = new int[30][30]; // dp[i][j] --&gt; 矩阵 Mi * Mi+1 * Mi+2 ... * Mj (i&lt;j) static int[][] com = new int[30][30]; // dp[i][j] --&gt; 矩阵 Mi ~ Mj 相乘的组合点 k. 即： Mij = Mi * ... Mk + Mk+1 * ... Mj static int n = 4;// public static void main(String[] args) { System.out.println(minValue(1, 4)); for (int i = 1; i &lt;= n; i++) { System.out.println(); for (int j = 1; j &lt;= n; j++) System.out.printf(com[i][j] + &quot; &quot;); } System.out.println(); combine(1, 4); } static int minValue(int i, int j) { if (i == j) { dp[i][j] = 0; return 0; } if (dp[i][j] != 0) { return dp[i][j]; } if (j == i + 1) { com[i][j] = i; dp[i][i + 1] = r[i] * r[i + 1] * r[i + 2]; return r[i] * r[i + 1] * r[i + 2]; } // i&lt; j int min = Integer.MAX_VALUE; for (int k = i; k &lt; j; k++) { int currentValue = minValue(i, k) + minValue(k + 1, j) + r[i] * r[k + 1] * r[j + 1]; if (min &gt; currentValue) { min = currentValue; com[i][j] = k; } } dp[i][j] = min; return min; } //输出算法 static void combine(int i, int j) { if (i == j) return; combine(i, com[i][j]); combine(com[i][j] + 1, j); System.out.printf(&quot;M[&quot; + i + com[i][j] + &quot;]&quot;); System.out.printf(&quot; and M[&quot; + (com[i][j] + 1) + &quot;&quot; + j + &quot;]&quot;); System.out.println(); }} 输出： 非递归算法123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.demo;public class Test5 { static int[] r = {0, 5, 20, 50, 1, 100}; //r1,r2,r3,r4,r5 static int[][] m = new int[30][30]; // static int[][] com = new int[30][30]; // static int n = 4;// public static void main(String[] args) { for (int i = 1; i &lt; n; i++) { m[i][i] = 0; com[i][i + 1] = i; m[i][i + 1] = r[i] * r[i + 1] * r[i + 2]; } for (int s = 2; s &lt; n; s++) { for (int i = 1; i &lt; n - s + 1; i++) { int j = i + s; // i: 起始位置 j:终点位置 m[i][j] = m[i][i] + m[i + 1][j] + r[i] * r[i + 1] * r[j + 1]; com[i][i] = i; for (int k = i + 1; k &lt; j; k++) { int t = m[i][k] + m[k + 1][j] + r[i] * r[k + 1] * r[j + 1]; if (t &lt; m[i][j]) { m[i][j] = t; com[i][j] = k; } } } } System.out.println(m[1][n]); for (int i = 1; i &lt;= 4; i++) { for (int j = 1; j &lt;= 4; j++) { System.out.printf(com[i][j] + &quot; &quot;); } System.out.println(); } }} 参考文章","link":"/2021/11/19/algorithm_dynamic/algorithm-dynamic-matrix-multiplication/"},{"title":"有一栋100层高楼,从某一层开始扔下的玻璃球刚好摔坏,现有两个玻璃球,试用最简便的方法确定这个恰好摔坏玻璃球的那层.","text":"二分法第一颗玻璃球： 从50层开始尝试， 75 -&gt; 87 -&gt; 93 -&gt; 96 -&gt; 98 -&gt; 99 -&gt; 100第二颗： 若在50层碎了，需要从第一层开始一层一层的尝试 粗调，细调第一颗玻璃球： 从10层开始尝试， 20 , 30 ,40, 50, 60, 70, 80, 90.第二颗： 第一层开始一层一层的尝试 最优算法：第一颗玻璃球： 14 27 39 50 60 69 77 84 90 95 99 100第二颗： 第一层开始一层一层的尝试 A:这个形象一点就像显微镜的两个调焦螺旋，一个粗调确定大范围，一个微调确定具体楼层。 B：不管什么情况，最终粗调微调的次数总和不变。 我们用①号球确定范围，②号球确定楼层。 (一)假设第一次范围为k层且①号碎了，那么①号球1次，②号球k-1次，合计1+k-1=k次。(二)假设①号球第二次才碎，那么①号球2次，为保证总次数不变②号球要丢k-2次，相当于这个范围有k-1层，情况以此类推。最糟糕情况就是要把100层都覆盖，那么所有次的范围之和加上最后的微调次数要≥98(第一层没高度，无意义，第100层也不用丢，所以是100-2)k+(k-1)+(k-2)+(k-3)+……+3+2+1≥98等差数列求和得k*(k+1)/2≥98，解得k=14，也就是最多14次，也就是第一个范围内有14层。 注意:k在这里即是总次数，也是第一次的层数。①号球具体丢的层数就是15层，28层，40层…… 参考文章 https://www.zhihu.com/question/31855632","link":"/2021/11/15/algorithm/alogrithm-5/"},{"title":"最长递增子序列的个数","text":"最长递增子序列 的进阶版本 参考文章 https://leetcode-cn.com/problems/number-of-longest-increasing-subsequence/","link":"/2021/11/24/algorithm_dynamic/algorithm-lis-2/"},{"title":"【动态规划】最大子段和","text":"一般思维 1234567891011121314151617181920212223242526public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int N = 6; public static void main(String[] args) { int maxSum = 0; for (int i = 1; i &lt;= N; i++) { //i : 表示每个子段的个数 for (int j = 1; j + i - 1 &lt;= N; j++) { //j : 起始位置 end: 结束位置 int end = i + j - 1; if (end &lt;= N) { // 计算 从j 开始， 包含i个元素的 字段 的 和 int temp = 0; for (int k = j; k &lt;= end; k++) { temp += a[k]; } maxSum = Math.max(maxSum, temp); } } } System.out.println(maxSum); }} 充分利用已经得到的结果，避免重复计算，节省计算时间 123456789101112131415161718192021222324252627public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int[][] dp = new int[MAX][MAX]; //保存从 j 到 i+j-1 子段的和； j :开始位置， i: 子段的长度 static int N = 6; public static void main(String[] args) { int maxSum = 0; for (int i = 1; i &lt;= 6; i++) { dp[1][i] = a[i]; } for (int i = 2; i &lt;= N; i++) { for (int j = 1; j &lt;= N; j++) { int k = i + j - 1; if (k &lt;= N) { dp[i][j] = dp[i - 1][j] + a[k]; if (dp[i][j] &gt; maxSum) { maxSum = dp[i][j]; } } } } System.out.println(maxSum); }} 动态规划解决： Kadane算法 （ref: https://zhuanlan.zhihu.com/p/107503435） 扫描一次整个数列的所有数值，在每一个扫描点计算以该点数值为结束点的子数列的最大和（ 正数和 ）。 该子数列由两部分组成：以前一个位置为结束点的最大子数列、该位置的数值。 因为该算法用到了“最佳子结构”（以每个位置为终点的最大子数列都是基于其前一位置的最大子数列计算得出）， 该算法可看成动态规划的一个例子。 将长度为n的目标序列存储在一个数组中,设为a。设数组b为如下 当b[j-1] &gt; 0时 b[j] = b[j-1] + a[j],否则b[j] = a[j]。由此可得计算b[j]的动态规划递归方程 b[j] = max{b[j - 1] + a[j],a[j]}, 1 &lt;= j &lt;= n 123456789101112131415161718192021public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int N = 6; public static void main(String[] args) { int sum = 0; int this_sum = 0; for (int i = 1; i &lt;= N; i++) { if (this_sum &gt; 0) this_sum = this_sum + a[i]; else this_sum = a[i]; sum = Math.max(this_sum, sum); } System.out.println(sum); }} 参考文章 https://blog.csdn.net/weixin_40170902/article/details/80585218 https://blog.csdn.net/qq_38538733/article/details/76579602","link":"/2021/11/22/algorithm_dynamic/algorithm-dynamic-max-sub-sum/"},{"title":"求两个字符序列的最长公共字符子序列。","text":"字符序列的子序列是指从给定字符序列中随意地（不一定连续）去掉若干个字符（可能一个也不去掉）后所形成的字符序列。 令给定的字符序列X=“x0,x1,…,xm-1”,序列Y=“y0,y1,…,yk-1”是X的子序列，存在X的一个严格递增下标序列i=i0,i1,…,ik-1,使得对所有的j=0,1,…,k-1,有xi＝yj。 例如，X=“ABCBDAB”,Y=“BCDB”是X的一个子序列。 递归123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.example.demo;public class Test8 { static String[] a = {&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;}; static String[] b = {&quot;B&quot;, &quot;D&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A&quot;}; static int n = a.length; static int m = b.length; static String[] str = new String[n]; static int[][] dp = new int[n + 1][m + 1]; public static void main(String[] args) { int k = lcs_len(n, m); build_lcs(k, n, m); for (String s : str) { System.out.println(s); } } static int lcs_len(int i, int j) { int t1, t2; if (i == 0 || j == 0) { dp[i][j] = 0; } else if (a[i - 1].equals(b[j - 1])) { dp[i][j] = lcs_len(i - 1, j - 1) + 1; } else { t1 = lcs_len(i, j - 1); t2 = lcs_len(i - 1, j); dp[i][j] = Math.max(t1, t2); } return dp[i][j]; } static void build_lcs(int k, int i, int j) { if (i == 0 || j == 0) { return; } if (dp[i][j] == dp[i - 1][j]) { build_lcs(k, i - 1, j); } else if (dp[i][j] == dp[i][j - 1]) { build_lcs(k, i, j - 1); } else { str[k] = a[i - 1]; build_lcs(k - 1, i - 1, j - 1); } }} 非递归1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.demo;public class Test8 { static String[] a = {&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;}; static String[] b = {&quot;B&quot;, &quot;D&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A&quot;}; static int n = a.length; static int m = b.length; static String[] str = new String[n]; static int[][] dp = new int[n + 1][m + 1]; public static void main(String[] args) { int k = lcs_len(); build_lcs(k); for (String s : str) { System.out.println(s); } } static void build_lcs(int k) { int i = n; int j = m; while (k &gt; 0) { if (dp[i][j] == dp[i - 1][j]) { i = i - 1; } else if (dp[i][j] == dp[i][j - 1]) { j = j - 1; } else { k = k - 1; i = i - 1; j = j - 1; str[k] = a[i]; } } } static int lcs_len() { for (int i = 0; i &lt;= n; i++) dp[i][0] = 0; for (int j = 0; j &lt;= m; j++) dp[0][j] = 0; for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= m; j++) { if (a[i - 1].equals(b[j - 1])) { dp[i][j] = dp[i - 1][j - 1] + 1; } else { dp[i][j] = Math.max(dp[i][j - 1], dp[i - 1][j]); } } } return dp[a.length][b.length]; }} 参考文章","link":"/2021/11/25/algorithm_dynamic/algorithm-max-pub-sub-sequence/"},{"title":"深度优先搜索（DFS）","text":"深度优先搜索是一种枚举所有完整路径以遍历所有情况的搜索方法。 从根节点开始，尽可能深的搜索每一个分支，把一个分支的结果搜索完，再去看另一个分支。形象来说：“一条路走到底，不撞南墙不回头”。 二叉搜索树的范围和题目描述给定二叉搜索树的根结点 root，返回值位于范围 [low, high] 之间的所有结点的值的和。 注意哦，根节点的值大于左子树，并且根节点的值小于右子树 detail 示例1： 12输入：root = [10,5,15,3,7,null,18], low = 7, high = 15输出：32 示例2： 12输入：root = [10,5,15,3,7,13,18,1,null,6], low = 6, high = 10输出：23 123456789101112131415161718static int rangeSumBST(TreeNode root, int low, int high) { //方法1：DFS //找递归边界（死胡同） if (root == null) { return 0; } //岔道口 //如果根节点的值大于high，那么右子树的值一定不满足，此时只需要判断左子树即可 if (root.val &gt; high) { return rangeSumBST(root.left, low, high); } //如果根节点的值小于low，那么左子树的值一定不满足，此时只需要判断右子树即可 if (root.val &lt; low) { return rangeSumBST(root.right, low, high); } //否则根节点的值在low和high之间，则根节点、左子树、右子树这三者都要判断 return root.val + rangeSumBST(root.left, low, high) + rangeSumBST(root.right, low, high);} 递归 1234567891011121314151617static int rangeSumBST2(TreeNode root, int low, int high) { //方法1：DFS //找递归边界（死胡同） if (root == null) { return 0; } //左子树 int leftSum = rangeSumBST(root.left, low, high); //右子树 int rightSum = rangeSumBST(root.right, low, high); int result = leftSum + rightSum; //判断根节点是否满足 if(root.val &gt;= low &amp;&amp; root.val &lt;= high){ result += root.val; } return result;} 岛屿数量给你一个由 ‘1’（陆地）和 ‘0’（水）组成的的二维网格，请你计算网格中岛屿的数量。 岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。 此外，你可以假设该网格的四条边均被水包围。 示例1： 1234567输入：grid = [ [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;]]输出：1 示例2： 1234567输入：grid = [ [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;]]输出：3 为了求出岛屿的数量，我们可以扫描整个二维网格。如果一个位置为 1，则以其为起始节点开始进行深度优先搜索。在深度优先搜索的过程中，每个搜索到的 1 都会被重新标记为 0,也就是说将1周围出现（上下左右）的1全部同化成0 12345678910111213141516171819202122232425262728293031int numIslands(char** grid, int gridSize, int* gridColSize){ //考虑特殊情况 if(grid == NULL || gridSize == 0){ return 0; } int row = gridSize;//行数 int col = *gridColSize;//列数 int count = 0;//用于计数 for(int i = 0; i &lt; row; i++){ for(int j = 0; j &lt; col; j++){ if(grid[i][j] == '1'){ count++; } dfs(grid, i, j, row, col); } } return count;} void dfs(char** grid, int x, int y, int row, int col){ //找递归边界（死胡同） if(x &lt; 0 || x &gt;= row || y &lt; 0 || y &gt;= col || grid[x][y] == '0'){ return; } grid[x][y] = '0'; //岔道口 dfs(grid, x - 1, y, row, col); dfs(grid, x + 1, y, row, col); dfs(grid, x, y - 1, row, col); dfs(grid, x, y + 1, row, col);} 0-1 背包问题有n件物品，每件物品的重量为w[i], 价值为c[i]。现在需要选出若干件物品放入一个容量为v的背包中，使得在选入背包的物品重量和不超过容量v的前提下，让背包中物品的价格之和最大，求最大价值。 123输入：物品重量：3 5 1 2 2 物品价值：4 5 2 1 3 输出：10 code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main { static int maxValue = 0;//最大价值 //下面四组数据可以自己设定，由于想简化题目所以在这里直接以全局变量的形式给出 static int n = 5;//物品数目 static int v = 8;//背包容量 static int w[] = {3, 5, 1, 2, 2};//w[i]为每件物品重量 static int c[] = {4, 5, 2, 1, 3};//c[i]为每件物品价值 static int result[] = {0, 0, 0, 0, 0}; static void DFS(int index, int sumW, int sumC, int[] list) { //已经完成了对n件物品的选择（递归边界--死胡同） if (index == n) { return; } //岔道口 int[] list1 = list.clone(); list1[index] = 0; DFS(index + 1, sumW, sumC, list);//不选第index件物品 //只有加入第index件物品后未超出容量v,才能继续执行（注意这个限制条件） if (sumW + w[index] &lt;= v) { int[] list2 = list.clone(); list2[index] = 1; //注意哦，如果加入第index件物品后总价值大于最大价值maxValue时记得要更新最大价值 if (sumC + c[index] &gt; maxValue) { maxValue = sumC + c[index];//更新最大价值maxValue result = list2; } DFS(index + 1, sumW + w[index], sumC + c[index], list2);//选择第index件物品 } } public static void main(String[] args) { int[] list = {0, 0, 0, 0, 0}; DFS(0, 0, 0, list);//初始时为第0件物品、当前总重量和总价值均为0 System.out.println(&quot;满足条件的最大价值为：&quot; + maxValue); for (Integer integer : result) { System.out.print(integer); } System.out.println(); }} 参考文章 https://blog.csdn.net/weixin_57544072/article/details/121262172","link":"/2021/11/16/algorithm_tree/algorithm-dfs/"},{"title":"分割等和子集","text":"思路：本题可以看成是0-1背包问题，给一个可装载重量为 sum / 2 的背包和 N 个物品，每个物品的重量记录在 nums 数组中，问是否在一种装法，能够恰好将背包装满？dp[i][j]表示前i个物品是否能装满容积为j的背包，当dp[i][j]为true时表示恰好可以装满。每个数都有放入背包和不放入两种情况，分析方法和0-1背包问题一样。 复杂度：时间复杂度O(n*sum)，n是nums数组长度，sum是nums数组元素的和。空间复杂度O(n * sum)，状态压缩之后是O(sum) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class Solution { //可以看成是0-1背包问题，给一个可装载重量为 sum / 2 的背包和 N 个物品， //每个物品的重量记录在 nums 数组中，问是否在一种装法，能够恰好将背包装满？ public boolean canPartition(int[] nums) { int len = nums.length; int sum = 0; for (int num : nums) { sum += num; } if ((sum &amp; 1) == 1) {//如果是奇数，那么分割不了，直接返回false return false; } int target = sum / 2; //dp[i][j]表示前i个物品是否能装满容积为j的背包，当dp[i][j]为true时表示恰好可以装满 //最后求的是 dp[n][sum] 表示前n个物品能否把容量为sum的背包恰好装满 //dp数组长度是n+1，而且是二维数组，第一维表示物品的索引，第二个维度表示背包大小 boolean[][] dp = new boolean[len][target + 1]; //dp数组初始化，dp[..][0] = true表示背包容量为0，这时候就已经装满了， //dp[0][..] = false 表示没有物品，肯定装不满 for (int i = 0; i &lt; n; i++) { dp[i][0] = true; } //当 i==0 时，只有一个正整数 nums[0] 可以被选取，因此 dp[0][nums[0]]==true。 if (nums[0] &lt;= target) { dp[0][nums[0]] = true; } for (int i = 1; i &lt; len; i++) { for (int j = 0; j &lt;= target; j++) { if (nums[i] &lt;= j) { //dp[i - 1][j]表示不装入第i个物品 //dp[i - 1][j-num]表示装入第i个，此时需要向前看前i - 1是否能装满j-num //和背包的区别，这里只是返回true和false 表示能否装满，不用计算价值 dp[i][j] = dp[i - 1][j] || dp[i - 1][j - nums[i]]; } else { //背包容量不足 不能放入背包 //dp[i][j]取决于前i-1个物品是否能前好装满j的容量 dp[i][j] = dp[i - 1][j]; } } if (dp[i][target]) { return true; } } return dp[len - 1][target]; }}//状态压缩public class Solution { public boolean canPartition(int[] nums) { int len = nums.length; int sum = 0; for (int num : nums) { sum += num; } if ((sum &amp; 1) == 1) { return false; } int target = sum / 2; boolean[] dp = new boolean[target + 1]; dp[0] = true; if (nums[0] &lt;= target) { dp[nums[0]] = true; } for (int i = 1; i &lt; len; i++) { for (int j = target; nums[i] &lt;= j; j--) { if (dp[target]) { return true; } dp[j] = dp[j] || dp[j - nums[i]]; } } return dp[target]; }} 参考文章 分割等和子集 0-1背包问题&amp;416. 分割等和子集 https://www.bilibili.com/video/BV1fY411x7pg?p=16 https://www.bilibili.com/video/BV1fY411x7pg?p=17 https://xiaochen1024.com/courseware/60b4f11ab1aa91002eb53b18/61963bcdc1553b002e57bf13","link":"/2021/11/25/algorithm_dynamic/dynamic-sum-equal-sub-set/"},{"title":"根据层序遍历构造二叉树","text":"1层序遍历： [10,5,15,3,7,13,18,1,null,6] 123456789101112131415161718192021222324252627//层序遍历的数组构造 二叉树static TreeNode buildTree(Object[] result, int index) { if (result[index] == null) { return null; } // 根结点 root 初始化 TreeNode root = new TreeNode((Integer)result[index]); root.left = null; root.right = null; int left = 2 * index + 1; int right = 2 * index + 2; //构造左子树 if (left &gt; result.length - 1) { root.left = null; } else { root.left = buildTree(result, left); } //构造右子树 if (right &gt; result.length - 1) { root.right = null; } else { root.right = buildTree(result, right); } return root;} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.example.demo;import java.util.LinkedList;public class Main { static class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int val) { this.val = val; } TreeNode() { } } //层序遍历的数组构造 二叉树 static TreeNode buildTree(Object[] result, int index) { if (result[index] == null) { return null; } TreeNode root = new TreeNode((Integer)result[index]); root.left = null; root.right = null; int left = 2 * index + 1; int right = 2 * index + 2; if (left &gt; result.length - 1) { root.left = null; } else { root.left = buildTree(result, left); } if (right &gt; result.length - 1) { root.right = null; } else { root.right = buildTree(result, right); } return root; } //先序遍历 打印 static void preOrderTraverse(TreeNode root) { //已经完成了对n件物品的选择（递归边界--死胡同） if (root == null) { return; } System.out.print(root.val + &quot; &quot;); preOrderTraverse(root.left); preOrderTraverse(root.right); } //层序遍历 打印 static void levelOrderTraverse(TreeNode root) { LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if (root == null) { return; } queue.addLast(root); while (!queue.isEmpty()) { TreeNode temp = queue.getFirst(); System.out.print(temp.val + &quot; &quot;); queue.removeFirst(); if (temp.left != null) { queue.addLast(temp.left); } if (temp.right != null) { queue.addLast(temp.right); } } } public static void main(String[] args) { Object[] result1 = {10, 5, 15, 3, 7, 13, 18, 1, null, 6}; preOrderTraverse(buildTree(result1, 0)); System.out.println(); levelOrderTraverse(buildTree(result1, 0)); System.out.println(); }} 参考文章","link":"/2021/11/16/algorithm_tree/algorithm-construct-binary-tree/"},{"title":"centos install git","text":"参考文章 https://blog.csdn.net/lqlqlq007/article/details/78983879 prepare12sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidocsudo yum install gcc perl-ExtUtils-MakeMaker 卸载系统自带的底版本git 123 git --versionsudo yum remove git install1cd /usr/local/src/ 1wget https://www.kernel.org/pub/software/scm/git/git-2.23.0.tar.xz 12tar -vxf git-2.23.0.tar.xzcd git-2.23.0 1sudo make prefix=/usr/local/git all 1sudo make prefix=/usr/local/git install 1sudo echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/profile 1source /etc/profile 12 git --versiongit version 2.15.1 如果是非root用户使用git，则需要配置下该用户下的环境变量 123 echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; ~/.bashrc source ~/.bashrcgit --version 生成SSH密钥1ssh-keygen -t rsa -C “469608976@qq.com” 添加密钥到GitHub 打开 Github，登录自己的账号后点击自己的头像-&gt;settings-&gt;SSH And GPG Keys-&gt;New SSH key 将本地 id_rsa.pub 中的内容粘贴到 Key 文本框中，随意输入一个 title(不要有中文)，点击 Add Key 即可 centos里测试验证1ssh git@github.com","link":"/2021/09/27/centos/centos-git/"},{"title":"centos install jenkins","text":"prepare: install JDKinstall1wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo 1rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key 如果不能安装就到官网下载jenkis的rmp包，官网地址（http://pkg.jenkins-ci.org/redhat-stable/）一. 官方下载地址：https://jenkins.io/download/二. 镜像下载地址：http://mirrors.jenkins-ci.org/ 123 wget http://mirror.serverion.com/jenkins/redhat-stable/jenkins-2.235.1-1.1.noarch.rpmrpm -ivh jenkins-2.222.3-1.1.noarch.rpmyum install -y jenkins-2.222.3-1.1.noarch.rpm 1yum install -y jenkins 配置jenkis的端口 1vim /etc/sysconfig/jenkins 12找到修改端口号：JENKINS_PORT=&quot;8080&quot; 此端口不冲突可以不修改 modify mirror of update centerhttps://www.jianshu.com/p/fb1bff7a21a1 vim /var/lib/Jenkins/hudson.model.UpdateCenter.xml 12345678&lt;?xml version='1.1' encoding='UTF-8'?&gt;&lt;sites&gt; &lt;site&gt; &lt;id&gt;default&lt;/id&gt; &lt;url&gt;https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json&lt;/url&gt; &lt;/site&gt;&lt;/sites&gt; config jenkins jdkvim /etc/init.d/jenkins 1/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64/bin/java 启动jenkins 1systemctl start/stop/restart jenkins 开机启动 1systemctl enable jenkins.service su jenkins1su -s /bin/bash jenkins 配置Jenkins，run webserver全局工具配置 git： /usr/local/git/bin/git Jdk: /usr/local/java/jdk1.8.0_211 maven_home : /usr/local/maven user Jenkins git ssh使用 jenkins 自动生成的账号 1su -s /bin/bash jenkins 生成ssh 公钥，私钥 1ssh-keygen -t rsa -C &quot;469608976@qq.com&quot; install plugin maven integration plugin deploy to container plugin github create Jenkins project config git maven1clean package -Dmaven.test.skip=true shellsh /usr/scripts/webserver.sh1234echo &quot;this is webserver.sh&quot;echo &quot;this is webserver&quot;chmod u=rwx,og=rwx /var/lib/jenkins/workspace/webserver/target/webserver-0.0.1-SNAPSHOT.jarnohup java -jar /var/lib/jenkins/workspace/webserver/target/webserver-0.0.1-SNAPSHOT.jar &gt;/dev/null 2&gt;&amp;1 &amp; 参考文档 总结 jenkin + git + maven centos install jenkins","link":"/2021/09/27/centos/centos-jinkins/"},{"title":"判断单链表有环","text":"双指针 穷举遍历哈希表缓存快慢指针p1, p2指针从头开始扫描链表。指针p1每次走1步，指针p2每次走2步。如果存在环，则指针p1、p2会相遇；如果不存在环，指针fast遇到NULL退出。 步骤演示： ref: https://blog.csdn.net/mucaoyx/article/details/81395782 原理分析：Q1: 求入环点。Q2: 求环的长度。求环长：从首次相遇节点继续循环前进，直到两个指针第2次相遇。此时，统计出来的前进次数就是环长。 求入环点：首次相遇时，指针p1每次只走一步，走过的距离 D+S1指针p2每次走两步，比p1多走一圈，做过的距离 D + S1 + S2 + S1p2的速度是p1的两倍，p2走过的距离也是p1的两倍，===&gt; 2(D+S1) = D + 2S1 + S2===&gt; D = S2 只要把其中一个指针放回到头节点位置，另一个指针在首次相遇的节点，两个指针每次向前走一步，最终归相遇的节点，就是入环节点。 12345678public class Node { int data; Node next; public Node(int data) { this.data = data; }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class TestLinked { public boolean isCycle(Node head) { if (head.next == null) { return false; } return getSameNode(head) != null; } public Integer getLengthOfCycle(Node head) { if (!isCycle(head)) { return 0; } Node slowNode = getSameNode(head); Node first = slowNode.next; Node second = slowNode.next.next; int i = 1; while (first != second) { i++; first = first.next; second = second.next.next; } return i; } private Node getSameNode(Node node) { Node fastNode = node; Node slowNode = node; while (fastNode != null) { if (fastNode.next != null) { fastNode = fastNode.next.next; } else { fastNode = null; } slowNode = slowNode.next; if (slowNode == fastNode) { return slowNode; } } return null; } public Node getEntranceOfCycle(Node head) { Node fastNode = head; Node slowNode = head; while (fastNode != null) { if (fastNode.next != null) { fastNode = fastNode.next.next; } else { fastNode = null; } slowNode = slowNode.next; if (slowNode == fastNode) { fastNode = head; while (fastNode != slowNode) { fastNode = fastNode.next; slowNode = slowNode.next; } return slowNode; } } return null; } @Test public void testIsCycle() { System.out.println(isCycle(Util.createList())); } @Test public void testGetLengthOfCycle() { System.out.println(getLengthOfCycle(Util.createList())); } @Test public void testGetEntranceOfCycle() { System.out.println(getEntranceOfCycle(Util.createList()).data); }} 1234567891011121314151617181920public class Util { public static Node createList() { Node node1 = new Node(5); Node node2 = new Node(3); Node node3 = new Node(7); Node node4 = new Node(2); Node node5 = new Node(6); Node node6 = new Node(8); Node node7 = new Node(1); node1.next = node2; node2.next = node3; node3.next = node4; node4.next = node5; node5.next = node6; node6.next = node7; node7.next = node4; return node1; }} 参考文章","link":"/2021/11/24/algorithm_linkedlist/alogrithm-judge-linkedList-cycle/"},{"title":"centos install jdk","text":"安装之前先查看一下有无系统自带jdk12345rpm -qa |grep javarpm -qa |grep jdkrpm -qa |grep gcj 如果有就使用批量卸载命令1rpm -qa | grep java | xargs rpm -e --nodeps 直接yum安装1.8.0版本openjdk1yum install java-1.8.0-openjdk* -y 查看版本1java -version 配置JAVA_HOMEA 定位JDK安装路径1. 终端输入：1which java 输出为： 1/usr/bin/java 2. 终端输入：1ls -lr /usr/bin/java 输出为： 1/usr/bin/java -&gt; 3. 终端输入1ls -lrt /etc/alternatives/java 输出： 1/etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64/jre/bin/java 至此，我们确定java的安装目录为： /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64 B 配置JAVA_HOME1. 打开配置环境变量的文件1vim /etc/profile 2. 添加以下配置：1234export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 1:wq保存退出。 3. 让配置生效1source /etc/profile 4. 测试配置结果1echo $JAVA_HOME","link":"/2021/09/27/centos/centos-jdk/"},{"title":"centos install maven","text":"1、获取安装包并解压1234cd /usr/localwget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gztar -zxvf apache-maven-3.6.3-bin.tar.gz 2、配置环境变量，添加export1vim /etc/profile 12export MAVEN_HOME=/usr/local/mavenexport PATH=${MAVEN_HOME}/bin:${PATH} 1source /etc/profile 1mvn -v 12vim ~/.bash_profile JAVA_HOME 和 M2_HOME 都设置成自己文件的位置 1source ~/.bash_profile 3、添加阿里云镜像1vim $MAVEN_HOME/conf/settings.xm 添加以下镜像配置 123456789101112131415&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;central-repository&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;http://central.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;","link":"/2021/09/27/centos/centos-maven/"},{"title":"centos install mysql","text":"https://blog.csdn.net/qq_36582604/article/details/80526287","link":"/2021/09/27/centos/centos-mysql/"},{"title":"centos install nginx","text":"prepare1sudo yum install -y gcc gcc-c++ 1sudo yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel root 安装PCRE库123456cd /usr/local/wget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.33/pcre-8.33.tar.gztar -zxvf pcre-8.33.tar.gzcd pcre-8.33./configuremake &amp;&amp; make install root 安装SSL库123456cd /usr/local/wget http://www.openssl.org/source/openssl-1.0.1j.tar.gztar -zxvf openssl-1.0.1j.tar.gzcd openssl-1.0.1j./configmake &amp;&amp; make install root 安装zlib库存123456 cd /usr/local/wget http://www.zlib.net/zlib-1.2.11.tar.gztar -zxvf zlib-1.2.11.tar.gz cd zlib-1.2.11./configuremake &amp;&amp; make install set up nginx123456cd /home/kubemkdir downloadscd downloadswget https://nginx.org/download/nginx-1.16.1.tar.gztar xvf nginx-1.16.1.tar.gz cd /home/kube/downloads/nginx-1.16.1 1./configure --prefix=/home/kube/apps/nginx --user=kube --group=kube --error-log-path=/home/kube/logs/nginx/error.log --http-log-path=/home/kube/logs/nginx/access.log --with-http_ssl_module --with-openssl=/usr/local/openssl-1.0.1j --with-pcre=/usr/local/pcre-8.33 --with-zlib=/usr/local/zlib-1.2.11 --with-http_stub_status_module 12makemake install 1/home/kube/apps/nginx/sbin/nginx -V login root1234567cd ~cd /home/kube/apps/nginx/sbinsudo chown root nginxsudo chmod +s nginxcd ~ kubesudo rm -rf nginx-1.16.1sudo rm nginx-1.16.1.tar.gz 或者normal account can start nginx at 80 port. 1sudo /usr/sbin/setcap 'cap_net_bind_service=+ep' /home1/irteam/apps/nginx/sbin/nginx nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465user root;worker_processes 2;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events { worker_connections 1024;}http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' # '$status $body_bytes_sent &quot;$http_referer&quot; ' # '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip off; # gzip_min_length 1k # gzip_comp_level 4 # gzip_types text/plain text/css application/json application/javascript server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://localhost:3000; } error_page 404 /404.html; location = /404.html { root html; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} commands for the Nginx process123./nginx # Start./nginx -s reload ## Reload configure./nginx -s stop ## End","link":"/2021/09/27/centos/centos-nginx/"},{"title":"在 Linux 系统上安装 Compose","text":"Docker Compose 依赖 Docker Engine 进行任何有意义的工作，因此请确保根据您的设置，在本地或远程安装了 Docker Engine。 Install using pip For alpine, the following dependency packages are needed: py-pip, python3-dev, libffi-dev, openssl-dev, gcc, libc-dev, rust, cargo, and make. Compose can be installed from pypi using pip. If you install using pip, we recommend that you use a virtualenv because many operating systems have python system packages that conflict with docker-compose dependencies. See the virtualenv tutorial to get started. 1pip3 install docker-compose 运行此命令以下载 Docker Compose 的当前稳定版本：1sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 对二进制文件应用可执行权限：1sudo chmod +x /usr/local/bin/docker-compose 注意：如果docker-compose安装后命令失败，请检查您的路径。您还可以/usr/bin在路径中创建指向或任何其他目录的符号链接。 例如： 1sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 测试安装1docker-compose --version shell12345678910## 运行此命令以下载 Docker Compose 的当前稳定版本：sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose## 对二进制文件应用可执行权限：sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose## 测试安装docker-compose --version 参考文章 https://docs.docker.com/compose/install/","link":"/2021/12/24/docker/docker-compose/"},{"title":"在 CentOS 上安装 Docker 引擎","text":"1234567891011121314151617181920212223242526272829# Uninstall old versionssudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # Install Docker Enginesudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y# Start Docker.sudo systemctl start docker## 设置docker开机启动systemctl enable docker# Verify that Docker Engine is installed correctly by running the hello-world image.sudo docker run hello-world 改用国内的镜像123456vim /etc/docker/daemon.json {&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn/&quot;,&quot;https://hub-mirror.c.163.com&quot;,&quot;https://registry.docker-cn.com&quot;],&quot;insecure-registries&quot;: [&quot;10.0.0.12:5000&quot;]}#systemctl restart docker Docker DockerfileDockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 使用 Dockerfile 定制镜像12FROM nginxRUN echo '这是一个本地构建的nginx镜像' &gt; /usr/share/nginx/html/index.html FROM 和 RUN 指令的作用FROM：定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 RUN：用于执行后面跟着的命令行命令。有以下俩种格式：ref: https://yeasy.gitbook.io/docker_practice/appendix/best_practices#run shell 格式： 12RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。 exec 格式： 123RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]# 例如：# RUN [&quot;./test.php&quot;, &quot;dev&quot;, &quot;offline&quot;] 等价于 RUN ./test.php dev offline 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 123456789101112FROM centosRUN yum -y install wgetRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot;RUN tar -xvf redis.tar.gz# 以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum -y install wget \\&amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\&amp;&amp; tar -xvf redis.tar.gz# 如上，以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。 注：最后的 . 代表本次执行的上下文路径，下一节会介绍。 1$ docker build -t nginx:v3 . 上下文路径上一节中，有提到指令最后一个 . 是上下文路径，那么什么是上下文路径呢？ 1$ docker build -t nginx:v3 . 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。 注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 指令详解COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 格式： 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] [–chown=:]：可选参数，用户改变复制到容器内文件的拥有者和属组。&lt;源路径&gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如： 12COPY hom* /mydir/COPY hom?.txt /mydir/ &lt;目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点： 在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点： 在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。 格式： 123CMD &lt;shell 命令&gt;CMD [&quot;&lt;可执行文件或命令&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...]CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。 ENTRYPOINT https://yeasy.gitbook.io/docker_practice/appendix/best_practices#entrypoint ENTRYPOINT 的最佳用处是设置镜像的主命令，允许将镜像当成命令本身来运行（用 CMD 提供默认选项）。 类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 CMD 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 格式： 12ENTRYPOINT [&quot;&lt;executeable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT [&quot;nginx&quot;, &quot;-c&quot;] # 定参CMD [&quot;/etc/nginx/nginx.conf&quot;] # 变参 1、不传参运行 12$ docker run nginx:test 容器内会默认运行以下命令，启动主进程。 12nginx -c /etc/nginx/nginx.conf 2、传参运行 1$ docker run nginx:test -c /etc/nginx/new.conf 容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件) 1nginx -c /etc/nginx/new.conf ENTRYPOINT 入口点 ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 –entrypoint 来指定。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 ““ 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： 123$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ 123$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://myip.ipip.net 后面。而 -i 根本不是命令，所以自然找不到。那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： 12$ docker run myip curl -s http://myip.ipip.net -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 这次我们再来尝试直接使用 docker run myip -i： 123456789101112131415161718$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通$ docker run myip -iHTTP/1.1 200 OKServer: nginx/1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text/html; charset=UTF-8Vary: Accept-EncodingX-Powered-By: PHP/5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 格式： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 以下示例设置 NODE_VERSION = 7.2.0 ， 在后续的指令中可以通过 $NODE_VERSION 引用： 1234ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\&amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; ARG构建参数，与 ENV 作用一致。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。格式：12VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]VOLUME &lt;路径&gt; 在启动容器 docker run 的时候，我们可以通过 -v 参数修改挂载点。 EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。格式：12EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 格式： 1WORKDIR &lt;工作目录路径&gt; USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 格式： 12USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 格式： 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这时执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 格式： ONBUILD &lt;其它指令&gt; LABELLABEL 指令用来给镜像添加一些元数据（metadata），以键值对的形式，语法格式如下： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...比如我们可以添加镜像的作者： LABEL org.opencontainers.image.authors=&quot;runoob&quot; 参考文章 https://docs.docker.com/engine/install/centos/#install-using-the-repository Orientation and setup &amp;&amp; guide Docker Dockerfile dockerfile 指令 Dockerfile 指令详解","link":"/2021/12/10/docker/docker-install/"},{"title":"fiddler简单使用","text":"Fiddler 是位于客户端和服务器端的 HTTP 代理，也是目前最常用的 HTTP 抓包工具之一。（Mac OS 建议采用 Charles） Fiddler 的基本原理 过滤拦截 的 url 修改request1.Fiddler想要抓到数据包，要确保Capture Traffic是开启，在File –&gt; Capture Traffic。开启后再左下角会有显示，当然也可以直接点击左下角的图标来关闭/开启抓包功能。 2. Rules -&gt; Automatic Breakpoints -&gt; Before Requests 3. 修改 request 参考文章 https://zhuanlan.zhihu.com/p/47003094 https://www.cnblogs.com/kristin/p/8445055.html https://www.cnblogs.com/yyhh/p/5140852.html","link":"/2021/10/29/fiddler/fiddler/"},{"title":"docker network","text":"网络模式 配置 说明 bridge模式 –net=bridge （默认为该模式）此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及Iptables nat表配置与宿主机通信。 host模式 –net=host 容器和宿主机共享Network namespace。 container模式 –net=container:NAME_or_ID 容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。 none模式 –net=none 该模式关闭了容器的网络功能。 Bridge模式Bridge模式的拓扑当Docker server启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配IP了，Docker会从RFC1918所定义的私有IP网段中，选择一个和宿主机不同的IP地址和子网分配给docker0，连接到docker0的容器就从这个子网中选择一个未占用的IP使用。如一般Docker会使用172.17.0.0/16这个网段，并将172.17.0.1/16分配给docker0网桥（在主机上使用ifconfig命令是可以看到docker0的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）。单机环境下的网络拓扑如下，主机地址为10.10.0.186/24。 Docker：网络模式详解Docker完成以上网络配置的过程大致是这样的： （1）在主机上创建一对虚拟网卡veth pair设备。veth设备总是成对出现的，它们组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来。因此，veth设备常用来连接两个网络设备。 （2）Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0。另一端放在主机中，以veth65f9这样类似的名字命名，并将这个网络设备加入到docker0网桥中，可以通过brctl show命令查看。 123brctl showbridge name bridge id STP enabled interfacesdocker0 8000.02425f21c208 no （3）从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 运行容器[root@server1 ~]# docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx 9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a# 查看容器[root@server1 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9582dbec7981 nginx &quot;nginx -g 'daemon ...&quot; 3 seconds ago Up 2 seconds 0.0.0.0:80-&gt;80/tcp nginx_bridge# 查看容器网络;[root@server1 ~]# docker inspect 9582dbec7981&quot;Networks&quot;: { &quot;bridge&quot;: { &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;, &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot; }}# 查看网桥信息，会看到有有一个容器[root@server1 ~]# docker network inspect bridge[ { &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;, &quot;Created&quot;: &quot;2019-06-09T23:20:28.061678042-04:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: { &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ { &quot;Subnet&quot;: &quot;172.17.0.0/16&quot; } ] }, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;Containers&quot;: { &quot;9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a&quot;: { &quot;Name&quot;: &quot;nginx_bridge&quot;, &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; } }, &quot;Options&quot;: { &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; }, &quot;Labels&quot;: {} }] bridge模式下容器的通信在bridge模式下，连在同一网桥上的容器可以相互通信（若出于安全考虑，也可以禁止它们之间通信，方法是在DOCKER_OPTS变量中设置–icc=false，这样只有使用–link才能使两个容器通信）。 Docker可以开启容器间通信（意味着默认配置–icc=false），也就是说，宿主机上的所有容器可以不受任何限制地相互通信，这可能导致拒绝服务攻击。进一步地，Docker可以通过–ip_forward和–iptables两个选项控制容器间、容器和外部世界的通信。 容器也可以与外部通信，我们看一下主机上的Iptable规则，可以看到这么一条 12-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 这条规则会将源地址为172.17.0.0/16的包（也就是从Docker容器产生的包），并且不是从docker0网卡发出的，进行源地址转换，转换成主机网卡的地址。这么说可能不太好理解，举一个例子说明一下。假设主机有一块网卡为eth0，IP地址为10.10.101.105/24，网关为10.10.101.254。从主机上一个IP为172.17.0.1/16的容器中ping百度（180.76.3.151）。IP包首先从容器发往自己的默认网关docker0，包到达docker0后，也就到达了主机上。然后会查询主机的路由表，发现包应该从主机的eth0发往主机的网关10.10.105.254/24。接着包会转发给eth0，并从eth0发出去（主机的ip_forward转发应该已经打开）。这时候，上面的Iptable规则就会起作用，对包做SNAT转换，将源地址换为eth0的地址。这样，在外界看来，这个包就是从10.10.101.105上发出来的，Docker容器对外是不可见的。 那么，外面的机器是如何访问Docker容器的服务呢？我们首先用下面命令创建一个含有web应用的容器，将容器的80端口映射到主机的80端口。 12docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx 然后查看Iptable规则的变化，发现多了这样一条规则： 12-A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 此条规则就是对主机eth0收到的目的端口为80的tcp流量进行DNAT转换，将流量发往172.17.0.2:80，也就是我们上面创建的Docker容器。所以，外界只需访问10.10.101.105:80就可以访问到容器中的服务。 除此之外，我们还可以自定义Docker使用的IP地址、DNS等信息，甚至使用自己定义的网桥，但是其工作方式还是一样的。 参考文章 docker四种网络模式 Docker网络详解——原理篇","link":"/2021/12/30/docker/docker-network/"},{"title":"docker_cmd","text":"docker 基本命令1234567891011121314# -a :提交的镜像作者；# -c :使用Dockerfile指令来创建镜像；# -m :提交时的说明文字；# -p :在commit时，将容器暂停。docker commit -a &quot;author&quot; -m &quot;commit msg&quot; {commitId} {name}:{tag}#docker commit -a &quot;author&quot; -m &quot;commit msg&quot; {commitId} author/myubuntu:v1docker logindocker push author/myubuntu:v1docker tag {imageId} {name}:{tag}docker run --name nginx-text -p 9090:90 -d nginx create network1docker network create --subnet 172.72.72.0/24 redisnet 设置docker开机启动1systemctl enable docker 容器使用启动容器以下命令使用 ubuntu 镜像启动一个容器，参数为以命令行模式进入该容器： 1$ docker run -it ubuntu /bin/bash 参数说明： -i: 交互式操作。 -t: 终端。 ubuntu: ubuntu 镜像。 /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。要退出终端，直接输入 exit:1root@ed09e4490c57:/# exit 启动已停止运行的容器查看所有的容器命令如下： 12$ docker ps -a 使用 docker start 启动一个已停止的容器： 1$ docker start b750bbbcfd88 后台运行在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 -d 指定容器的运行模式。 1$ docker run -itd --name ubuntu-test ubuntu /bin/bash 注：加了 -d 参数默认不会进入容器，想要进入容器需要使用指令 docker exec（下面会介绍到）。 停止一个容器停止容器的命令如下： 1$ docker stop &lt;容器 ID&gt; 停止的容器可以通过 docker restart 重启：$ docker restart &lt;容器 ID&gt; 进入容器 exec 命令1docker exec -it 243c32535da7 /bin/bash # container id or name ###导出和导入容器 导出容器 如果要导出本地某个容器，可以使用 docker export 命令。 1$ docker export 1e560fca3906 &gt; ubuntu.tar 导入容器快照 可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test/ubuntu:v1: 1$ cat docker/ubuntu.tar | docker import - test/ubuntu:v1 此外，也可以通过指定 URL 或者某个目录来导入，例如： 1$ docker import http://example.com/exampleimage.tgz example/imagerepo 删除容器删除容器使用 docker rm 命令： 1$ docker rm -f 1e560fca3906 常见问题ps命令在docker容器不存在1apt-get update &amp;&amp; apt-get install procps -y 容器 下查看redis的安装目录的方法是什么1ps -ef|grep redis 得到了进程号 xxxx，然后 ls -l /proc/xxxx/cwd Redis集群Hash槽分配异常 CLUSTERDOWN Hash slot not served的解决方式12redis-cli --cluster check 192.168.171.134:6379redis-cli --cluster fix 192.168.171.134:6379 1redis-cli -c -h 192.168.171.134 ref Docker 容器使用","link":"/2021/09/27/docker/docker-cmd/"},{"title":"centos install kubernetes (standalone)","text":"单机版kubernetes 1. 安装 etcd , kubernetes.1sudo yum install -y etcd kubernetes 2. 修改配置文件1sudo vim /etc/sysconfig/docker OPTIONS 内容设置为 : 1OPTIONS='--selinux-enabled=false --insecure-registry gcr.io' 1sudo vim /etc/kubernetes/apiserver 1把 --admission_control参数中的 ServiceAccount删除。 或者 ref: https://blog.csdn.net/a506681571/article/details/86087456Generate a signing key: 1openssl genrsa -out /tmp/serviceaccount.key 2048 Update /etc/kubernetes/apiserver: 1KUBE_API_ARGS=&quot;--service_account_key_file=/tmp/serviceaccount.key&quot; Update /etc/kubernetes/controller-manager: 1KUBE_CONTROLLER_MANAGER_ARGS=&quot;--service_account_private_key_file=/tmp/serviceaccount.key&quot; 3，按顺序启动所有服务：1234567sudo systemctl start etcdsudo systemctl start dockersudo systemctl start kube-apiserversudo systemctl start kube-controller-managersudo systemctl start kube-schedulersudo systemctl start kubeletsudo systemctl start kube-proxy 参考文章","link":"/2021/12/23/kubenetes/kubenetes-centos-standalone-k8s/"},{"title":"burp suit 简单使用","text":"拦截，修改request启动burpsuite–切换到“Proxy”选项卡–选择“Options”菜单–往下看到“Intercept Client Requests”节区在该节区中我们可以看到这个位置可以配置拦截条件，我们以只拦截“www.baidu.com”为例 点击“Add”–布尔运算选择“And”–匹配类型选择“Domain name”–匹配关系选择“Matches”–匹配条件输入“www.baidu.com”--点击“OK” 切换回“Intercept”，此时“Intercept is on”但只会拦截百度的数据包，其他网站的数据包都直接放行了其实在“Intercept Client Requests”节区还可以配置各式各样的过滤条件自己随意发挥。 修改参数后继续请求API 设置 proxy -&gt; HTTP history response:如果要配置Respone的过滤，要到再下边一点的“Intercept Server Respones”节区进行配置。 参考文章 https://blog.csdn.net/weixin_34267123/article/details/86130311","link":"/2021/10/29/fiddler/burp-suit/"},{"title":"install flink &amp; IDEA Hello world","text":"1. install flink** 下载和解压 ** 从下载页下载一个二进制的包，你可以选择任何你喜欢的Hadoop/Scala组合包。如果你计划使用文件系统，那么可以使用任何Hadoop版本。进入下载目录解压下载的压缩包 123$ cd ~/Downloads # Go to download directory$ tar xzf flink-*.tgz # Unpack the downloaded archive$ cd flink-1.2.0 2. start flink cluster1$ ./bin/start-local.sh # Start Flink 通过访问http://localhost:8081检查JobManager网页,确保所有组件都已运行。网页会显示一个有效的TaskManager实例。 3. run SocketWindowWordCount现在, 我们可以运行Flink 应用程序。 这个例子将会从一个socket中读一段文本，并且每隔5秒打印每个单词出现的数量。 例如 a tumbling window of processing time, as long as words are floating in. 1$ nc -l 9000 1$ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000 单词的数量在5秒的时间窗口中进行累加（使用处理时间和tumbling窗口），并打印在stdout。监控JobManager的输出文件，并在nc写一些文本(回车一行就发送一行输入给Flink) : 1234$ nc -l 9000lorem ipsumipsum ipsum ipsumbye 译者注：mac下使用命令nc -l -p 9000来启动监听端口，如果有问题可以telnet localhost 9000看下监听端口是否已经启动，如果启动有问题可以重装netcat ，使用命令brew install netcat。 .out文件将被打印每个时间窗口单词的总数： 1234$ tail -f log/flink-*-jobmanager-*.outlorem : 1bye : 1ipsum : 4 使用以下命令来停止Flink: 1$ ./bin/stop-local.sh 4. idea -&gt; flink maven projectref: https://www.jianshu.com/p/fdc4212422f7 选择Maven 然后选中create from archetype 在列表中找flink-quickstart 找不到的话，点击右边的add archetype 在弹出框中输入： groupId：org.apache.flinkartifactId：flink-quickstart-javaversion：1.11.1repository：https://mirrors.huaweicloud.com/repository/maven/ 从flink.apache.org下载flink-1.11.1-src.tgz，(下载地址：https://www.apache.org/dyn/closer.lua/flink/flink-1.11.1/flink-1.11.1-src.tgz) 也可以从https://github.com/中搜flink，然后点击apache/flink下载源码 将flink-1.11.1-src.tgz解压缩后， 找到子目录\\flink-1.11.1-src\\flink-1.11.1\\flink-examples\\flink-examples-batch\\src\\main\\java\\org\\apache\\flink\\examples\\java\\wordcountcopy文件 将其下的WordCount.java文件及util文件夹复制到FlinkTest工程的以下子目录下 Flink-QuickStart-Java\\src\\main\\java\\org\\example 然后到IDEA,会多出两个文件 修改WordCount.java 把WordCount.java中的 1.将package org.apache.flink.examples.java.wordcount改为 package org.example; 2.将import org.apache.flink.examples.java.wordcount.util.WordCountData; 改为 import org.example.util.WordCountData; 修改util/WordCountData.java 把package org.apache.flink.examples.java.wordcount.util改为 package org.example.util; b)重新编译和打包 运行之：在 {FLINK_HOME}/examples 创建 words.txt. 1./bin/flink run -m localhost:8081 -c org.summer.WordCount examples/myflink-1.0-SNAPSHOT.jar --input examples/words.txt --output examples/result001.txt 5. run flink in Idea下载flink-1.13.0 安装包，这里面有flink网页服务用到的一个jar，地址是：https://flink.apache.org/downloads.html 下载后解压，在lib目录下有个flink-dist_2.11-1.13.0.jar文件，记住此文件的位置，稍后会用到；回到IDEA，在项目上点击右键，点击菜单Open Module Settings：设置工作已经完成，由于StreamingJob的工作是读取本机9000端口的数据，所以我们要把9000端口的服务启动起来，不然StreamingJob运行时是连不上端口的，打开一个控制台，执行命令：nc -l 9000现在可以将StreamingJob运行起来，如下图，右键点击StreamingJob，选择Run ‘StreamingJob.main()’：即可启动flink任务，如果想打断点调试，请选择Debug ‘StreamingJob.main()’ 参考文章 《Flink官方文档》Quick Start flink入门：01 构建简单运行程序 IDEA上运行Flink任务 Flink：你绕不过去的 Hello World https://www.jianshu.com/p/4a1442da2c4e","link":"/2021/10/25/flink/flink-helloworld/"},{"title":"kubernetes install","text":"参考文章 使用Kubeadm工具快速安装K8S集群 使用kubeadm在Centos8上部署kubernetes1.18 https://www.kubernetes.org.cn/5904.html Ubuntu 18.04 离线安装Kubernetes v1.11.1 centos7使用kubeadm安装kubernetes 1.11版本多主高可用 kubernetes1.11.0安装","link":"/2021/12/10/kubenetes/kubenetes-install/"},{"title":"kubernetes 基础知识","text":"什么是 Kubernetes？Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化工作负载和服务，有助于声明式配置和自动化。它拥有庞大且快速发展的生态系统。Kubernetes 服务、支持和工具随处可见。 传统部署时代早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况， 结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。 虚拟化部署时代作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。 虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。 每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。 容器部署时代容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。 容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处： 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。 可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 Kubernetes 为您提供： 服务发现和负载平衡 Kubernetes 可以使用 DNS 名称或使用自己的 IP 地址公开容器。如果容器的流量很高，Kubernetes 能够负载均衡和分配网络流量，从而使部署稳定。 存储编排 Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。 自动推出和回滚 您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 为您的部署创建新容器、删除现有容器并将其所有资源用于新容器。 自动装箱 您为 Kubernetes 提供了一组节点，可用于运行容器化任务。您告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。Kubernetes 可以将容器安装到您的节点上，以充分利用您的资源。 自我修复 Kubernetes 会重启失败的容器、替换容器、杀死不响应用户定义的健康检查的容器，并且在它们准备好提供服务之前不会向客户端通告它们。 秘密和配置管理 Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 SSH 密钥。您可以部署和更新机密和应用程序配置，而无需重建容器映像，也无需在堆栈配置中公开机密。 参考文章 什么是 Kubernetes？ Kubernetes 组件 Kubernetes是什么 Kubernetes 基础知识入门","link":"/2021/12/29/kubenetes/kubernetes-base/"},{"title":"Kubernetes 组件","text":"控制平面组件（Control Plane Components） – master控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于多 VM 控制平面设置的示例。 kube-apiserverAPI 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 etcdetcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 kube-scheduler控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 kube-controller-manager运行控制器进程的控制平面组件。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应 任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod) 服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌cloud-controller-manager云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 Node 组件节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 kube-proxykube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 容器运行时（Container Runtime）容器运行环境是负责运行容器的软件。 Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 podPod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。Pod 的共享上下文包括一组 Linux 名字空间、控制组（cgroup）和可能一些其他的隔离 方面，即用来隔离 Docker 容器的技术。 在 Pod 的上下文中，每个独立的应用可能会进一步实施隔离。 就 Docker 概念的术语而言，Pod 类似于共享名字空间和文件系统卷的一组 Docker 容器。 每个 Pod 都有一个特殊的被称为“根容器＂的 Pause 容器 。Pause 器对应的镜像属于 Kubernetes 平台的一部分，除了 Pause 容器，每个 Pod 都还包含一个或多个紧密相关的用户业务容器。 Kubernete 为每个 Pod 分配了唯一 IP 地址，称之为 Pod IP, 一个 Pod 里的 多个容器共享 Pod IP 地址 Kubernetes 要求底层网络支待集群内任意两个 Pod 之间的 TCP/IP直接通信，这通常采用虚拟二层网络技术实现，例如 Flannel Open vSwitch 等，因此我们需要牢记一点 Kubernetes 里， 一个 Pod 里的容器与另外主机上的 Po 容器能够直接通信。 Pod 其实有两种类型：普通的 Pod 及静态 Pod (Static Pod)。后者比较特殊，它并没被 存放在 Kubernetes etcd 中，而是被存放在某个具体的 Node 上的 一个具体文件中，并且只能在此 Node 启动、运行。而普通的 Pod 旦被创建，就会被放入 etcd 中存储。 Pod Volume, Pod Volume 是被定义在 Pod 上，然后被各个容器挂载到自己的文件系统中 的。 Volume 单来说就是被挂载到 Pod 里的文件目录。 pod 与 deploymentendpointPod IP 加上这里的容器端口 (containerPort ） 状态的应用集群 StatefulSets StatefulSet 基础StatefulSet 之前曾用过 PetSet 这个名称，很多人都知道，在IT 世界里，有状态的应用被类比 宠物 Pet ，无状态的应用则被类比为牛羊，每个宠物在主人那里都是“唯一的存在＂，宠物生病了，我们是要 很多钱去治疗 ，需要我们用照料，而无差别 牛羊则没有这个待遇 总结下来，在有状态集群中一般有如下特殊共性 每个节点都有固定的身份 ID, 通过这个 ID 集群中的成员可以相互发现并通信 集群的规模是比较固定的，集群规模不能随意变动 集群中 每个节点都是有状态的，通常会待久 数据到永久存储中，每个节点在 重启后都需要使用原有的持久化数据 集群中成员节点的启动顺序（以及关闭顺序 ）通常也是确定的 如果磁盘损坏，则集群里的某个节点无法正常运行，集群功能受损 StatefulSet 是用来管理有状态应用的工作负载 API 对象。 StatefulSet 用来管理某 Pod 集合的部署和扩缩， 并为这些 Pod 提供持久存储和持久标识符。 和 Deployment 类似， StatefulSet 管理基于相同容器规约的一组 Pod。但和 Deployment 不同的是， StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。 StatefulSet 里的每个 Pod 都有稳定 唯一的网络标识，可以用来发现集群内的其他成员假设 StatefulSet 的名称为 kafka, 那么第1个 Pod 叫 kafka-0, 第2个叫 kafka-1,以此类推 StatefulSet 控制的 Pod 副本的启停顺序是受控的，操作第n个Pod 时，前 n-1 Pod 经是运行且准备好的状态 StatefulSet Pod 采用稳定的持久化存储卷，通过 PV PVC 来实现，删除 Pod 默认不会删除与 StatefulSet 相关的存储卷 （为了保证数据安全） 批处理应用 Jobhttps://kubernetes.io/zh/docs/concepts/workloads/controllers/job/ ConfigMap 配置中心https://kubernetes.io/zh/docs/concepts/configuration/configmap/ 存储卷卷示例：使用 Persistent Volumes 部署 WordPress 和 MySQL 参考文章 什么是 Kubernetes？ Kubernetes 组件 Kubernetes是什么 Kubernetes 基础知识入门","link":"/2021/12/29/kubenetes/kubernetes-components/"},{"title":"kubernetes demo","text":"准备工作Docker拉取mysql镜像和tomcat镜像 1sudo docker pull mysql:5.7 1sudo docker pull kubeguide/tomcat-app:v1 为了解决， kubernetes pod卡在ContainerCreating的问题 12sudo docker pull registry.cn-hangzhou.aliyuncs.com/sunyuki/pod-infrastructuresudo docker tag f66f4bd9b894 registry.access.redhat.com/rhel7/pod-infrastructure:latest 创建 rc, svc yaml1vim mysql-rc.yaml 123456789101112131415161718192021apiVersion: v1kind: ReplicationControllermetadata: name: mysqlspec: replicas: 1 selector: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: &quot;123456&quot; 1vim mysql-svc.yaml 123456789apiVersion: v1kind: Servicemetadata: name: mysqlspec: ports: - port: 3306 selector: app: mysql 1vim myweb-rc.yaml 1234567891011121314151617181920212223apiVersion: v1kind: ReplicationControllermetadata: name: mywebspec: replicas: 1 selector: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: kubeguide/tomcat-app:v1 ports: - containerPort: 8080 env: - name: MYSQL_SERVICE_HOST value: &quot;mysql&quot; - name: MYSQL_SERVICE_PORT value: &quot;3306&quot; 1vim myweb-svc.yaml 1234567891011apiVersion: v1kind: Servicemetadata: name: mywebspec: type: NodePort ports: - port: 8080 nodePort: 30001 selector: app: myweb 1234sudo kubectl create -f mysql-rc.yamlsudo kubectl create -f mysql-svc.yamlsudo kubectl create -f myweb-rc.yamlsudo kubectl create -f myweb-svc.yaml 1234sudo kubectl delete -f mysql-rc.yamlsudo kubectl delete -f mysql-svc.yamlsudo kubectl delete -f myweb-rc.yamlsudo kubectl delete -f myweb-svc.yaml 1234sudo kubectl get rcsudo kubectl get svcsudo kubectl get podssudo kubectl get ep 1234567 kubectl get ep[root@localhost ~]# kubectl exec -ti myweb-qrjsd -- /bin/bashroot@myweb-qrjsd:/usr/local/tomcat# echo $MYSQL_SERVICE_HOSTmysqlroot@myweb-qrjsd:/usr/local/tomcat# echo &quot;172.17.0.2 mysql&quot; &gt;&gt; /etc/hostsroot@myweb-qrjsd:/usr/local/tomcat# 使用127.0.0.1:30001/demo打开页面 参考文章","link":"/2021/12/23/kubenetes/kubernetes-hello-world/"},{"title":"Kubernetes网络原理及方案","text":"前置知识Docker的网络模型 名词解释1、网络的命名空间：Linux在网络栈中引入网络命名空间，将独立的网络协议栈隔离到不同的命令空间中，彼此间无法通信；docker利用这一特性，实现不容器间的网络隔离。 2、Veth设备对：也叫虚拟网络接口对。Veth设备对的引入是为了实现在不同网络命名空间的通信。 3、Iptables/Netfilter：Netfilter负责在内核中执行各种挂接的规则(过滤、修改、丢弃等)，运行在内核 模式中；Iptables模式是在用户模式下运行的进程，负责协助维护内核中Netfilter的各种规则表；通过二者的配合来实现整个Linux网络协议栈中灵活的数据包处理机制。 4、网桥：网桥是一个二层网络设备,通过网桥可以将linux支持的不同的端口连接起来,并实现类似交换机那样的多对多的通信。 5、路由：Linux系统包含一个完整的路由功能，当IP层在处理数据发送或转发的时候，会使用路由表来决定发往哪里。 kubernetes网络模型Kubernetes 网络设计的一个基本原则是：每个Pod 都有一个全局唯一的IP, 而且假定所有的Pod 都在一个可以直接连通的，扁平的网络空间中，Pod 之间可以跨主机通信，按照这种网络原则抽象出来的一个Pod 对应一个IP的设计模型也被称作IP-per-Pod 模型。 相比于Docker 原生的NAT方式来说，这样使得容器在网络层面更像虚拟机或者物理机，复杂度整体降低，更加容易实现服务发现，迁移，负载均衡等功能。 容器间的通信同一个Pod的容器共享同一个网络命名空间，它们之间的访问可以用localhost地址 + 容器端口就可以访问。 这种情况下，同一个pod内共享网络命名空间，容器之间通过访问127.0.0.1:（端口）即可。图中的veth*即指veth对的一端（另一端未标注，但实际上是成对出现），该veth对是由Docker Daemon挂载在docker0网桥上，另一端添加到容器所属的网络命名空间，图上显示是容器中的eth0。 图中演示了bridge模式下的容器间通信。docker1向docker2发送请求，docker1，docker2均与docker0建立了veth对进行通讯。 当请求经过docker0时，由于容器和docker0同属于一个子网，因此请求经过docker2与docker0的veth*对，转发到docker2，该过程并未跨节点，因此不经过eth0。 Pod 间的通信 同一Node中Pod间通信：同一Node中Pod的默认路由都是docker0的地址，由于它们关联在同一个docker0网桥上，地址网段相同，所有它们之间应当是能直接通信的。 由于Pod内共享网络命名空间（由pause容器创建），所以本质上也是同节点容器间的通信。同时，同一Node中Pod的默认路由都是docker0的地址，由于它们关联在同一个docker0网桥上，地址网段相同，所有它们之间应当是能直接通信的。来看看实际上这一过程如何实现。如上图，Pod1中容器1和容器2共享网络命名空间，因此对pod外的请求通过pod1和Docker0网桥的veth对（图中挂在eth0和ethx上）实现。 不同Node中Pod间通信：不同Node中Pod间通信要满足2个条件： Pod的IP不能冲突； 将Pod的IP和所在的Node的IP关联起来，通过这个关联让Pod可以互相访问。 跨节点通信 CNI：容器网络接口 CNI 是一种标准，它旨在为容器平台提供网络的标准化。不同的容器平台（比如目前的 kubernetes、mesos 和 rkt）能够通过相同的接口调用不同的网络组件。 目前kubernetes支持的CNI组件种类很多，例如：bridge calico calico-ipam dhcp flannel host-local ipvlan loopback macvlan portmap ptp sample tuning vlan。在docker中，主流的跨主机通信方案主要有一下几种： 1）基于隧道的overlay网络：按隧道类型来说，不同的公司或者组织有不同的实现方案。docker原生的overlay网络就是基于vxlan隧道实现的。ovn则需要通过geneve或者stt隧道来实现的。flannel最新版本也开始默认基于vxlan实现overlay网络。 2）基于包封装的overlay网络：基于UDP封装等数据包包装方式，在docker集群上实现跨主机网络。典型实现方案有weave、flannel的早期版本。 3）基于三层实现SDN网络：基于三层协议和路由，直接在三层上实现跨主机网络，并且通过iptables实现网络的安全隔离。典型的方案为Project Calico。同时对不支持三层路由的环境，Project Calico还提供了基于IPIP封装的跨主机网络实现 集群内跨节点通信涉及到不同的子网间通信，仅靠docker0无法实现，这里需要借助CNI网络插件来实现。图中展示了使用flannel实现跨节点通信的方式。 简单说来，flannel的用户态进程flanneld会为每个node节点创建一个flannel.1的网桥，根据etcd或apiserver的全局统一的集群信息为每个node分配全局唯一的网段，避免地址冲突。同时会为docker0和flannel.1创建veth对，docker0将报文丢给flannel.1,。 Flanneld维护了一份全局node的网络表，通过flannel.1接收到请求后，根据node表，将请求二次封装为UDP包，扔给eth0，由eth0出口进入物理网路发送给目的node。 在另一端以相反的流程。Flanneld解包并发往docker0，进而发往目的Pod中的容器。 Pod 到Service 通信 当一个 Service 对象在 Kubernetes 集群中被定义出来时，集群内的客户端应用就可以通过服务 IP 访问到 体的 Pod 容器提供 的服务了。从服务 IP 到后 Pod 的负载均衡机制，则是由每个 Node 上的 kube-proxy 负责实现的。 kube-proxyKube-proxy是一个简单的网络代理和负载均衡器，它的作用主要是负责Service的实现，具体来说，就是实现了内部从Pod到Service和外部的从NodePort向Service的访问。 实现方式： userspace是在用户空间，通过kuber-proxy实现LB的代理服务，这个是kube-proxy的最初的版本，较为稳定，但是效率也自然不太高。 iptables是纯采用iptables来实现LB，是目前kube-proxy默认的方式。 kube-proxy 通过设置 Linux Kernel的 iptables 规则，实现从 Service到后端 Endpoint 列表的负载分发规则，效率很高 但是，如果某个后端 Endpoint在转发时不可用，此次客户端请求就会得到失败的响应，相对于 userspace 模式来说更不可靠。 此时应该通过为 Pod 设置 readinessprobe （服务可用性健康检查）来保证只有达到 ready 状态的 Endpoint 才会被设置为 Service 的后端 Endpoint. ipvs 模式：在 Kubernetes 11 本中达到 Stable 阶段， kube-proxy 通过设置 LinuxKernel netlink 接口设置 IPVS 规则，转发效率和支持的吞吐率都是最高的。 ipvs模式要求 Linux Kernel 启用 IPVS 模块，如果操作系统未启用 IPVS 内核模块，kube-proxy 则会自动切换至 iptables 模式 同时， ipvs 模式支持更多的负载均衡策略，如下所述 rr: round-robi n, 轮询 le: least connection, 最小连接数 dh: destination hashing, 目的地址哈希 sh: source has ing, 源地址哈希 sed: shortest expected delay 最短期望延时 nq: never queue, 永不排队。下面是iptables模式下Kube-proxy的实现方式： 在这种模式下，kube-proxy监视Kubernetes主服务器添加和删除服务和端点对象。对于每个服务，它安装iptables规则，捕获到服务的clusterIP（虚拟）和端口的流量，并将流量重定向到服务的后端集合之一。对于每个Endpoints对象，它安装选择后端Pod的iptables规则。 默认情况下，后端的选择是随机的。可以通过将service.spec.sessionAffinity设置为“ClientIP”（默认为“无”）来选择基于客户端IP的会话关联。 与用户空间代理一样，最终结果是绑定到服务的IP:端口的任何流量被代理到适当的后端，而客户端不知道关于Kubernetes或服务或Pod的任何信息。这应该比用户空间代理更快，更可靠。然而，与用户空间代理不同，如果最初选择的Pod不响应，则iptables代理不能自动重试另一个Pod，因此它取决于具有工作准备就绪探测。 外部到内部的通信 从集群外访问集群有多种方式，比如loadbalancer，Ingress，nodeport，nodeport和loadbalancer是service的两个基本类型，是将service直接对外暴露的方式，ingress则是提供了七层负载均衡，其基本原理将外部流量转发到内部的service，再转发到后端endpoints，在平时的使用中，我们可以依据具体的业务需求选用不同的方式。 Kubernetes 支持两种对外服务的Service 的Type 定义：NodePort 和LoadBalancer。 NodePort：在每个Node 上打开一个端口并且每个Node 的端口都是一样的，通过:NodePort 的方式，Kubernetes 集群外部的程序可以访问Service；LoadBalancer:通过外部的负载均衡器来访问。 Ingress Ingress是推荐在生产环境使用的方式，它起到了七层负载均衡器和Http方向代理的作用，可以根据不同的url把入口流量分发到不同的后端Service。外部客户端只看到http://foo.bar.com这个服务器，屏蔽了内部多个Service的实现方式。采用这种方式，简化了客户端的访问，并增加了后端实现和部署的灵活性，可以在不影响客户端的情况下对后端的服务部署进行调整。 其部署的yaml可以参考如下模板 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: ingress.kubernetes.io/rewrite-target: /spec: rules: - host: test.name.com http: paths: - path: /test backend: serviceName: service-1 servicePort: 8118 - path: /name backend: serviceName: service-2 servicePort: 8228 这里我们定义了一个ingress模板，定义通过http://test.name.com来访问服务，在虚拟主机http://test.name.com下面定义了两个Path，其中/test被分发到后端服务s1，/name被分发到后端服务s2。 集群中可以定义多个ingress，来完成不同服务的转发，这里需要一个ingress controller来管理集群中的Ingress规则。Ingress Contronler 通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload使用配置生效。 Kubernetes提供的Ingress Controller模板如下： 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: ingress.kubernetes.io/rewrite-target: /spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 Kube-dns介绍Kube-dns用来为kubernetes service分配子域名，在集群中可以通过名称访问service；通常kube-dns会为service赋予一个名为“service名称.namespace.svc.cluster.local”的A记录，用来解析service的clusterip。 Kube-dns组件： 在Kubernetes v1.4版本之前由“Kube2sky、Etcd、Skydns、Exechealthz”四个组件组成。 在Kubernetes v1.4版本及之后由“Kubedns、dnsmasq、exechealthz”三个组件组成。 Kubedns 接入SkyDNS，为dnsmasq提供查询服务。 替换etcd容器，使用树形结构在内存中保存DNS记录。 通过K8S API监视Service资源变化并更新DNS记录。 服务10053端口。 Dnsmasq Dnsmasq是一款小巧的DNS配置工具。 在kube-dns插件中的作用是： 通过kubedns容器获取DNS规则，在集群中提供DNS查询服务 提供DNS缓存，提高查询性能 降低kubedns容器的压力、提高稳定性 Dockerfile在GitHub上Kubernetes组织的contrib仓库中，位于dnsmasq目录下。 在kube-dns插件的编排文件中可以看到，dnsmasq通过参数–server=127.0.0.1:10053指定upstream为kubedns。 Exechealthz 在kube-dns插件中提供健康检查功能。 源码同样在contrib仓库中，位于exec-healthz目录下。 新版中会对两个容器都进行健康检查，更加完善。 Flannel容器网络：Flannel之所以可以搭建kubernets依赖的底层网络，是因为它可以实现以下两点： 它给每个node上的docker容器分配相互不想冲突的IP地址； 它能给这些IP地址之间建立一个覆盖网络，同过覆盖网络，将数据包原封不动的传递到目标容器内。 Flannel介绍 Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。 在默认的Docker配置中，每个节点上的Docker服务会分别负责所在节点容器的IP分配。这样导致的一个问题是，不同节点上容器可能获得相同的内外IP地址。并使这些容器之间能够之间通过IP地址相互找到，也就是相互ping通。 Flannel的设计目的就是为集群中的所有节点重新规划IP地址的使用规则，从而使得不同节点上的容器能够获得“同属一个内网”且”不重复的”IP地址，并让属于不同节点上的容器能够直接通过内网IP通信。 Flannel实质上是一种“覆盖网络(overlaynetwork)”，也就是将TCP数据包装在另一种网络包里面进行路由转发和通信，目前已经支持udp、vxlan、host-gw、aws-vpc、gce和alloc路由等数据转发方式，默认的节点间数据通信方式是UDP转发。 Calico容器网络：Calico介绍 Calico是一个纯3层的数据中心网络方案，而且无缝集成像OpenStack这种IaaS云架构，能够提供可控的VM、容器、裸机之间的IP通信。Calico不使用重叠网络比如flannel和libnetwork重叠网络驱动，它是一个纯三层的方法，使用虚拟路由代替虚拟交换，每一台虚拟路由通过BGP协议传播可达信息（路由）到剩余数据中心。 Calico在每一个计算节点利用Linux Kernel实现了一个高效的vRouter来负责数据转发，而每个vRouter通过BGP协议负责把自己上运行的workload的路由信息像整个Calico网络内传播——小规模部署可以直接互联，大规模下可通过指定的BGP route reflector来完成。 Calico节点组网可以直接利用数据中心的网络结构（无论是L2或者L3），不需要额外的NAT，隧道或者Overlay Network。 Calico基于iptables还提供了丰富而灵活的网络Policy，保证通过各个节点上的ACLs来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。Calico架构图 参考文章 Kubernetes网络原理及方案 Kubernetes初探：网络技术原理 Kubernetes网络介绍 一篇文章为你图解kubernetes网络通信原理","link":"/2021/12/31/kubenetes/kubernetes-network/"},{"title":"hexo icarus 配置 Gitalk 评论系统","text":"登录GitHub并点此注册一个新的OAuth应用 第一个 Application name 是应用名称 第二个 Homepage URL 是主页地址 第三个 是描述 第四个 是回调地址！！这个最重要！！写你博客的地址就可以了 打开对应hexo主题的_config.yml添加如下内容：12345678gitalk:enable: truegithubID: github帐号 # 例：asdfv1929repo: 仓库名称 # 例：blogClientID: Client IDClientSecret: Client SecretadminUser: github帐号 #指定可初始化评论账户distractionFreeMode: true 12345678910111213141516comment: type: gitalk client_id: xxxxxxxxxxxxxxxxxxxx client_secret: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx repo: Some-of-Your-GitHub-Repo owner: you_github_name admin: - you_github_name per_page: 20 # 可选填 distraction_free_mode: false # 可选填 pager_direction: last # 可选填 create_issue_manually: false # 可选填 proxy: # 可选填 flip_move_options: # 可选填 enable_hotkey: true # 可选填 ref: https://blog.csdn.net/qq_36537546/article/details/90730412 https://www.jianshu.com/p/09c1bced3a1f https://blog.csdn.net/qq_23452385/article/details/105936095","link":"/2021/10/14/hexo/hexo-comment/"},{"title":"git常用命令","text":"1. 常用命令git tag12345678910111213141516# create taggit tag test_tag# delete taggit tag -d test_taggit push origin :refs/tags/test_tag# push taggit push origin test_taggit push origin --tags# show taggit show test_tag# 基于某个commit id create taggit tag -a test_tag {commitId} 查看本地和远程仓库的所有分支1git branch -a 查看远程仓库的分支1git branch -r 查看项目远程地址1git remote -v git 版本回退123456789101112131415161718# git log 命令可以显示所有提交过的版本信息# --pretty=oneline，只会显示版本号和提交时的备注信息git log --pretty=oneline# git reflog 可以查看所有分支的所有操作记录（包括已经被删除的 commit 记录和 reset 的操作）git reflog # git reset –-soft：回退到某个版本，只回退了commit的信息，不会恢复到index file一级。如果还要提交，直接commit即可；# 撤销该commit，但是又不能撤销该提交包含的更改，使用git reset --soft# 可见commit取消了，代码更改并没有取消git reset --soft {commitId}# git reset -–hard：彻底回退到某个版本，本地的源码也会变为上一个版本的内容，撤销的commit中所包含的更改被冲掉；git reset --hard {commitId}git push origin HEAD --force# 用某个commit 创建一个分支git branch {branch_name} {commitId} 2. git 安装配置1、检查git是否已经安装，输入git version命令即可，如果没有显示版本号表示没有安装git2、安装git ubuntusudo apt-get install git 3、配置git全局环境12git config --global user.name &quot;用户名&quot;git config --global user.email &quot;邮箱地址&quot; 4、生成ssh密钥ssh-keygen -t rsa -C &quot;这里换上你的邮箱&quot;会在用户目录~/.ssh/下建立相应的密钥文件。 5、创建完公钥后，需要上传。使用命令cd ~/.ssh进入~/.ssh文件夹，输入cat id_rsa.pub打开id_rsa.pub文件，复制其中所有内容。接着访问git网页，点击SSH公钥，标题栏可以随意输入，公钥栏把刚才复制的内容粘贴进去。 创建一个空的目录，初始化git仓库，添加远程仓库做测试 6、测试连接ssh -T git@github.com 7、git使用命令123456789git clone 项目地址 拉项目git pull 拉代码git push 提交到仓库git init指令初始化一个git仓库git add .添加文件git commit -m &quot;注释&quot;提交至仓库。git remote add origin https://git.oschina.net/你的用户名/项目名.git，git push origin master即可完成推送git checkout master 切换到master分支","link":"/2021/09/27/git/git-cmd/"},{"title":"hexo_guide","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start1hexo clean &amp;&amp; hexo g &amp;&amp; hexo server Create a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo clean &amp;&amp; hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/09/23/hexo/hexo-guide/"},{"title":"kubernetes service","text":"Service是一组Pod的服务抽象，相当于一组Pod的LB，负责将请求分发给对应的 Pod；Service会为这个LB提供一个IP，一般称为ClusterIP。 service 概述 Kubernetes 里的 Service 具有一个全局唯一的虚拟 ClusterIP 地址，Service 一旦被创建， Kubernetes 就会自动为它分配一个可用的 clusterIP 地址，而且在 Service 整个生命周期中，它的 clusterIP 地址都不会改变，客户端可以通过这个虚拟 IP 地址+服务的端口直接访问该服务, 再通过部署 Kubernetes 集群的 DNS 服务，就可以实现 Service Name（域名）到 clusterIP 地址的 DNS 映射功能，我们只要使用服务的名称（ DNS 名称 ）即可完成到目标服务的访问请求 。“ 服务发现“这个传统架构中的棘手问题在这里首次得以完美解决，同时，凭借 lusterIP 地址的独特设计， kubernetes 进一 步实现了 Service 的透明负载均衡和故障自动恢复的高级特性。 Service: Cluster IP 每个 Pod 都会被分配一个单独的 IP 地址，而且每 Pod 都提供了一个独立的 Endpoint (Pod IP + container port) 以被客户端访问，那么现在多个 Pod 副本组成了一个集群来提供服务，客户端如何访问它们呢？ 传统的做法是部署一个负载均衡器（软件或硬件），为这组 Pod 开启一个对外的服务端口如 8000 端口，并且将这些 Pod Endpoint 表加入 8000 端口的转发列表中，客户端就可以通过负载均衡器的对外IP地址＋8000 端口访问此服务了。kubernetes 也是类似的做法，Kubernetes 内部在每个 Node 上都运行了一套全局的虚拟负载均衡器 kube-proxy ，自动注入并自动实时更新集群中所有 Service 的路由表，通过iptables 或者 IP 机制, 把对 Service 的请求转发到其后端对应的某个 Pod 实例上，并在内部实现服务的负载均衡与会话保待机制 不仅如此， Kubernetes 还采用了 种很巧妙又影响深远的设计一Cluster IP 地址 .我们知道， pod的Endpoint 地址会随着 Pod 的销毁和重新创建而发生改变， 因为新 Pod IP 地址与之前旧 Pod 的不同 ，Service 一旦被创建，Kubernetes 就会自动为它 配一个全局唯一的虚拟 IP 地址——Cluster 地址，而且在Service 的整个生命周期内，ClusterIP 地址不会发生改变，这样一来，每个服务就变成了具备唯一 IP 的通信节 ，远程服务之间的通信间题就变成了基础的 TCP 网络通信问题。 查看cluster ip1kubectl get svc tomcat-service -o yaml Service是一组Pod的服务抽象，相当于一组Pod的LB，负责将请求分发给对应的 Pod；Service会为这个LB提供一个IP，一般称为ClusterIP。 service 定义1234567891011apiVersion: v1kind: Servicemetadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 上述配置创建一个名称为 “my-service” 的 Service 对象，它会将请求代理到使用 TCP 端口 9376，并且具有标签 “app=MyApp” 的 Pod 上。ports 定义部分指定了 Service 本身的端口号为 8080, targetPort 则用来指定 后端 Pod 的容器端口号 Kubernetes 为该服务分配一个 ClusterIP 地址（有时称为 “集群IP”），该 IP 地址由服务代理使用。 服务选择算符的控制器不断扫描与其选择器匹配的 Pod，然后将所有更新发布到也称为 “my-service” 的 Endpoint 对象。 service typeClusterIP 通过集群的内部 IP 暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的 ServiceType。当然，用户也可手工指定一个 ClusterIP 地址，不过需要确保该 IP 在 Kubernetes 集群设置 clusterIP 地址范围内（通过 kube-apiserver 服务的启 动参数– service-cluster-ip-range 设置），并且没有被其他 Service 使用 NodePort 将 Service 的端口号映射到每个 Node 一个端口号上，这样集群中的 任意 Node 都可以作为 Service 访问入口地址，即 NodeIP:NodePort. 通过每个节点上的 IP 和静态端口（NodePort）暴露服务。 NodePort 服务会路由到自动创建的 ClusterIP 服务。 通过请求 &lt;节点 IP&gt;:&lt;节点端口&gt;，你可以从集群的外部访问一个 NodePort 服务。 123456789101112131415apiVersion: v1kind: Servicemetadata: name: my-servicespec: type: NodePort selector: app: MyApp ports: # 默认情况下，为了方便起见，`targetPort` 被设置为与 `port` 字段相同的值。 - port: 80 targetPort: 80 # 可选字段 # 默认情况下，为了方便起见，Kubernetes 控制平面会从某个范围内分配一个端口号（默认：30000-32767） nodePort: 30007 通过将Service的类型设置为NodePort，就可以在Cluster中的主机上通过一个指定端口暴露服务。注意通过Cluster中每台主机上的该指定端口都可以访问到该服务，发送到该主机端口的请求会被kubernetes路由到提供服务的Pod上。采用这种服务类型，可以在kubernetes cluster网络外通过主机IP：端口的方式访问到服务。 1234567891011kind: ServiceapiVersion: v1metadata: name: influxdbspec: type: NodePort ports: - port: 8086 nodePort: 31112 selector: name: influxdb LoadBalancer 将 Service 映射到一个已存在的负载均衡器的 IP 地址上，通常在公有云环境中使用. 在使用支持外部负载均衡器的云提供商的服务时，设置 type 的值为 “LoadBalancer”， 将为 Service 提供负载均衡器。 负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过 Service 的 status.loadBalancer 字段发布出去。 实例： 1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 192.0.2.127 来自外部负载均衡器的流量将直接重定向到后端 Pod 上，不过实际它们是如何工作的，这要依赖于云提供商。 某些云提供商允许设置 loadBalancerIP。 在这些情况下，将根据用户设置的 loadBalancerIP 来创建负载均衡器。 如果没有设置 loadBalancerIP 字段，将会给负载均衡器指派一个临时 IP。 如果设置了 loadBalancerIP，但云提供商并不支持这种特性，那么设置的 loadBalancerIP 值将会被忽略掉。 ExternalName 将Service 映射为 一个外部域名地址 ，通过 externalName 字段进行设置。 通过返回 CNAME 和对应值，可以将服务映射到 externalName 字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理。 headless service有时不需要或不想要负载均衡，以及单独的 Service IP。 遇到这种情况，可以通过指定 Cluster IP（spec.clusterIP）的值为 “None” 来创建 Headless Service。 你可以使用无头 Service 与其他服务发现机制进行接口，而不必与 Kubernetes 的实现捆绑在一起。 对这无头 Service 并不会分配 Cluster IP，kube-proxy 不会处理它们， 而且平台也不会为它们进行负载均衡和路由。 DNS 如何实现自动配置，依赖于 Service 是否定义了选择算符。 带选择算符的服务对定义了选择算符的无头服务，Endpoint 控制器在 API 中创建了 Endpoints 记录， 并且修改 DNS 配置返回 A 记录（IP 地址），通过这个地址直接到达 Service 的后端 Pod 上。 无选择算符的服务对没有定义选择算符的无头服务，Endpoint 控制器不会创建 Endpoints 记录。 然而 DNS 系统会查找和配置，无论是： 对于 ExternalName 类型的服务，查找其 CNAME 记录对所有其他类型的服务，查找与 Service 名称相同的任何 Endpoints 的记录 在 spec.ports 的定义中， targetPort 属性用来确定提供该服务的容器所悬露 (Expose)的端口号，即具体的业务进程在容器内的 targetPort 上提供 TCP/IP 接入； port 属性则定义Service 的端口。前面定义 Tomcat 服务时并没有指定 targetPort, 所以 targetPort 默认与port 相同。除了正常的 service ，还有一种特殊的 Service – Headless service ，只要在 Service的定义中设置了 clusterIP: None, 就定义了一个 Headless service, 它与普通 service 的关键区别在于它没有 ClusterIP 地址，如果解析 Headless service DNS 域名，则返回的是该Service 对应的全部 Pod Endpoint 列表，这意味着客户端是直接与后端的 pod建立 TCP/IP连接进行通信的，没有通过虚拟 clusterIP 地址进行转发，因此通信性能最高，等同千”原生网络通信”。 Service 的外网访问问题 Service 暴霓到集群外部 Kubernetes Service 创建的 ClusterIP 地址是对后端 Pod 列表的一层抽象，对于集群外部来说并没有意义，但有许多 Service 是需要对集群外部提供服务的， Kubernetes 提供了多种机制将 Service 暴露出去，供集群外部的客户端访问 这可以通过 Service 资源对象的类型字段 “type：【clusterIp, NodePort, LoadBalancer, ExternalName】” 进行设置。 前面提到，服务的 lusterIP 地址在 Kubernetes 集群内才能被访问，那么如何让集群外的应用访问我们的服务呢？这也是一个相对复杂的问题 要弄明白这个问题的解决思路和解决方法，我们需要先弄明白 Kubernetes 的三种 IP, 这三种 IP 分别如下 Node IP: Node IP 地址 Pod IP: Pod IP 地址 Service IP: Service IP 地址 首先， Node IP 是 Kubernetes 集群中每个节点的物理网卡的 IP 地址，是 个真实存在的物理网络，所有属于这个网络的服务器都能通过这个网络直接通信，不管其中是否有部分节点不属于这个 Kubernetes 集群 这也表明 ubernetes 集群之外的节点访问 Kubernetes集群内的某个节点或者 TCP/I 务时，都必须通过 Node IP.其次， Pod IP 是每个 Pod IP 地址，在使用 Docker 作为容器支持引擎的情况下，它Docker Engine 艰据 dockerO 网桥的 IP 地址段进行分配的，通常是一个虚拟二层网络。前面说过， Kubernetes 要求位于不同 Node的Pod 能够彼此直接通信，所以 Kubernetes中一个 Pod 里的容器访问另外一个 Pod 里的容器时， 就是通过 Pod IP 所在的虚拟二层网络进行通信的，而真实的 TCP IP 流童是通过 Node IP 所在的物理网卡流出的. 在Kubernetes 集群内， Service ClusterIP 地址属于集群内的地址，无法在 群外接使用这个地址 为了解决这个问题， Kubernetes 首先引入了 NodePort 这个概念， NodePort也是解决集群外的应用访问集群内服务的直接、有效的常见做法 NodePort 负载均衡器组件独立于 Kubernetes 集群之外 参考文章","link":"/2021/12/31/kubenetes/kubernetes-service/"},{"title":"ConfigurationProperties","text":"在 Spring Boot 项目中，我们将大量的参数配置在 application.properties 或 application.yml 文件中，通过 @ConfigurationProperties 注解，我们可以方便的获取这些参数值 使用 @ConfigurationProperties 配置模块假设我们正在搭建一个发送邮件的模块。在本地测试，我们不想该模块真的发送邮件，所以我们需要一个参数来「开关」 disable 这个功能。另外，我们希望为这些邮件配置一个默认的主题，这样，当我们查看邮件收件箱，通过邮件主题可以快速判断出这是测试邮件 在 application.properties 文件中创建这些参数:我们可以使用 @Value 注解或着使用 Spring Environment bean 访问这些属性，是这种注入配置方式有时显得很笨重。我们将使用更安全的方式(@ConfigurationProperties )来获取这些属性 @ConfigurationProperties 的基本用法非常简单:我们为每个要捕获的外部属性提供一个带有字段的类。请注意以下几点: 前缀定义了哪些外部属性将绑定到类的字段上 根据 Spring Boot 宽松的绑定规则，类的属性名称必须与外部属性的名称匹配 我们可以简单地用一个值初始化一个字段来定义一个默认值 类本身可以是包私有的 类的字段必须有公共 setter 方法 激活 @ConfigurationProperties对于 Spring Boot，创建一个 MailModuleProperties 类型的 bean，我们可以通过下面几种方式将其添加到应用上下文中 首先，我们可以通过添加 @Component 注解让 Component Scan 扫描到很显然，只有当类所在的包被 Spring @ComponentScan 注解扫描到才会生效，默认情况下，该注解会扫描在主应用类下的所有包结构 参考文章 https://blog.csdn.net/yusimiao/article/details/97622666 面试还不知道BeanFactory和ApplicationContext的区别？","link":"/2021/11/03/java/java-ConfigurationProperties/"},{"title":"apache.http.impl.client.HttpClients","text":"12345678try (CloseableHttpClient httpClient = HttpClients.custom().disableAutomaticRetries().build()) { HttpPost httpPost = new HttpPost(&quot;http://www.baidu.com&quot;); try (CloseableHttpResponse response = httpClient.execute(httpPost)) { int statusCode = response.getStatusLine().getStatusCode(); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package com.example.demo;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import org.apache.http.HttpEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpPost;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.util.EntityUtils;public class Main { public static void main(String[] args) throws IOException { try (CloseableHttpClient httpClient = HttpClients.custom().disableAutomaticRetries().build()) { HttpPost httpPost = new HttpPost(&quot;http://www.baidu.com&quot;); // HttpGet httGet = new HttpGet(&quot;http://www.baidu.com&quot;); // httpPost.setEntity(&quot;&quot;); // httpPost.setHeader(&quot;Accept&quot;, &quot;application/json&quot;); // httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); try (CloseableHttpResponse response = httpClient.execute(httpPost)) { int statusCode = response.getStatusLine().getStatusCode(); InputStream inputStream = response.getEntity().getContent(); readByChars(inputStream); InputStreamReader inputStreamReader = new InputStreamReader(inputStream); readWithBufferedReader(inputStreamReader); if (statusCode != 200) { final HttpEntity entity = response.getEntity(); final String result = EntityUtils.toString(entity); System.out.println(result); } } } } /** * 以字符为单位读取文件，常用于读文本，数字等类型的文件 */ public static void readByChars(InputStream inputStream) { InputStreamReader reader = null; // try { // System.out.println(&quot;以字符为单位读取文件内容，一次读一个字节：&quot;); // //1. 一次读一个字符 // reader = new InputStreamReader(inputStream);//可以是任意的InputStream类，不一定必须是FileInputStream // int tempchar; // while ((tempchar = reader.read()) != -1) { // if (((char)tempchar) != '\\r') { // System.out.print((char)tempchar); // } // } // reader.close(); // } catch (Exception e) { // e.printStackTrace(); // } try { System.out.println(&quot;以字符为单位读取文件内容，一次读多个字节：&quot;); //2. 一次读多个字符 char[] tempchars = new char[30]; int charread = 0; reader = new InputStreamReader(inputStream); while ((charread = reader.read(tempchars)) != -1) { for (int i = 0; i &lt; charread; i++) { if (tempchars[i] != '\\r') { System.out.print(tempchars[i]); } } } } catch (Exception e1) { e1.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } } public static void readWithBufferedReader(InputStreamReader inputStreamReader) { BufferedReader reader = null; try { reader = new BufferedReader(inputStreamReader); String tempString = null; int line = 1; // 一次读入一行，直到读入null为文件结束 while ((tempString = reader.readLine()) != null) { System.out.println(&quot;line &quot; + line + &quot;: &quot; + tempString); line++; } reader.close(); } catch (IOException e) { e.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } }} 参考文章","link":"/2021/12/08/java/java-apache-httpclient/"},{"title":"bind header to controller","text":"12345678910111213141516171819202122232425262728293031import javax.servlet.http.HttpServletRequest;import org.springframework.core.MethodParameter;import org.springframework.web.bind.support.WebDataBinderFactory;import org.springframework.web.context.request.NativeWebRequest;import org.springframework.web.method.support.HandlerMethodArgumentResolver;import org.springframework.web.method.support.ModelAndViewContainer;import lombok.extern.slf4j.Slf4j;import summer.webserver.util.SummerUtils;@Slf4jpublic class SummerArgumentResolver implements HandlerMethodArgumentResolver { public SummerArgumentResolver() { super(); } @Override public boolean supportsParameter(MethodParameter parameter) { return SummerHeader.class.isAssignableFrom(parameter.getParameterType()); } @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) { return SummerUtils.getSummerHeader(webRequest.getNativeRequest(HttpServletRequest.class)); }} 12345678910111213141516171819@Slf4jpublic class SummerUtils { public static SummerHeader getSummerHeader(HttpServletRequest request) { User user = (User)request.getAttribute(&quot;user&quot;); String userName = Objects.isNull(user) ? request.getHeader(USER_NAME) : user.getUserName(); String userId = Objects.isNull(user) ? request.getHeader(USER_ID) : user.getUserId(); SummerHeader summerHeader = SummerHeader.builder() .userName(userName) .userId(userId) .build(); if (log.isDebugEnabled()) { log.debug(summerHeader.toString()); } request.setAttribute(&quot;summerHeader&quot;, summerHeader); return summerHeader; }} usage1234567891011121314@Api(tags = &quot;User&quot;)@RestController()@RequestMapping(ROOT_DOMAIN + &quot;/users&quot;)@Slf4jpublic class UserController { @ApiOperation(value = &quot;delete user&quot;) @DeleteMapping(&quot;/{user-id}&quot;) @ResponseStatus(HttpStatus.OK) public void deleteUser(SummerHeader summerHeader, @ApiParam(required = true) @Length(max = 10) @PathVariable(value = &quot;user-id&quot;) String userId) { userMapper.deleteById(userId); }}","link":"/2021/10/25/java/java-bind-header-to-controller/"},{"title":"时间格式 注解 验证","text":"EnumValid.java12345678910111213@Constraint(validatedBy = DateFormatValidator.class)@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface DateFormat { String message() default &quot;&quot;; String pattern() default &quot;yyyy-MM-dd HH:mm:ss&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} 校验器EnumValidator.java1234567891011121314151617181920212223242526272829303132333435public class DateFormatValidator implements ConstraintValidator&lt;DateFormat, String&gt; { private String pattern; @Override public void initialize(DateFormat dateFormat) { this.pattern = dateFormat.pattern(); } @Override public boolean isValid(String value, ConstraintValidatorContext context) { boolean isValid = (value == null) || isValid(value); if (!isValid) { throw new RuntimeException(&quot;invalid input parameter.&quot;); } return isValid; } private boolean isValid(String value) { boolean isValid = true; try { String time = URLDecoder.decode(value, &quot;UTF-8&quot;); if (pattern.length() != time.length()) { isValid = false; } else { SimpleDateFormat dateFormat = new SimpleDateFormat(pattern); dateFormat.setLenient(false); dateFormat.parse(time); } } catch (Exception e) { isValid = false; } return isValid; }} 使用的时候，注解作用在DTO字段上：12345public class RequestDto { @DateFormat(pattern = &quot;yyyy-MM-dd&quot;) private String data;}","link":"/2021/10/14/java/java-dataformat-validator/"},{"title":"枚举类型参数验证","text":"EnumValid.java1234567891011121314@Documented@Constraint(validatedBy = EnumValidator.class)@Target({ElementType.TYPE, ElementType.FIELD, ElementType.PARAMETER})@Retention(RetentionPolicy.RUNTIME)public @interface EnumValid { Class&lt;? extends Enum&lt;?&gt;&gt; enumClass(); String message() default &quot;invalid enum item value.&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} 校验器EnumValidator.java12345678910111213141516171819202122232425262728293031323334@Slf4jpublic class EnumValidator implements ConstraintValidator&lt;EnumValid, String&gt; { private Class&lt;? extends Enum&lt;?&gt;&gt; enumClass; @Override public void initialize(EnumValid enumValid) { enumClass = enumValid.enumClass(); } @Override public boolean isValid(String value, ConstraintValidatorContext context) { if (!valid(value)) { throw new RuntimeException(&quot;invalid input parameter.&quot;); return false; } return true; } private boolean valid(String value) { try { if (enumClass.isEnum()) { Method method = enumClass.getMethod(&quot;isValidName&quot;, value.getClass()); Boolean result = (Boolean)method.invoke(null, value); return result != null &amp;&amp; result; } } catch (InvocationTargetException | NoSuchMethodException | IllegalAccessException e) { throw new RuntimeException(&quot;Enum values valid error.&quot;); } return false; }} 枚举类123456789public enum SxWhetherIntEnum { YES, NO; public static boolean isValidName(String name) { return Arrays.stream(values()).anyMatch(item -&gt; item.name().equals(name)); }} 使用的时候，注解作用在DTO字段上：123456public class RequestDto { @ApiModelProperty(value = &quot;是否可转定，1-是，2-否（补充）&quot;) @EnumValid(enumClass = SxWhetherIntEnum.class) private Integer payable;} 参考文章 https://www.cnblogs.com/wjqhuaxia/p/12153053.html https://blog.csdn.net/www_tlj/article/details/103950945 https://www.cnblogs.com/wjqhuaxia/p/12153053.html","link":"/2021/10/14/java/java-enum-valid/"},{"title":"GC算法 垃圾收集器","text":"概述jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理。 因此，我们的内存垃圾回收主要集中于 **java 堆和方法区中**，在程序运行期间，这部分内存的分配和使用都是动态的. 对象存活判断判断对象是否存活一般有两种方式： 引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。 可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。 在Java语言中，GC Roots包括： 虚拟机栈中引用的对象。 方法区中类静态属性实体引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 垃圾收集算法标记 -清除算法 “标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。 它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 参考文章-","link":"/2021/09/29/java/java-gc/"},{"title":"图 DFS","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import java.util.Stack;public class Graph { class Vertex{ //顶点 public char lebel; public boolean visited; public Vertex(char lab){ lebel = lab; visited = false; } } private final int maxVertices = 20 ; //最大顶点数 private Vertex vertexList[]; private int adjMatrix[][]; private int vertexCount; private Stack theStack; public Graph(){ vertexList = new Vertex[maxVertices]; adjMatrix = new int[maxVertices][maxVertices]; vertexCount = 0; for(int y = 0 ; y &lt; maxVertices ; y++){ for(int x = 0 ; x &lt; maxVertices ; x ++){ adjMatrix[x][y] = 0; } } theStack = new Stack(); } public void addVertex(char lab){ vertexList[vertexCount++]=new Vertex(lab); } public void addEdge(int start,int end){ adjMatrix[start][end] = 1; adjMatrix[end][start] = 1; } public void displayVertex(int v){ System.out.println(vertexList[v].lebel); } public void dfs(){ vertexList[0].visited = true; displayVertex(0); theStack.push(0); while (!theStack.isEmpty()){ int v = getAdjUnvisitedVertes((int)theStack.peek()); if(v == -1){ theStack.pop(); }else { vertexList[v].visited = true; displayVertex(v); theStack.push(v); } } for(int j = 0 ; j &lt; vertexCount; j++){ vertexList[j].visited = false; } } public int getAdjUnvisitedVertes(int v){ for(int j = 0 ; j &lt; vertexCount ; j ++){ if(adjMatrix[v][j] == 1 &amp;&amp; vertexList[j].visited == false){ return j; } } return -1; } public static void main(String[] args) { int col = 9 ; int[][] a = new int[col][col]; a[0][1] = 1;a[0][5] = 1;a[1][2] = 1;a[1][6]= 1;a[1][8]= 1; a[2][3] = 1; a[2][8] = 1; a[3][8] =1; a[3][6]= 1; a[3][7] = 1;a[3][4] = 1; a[4][5] =1; a[4][7]= 1; a[5][6] = 1;a[6][7] = 1; Graph graph = new Graph(); graph.addVertex('A'); graph.addVertex('B'); graph.addVertex('C'); graph.addVertex('D'); graph.addVertex('E'); graph.addVertex('F'); graph.addVertex('G'); graph.addVertex('H'); graph.addVertex('I'); for(int y = 0 ; y &lt; col; y ++){ for(int x = 0 ; x &lt; col ; x ++ ){ if(a[y][x] == 1){ graph.addEdge(y,x); } } } graph.dfs(); }}","link":"/2021/10/25/java/java-graph-dfs/"},{"title":"Jdk8 DNS解析","text":"Java提供InetAddress类，可以对域名-IP进行正向、逆向解析。 InetAddress解析的时候一般是调用系统自带的DNS程序。 linux 默认的DNS方式是读取/etc/resolv.conf进行DNS解析。 mac 默认的方式是向网关请求获取DNS服务器，然后直接请求DNS服务器进行解析，没有读取/etc/resolv.conf。 DNSNameService 根据sun.net.spi.nameservice.nameservers指定的name server或/etc/resolv.conf文件中配置的name server进行DNS解析 根据不同的DNS分别解析域名，因此需要动态的设置DNS。 JNDI DNS服务提供者设置官方文档 1234567891011121314151617JNDI DNS service provider settingsThese properties may not be supported in future releases.---sun.net.spi.nameservice.provider.&lt;n&gt;=&lt;default|dns,sun|...&gt;Specifies the name service provider that you can use. By default, Java will use the system configured name lookup mechanism, such as file, nis, etc. You can specify your own by setting this option. &lt;n&gt; takes the value of a positive number, it indicates the precedence order with a small number takes higher precendence over a bigger number. Aside from the default provider, the JDK includes a DNS provider named &quot;dns,sun&quot;.Prior to JDK 7, the first provider that was successfully loaded was used. In JDK 7, providers are chained, which means that if a lookup on a provider fails, the next provider in the list is consulted to resolve the name.---sun.net.spi.nameservice.nameservers=&lt;server1_ipaddr,server2_ipaddr ...&gt;You can specify a comma separated list of IP addresses that point to the DNS servers you want to use. If the sun.net.spi.nameservice.nameservers property is not defined, then the provider will use any name servers already configured in the platform DNS configurationsun.net.spi.nameservice.provider.&lt;n&gt;=&lt;default|dns,sun|...&gt; 用于设置域名服务提供者= default的时候调用系统自带的DNS= dns,sun的时候，会调用sun.net.spi.nameservice.nameservers=&lt;server1_ipaddr,server2_ipaddr ...&gt;指定的DNS来解析 参考文章 Java动态解析域名 Jdk8 DNS解析 https://docs.oracle.com/javase/8/docs/technotes/guides/net/properties.html","link":"/2021/12/06/java/java-jdk-dns-resolution/"},{"title":"log4j2 JNDI injection_vulnerability","text":"123&lt;properties&gt; &lt;log4j2.version&gt;2.16.0&lt;/log4j2.version&gt;&lt;/properties&gt; 参考文章 Apache Log4j2 远程代码执行漏洞分析 Log4J2 Vulnerability and Spring Boot 令无数程序员加班的 Log4j2 远程执行漏洞复现 Log4j2发布2.16.0，删除Message Lookups，加固漏洞防御","link":"/2021/12/16/java/java-log4j2-jndi-injection-vulnerability/"},{"title":"Java内存模型","text":"Java 内存模型对JVM内存结构的描述中，我们知道了堆和方法区是线程共享的。而局部变量，方法定义参数和异常处理器参数就不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 Java内存模型的抽象示意图如下： 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！为了具体说明，请看下面示例： 1234Processor A Processor Ba = 1; //A1 x = b; //A2 b = 2; //B1 y = a; //B2 初始状态：a = b = 0 处理器允许执行后得到结果：x = y = 0假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 **提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性**。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具体说明 happens-before 为什么要这么定义。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 参考文章 https://zhuanlan.zhihu.com/p/38348646 https://www.infoq.cn/article/java-memory-model-1/","link":"/2021/09/28/java/java-jmm/"},{"title":"java多线程那点事","text":"java多线程那点事|提升java能力阿里面试官的分享Java面试中需要准备哪些多线程并发的技术要点","link":"/2021/10/25/java/java-multi-thread/"},{"title":"some parameters that only one is not null valid","text":"注解12345678910111213141516171819202122@Documented@Target({ElementType.FIELD})@Retention(RetentionPolicy.RUNTIME)public @interface CustomValid {}@Documented@Constraint(validatedBy = OnlyOneNotNullValidator.class)@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)public @interface OnlyOneNotNull { String message() default &quot;only one filed should not be null&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {}; String[] fieldNames();} OnlyOneNotNullValidator.java12345678910111213141516171819202122232425262728293031323334353637383940414243@Component@Slf4jpublic class OnlyOneNotNullValidator implements ConstraintValidator&lt;OnlyOneNotNull, Object&gt; { private String[] fieldNames; @Override public void initialize(OnlyOneNotNull onlyOneNotNull) { this.fieldNames = onlyOneNotNull.fieldNames(); } @Override public boolean isValid(Object object, ConstraintValidatorContext context) { if (Objects.isNull(object)) { return true; } Class clazz = object.getClass(); try { List&lt;Field&gt; fields = Arrays.stream(fieldNames) .map(fieldName -&gt; ReflectionUtils.findField(clazz, fieldName)) .filter(Objects::nonNull).peek(field -&gt; field.setAccessible(true)) .filter(field -&gt; Objects.nonNull(ReflectionUtils.getField(field, object))) .collect(Collectors.toList()); boolean onlyOneNotNull = fields.size() == 1; if (!onlyOneNotNull) { invalid(context); } else if (fields.get(0).isAnnotationPresent(CustomValid.class)) { validate(fields.get(0).get(object)); } return onlyOneNotNull; } catch (IllegalAccessException e) { log.warn(e.getMessage(), e); return false; } catch (Exception e) { return false; } } private void invalid(ConstraintValidatorContext context) { throw new RuntimeException(String.format(&quot;[%s]&quot;, String.join(&quot;, &quot;, fieldNames)) + &quot; only one filed should not be null&quot;); }} 12345678910111213141516171819202122// valid object's field, for example: valid ClassA.aaa notNull. public static void validate(Object object) { if (object != null) { Class objClass = object.getClass(); try { object = objectMapper.readValue(objectMapper.writeValueAsString(object), Object.class); XssUtils.unescapeObject(object); object = objectMapper.convertValue(object, objClass); } catch (IOException e) { throw new RuntimeException(&quot;QUERY_PARAM_ERROR&quot;); } } javax.validation.Validator validator = (javax.validation.Validator)new ApplicationContextHolder().context.getBean(&quot;validator&quot;); Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = validator.validate(object); if (!violations.isEmpty()) { StringBuilder msg = new StringBuilder(); for (ConstraintViolation&lt;Object&gt; violation : violations) { msg.append(&quot;[&quot;).append(violation.getPropertyPath()).append(&quot;]&quot;).append(violation.getMessage()); } throw new RuntimeException(&quot;bad request&quot;); } } 使用123456789101112131415161718192021222324252627282930313233@Getter@Setter@Builder@NoArgsConstructor@AllArgsConstructor@OnlyOneNotNull(fieldNames = {&quot;aClass&quot;, &quot;bClass&quot;, &quot;cClass&quot;})public class RequestDto { @CustomValid private AClass aClass; @CustomValid private BClass bClass; @CustomValid private CClass cClass;}@Getter@Setter@Builder@NoArgsConstructor@AllArgsConstructorpublic class AClass { @NotNull private Boolean aaa; @NotNull private BBBB bnbb; @NotBlank @Pattern(regexp = ApiGatewayConst.PatternRegexp.METHOD_HTTP_URL) @Length(max = 1500) private String url;}","link":"/2021/10/14/java/java-onlyOneNotNull-valid/"},{"title":"常见内存溢出错误","text":"Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space 原因：对象不能被分配到堆内存中。 Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space 原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。 Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：创建的数组大于堆内存的空间。 Exception in thread “main”: java.lang.OutOfMemoryError: request bytes for . Out of swap space? 原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。 Exception in thread “main”: java.lang.OutOfMemoryError: （Native method） 原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现。 Troubleshooting Guide for HotSpot VM”, Chapter 3 on “Troubleshooting on memory leaks","link":"/2021/09/28/java/java-oom/"},{"title":"java_quarkus","text":"参考文章 试用 Quarkus 的四大理由 Quarkus框架入门之一：Quarkus框架介绍及简单示例 5分钟拥抱云原生 | SpringBoot 迁移至 Quarkus 一个简单的Quarkus web服务入门","link":"/2021/12/28/java/java-quarkus/"},{"title":"读取txt文件","text":"12345678910111213141516171819202122public class ReadFileByLines { public static void main(String[] args) { try { //1.打开一个file File file = new File(&quot;E:/test.txt&quot;); //2.InputStreamReader&lt;-FileInputStream&lt;-file FileInputStream fis = new FileInputStream(file); InputStreamReader is = new InputStreamReader(fis); //3.用BufferedReader(&lt;-InputStreamReader)的readLine()方法读取 BufferedReader br = new BufferedReader(is); //4.输出 String txtLine = null; while ((txtLine = br.readLine()) != null) { System.out.println(txtLine); } br.close(); } catch (Exception e) { e.printStackTrace(); } }} 123456789101112131415161718public class ReadFileByLines { public static void main(String[] args) { try { File file = new File(&quot;E:/test.txt&quot;); BufferedReader br = new BufferedReader(new FileReader(file)); String txtLine = null; while ((txtLine = br.readLine()) != null) { System.out.println(txtLine); } br.close(); } catch (Exception e) { e.printStackTrace(); } }}","link":"/2021/10/25/java/java-read-txt-file/"},{"title":"ThreadPoolTaskExecutor","text":"1234567891011121314151617181920212223242526import java.util.concurrent.ThreadPoolExecutor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;@Configuration@EnableAsyncpublic class ThreadPool { public static final int DEFAULT_THREADS_NUMS = 2 * Runtime.getRuntime().availableProcessors(); @Bean(&quot;taskExecutor&quot;) public ThreadPoolTaskExecutor taskExecutor() { ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor(); int maxPoolSize = 2 * DEFAULT_THREADS_NUMS; threadPoolTaskExecutor.setCorePoolSize(DEFAULT_THREADS_NUMS); threadPoolTaskExecutor.setMaxPoolSize(maxPoolSize); threadPoolTaskExecutor.setQueueCapacity(maxPoolSize); threadPoolTaskExecutor.setKeepAliveSeconds(60); threadPoolTaskExecutor.setThreadNamePrefix(&quot;Async-Thread-&quot;); threadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); return threadPoolTaskExecutor; }} 参考文章","link":"/2021/11/10/java/java-threadpool/"},{"title":"java 单例模式的写法","text":"饱汉模式饱汉是变种最多的单例模式。我们从饱汉出发，通过其变种逐渐了解实现单例模式时需要关注的问题。 基础的饱汉饱汉，即已经吃饱，不着急再吃，饿的时候再吃。所以他就先不初始化单例，等第一次使用的时候再初始化，即·“懒加载”·。 12345678910111213// 饱汉// UnThreadSafepublic class Singleton1 { private static Singleton1 singleton = null; private Singleton1() { } public static Singleton1 getInstance() { if (singleton == null) { singleton = new Singleton1(); } return singleton; }} 饱汉模式的核心就是懒加载。好处是更启动 速度快、节省资源，一直到实例被第一次访问，才需要初始化单例；小坏处是写起来麻烦，大坏处是线程不安全，if语句存在竞态条件。 写起来麻烦不是大问题，可读性好啊。因此，单线程环境下，基础饱汉是最好。但多线程环境下，基础饱汉就彻底不可用了。下面的几种变种都在试图解决基础饱汉线程不安全的问题。 饱汉 - 变种 1最粗暴的犯法是用synchronized关键字修饰getInstance()方法，这样能达到绝对的线程安全。 12345678910111213// 饱汉// ThreadSafepublic class Singleton1_1 { private static Singleton1_1 singleton = null; private Singleton1_1() { } public synchronized static Singleton1_1 getInstance() { if (singleton == null) { singleton = new Singleton1_1(); } return singleton; }} 变种1的好处是写起来简单，且绝对线程安全；坏处是并发性能极差，事实上完全退化到了串行。单例只需要初始化一次，但就算初始化以后，synchronized的锁也无法避开，从而getInstance()完全变成了串行操作。性能不敏感的场景建议使用。 饱汉 - 变种 2变种2是“臭名昭著”的DCL 1.0。 针对变种1中单例初始化后锁仍然无法避开的问题，变种2在变种1的外层又套了一层check，加上synchronized内层的check，即所谓“双重检查锁”（Double Check Lock，简称DCL）。 123456789101112131415161718192021// 饱汉// UnThreadSafepublic class Singleton1_2 { private static Singleton1_2 singleton = null; public int f1 = 1; // 触发部分初始化问题 public int f2 = 2; private Singleton1_2() { } public static Singleton1_2 getInstance() { // may get half object if (singleton == null) { synchronized (Singleton1_2.class) { if (singleton == null) { singleton = new Singleton1_2(); } } } return singleton; }} 变种2的核心是DCL，看起来变种2似乎已经达到了理想的效果：懒加载+线程安全。可惜的是，正如注释中所说，DCL仍然是线程不安全的，由于指令重排序，你可能会得到“半个对象”，即”部分初始化“问题。 参考：volatile关键字的作用、原理 饱汉 - 变种 3变种3专门针对变种2，可谓DCL 2.0。 针对变种3的“半个对象”问题，变种3在instance上增加了volatile关键字，原理见上述参考。 123456789101112131415161718192021// 饱汉// ThreadSafepublic class Singleton1_3 { private static volatile Singleton1_3 singleton = null; public int f1 = 1; // 触发部分初始化问题 public int f2 = 2; private Singleton1_3() { } public static Singleton1_3 getInstance() { if (singleton == null) { synchronized (Singleton1_3.class) { // must be a complete instance if (singleton == null) { singleton = new Singleton1_3(); } } } return singleton; }} 多线程环境下，变种3更适用于性能敏感的场景。但后面我们将了解到，就算是线程安全的，还有一些办法能破坏单例。 当然，还有很多方式，能通过与volatile类似的方式防止部分初始化。读者可自行阅读内存屏障相关内容，但面试时不建议主动装逼。猴子后面会专门整理一篇文章讨论内存屏障，此处不表。 饿汉模式与饱汉相对，饿汉很饿，只想着尽早吃到。所以他就在最早的时机，即类加载时初始化单例，以后访问时直接返回即可。 12345678910// 饿汉// ThreadSafepublic class Singleton2 { private static final Singleton2 singleton = new Singleton2(); private Singleton2() { } public static Singleton2 getInstance() { return singleton; }} 饿汉的好处是天生的线程安全（得益于类加载机制），写起来超级简单，使用时没有延迟；坏处是有可能造成资源浪费（如果类加载后就一直不使用单例的话）。 值得注意的时，单线程环境下，饿汉与饱汉在性能上没什么差别；但多线程环境下，由于饱汉需要加锁，饿汉的性能反而更优。 Holder模式我们既希望利用饿汉模式中静态变量的方便和线程安全；又希望通过懒加载规避资源浪费。Holder模式满足了这两点要求：核心仍然是静态变量，足够方便和线程安全；通过静态的Holder类持有真正实例，间接实现了懒加载。 123456789101112131415// Holder模式// ThreadSafepublic class Singleton3 { private static class SingletonHolder { private static final Singleton3 singleton = new Singleton3(); private SingletonHolder() { } } private Singleton3() { } public static Singleton3 getInstance() { return SingletonHolder.singleton; }} 相对于饿汉模式，Holder模式仅增加了一个静态内部类的成本，与饱汉的变种3效果相当（略优），都是比较受欢迎的实现方式。同样建议考虑。 枚举模式用枚举实现单例模式，相当好用，但可读性是不存在的。 基础的枚举将枚举的静态成员变量作为单例的实例： 12345// 枚举// ThreadSafepublic enum Singleton4 { SINGLETON;} 代码量比饿汉模式更少。但用户只能直接访问实例Singleton4.SINGLETON——事实上，这样的访问方式作为单例使用也是恰当的，只是牺牲了静态工厂方法的优点，如无法实现懒加载。 丑陋但好用的语法糖Java的枚举是一个“丑陋但好用的语法糖”。 枚举型单例模式的本质通过反编译（jad，源码|String拼接操作”+”的优化？也用到了）打开语法糖，就看到了枚举类型的本质，简化如下： 1234567// 枚举// ThreadSafepublic class Singleton4 extends Enum&lt;Singleton4&gt; { ... public static final Singleton4 SINGLETON = new Singleton4(); ...} 本质上和饿汉模式相同，区别仅在于公有的静态成员变量。 用枚举实现一些trick这一部分与单例没什么关系，可以跳过。如果选择阅读也请认清这样的事实：虽然枚举相当灵活，但如何恰当的使用枚举有一定难度。一个足够简单的典型例子是TimeUnit类，建议有时间耐心阅读。 上面已经看到，枚举型单例的本质仍然是一个普通的类。实际上，我们可以在枚举型型单例上增加任何普通类可以完成的功能。要点在于枚举实例的初始化，可以理解为实例化了一个匿名内部类。为了更明显，我们在Singleton4_1中定义一个普通的私有成员变量，一个普通的公有成员方法，和一个公有的抽象成员方法，如下： 123456789101112131415161718192021// 枚举// ThreadSafepublic enum Singleton4_1 { SINGLETON(&quot;enum is the easiest singleton pattern, but not the most readable&quot;) { public void testAbsMethod() { print(); System.out.println(&quot;enum is ugly, but so flexible to make lots of trick&quot;); } }; private String comment = null; Singleton4_1(String comment) { this.comment = comment; } public void print() { System.out.println(&quot;comment=&quot; + comment); } abstract public void testAbsMethod(); public static Singleton4_1 getInstance() { return SINGLETON; }} 这样，枚举类Singleton4_1中的每一个枚举实例不仅继承了父类Singleton4_1的成员方法print()，还必须实现父类Singleton4_1的抽象成员方法testAbsMethod()。 总结上面的分析都忽略了反射和序列化的问题。通过反射或序列化，我们仍然能够访问到私有构造器，创建新的实例破坏单例模式。此时，只有枚举模式能天然防范这一问题。反射和序列化猴子还不太了解，但基本原理并不难，可以在其他模式上手动实现。 下面继续忽略反射和序列化的问题，做个总结回味一下： 实现方式 关键点 资源浪费 线程安全 多线程环境的性能足够优化 基础饱汉 懒加载 否 否 - 饱汉变种1 懒加载、同步 否 是 否 饱汉变种2 懒加载、DCL 否 否 - 饱汉变种3 懒加载、DCL、volatile 否 是 是 饿汉 静态变量初始化 是 是 是 Holder 静态变量初始化、holder 否 是 是 枚举 枚举本质、静态变量初始化 否 是 是","link":"/2021/09/23/java/java-singleton/"},{"title":"linux 常用命令","text":"将 文件分割123$ split -b 100M -d node01.zip$ lsnode01.zip x00 x01 x02 参数详情 参 数 描述 -b 100M 分割文件大小为 100MB -d 加上该参数后，分割后的文件将使用数字后缀；反之，分割文件名将是字母后缀。详情见下表。 分割文件格式 类型 样例 数字后缀 x01 x02 x03 字母后缀 xaa xab xac 分割文件传输将分割文件传输至本地保存 分割文件合并该步骤样例在 Windows 10 上的 CMD 运行。（ * 使用 PowerShell 可能导致运行失败） 1234567C:\\dump&gt;copy /b x* node01.zipx00x01x02Copied 1 fileC:\\dump&gt;dirnode01.zip x00 x01 x02 这样就在本地获得了服务器中的 文件 拷贝文件 SCP123456# 拷贝本地文件到远程scp xxx.txt root@{ip/hosts}:/root# 拷贝远程文件到本地scp root@{ip/hosts}:/root/xxx.txt /root top 命令1234567891011# d：指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。# p:通过指定监控进程ID来仅仅监控某个进程的状态。# q:该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。# S：指定累计模式。# s：使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。# i：使top不显示任何闲置或者僵死进程。# c:显示整个命令行而不只是显示命令名。top -H -b -d 1 -n 200 &gt; top.txt# -p : 通过监控进程ID来仅仅监控某个进程的状态top -p {pid}# -i ： 不显示任何闲置或僵死的进程 free12free -mfree -h jmap123# 查看堆内存使用情况jmap -heap {pid} netstat 123456789101112131415# -a (all)显示所有选项，默认不显示LISTEN相关# -t (tcp)仅显示tcp相关选项# -u (udp)仅显示udp相关选项# -n 拒绝显示别名，能显示数字的全部转化成数字。# -l 仅列出有在 Listen (监听) 的服務状态# -p 显示建立相关链接的程序名# -r 显示路由信息，路由表# -e 显示扩展信息，例如uid等# -s 按各个协议进行统计# -c 每隔一个固定时间，执行该netstat命令。netstat -ltnpnetstat -ano | findstr &quot;6379&quot; cat 日志查询123456789# 1. 查询日志中关键字cat -n summer.log | grep &quot;关键字&quot; | wc -l # 2.查询某段时间内的日志sed -n '/start_time/,/end_time/p' summer.log|grep &quot;key words&quot;# set -n '/2021-03-15 01:29:17/,/2021-03-15 02:29:17/p' summer.logwc -l # 统计行数wc -c # 统计字节数wc -l # 统计字数 sed123# sed -n '/start time/,/end time/p' aaa.log | grep &quot;keyword&quot;sed -n '/2021-03-16 01:29:17/,/2021-03-16 02:29:17/p' aa.log | grep &quot;keyword&quot; grep 查看大日志文件123456789101112# A -&gt; After# B -&gt; Before# C -&gt; Contextgrep -A5 'Time: 210607 15:[45-59]' slow3306_9110.log# 匹配多个关键字（且）# 管道符连接 多个条件 实现关键字 且关系 匹配：grep -A5 'Time: 210607 15:[45-59]' slow3306_9110.log | grep 'Query_time: (\\d[2-5])'# 同一行同时满足两个条件（Time、Query_time）才能够匹配。# grep -E 匹配多个关键字（或）grep -E &quot;word1|word2|word3&quot; file.txt# 匹配文件中 同一行包含 word1、word2、word3 之一 tar 压缩、解压123456789# -c: 打包 把 /conf/xxx.* 打包到 xxx.tar.gztar czvf xxx.tar.gz /conf/xxx.*# -x: 解压缩 tar xzvf xxx.tar.gz# -z: gzip 压缩格式# -v: 显示打包guoch# -f：显示打包名称 linux 重启hosts12sudo /etc/init.d/network restart linux 文件属性、权限123456789101112131415# 修改文件属主、组chown -R lch.lch /usr/localchgrp -R lch /usr/local# 修改 u g o 权限chomd g=rwx 1.txtchomd u=rwx 1.txtchomd o=rwx 1.txt# 增加shell 执行权限chmod +x xxx.sh# 修改用户的组usermod -g root lchuserdel -R lch add user123456adduser '用户名'passwd '用户名'chmod -v u+w /etc/sudoersvim /etc/sudoers 找到Allow root to run any commands anywhere之后添加一行 1'用户名' ALL=(ALL) ALL 如需新用户使用sudo时不用输密码，把最后一个ALL改为NOPASSWD:ALL即可 delete user1sudo userdel '用户名' list user123less /etc/passwdcut -d: -f1 /etc/passwd. firewall1sudo systemctl status firewalld 1sudo firewall-cmd --zone=public --add-port=3306/tcp --permanent 1sudo firewall-cmd --reload 1sudo firewall-cmd --list-all 1234567891011121314151617181920212223启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed配置firewalld-cmd查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic ab testapach AB test1234# -n: 执行的请求数# -c: 并发数ab -c10 -n100 http://www.baidu.com/","link":"/2021/09/27/linux/linux-cmd/"},{"title":"Linux 组调度","text":"参考文章 Linux 组调度浅析 Linux内核之实时进程调度和组调度","link":"/2021/09/24/linux/linux-cgroup/"},{"title":"基于Zookeeper搭建Kafka高可用集群","text":"install zookeeper/kafka cluster 一、Zookeeper集群搭建为保证集群高可用，Zookeeper 集群的节点数最好是奇数，最少有三个节点，所以这里搭建一个三个节点的集群。 1.1 下载 &amp; 解压下载对应版本 Zookeeper，这里我下载的版本 3.4.14。官方下载地址：https://archive.apache.org/dist/zookeeper/ 1234# 下载wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz# 解压tar -zxvf zookeeper-3.4.14.tar.gz 1.2 修改配置拷贝三份 zookeeper 安装包。分别进入安装目录的 conf 目录，拷贝配置样本 zoo_sample.cfg 为 zoo.cfg 并进行修改，修改后三份配置文件内容分别如下： zookeeper01 配置： 123456789101112tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/01dataLogDir=/usr/local/zookeeper-cluster/log/01clientPort=2181# server.1 这个1是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到dataDir目录下面myid文件里# 指名集群间通讯端口和选举端口server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 如果是多台服务器，则集群中每个节点通讯端口和选举端口可相同，IP 地址修改为每个节点所在主机 IP 即可。 zookeeper02 配置，与 zookeeper01 相比，只有 dataLogDir、dataLogDir 和 clientPort 不同： 12345678910tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/02dataLogDir=/usr/local/zookeeper-cluster/log/02clientPort=2182server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 zookeeper03 配置，与 zookeeper01，02 相比，也只有 dataLogDir、dataLogDir 和 clientPort 不同： 12345678910tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/03dataLogDir=/usr/local/zookeeper-cluster/log/03clientPort=2183server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 配置参数说明： tickTime：用于计算的基础时间单元。比如 session 超时：N*tickTime； initLimit：用于集群，允许从节点连接并同步到 master 节点的初始化连接时间，以 tickTime 的倍数来表示； syncLimit：用于集群， master 主节点与从节点之间发送消息，请求和应答时间长度（心跳机制）； dataDir：数据存储位置； dataLogDir：日志目录； clientPort：用于客户端连接的端口，默认 2181 1.3 标识节点分别在三个节点的数据存储目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 leader 节点。 创建存储目录： 123456# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/01# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/02# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/03 创建并写入节点标识到 myid 文件： 123456#server1echo &quot;1&quot; &gt; /usr/local/zookeeper-cluster/data/01/myid#server2echo &quot;2&quot; &gt; /usr/local/zookeeper-cluster/data/02/myid#server3echo &quot;3&quot; &gt; /usr/local/zookeeper-cluster/data/03/myid 1.4 启动集群分别启动三个节点： 123456# 启动节点1/usr/app/zookeeper-cluster/zookeeper01/bin/zkServer.sh start# 启动节点2/usr/app/zookeeper-cluster/zookeeper02/bin/zkServer.sh start# 启动节点3/usr/app/zookeeper-cluster/zookeeper03/bin/zkServer.sh start 1.5 集群验证使用 jps 查看进程，并且使用 zkServer.sh status 查看集群各个节点状态。如图三个节点进程均启动成功，并且两个节点为 follower 节点，一个节点为 leader 节点。 二、Kafka集群搭建2.1 下载解压Kafka 安装包官方下载地址：http://kafka.apache.org/downloads ，本用例下载的版本为 2.2.0，下载命令： 1234# 下载wget https://www-eu.apache.org/dist/kafka/2.2.0/kafka_2.12-2.2.0.tgz# 解压tar -xzf kafka_2.12-2.2.0.tgz 这里解释一下 kafka 安装包的命名规则：以 kafka_2.12-2.2.0.tgz 为例，前面的 2.12 代表 Scala 的版本号（Kafka 采用 Scala 语言进行开发），后面的 2.2.0 则代表 Kafka 的版本号。 2.2 拷贝配置文件进入解压目录的 config 目录下 ，拷贝三份配置文件： 123# cp server.properties server-1.properties# cp server.properties server-2.properties# cp server.properties server-3.properties 2.3 修改配置分别修改三份配置文件中的部分配置，如下： server-1.properties： 12345678# The id of the broker. 集群中每个节点的唯一标识broker.id=0# 监听地址listeners=PLAINTEXT://hadoop001:9092# 数据的存储位置log.dirs=/usr/local/kafka-logs/00# Zookeeper连接地址zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 server-2.properties： 1234broker.id=1listeners=PLAINTEXT://hadoop001:9093log.dirs=/usr/local/kafka-logs/01zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 server-3.properties： 1234broker.id=2listeners=PLAINTEXT://hadoop001:9094log.dirs=/usr/local/kafka-logs/02zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 这里需要说明的是 log.dirs 指的是数据日志的存储位置，确切的说，就是分区数据的存储位置，而不是程序运行日志的位置。程序运行日志的位置是通过同一目录下的 log4j.properties 进行配置的。 2.4 启动集群分别指定不同配置文件，启动三个 Kafka 节点。启动后可以使用 jps 查看进程，此时应该有三个 zookeeper 进程和三个 kafka 进程。 123bin/kafka-server-start.sh config/server-1.propertiesbin/kafka-server-start.sh config/server-2.propertiesbin/kafka-server-start.sh config/server-3.properties 2.5 创建测试主题创建测试主题： 123bin/kafka-topics.sh --create --bootstrap-server hadoop001:9092 \\ --replication-factor 3 \\ --partitions 1 --topic my-replicated-topic 创建后可以使用以下命令查看创建的主题信息： 1bin/kafka-topics.sh --describe --bootstrap-server hadoop001:9092 --topic my-replicated-topic 可以看到分区 0 的有 0,1,2 三个副本，且三个副本都是可用副本，都在 ISR(in-sync Replica 同步副本) 列表中，其中 1 为首领副本，此时代表集群已经搭建成功。 参考文章 Kafka集群搭建 基于Zookeeper搭建Kafka高可用集群","link":"/2021/12/15/kafka/kafka-cluster/"},{"title":"linux内核分析——CFS（完全公平调度算法）","text":"参考文章 CFS（完全公平调度算法） Linux进程调度策略（CFS调度）详解 [Linux][Power]CFS调度策略 Linux完全公平调度算法原理与实现 Linux进程调度：完全公平调度器CFS 基本介绍 在 2.5 版本之前，Linux 内核采用传统 UNIX 调度算法。 在内核 V2.5 中，调度程序进行了大改，采用了称为 O(1) 的调度算法，它的运行时间为常量，与系统内任务数量无关。 在内核 V2.6 的开发中，调度程序再次修改；在内核 V2.6.23 的发布中，完全公平调度程序（CFS）成为默认的 Linux 调度算法。 Linux 系统的调度基于调度类。每个类都有一个特定优先级。内核针对不同的调度类，采用不同的调度算法，以便满足系统与进程的需要。Linux 标准内核实现两个调度类：采用 CFS 调度算法的 默认调度类和实时调度类。 CFS 调度程序并不采用严格规则来为一个优先级分配某个长度的时间片，而是为每个任务分配一定比例的 CPU 处理时间。每个任务分配的具体比例是根据友好值来计算的。友好值的范围从 -20 到 +19，数值较低的友好值表示较高的相对优先级。具有较低友好值的任务，与具有较高友好值的任务相比，会得到更高比例的处理器处理时间。默认友好值为 0。 友好一词源自如下想法：当一个任务增加了它的友好值，如从 0 至 +10，该任务通过降低优先级，进而对其他任务更加友好。 CFS 没有使用离散的时间片，而是采用目标延迟，这是每个可运行任务应当运行一次的时间间隔。根据目标延迟，按比例分配 CPU 时间。除了默认值和最小值外，随着系统内的活动任务数量超过了一定阈值，目标延迟可以增加。 CFS 调度程序没有直接分配优先级。相反，它通过每个任务的变量 vruntime 以便维护虚拟运行时间，进而记录每个任务运行多久。虚拟运行时间与基于任务优先级的衰减因子有关，更低优先级的任务比更高优先级的任务具有更高衰减速率。对于正常优先级的任务（友好值为 0），虚拟运行时间与实际物理运行时间是相同的。 因此，如果一个默认优先级的任务运行 200ms，则它的虚拟运行时间也为 200ms。然而，如果一个较低优先级的任务运行 200ms，则它的虚拟运行时间将大于 200ms。同样，如果一个更高优先级的任务运行 200ms，则它的虚拟运行时间将小于 200ms。当决定下步运行哪个任务时，调度程序只需选择具有最小虚拟运行时间的任务。此外，一个更高优先级的任务如成为可运行，就会抢占低优先级任务。 下面分析一下 CFS 调度程序是如何工作的。假设有两个任务，它们具有相同的友好值。一个任务是 I/O 密集型而另一个为 CPU 密集型。通常，I/O 密集型任务在运行很短时间后就会阻塞以便等待更多的 I/O；而 CPU 密集型任务只要有在处理器上运行的机会，就会用完它的时间片。 因此，I/O 密集型任务的虚拟运行时间最终将会小于 CPU 密集型任务的，从而使得 I/O 密集型任务具有更高的优先级。这时，如果 CPU 密集型任务在运行，而 I/O 密集型任务变得有资格可以运行（如该任务所等待的 I/O 已成为可用)，那么 I/O 密集型任务就会抢占 CPU 密集型任务。 Linux 也实现了实时调度。采用 SCHED_FIFO 或 SCHED_RR 实时策略来调度的任何任务，与普通（非实时的）任务相比，具有更高的优先级。 Linux 采用两个单独的优先级范围，一个用于实时任务，另一个用于正常任务。实时任务分配的静态优先级为 0〜99，而正常任务分配的优先级为 100〜139。 这两个值域合并成为一个全局的优先级方案，其中较低数值表明较高的优先级。正常任务，根据它们的友好值，分配一个优先级；这里 -20 的友好值映射到优先级 100，而 +19 的友好 1.1 CFS原理cfs定义了一种新的模型，它给cfs_rq（cfs的run queue）中的每一个进程安排一个虚拟时钟，vruntime。如果一个进程得以执行，随着时间的增长（也就是一个个tick的到来），其vruntime将不断增大。没有得到执行的进程vruntime不变。而调度器总是选择vruntime跑得最慢的那个进程来执行。这就是所谓的“完全公平”。为了区别不同优先级的进程，优先级高的进程vruntime增长得慢，以至于它可能得到更多的运行机会。 1.2 CFS基本设计思路CFS思路很简单，就是根据各个进程的权重分配运行时间(权重怎么来的后面再说)。 进程的运行时间计算公式为: 分配给进程的运行时间 = 调度周期 * 进程权重 / 所有进程权重之和 (公式1) 调度周期: 将所有处于TASK_RUNNING态进程都调度一遍的时间,差不多相当于O(1)调度算法中运行队列和过期队列切换一次的时间。 举个例子，比如只有两个进程A, B，权重分别为1和2，调度周期设为30ms，那么分配给A的CPU时间为:30ms * (1/(1+2)) = 10ms；而B的CPU时间为：30ms * (2/(1+2)) = 20ms。那么在这30ms中A将运行10ms，B将运行20ms。 公平怎么体现呢？它们的运行时间并不一样阿？其实公平是体现在另外一个量上面，叫做**virtual runtime(vruntime)**，它记录着进程已经运行的时间，但是并不是直接记录，而是要根据进程的权重将运行时间放大或者缩小一个比例。我们来看下从实际运行时间到vruntime的换算公式 vruntime = 实际运行时间 * 1024 / 进程权重 。 (公式2) 为了不把大家搞晕，这里我直接写1024，实际上它等于nice为0的进程的权重，代码中是NICE_0_LOAD。也就是说，所有进程都以nice为0的进程的权重1024作为基准，计算自己的vruntime增加速度。 还以上面AB两个进程为例，B的权重是A的2倍，那么B的vruntime增加速度只有A的一半。 现在我们把公式2中的实际运行时间用公式1来替换，可以得到这么一个结果： vruntime = (调度周期 * 进程权重 / 所有进程总权重) * 1024 / 进程权重 = 调度周期 * 1024 / 所有进程总权重 看出什么眉目没有？没错，虽然进程的权重不同，但是它们的 vruntime增长速度应该是一样的 ，与权重无关。好，既然所有进程的vruntime增长速度宏观上看应该是同时推进的， 那么就可以用这个vruntime来选择运行的进程，谁的vruntime值较小就说明它以前占用cpu的时间较短，受到了“不公平”对待，因此下一个运行进程就是它。这样既能公平选择进程，又能保证高优先级进程获得较多的运行时间。这就是CFS的主要思想了。 或者可以这么理解：CFS的思想就是让每个调度实体（没有组调度的情形下就是进程，以后就说进程了）的vruntime互相追赶，而每个调度实体的vruntime增加速度不同，权重越大的增加的越慢，这样就能获得更多的cpu执行时间。 再补充一下权重的来源，权重跟进程nice值之间有一一对应的关系，可以通过全局数组prio_to_weight来转换，nice值越大，权重越低。 1.3 CFS数据结构介绍代码之前先介绍一下CFS相关的结构第一个是调度实体sched_entity，它代表一个调度单位，在组调度关闭的时候可以把他等同为进程。每一个task_struct中都有一个sched_entity，进程的vruntime和权重都保存在这个结构中。那么所有的sched_entity怎么组织在一起呢？红黑树。所有的sched_entity以vruntime为key(实际上是以vruntime - min_vruntime为key，是为了防止溢出， 反正结果是一样的)插入到红黑树中，同时缓存树的最左侧节点，也就是vruntime最小的节点，这样可以迅速选中vruntime最小的进程。注意只有等待CPU的就绪态进程在这棵树上，睡眠进程和正在运行的进程都不在树上。 红黑树： 红黑树是自平衡的，没有路径比其它任何路径长两倍以上。树上运行按O(log n)时间发生（n是树中节点的数量），可以快速高效的插入或者删除任务。 任务存储在以时间为顺序的红黑树中（由 sched_entity 对象表示），对处理器需求最多的任务 （最低虚拟运行时）存储在树的左侧，处理器需求最少的任务（最高虚拟运行时）存储在树的右侧。为了公平，调度器然后选取红黑树最左端的节点调度为下一个以便保持公平性。任务通过将其运行时间添加到虚拟运行时，说明其占用 CPU 的时间，然后如果可运行，再插回到树中。这样，树左侧的任务就被给予时间运行了，树的内容从右侧迁移到左侧以保持公平。 因此，每个可运行的任务都会追赶其他任务以维持整个可运行任务集合的执行平衡。 1.4 Vruntime溢出问题之前说过红黑树中实际的作为key的不是vruntime而是vruntime - min_vruntime。min_vruntime是当前红黑树中最小的key。这是为什么呢，我们先看看vruntime的类型，是usigned long类型的，再看看key的类型，是signed long类型的，因为进程的虚拟时间是一个递增的正值，因此它不会是负数，但是它有它的上限，就是unsigned long所能表示的最大值，如果溢出了，那么它就会从0开始回滚，如果这样的话，结果会怎样？结果很严重啊，就是说会本末倒置的，比如以下例子，以unsigned char说明问题： 123unsigned char a = 251, b = 254;b += 5;//到此判断a和b的大小 看看上面的例子，b回滚了，导致a远远大于b，其实真正的结果应该是b比a大8，怎么做到真正的结果呢？改为以下： 12345unsigned char a = 251, b = 254;b += 5;signed char c = a - 250,d = b - 250;//到此判断c和d的大小 结果正确了，要的就是这个效果，可是进程的vruntime怎么用unsigned long类型而不处理溢出问题呢？因为这个vruntime的作用就是推进虚拟时钟，并没有别的用处，它可以不在乎，然而在计算红黑树的key的时候就不能不在乎了，于是减去一个最小的vruntime将所有进程的key围绕在最小vruntime的周围，这样更加容易追踪。运行队列的min_vruntime的作用就是处理溢出问题的。 1.5 组调度引入组调度是为了实现做一件事的一组进程与做另一件事的另一组进程的隔离。每件“事情”各自有自己的权重，而不管它需要使用多少进程来完成。在cfs中，task_group和进程是同等对待的，task_group的优先级也由用户来控制（通过cgroup文件cpu.shares）。实现上，task_group和进程都被抽象成schedule_entity（调度实体，以下简称se），上面说到的vruntime、load、等这些东西都被封装在se里面。而task_group除了有se之外，还有cfs_rq。属于这个task_group的进程就被装在它的cfs_rq中（“组”不仅是一个被调度的实体，也是一个容器）。组调度引入以后，一系列task_group的cfs_rq组成了一个树型结构。树根是cpu所对应的cfs_rq（也就是root group的cfs_rq）、树的中间节点是各个task_group的cfs_rq、 叶子节点是各个进程。在一个task_group的两头，是两个不同的世界，就像《盗梦空间》里不同层次的梦境一样。 1.6 CFS小结CFS还有一个重要特点，即调度粒度小。CFS之前的调度器中，除了进程调用了某些阻塞函数而主动参与调度之外，每个进程都只有在用完了时间片或者属于自己的时间配额之后才被抢占。而CFS则在每次tick都进行检查，如果当前进程不再处于红黑树的左边，就被抢占。在高负载的服务器上，通过调整调度粒度能够获得更好的调度性能。","link":"/2021/09/23/linux/linux_cfs/"},{"title":"nodejs httpserver","text":"1touch time.js 1234567891011121314151617181920212223242526272829303132333435var http = require(&quot;http&quot;);var sleep = require('system-sleep');var server = http.createServer(function (req, res) { var requestBody = &quot;&quot;; req.on('data', function(chunk) { requestBody += chunk; }); req.on('end', function() { var request = req.method + &quot; &quot; + req.url + &quot;\\n\\n&quot;; var hrTime = process.hrtime(); request += (hrTime[0] * 1000000 + hrTime[1] / 1000); request += &quot;\\n\\n&quot;; res.setHeader('Content-Type', 'application/json'); res.setHeader('X-QUOTA', '100'); res.setHeader('Access-Control-Allow-Origin','*'); if (req.url != &quot;/&quot;) { console.log(request); } if (req.url != &quot;/no-end-response&quot;){ res.end(request); } }); req.on('error', function(err) { console.log(err); });});server.listen(9999);server.timeout = 400000 12touch run_time_server.sh 1234#!/bin/shpkill nodenode --max-old-space-size=2048 time.js &amp; 12## run time server./run_time_server.sh 参考文章","link":"/2021/11/17/javascript/nodejs-httpserver/"},{"title":"在Windows下安装使用Kafka","text":"123456cd xxxx\\kafka\\bin\\windows# start zookeeper.\\zookeeper-server-start.bat ..\\..\\config\\zookeeper.properties# start kafka.\\kafka-server-start.bat ..\\..\\config\\server.properties 下载地址创建一个主题1.\\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafka-test-topic 查看创建的主题列表1.\\kafka-topics.bat --list --zookeeper localhost:2181 启动生产者：1.\\kafka-console-producer.bat --broker-list localhost:9092 --topic kafka-test-topic 启动消费者：1.\\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic kafka-test-topic --from-beginning 参考文章 在Windows下安装使用Kafka kafka quick start kafka 在windows 平台的搭建和简单实用 Kafka集群搭建","link":"/2021/12/15/kafka/kafka-windows-install/"},{"title":"select...for update","text":"作用：select for update 是为了在查询时,避免其他用户以该表进行插入,修改或删除等操作,造成表的不一致性.该语句用来锁定特定的行（如果有where子句，就是满足where条件的那些行）。当这些行被锁定后，其他会话可以选择这些行，但不能更改或删除这些行，直到该语句的事务被commit语句或rollback语句结束为止。 for update的使用场景如果遇到存在高并发并且对于数据的准确性很有要求的场景，是需要了解和使用for update的。 比如涉及到金钱、库存等。一般这些操作都是很长一串并且是开启事务的。如果库存刚开始读的时候是1，而立马另一个进程进行了update将库存更新为0了，而事务还没有结束，会将错的数据一直执行下去，就会有问题。所以需要for upate 进行数据加锁防止高并发时候数据出错。 记住一个原则：一锁二判三更新 SELECT…FOR UPDATE 语句的语法如下：12345SELECT ... FOR UPDATE [OF column_list][WAIT n|NOWAIT][SKIP LOCKED];-- 其中：-- OF 子句用于指定即将更新的列，即锁定行上的特定列。-- WAIT 子句指定等待其他用户释放锁的秒数，防止无限期的等待。 使用”FOR UPDATE WAIT”子句的优点如下： 1 防止无限期地等待被锁定的行； 2 允许应用程序中对锁的等待时间进行更多的控制。 3 对于交互式应用程序非常有用，因为这些用户不能等待不确定 4 若使用了skip locked，则可以越过锁定的行，不会报告由wait n 引发的‘资源忙’异常报告 For Example: select * from t for update 会等待行锁释放之后，返回查询结果。 select * from t for update nowait 不等待行锁释放，提示锁冲突，不返回结果 select * from t for update wait 5 等待5秒，若行锁仍未释放，则提示锁冲突，不返回结果 select * from t for update skip locked 查询返回查询结果，但忽略有行锁的记录 排他锁的申请前提没有线程对该结果集中的任何行数据使用排他锁或共享锁，否则申请会阻塞。 for update仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。 场景分析假设有一张商品表 goods，它包含 id，商品名称，库存量三个字段，表结构如下： 1234567CREATE TABLE `goods` (`id` int(11) NOT NULL AUTO_INCREMENT,`name` varchar(100) DEFAULT NULL,`stock` int(11) DEFAULT NULL,PRIMARY KEY (`id`),UNIQUE KEY `idx_name` (`name`) USING HASH) ENGINE=InnoDB 插入如下数据： 123456789INSERT INTO `goods` VALUES ('1', 'prod11', '1000');INSERT INTO `goods` VALUES ('2', 'prod12', '1000');INSERT INTO `goods` VALUES ('3', 'prod13', '1000');INSERT INTO `goods` VALUES ('4', 'prod14', '1000');INSERT INTO `goods` VALUES ('5', 'prod15', '1000');INSERT INTO `goods` VALUES ('6', 'prod16', '1000');INSERT INTO `goods` VALUES ('7', 'prod17', '1000');INSERT INTO `goods` VALUES ('8', 'prod18', '1000');INSERT INTO `goods` VALUES ('9', 'prod19', '1000'); 一、数据一致性假设有A、B两个用户同时各购买一件 id=1 的商品，用户A获取到的库存量为 1000，用户B获取到的库存量也为 1000，用户A完成购买后修改该商品的库存量为 999，用户B完成购买后修改该商品的库存量为 999，此时库存量数据产生了不一致。 有两种解决方案： 悲观锁方案： 每次获取商品时，对该商品加排他锁。也就是在用户A获取获取 id=1 的商品信息时对该行记录加锁，期间其他用户阻塞等待访问该记录。悲观锁适合写入频繁的场景。 1234begin;select * from goods where id = 1 for update;update goods set stock = stock - 1 where id = 1;commit; 乐观锁方案： 每次获取商品时，不对该商品加锁。在更新数据的时候需要比较程序中的库存量与数据库中的库存量是否相等，如果相等则进行更新，反之程序重新获取库存量，再次进行比较，直到两个库存量的数值相等才进行数据更新。乐观锁适合读取频繁的场景。 123456#不加锁获取 id=1 的商品对象select * from goods where id = 1begin;#更新 stock 值，这里需要注意 where 条件 “stock = cur_stock”，只有程序中获取到的库存量与数据库中的库存量相等才执行更新update goods set stock = stock - 1 where id = 1 and stock = cur_stock;commit; 如果我们需要设计一个商城系统，该选择以上的哪种方案呢？ 查询商品的频率比下单支付的频次高，基于以上我可能会优先考虑第二种方案（当然还有其他的方案，这里只考虑以上两种方案）。 二、行锁与表锁InnoDB默认是行级别的锁，当有明确指定的主键时候，是行级锁。否则是表级别。 for update的注意点 for update 仅适用于InnoDB，并且必须开启事务，在begin与commit之间才生效。 要测试for update的锁表情况，可以利用MySQL的Command Mode，开启二个视窗来做测试。 1、只根据主键进行查询，并且查询到数据，主键字段产生行锁。 123begin;select * from goods where id = 1 for update;commit; 2、只根据主键进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 for update;commit; 3、根据主键、非主键含索引（name）进行查询，并且查询到数据，主键字段产生行锁，name字段产生行锁。 123begin;select * from goods where id = 1 and name='prod11' for update;commit; 4、根据主键、非主键含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 and name='prod12' for update;commit; 5、根据主键、非主键不含索引（name）进行查询，并且查询到数据，如果其他线程按主键字段进行再次查询，则主键字段产生行锁，如果其他线程按非主键不含索引字段进行查询，则非主键不含索引字段产生表锁，如果其他线程按非主键含索引字段进行查询，则非主键含索引字段产生行锁，如果索引值是枚举类型，mysql也会进行表锁，这段话有点拗口，大家仔细理解一下。 123begin;select * from goods where id = 1 and name='prod11' for update;commit; 6、根据主键、非主键不含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 and name='prod12' for update;commit; 7、根据非主键含索引（name）进行查询，并且查询到数据，name字段产生行锁。 123begin;select * from goods where name='prod11' for update;commit; 8、根据非主键含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where name='prod11' for update;commit; 9、根据非主键不含索引（stock）进行查询，并且查询到数据，stock字段产生表锁。 123begin;select * from goods where stock='1000' for update;commit; 10、根据非主键不含索引（stock）进行查询，没有查询到数据，stock字段产生表锁。 123begin;select * from goods where stock='2000' for update;commit; 11、只根据主键进行查询，查询条件为不等于，并且查询到数据，主键字段产生表锁。 123begin;select * from goods where id &lt;&gt; 1 for update;commit; 12、只根据主键进行查询，查询条件为不等于，没有查询到数据，主键字段产生表锁。 123begin;select * from goods where id &lt;&gt; 1 for update;commit; 13、只根据主键进行查询，查询条件为 like，并且查询到数据，主键字段产生表锁。 123begin;select * from goods where id like '1' for update;commit; 14、只根据主键进行查询，查询条件为 like，没有查询到数据，主键字段产生表锁。 123begin;select * from goods where id like '1' for update;commit; 测试环境数据库版本：5.1.48-community数据库引擎：InnoDB Supports transactions, row-level locking, and foreign keys数据库隔离策略：REPEATABLE-READ（系统、会话） 总结1、InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。 2、由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。 3、当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 4、即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 5、检索值的数据类型与索引字段不同，虽然MySQL能够进行数据类型转换，但却不会使用索引，从而导致InnoDB使用表锁。通过用explain检查两条SQL的执行计划，我们可以清楚地看到了这一点。 参考文章 https://blog.csdn.net/ll594317566/article/details/103869619 https://zhuanlan.zhihu.com/p/143866444 https://www.cnblogs.com/wxgblogs/p/6849064.html","link":"/2021/10/26/mysql/mysql-select-for-update/"},{"title":"mysql 数据库事务","text":"事务四大属性原子性（Atomicity）事务包含的所有操作要么全部成功，要么全部失败回滚 一致性（Consistency）一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。举例来说，假设用户A和用户B两者的钱加起来一共是1000，那么不管A和B之间如何转账、转几次账，事务结束后两个用户的钱相加起来应该还得是1000，这就是事务的一致性。 隔离性（Isolation）隔离性是当多个用户并发访问数据库时，比如同时操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性（Durability）持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务已经正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成。否则的话就会造成我们虽然看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。这是不允许的。 事务的隔离级别现在来看看MySQL数据库为我们提供的四种隔离级别： 1234 ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 为什么要设置隔离级别在数据库操作中，在并发的情况下可能出现如下问题： 更新丢失（Lost update）如果多个线程操作，基于同一个查询结构对表中的记录进行修改，那么后修改的记录将会覆盖前面修改的记录，前面的修改就丢失掉了，这就叫做更新丢失。这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来。 第1类丢失更新：事务A撤销时，把已经提交的事务B的更新数据覆盖了。 第2类丢失更新：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。 解决方法：对行加锁，只允许并发一个更新事务。 脏读（Dirty Reads）脏读（Dirty Read）：A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。 解决办法：如果在第一个事务提交前，任何其他事务不可读取其修改过的值，则可以避免该问题。 不可重复读（Non-repeatable Reads）一个事务对同一行数据重复读取两次，但是却得到了不同的结果。事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值。 解决办法：如果只有在修改事务完全提交之后才可以读取数据，则可以避免该问题。 幻象读指两次执行同一条 select 语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中。一般情况下，幻象读应该正是我们所需要的。但有时候却不是，如果打开的游标，在对游标进行操作时，并不希望新增的记录加到游标命中的数据集中来。隔离级别为 游标稳定性 的，可以阻止幻象读。例如：目前工资为1000的员工有10人。那么事务1中读取所有工资为1000的员工，得到了10条记录；这时事务2向员工表插入了一条员工记录，工资也为1000；那么事务1再次读取所有工资为1000的员工共读取到了11条记录。 解决办法：如果在操作事务完成数据处理之前，任何其他事务都不可以添加新数据，则可避免该问题。 正是为了解决以上情况，数据库提供了几种隔离级别。 事务的隔离级别数据库事务的隔离级别有4个，由低到高依次为Read uncommitted(未授权读取、读未提交)、Read committed（授权读取、读提交）、Repeatable read（可重复读取）、Serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻象读这几类问题。 Read uncommitted(未授权读取、读未提交)：如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。Read committed（授权读取、读提交）：读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。 Repeatable read（可重复读取）：可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。 Serializable（序列化）：提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed。它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读和第二类丢失更新这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。MySQL的默认隔离级别就是Repeatable read。 悲观锁和乐观锁虽然数据库的隔离级别可以解决大多数问题，但是灵活度较差，为此又提出了悲观锁和乐观锁的概念。 悲观锁悲观锁，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度。因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制。也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统的数据访问层中实现了加锁机制，也无法保证外部系统不会修改数据。 使用场景举例：以MySQL InnoDB为例 商品t_items表中有一个字段status，status为1代表商品未被下单，status为2代表商品已经被下单（此时该商品无法再次下单），那么我们对某个商品下单时必须确保该商品status为1。假设商品的id为1。如果不采用锁，那么操作方法如下： 123456//1.查询出商品信息select status from t_items where id=1;//2.根据商品信息生成订单,并插入订单表 t_orders insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_items set status=2; 但是上面这种场景在高并发访问的情况下很可能会出现问题。例如当第一步操作中，查询出来的商品status为1。但是当我们执行第三步Update操作的时候，有可能出现其他人先一步对商品下单把t_items中的status修改为2了，但是我们并不知道数据已经被修改了，这样就可能造成同一个商品被下单2次，使得数据不一致。所以说这种方式是不安全的。 使用悲观锁来解决问题 在上面的场景中，商品信息从查询出来到修改，中间有一个处理订单的过程，使用悲观锁的原理就是，当我们在查询出t_items信息后就把当前的数据锁定，直到我们修改完毕后再解锁。那么在这个过程中，因为t_items被锁定了，就不会出现有第三者来对其进行修改了。需要注意的是，要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。我们可以使用命令设置MySQL为非autocommit模式：set autocommit=0;设置完autocommit后，我们就可以执行我们的正常业务了。具体如下： 12345678910//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select status from t_items where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_items set status=2;//4.提交事务commit;/commit work; 上面的begin/commit为事务的开始和结束，因为在前一步我们关闭了mysql的autocommit，所以需要手动控制事务的提交。上面的第一步我们执行了一次查询操作：select status from t_items where id=1 for update;与普通查询不一样的是，我们使用了select…for update的方式，这样就通过数据库实现了悲观锁。此时在t_items表中，id为1的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。需要注意的是，在事务中，只有SELECT … FOR UPDATE 或LOCK IN SHARE MODE 操作同一个数据时才会等待其它事务结束后才执行，一般SELECT … 则不受此影响。拿上面的实例来说，当我执行select status from t_items where id=1 for update;后。我在另外的事务中如果再次执行select status from t_items where id=1 for update;则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但是如果我是在第二个事务中执行select status from t_items where id=1;则能正常查询出数据，不会受第一个事务的影响。 Row Lock与Table Lock 使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认Row-Level Lock，所以只有「明确」地指定主键或者索引，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。举例如下：1、select * from t_items where id=1 for update; 这条语句明确指定主键（id=1），并且有此数据（id=1的数据存在），则采用row lock。只锁定当前这条数据。2、select * from t_items where id=3 for update; 这条语句明确指定主键，但是却查无此数据，此时不会产生lock（没有元数据，又去lock谁呢？）。3、select * from t_items where name='手机' for update; 这条语句没有指定数据的主键，那么此时产生table lock，即在当前事务提交前整张数据表的所有字段将无法被查询。4、select * from t_items where id&gt;0 for update; 或者select * from t_items where id&lt;&gt;1 for update;（注：&lt;&gt;在SQL中表示不等于）上述两条语句的主键都不明确，也会产生table lock。5、select * from t_items where status=1 for update;（假设为status字段添加了索引）这条语句明确指定了索引，并且有此数据，则产生row lock。6、select * from t_items where status=3 for update;（假设为status字段添加了索引）这条语句明确指定索引，但是根据索引查无此数据，也就不会产生lock。 悲观锁小结 悲观锁并不是适用于任何场景，它也有它存在的一些不足，因为悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。如果加锁的时间过长，其他用户长时间无法访问，影响了程序的并发访问性，同时这样对数据库性能开销影响也很大，特别是对长事务而言，这样的开销往往无法承受。所以与悲观锁相对的，我们有了乐观锁。 乐观锁乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以只会在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回用户错误的信息，让用户决定如何去做。实现乐观锁一般来说有以下2种方式： 使用版本号 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 使用时间戳 乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。 参考文章: https://www.cnblogs.com/limuzi1994/p/9684083.html","link":"/2021/10/19/mysql/mysql-affairs/"},{"title":"Linux 网络协议栈","text":"linux虚拟网络接口 —— 环回接口 lo 参考文章 理解 Linux 网络栈（1）：Linux 网络协议栈简单总结 理解TCP/IP网络栈 Linux 网络栈剖析 Linux网络栈解剖","link":"/2021/12/30/linux/linux-network-stack/"},{"title":"查询SQL具体的执行流程","text":"MySql的整体架构描述 Server层各节点描述Server层中主要由 连接器、查询缓存、解析器/分析器、优化器、执行器 连接器客户端想要对数据库进行操作时，前提是与数据库建立好连接；而连接器就是用来负责跟客户端建立连接、获取权限、维持和管理连接的。 连接方式： 短连接就是操作完毕后，马上close关掉。 长连接可以保持打开，减少服务端创建和释放连接的消耗，后面的程序访问的时候还可以使用这个连接。 一般我们会在连接池中使用长连接。 长连接使用时的注意事项：客户端与服务器建立长连接，默认有效时间是 8小时 ，超过8小时MySql服务器就会将连接断开了，那么客户端再次请求的话，就会报 连接已断开的问题 ；并且保持长连接会消耗内存。长时间不活动的连接，MySQL服务器会断开。 查看长连接的超时时间 12345-- 非交互式超时时间，如 JDBC 程序show global variables like 'wait_timeout'; -- 交互式超时时间，如数据库工具show global variables like' interactive_timeout'; 执行后得到下图结果：默认都是28800秒，8小时 。一般项目中使用的连接池中的连接都是长连接的；（例如：druid、c3p0、dbcp等） 长连接超时断的解决方案 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存MySQL缓存是默认关闭的，也就是说不推荐使用缓存，为什么呢？ MySql为什么默认不开启缓存呢？主要是由于它的使用场景限制的： 缓存中数据存储格式：key（sql语句）-value（数据值）；所以如果SQL语句（key）只要存在一点不同之处就会直接进行数据库查询了； 由于表中的数据不是一成不变的，大多数是经常变化的，而当数据库中的数据变化了，那么相应的与此表相关的缓存数据就需要移除掉； MySQL 8.0 版本直接将查询缓存的整块功能删掉了。 解析器/分析器分析器的工作主要是对要执行的SQL语句进行解析，最终得到抽象语法书，然后再使用预处理器判断抽象语法树中的表是否存在，如果存在的话，在接着判断select投影列字段是否在表中存在等。 词法分析词法分析用于将SQL拆解为不可再分的原子符号，称为Token。并根据不同数据库方言所提供的字典，将其归类为关键字，表达式，字面量和操作符。 语法分析语法分析就是根据词法分析拆解出来的Token（原子符号）将SQL语句转换为抽象语法树。下面就直接举例说明，看一个SQL它的抽象语法书到底长神魔样： SQL语句： 1SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age &gt; 18 然后上面的SQL语句经过词法分析、语法分析后得到的抽象语法书如下：注意，为了便于理解，抽象语法树中的关键字的Token用绿色表示，变量的Token用红色表示，灰色表示需要进一步拆分。 预处理器预处理是用来对生成的 抽象语法树 进行语义校验，语义校验就是对查询的表、select投影列字段进行校验，判断表、字段是否存在等； 优化器优化器的作用：主要是将SQL经过词法解析/语法解析后得到的语法树，通过MySQL的数据字典和统计信息的内容，经过 一系列运算 ，从而得出一个 执行计划 。 在优化过程中，经过的一系列运算是什么呢？下面简单说下： 逻辑变换：例如SQL的where条件中存在 8&gt;9，那逻辑转换就是将语法树中存在的这种常量表达式直接进行化简，化简为 false；除了化简还有常量表达式计算等。 代价优化：就是通过付出一些数据统计分析的代价，来得到这个SQL执行是否可以走索引，以及走哪些索引；除此之外，在多表关联查询中，确定最终表join的顺序等； 在分析是否走索引查询时，是通过进行 动态数据采样统计分析 出来；只要是统计分析出来的，那就可能会存在分析错误的情况，所以在SQL执行不走索引时，也要考虑到这方面的因素。 MySql执行计划怎么查看呢？在执行的SQL语句前添加上 explain 关键字即可； 扩展： Oracle怎么查看执行计划？ 参考此文章 Oracle通过执行计划查看查询语句是否使用索引 执行器MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。开始执行的时候，要先判断一下建立连接的对象对这个表有没有执行操作的权限，如果没有，就会返回没有权限的错误；如果有，就按照生成的执行计划进行执行。 通过文章最开始的架构图可知，执行器下面连接的就是存储引擎了，执行器就是通过调用存储引擎提供的API接口进行调用操作数据的。 存储引擎描述存储引擎是对底层物理数据执行实际操作的组件，为Server服务器层提供各种操作数据的 API。MySQL 支持插件式的存储引擎，包括 InnoDB 、MyISAM、Memory 等。一般情况下，MySQL默认使用的存储引擎是 InnoDB 。 InnoDB 存储引擎支持的功能总览 扩展其整体架构图：如下图所示，InnoDB存储引擎整体分为内存架构（Memory Structures）和磁盘架构（Disk Structures）。 深入学习，请参考此文章 你居然还不知道Mysql存储引擎InnoDB分为内存架构、磁盘架构？","link":"/2021/10/15/mysql/mysql-execute-process/"},{"title":"netty hello_world","text":"1curl --location --request GET 'http://localhost:8089' 创建一个Springboot project pom.xml 添加netty 依赖 123456 &lt;!-- https://mvnrepository.com/artifact/io.netty/netty-all --&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.69.Final&lt;/version&gt;&lt;/dependency&gt; NettyServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.ChannelPipeline;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.http.HttpServerCodec;import io.netty.handler.logging.LogLevel;import io.netty.handler.logging.LoggingHandler;public class NettyServer { private static final int PORT = 8089; public static void main(String[] args) { // Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.option(ChannelOption.SO_BACKLOG, 1024); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { ChannelPipeline p = socketChannel.pipeline(); p.addLast(new HttpServerCodec()); p.addLast(new HttpHelloWorldServerHandler()); } }); Channel ch = b.bind(PORT).sync().channel(); ch.closeFuture().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }} HttpHelloWorldServerHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import static io.netty.handler.codec.http.HttpHeaderNames.*;import static io.netty.handler.codec.http.HttpHeaderValues.*;import static io.netty.handler.codec.http.HttpHeaderValues.KEEP_ALIVE;import static io.netty.handler.codec.http.HttpResponseStatus.*;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.handler.codec.http.DefaultFullHttpResponse;import io.netty.handler.codec.http.FullHttpResponse;import io.netty.handler.codec.http.HttpObject;import io.netty.handler.codec.http.HttpRequest;import io.netty.handler.codec.http.HttpUtil;public class HttpHelloWorldServerHandler extends SimpleChannelInboundHandler&lt;HttpObject&gt; { private static final byte[] CONTENT = { 'H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd' }; @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void channelRead0(ChannelHandlerContext ctx, HttpObject msg) { if (msg instanceof HttpRequest) { HttpRequest req = (HttpRequest) msg; boolean keepAlive = HttpUtil.isKeepAlive(req); System.out.println(&quot;=======================&quot;); System.out.println(&quot;keep alive is:&quot;+keepAlive); FullHttpResponse response = new DefaultFullHttpResponse(req.protocolVersion(), OK, Unpooled.wrappedBuffer(CONTENT)); response.headers() .set(CONTENT_TYPE, TEXT_PLAIN) .setInt(CONTENT_LENGTH, response.content().readableBytes()); if (keepAlive) { if (!req.protocolVersion().isKeepAliveDefault()) { response.headers().set(CONNECTION, KEEP_ALIVE); } } else { // Tell the client we're going to close the connection. response.headers().set(CONNECTION, CLOSE); } ChannelFuture f = ctx.write(response); if (!keepAlive) { f.addListener(ChannelFutureListener.CLOSE); } } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); }} run or debug NettyServer.main参考文章","link":"/2021/11/16/netty/netty-helloworld/"},{"title":"SQL语句不走索引时的排查利器 explain extended + show warnings","text":"索引字段出现隐式字符集转换,索引失效如果索引字段出现隐式字符集转换的话，那么索引将失效，进而转为全表扫描，查询效率将大大降低，要避免出现隐式字符集转换； 隐式字符集转换导致索引失效的原因MySQL索引的数据结构是 B+Tree，想要走索引查询必须要满足其 最左前缀原则 ，否则无法通过索引树进行查找，只能进行全表扫描； 例如：下面的这个SQL由于在 索引字段 上使用函数进行运算，导致索引失效 1select * from t_user where SUBSTR(name, 1, 2) = '李彤' 上面的这个SQL怎么改造才能使索引生效呢？如下所示： 1select * from t_user where name like '李彤%' 通过上面的小例子可以知道，如果在索引字段上使用函数运算，则会导致索引失效，而索引字段的 隐式字符集转换 由于MySQL会自动的在索引字段上加上 转换函数 ，进而会导致索引失效；那接下来我们就通过模拟的实际场景来具体看看是不是由于MySQL自动给加上了转换函数而导致索引失效的； explain extended + show warningsEXTENDED关键字的具体查阅资料：https://dev.mysql.com/doc/refman/5.7/en/explain-extended.html 模拟隐式字符集转换的场景：首先创建两个字符集不一样的表： 1234567891011121314151617181920CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `de_no` varchar(32) NOT NULL, `info` varchar(200) DEFAULT NULL, `de_name` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_de_no` (`de_no`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8mb4;CREATE TABLE `t_employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `em_no` varchar(32) NOT NULL, `de_no` varchar(32) NOT NULL, `age` int(11) DEFAULT NULL, `info` varchar(200) DEFAULT NULL, `em_name` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_em_no` (`de_no`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8; 然后使用存储过程构造数据： 1234567891011121314151617# 如果存储过程存在则删除DROP PROCEDURE IF EXISTS proc_initData;DELIMITER $# 创建存储过程CREATE PROCEDURE proc_initData()BEGINDECLARE i INT DEFAULT 1;WHILE i&lt;=30 DO# 新增数据INSERT INTO t_employees ( em_no, de_no, info, em_name , age) VALUES ( CONCAT('001', i), '003', 'test11', 'test2', i ); #执行的sql语句SET i = i+1;END WHILE;END $# 调用存储过程CALL proc_initData(); 注意：在构造数据时，记得将 t_employees 表中的 de_no 字段值构造的 离散些 ，因为如果索引字段值的 区分度很低 的话，那么MyQSL优化器通过采样统计分析时，发现索引查询和全表扫描性能差不多，就会直接进行全表扫描了； 索引失效的查询SQL语句： 将表和数据构造完后，我们使用SQL语句进行查询下，然后再看看其执行计划； 12explainselect * from t_department a LEFT JOIN t_employees b on a.de_no = b.de_no where a.id = 16 其执行计划如下：发现 t_employees 表中的 de_no 字段有索引，但是没有走索引查询，type=ALL 走的全表扫描. 使用利器快速排查问题： 注意：explain 后面跟的关键字 EXTENDED（扩展信息） 在MySQL5.7及之后的版本中废弃了，但是该语法仍被识别为向后兼容，所以在5.7版本及后续版本中，可以不用在 explain 后面添加 EXTENDED 了； 具体使用方法如下：1 首先在MySQL的可视化工具中打开一个 命令列介面 ：工具 –&gt; 命令列介面2 然后输入下面的SQL并按回车： 12explain EXTENDEDselect * from t_department a LEFT JOIN t_employees b on a.de_no = b.de_no where a.id = 4019; 3 然后紧接着输入命令 show warnings; 并回车，会出现如下图所示内容：通过展示出的执行SQL扩展信息，发现MySQL在字符集不一致时自动添加上字符集转换函数，因为是在 索引字段 de_no 上添加的转换函数，所以就导致了索引失效；而如果我们没看扩展信息的话，那么可能直到我们查看表结构的时候才会发现是由于字符集不一致导致的，这样就会花费很多的时间； 扩展：隐式类型转换咱们聊完上面的隐式字符集转换导致索引失效的情况，再来简单聊聊另一种 隐式类型转换 导致索引失效的情况； 隐式类型转换：简单的说就是字段的类型与其赋值的类型不一致时会进行隐式的转换； 小例如下： 1select * from t_employees where em_name = 123; 上面的SQL中 em_name 为索引字段，字段类型是 varchar，为其赋 int 类型的值时，会发现索引失效，这里也可以通过 explain extended + show warnings 查看，会发现如下图所示内容：","link":"/2021/10/15/mysql/mysql-explain/"},{"title":"connection_closed_before_response","text":"reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE responseSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: desc:PrematureCloseException caused by : customer request with header: connection:close gateway send all customer request headers to endpoint , so include connection:close endpoint response without connection header, so release TCP to pool connect instead of close. but endpoint closed the TCP connection fix:when request endpoint, don’t include customer’s connection header, proxy or gateway set keep-alive . ref: https://tools.ietf.org/html/rfc7230#section-6 The “Connection” header field allows the sender to indicate desiredcontrol options for the current connection. In order to avoidconfusing downstream recipients, a proxy or gateway MUST remove orreplace any received connection options before forwarding themessage. 参考文章 Connection has been closed BEFORE response, while sending request body Connection has been closed BEFORE response, while sending request body - keepalive timeout reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE response解决方案","link":"/2021/12/09/netty/netty-connection-closed-before-response/"},{"title":"nginx错误分析 Connection reset by peer","text":"nginx上下游针对请求处理的超时时间配置不合理，导致报connection reset by peer问题，即低频502，如图： 此类问题主要原因为，客户端在对上游长连接fd读写时，正好此fd被上游服务器关闭了，此时会报connection reset by peer，所以需要尽量避免上游服务器主动断开连接； 故障描述 根据tomcat官方文档说明，keepAliveTimeout默认等于connectionTimeout，我们这里配置的是20s。 参数 解释 keepAliveTimeout The number of milliseconds this Connector will wait for another HTTP request before closing the connection. The default value is to use the value that has been set for the connectionTimeout attribute. Use a value of -1 to indicate no (i.e. infinite) timeout. maxKeepAliveRequests The maximum number of HTTP requests which can be pipelined until the connection is closed by the server. Setting this attribute to 1 will disable HTTP/1.0 keep-alive, as well as HTTP/1.1 keep-alive and pipelining. Setting this to -1 will allow an unlimited amount of pipelined or keep-alive HTTP requests. If not specified, this attribute is set to 100. connectionTimeout The number of milliseconds this Connector will wait, after accepting a connection, for the request URI line to be presented. Use a value of -1 to indicate no (i.e. infinite) timeout. The default value is 60000 (i.e. 60 seconds) but note that the standard server.xml that ships with Tomcat sets this to 20000 (i.e. 20 seconds). Unless disableUploadTimeout is set to false, this timeout will also be used when reading the request body (if any). tomcat官方文档 https://tomcat.apache.org/tomcat-7.0-doc/config/http.htmlnginx(nginx-ingress-controller)中的配置 由于没有显示的配置，所以使用的是nginx的默认参数配置，默认是60s。 12345678http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive_timeout Syntax: keepalive_timeout timeout;Default: keepalive_timeout 60s;Context: upstreamThis directive appeared in version 1.15.3.Sets a timeout during which an idle keepalive connection to an upstream server will stay open. 解决竟然有了大概的分析猜测，可以尝试调整nginx的keepalive timeout为15s(需要小于tomcat的超时时间)，测试了之后，故障就这样得到了解决。 参考文章 nginx错误分析 104: Connection reset by peer Nginx: Connection reset by peer 错误定位 https://www.digitalreborn.com/fix-nginx-connection-reset-by-peer-upstream/","link":"/2021/12/08/nginx/nginx-connection-reset-by-peer/"},{"title":"netty HttpClient","text":"netty httpclient support http/2. HTTP/2ref: https://projectreactor.io/docs/netty/release/reference/index.html#_http2_2 By default, the HTTP client supports HTTP/1.1. If you need HTTP/2, you can get it through configuration. In addition to the protocol configuration, if you need H2 but not H2C (cleartext), you must also configure SSL. 12345678910111213141516171819202122232425import io.netty.handler.codec.http.HttpHeaders;import reactor.core.publisher.Mono;import reactor.netty.http.HttpProtocol;import reactor.netty.http.client.HttpClient;import reactor.util.function.Tuple2;public class H2Application { public static void main(String[] args) { HttpClient client = HttpClient.create() .protocol(HttpProtocol.H2) .secure(); Tuple2&lt;String, HttpHeaders&gt; response = client.get() .uri(&quot;https://example.com/&quot;) .responseSingle((res, bytes) -&gt; bytes.asString() .zipWith(Mono.just(res.responseHeaders()))) .block(); System.out.println(&quot;Used stream ID: &quot; + response.getT2().get(&quot;x-http2-stream-id&quot;)); System.out.println(&quot;Response: &quot; + response.getT1()); }} simple usage123456789101112131415161718192021HttpClient.create() .baseUrl(&quot;https://example.com&quot;) .get() .response() .block();HttpClient.create() .post() .uri(&quot;https://example.com&quot;) .send(Flux.just(bb1, bb2, bb3)) .responseSingle((res, content) -&gt; Mono.just(res.status().code())) .block();HttpClient.create() .baseUri(&quot;https://example.com&quot;) .post() .send(ByteBufFlux.fromString(flux)) .responseSingle((res, content) -&gt; Mono.just(res.status().code())) .block(); 参考文章 https://projectreactor.io/docs/netty/release/api/reactor/netty/http/client/HttpClient.html netty http2 https://www.baeldung.com/httpclient-guide https://projectreactor.io/docs/netty/release/reference/index.html#_http2_2","link":"/2021/12/03/netty/netty-httpclient/"},{"title":"nginx header-connection","text":"ref: https://datatracker.ietf.org/doc/html/rfc7230#section-6 The “Connection” header field allows the sender to indicate desiredcontrol options for the current connection. In order to avoidconfusing downstream recipients, a proxy or gateway MUST remove orreplace any received connection options before forwarding themessage. nginx转发,设置 Connection: close proxy_set_header Connection &quot;&quot;; By default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the $proxy_host variable, and “Connection” is set to close. 而且 其中一个配置： 1234Syntax: proxy_http_version 1.0 | 1.1;Default: proxy_http_version 1.0;Context: http, server, locationThis directive appeared in version 1.1.4. 所以其实 nginx 到后端 例如 tomcat 之间的连接是 http1.0的协议 所以解决 方法很简单： 1234567891011121314upstream http_backend { server 127.0.0.1:8080;}server { ... location /http/ { proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; ... }} 参考文章 nginx优化——包括https、keepalive等 解决nginx到后端服务器Connection: close问题 Nginx 对 Connection 头的处理过程 nginx http header [Connection: keep-alive]的实现原理 nginx中开启keepalive后应答反而为close的原因","link":"/2021/12/09/nginx/nginx-connection/"},{"title":"nginx access.log format","text":"$upstream_addr保留 IP 地址和端口，或上游服务器的 UNIX 域套接字的路径。如果在请求处理期间联系了多个服务器，则它们的地址用逗号分隔，例如“ 192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock”。如果发生从一个服务器组到另一个服务器组的内部重定向，由“X-Accel-Redirect”或 error_page 发起，则来自不同组的服务器地址用冒号分隔，例如“ 192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock : 192.168.10.1:80, 192.168.10.2:80”。如果无法选择服务器，该变量将保留服务器组的名称。 $proxy_portproxy_pass指令中指定的代理服务器的端口 ，或协议的默认端口； $server_port接受请求的服务器端口 12345678910111213141516171819变量 含义$bytes_sent 发送给客户端的总字节数$body_bytes_sent 发送给客户端的字节数，不包括响应头的大小$connection 连接序列号$connection_requests 当前通过连接发出的请求数量$msec 日志写入时间，单位为秒，精度是毫秒$pipe 如果请求是通过http流水线发送，则其值为&quot;p&quot;，否则为“.&quot;$request_length 请求长度（包括请求行，请求头和请求体）$request_time 请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止$status 响应状态码$time_iso8601 标准格式的本地时间,形如“2017-05-24T18:31:27+08:00”$time_local 通用日志格式下的本地时间，如&quot;24/May/2017:18:31:27 +0800&quot;$http_referer 请求的referer地址。$http_user_agent 客户端浏览器信息。$remote_addr 客户端IP$http_x_forwarded_for 当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。$request 完整的原始请求行，如 &quot;GET / HTTP/1.1&quot;$remote_user 客户端用户名称，针对启用了用户认证的请求$request_uri 完整的请求地址，如 &quot;https://daojia.com/&quot; 12345678http { access_log /var/logs/nginx-access.log main log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; ...} 我们使用log_format指令定义了一个main的格式，并在access_log指令中引用了它。假如客户端有发起请求：https://suyunfe.com/，我们看一下我截取的一个请求的日志记录: 1112.195.209.90 - - [20/Feb/2018:12:12:14 +0800] &quot;GET / HTTP/1.1&quot; 200 190 &quot;-&quot; &quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36&quot; &quot;-&quot; 参考文章 https://docs.nginx.com/nginx/admin-guide/monitoring/logging/ Nginx日志配置详解 Alphabetical index of variables","link":"/2021/12/23/nginx/nginx-accesslog-format/"},{"title":"网关、网卡、网桥","text":"网关是邮电局,所有的信息必须通过这里的打包、封箱、寻址，才能发出去与收进来；网卡是设备，也就是邮电局邮筒，你家的信箱；网桥是邮递员，但他只负责一个镇里面(局域网)不负责广域网。 网关 网关实质上是一个网络通向其他网络的IP地址 网关是一种充当转换重任的计算机系统或设备,又叫网间连接器、协议转换器 从一个房间走到另一个房间，必然要经过一扇门。同样，从一个网络向另一个网络发送信息，也必须经过一道“关口”，这道关口就是网关。顾名思义，网关（Gateway） [1] 就是一个网络连接到另一个网络的“关口”。也就是网络关卡。 网关(Gateway)又称网间连接器、协议转换器。网关在网络层以上实现网络互连，是复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。使用在不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同层–应用层。 【说明：由于历史的原因，许多有关TCP/IP的文献曾经把网络层使用的路由器称为网关，在今天很多局域网采用都是路由来接入网络，因此通常指的网关就是路由器的IP！】 案例 那么网关到底是什么呢？网关实质上是一个网络通向其他网络的IP地址。比如有网络A和网络B，网络A的IP地址范围为“192.168.1.1 ~ 92. 168.1.254”，子网掩码为255.255.255.0；网络B的IP地址范围为“192.168.2.1~192.168.2.254”，子网掩码为255.255.255.0。在没有路由器的情况下，两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP协议也会根据子网掩码（255.255.255.0）与主机的IP 地址作 “与” 运算的结果不同判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关。如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机（如附图所示）。网络A向网络B转发数据包的过程。 所以说，只有设置好网关的IP地址，TCP/IP协议才能实现不同网络之间的相互通信。那么这个IP地址是哪台机器的IP地址呢？网关的IP地址是具有路由功能的设备的IP地址，具有路由功能的设备有路由器、启用了路由协议的服务器（实质上相当于一台路由器）、代理服务器（也相当于一台路由器）。 在和 Novell NetWare 网络交互操作的上下文中，网关在 Windows 网络中使用的服务器信息块 (SMB) 协议以及NetWare网络使用的 NetWare 核心协议 (NCP) 之间起着桥梁的作用。网关也被称为 IP路由器。 案例 网卡 网卡是一块被设计用来允许计算机在计算机网络上进行通讯的计算机硬件。 一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的MAC地址 主要功能 1、数据的封装与解封 发送时将上一层传递来的数据加上首部和尾部，成为以太网的帧。接收时将以太网的帧剥去首部和尾部，然后送交上一层 2、链路管理 主要是通过CSMA/CD（Carrier Sense Multiple Access with Collision Detection ，带冲突检测的载波监听多路访问）协议来实现 3、数据编码与译码 即曼彻斯特编码与译码。其中曼彻斯特码，又称数字双向码、分相码或相位编码(PE)，是一种常用的的二元码线路编码方式之一，被物理层使用来编码一个同步位流的时钟和数据。在通信技术中，用来表示所要发送比特 流中的数据与定时信号所结合起来的代码。 常用在以太网通信，列车总线控制，工业总线等领域。 网桥网桥也叫桥接器，是连接两个局域网的一种存储/转发设备，它能将一个大的LAN)分割为多个网段，或将两个以上的LAN互联为一个逻辑LAN，使LAN上的所有用户都可访问服务器。 LAN 一般指局域网WLAN 指无线局域网 原理网桥将两个相似的网络连接起来，并对网络数据的流通进行管理。它工作于数据链路层，不但能扩展网络的距离或范围，而且可提高网络的性能、可靠性和安全性。网络1 和网络2 通过网桥连接后，网桥接收网络1 发送的数据包，检查数据包中的地址，如果地址属于网络1 ，它就将其放弃，相反，如果是网络2 的地址，它就继续发送给网络2.这样可利用网桥隔离信息，将同一个网络号划分成多个网段（属于同一个网络号），隔离出安全网段，防止其他网段内的用户非法访问。由于网络的分段，各网段相对独立（属于同一个网络号），一个网段的故障不会影响到另一个网段的运行。网桥可以是专门硬件设备，也可以由计算机加装的网桥软件来实现，这时计算机上会安装多个网络适配器（网卡）。 网桥的功能在延长网络跨度上类似于中继器，然而它能提供智能化连接服务，即根据帧的终点地址处于哪一网段来进行转发和滤除。网桥对站点所处网段的了解是靠“自学习”实现的，有透明网桥、转换网桥、封装网桥、源路由选择网桥。网桥示意如图1所示。 简述网桥、网关、网卡之间的联系和区别网桥，是把两个不同物理层，不同MAC子层，不同速率的局域网连接在一起。比如说10MB/S与100MB/S的局域网。因为它有储存转化功能。网桥是一种链路层产品. 网卡是电脑的一个接收信息 转换信息 暂储信息的一个硬件。它是把接受到信息递交给上层，如（CUP）的一个接口。 网关(Gateway)又称网间连接器、协议转换器。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。在使用不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关也可以提供过滤和安全功能。大多数网关运行在OSI 7层协议的顶层–应用层。 所以生动的表示以下: 网关是邮电局,所有的信息必须通过这里的打包、封箱、寻址，才能发出去与收进来； 网卡是设备，也就是邮电局邮筒，你家的信箱； 网桥是邮递员，但他只负责一个镇里面(局域网)不负责广域网。 参考文章 网关 网桥 网关、网卡、网桥、","link":"/2021/12/31/network/network-gateway-bridge-network-card/"},{"title":"使用logrotate工具实现nginx日志切割","text":"12345678910111213141516171819/usr/local/nginx/logs/*.log { # 指定转储周期为每天 daily # 使用当期日期作为命名格式 dateext # 如果日志丢失，不报错继续滚动下一个日志 missingok # 保留 31 个备份 rotate 31 # 不压缩 nocompress # 整个日志组运行一次的脚本 sharedscripts # 转储以后需要执行的命令 postrotate # 重新打开日志文件 [ ! -f /usr/local/nginx/nginx.pid ] || kill -USR1 `cat /usr/local/nginx/nginx.pid` endscript} 安装 logrotate:1$ yum install logrotate logrotate 命令参数123456logrotate [OPTION...] &lt;configfile&gt;-d, --debug ：debug模式，测试配置文件是否有错误。-f, --force ：强制转储文件。-m, --mail=command ：压缩日志后，发送日志到指定邮箱。-s, --state=statefile ：使用指定的状态文件。-v, --verbose ：显示转储过程。 手动执行 logrotate12345678910111213141516171819202122232425262728293031323334353637# '-d' 调试模式（不切分日志文件），并输出详细处理过程日志$ logrotate -d -f /etc/logrotate.d/nginx# '-f' 强制切分日志，'-v' 输出详细信息$ logrotate -vf /etc/logrotate.d/nginxreading config file nginxAllocating hash table for state file, size 15360 BHandling 1 logsrotating pattern: /usr/local/nginx/logs/*.log forced from command line (100 rotations)empty log files are rotated, old logs are removedconsidering log /usr/local/nginx/logs/access.loglog needs rotatingconsidering log /usr/local/nginx/logs/error.loglog needs rotatingrotating log /usr/local/nginx/logs/access.log, log-&gt;rotateCount is 100dateext suffix '-20201121'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding old rotated logs failedrotating log /usr/local/nginx/logs/error.log, log-&gt;rotateCount is 100dateext suffix '-20201121'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding old rotated logs failedrenaming /usr/local/nginx/logs/access.log to /usr/local/nginx/logs/access.log-20201121renaming /usr/local/nginx/logs/error.log to /usr/local/nginx/logs/error.log-20201121running postrotate script# 切分后的日志文件$ ls -lt /usr/local/nginx/logs总用量 0-rw-r--r-- 1 nginx root 0 11月 21 18:58 access.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 access.log-20201121-rw-r--r-- 1 nginx root 0 11月 21 18:58 error.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 error.log-20201121-rw-r--r-- 1 nginx root 0 11月 21 18:58 images.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 images.log-20201121 参考文章 Nginx 使用 logrotate 进行日志滚动 linux环境下使用logrotate工具实现nginx日志切割 Nginx使用Logrotate工具实现日志切割","link":"/2021/12/23/nginx/nginx-logrotate-d/"},{"title":"windows下nginx的安装及使用","text":"12345678910111213141516# 打开cmd命令窗口，切换到nginx解压目录下# start nginx./nginx.exe start nginx.exe# 检查80端口是否被占用的命令是：netstat -ano | findstr 0.0.0.0:80 netstat -ano | findstr &quot;80&quot;./nginx.exe -s reload# 快速停止nginx./nginx.exe -s stoptaskkill /f /t /im nginx.exe# 完整有序的停止nginx./nginx.exe -s quit 下载nginxhttp://nginx.org/en/download.html 下载后解压，解压后如下 启动nginx有很多种方法启动nginx (1)直接双击nginx.exe，双击后一个黑色的弹窗一闪而过 (2)打开cmd命令窗口，切换到nginx解压目录下，输入命令 nginx.exe 或者 start nginx ，回车即可 检查nginx是否启动成功直接在浏览器地址栏输入网址 http://localhost:80，回车，出现以下页面说明启动成功 参考文章 windows下nginx的安装及使用","link":"/2021/12/09/nginx/nginx-install-on-windows/"},{"title":"nginx documentation","text":"https://nginx.org/en/docs/ngx_http_core_module client_body_buffer_size 参考文章 https://nginx.org/en/docs/ ngx_http_core_module","link":"/2021/12/27/nginx/nginx-documentation/"},{"title":"nginx keepalive","text":"keepalive是在TCP中一个可以检测死连接的机制，可以保持tcp长连接不被断开，属于tcp层功能。http1.1协议默认开启keepa-live保持长连接，主要作用是提高对tcp连接的复用率，减少创建连接过程给系统带来的性能损耗。 keepalive与keep-alive区别？keepalive是tcp层长连接探活机制； keep-alive是应用层http协议使用，在其头部Connection字段中的一个值，只是代表客户端与服务之间需要保持长连接，可以理解为通过此字段来告诉nginx此连接需要维持长连接，处理完别直接关闭连接。 nginx的keepalive会做哪些事情？当使用nginx作为代理服务器时，这两点必然要满足： client到nginx的连接是长连接 nginx到server的连接是长连接nginx与keepalive相关的配置介绍场景1,配置TCP层keepalive探活机制的三个参数1234567891011121314case1:http {server { listen 127.0.0.1:3306 so_keepalive=on;//开启keepalive探活，探测策略走系统默认 }}case2:http {server { listen 127.0.0.1:3306 so_keepalive=7m:75s:9;//把空闲时长从系统默认的5分钟改为了7分钟 }} 其中so_keepalive有如下选择配置，官方文档：so_keepalive123456so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]* on: 开启，探测参数更加系统默认值* off: 关闭* keepidle: 连接空闲等待时间 * keepintvl: 发送探测报文间隔时间* keepcent: 探测报文重试次数 每个参数主要是覆盖linux系统针对keepalive的默认配置，如果nginx未设置so_keepalive配置，则走系统默认的探活策略 场景2、nginx与客户端（一般为浏览器、APP等）保持的长连接进行限制管理；1234http { keepalive_timeout 120s 120s; keepalive_requests 100;} 客户端请求header头： 123GET /uri HTTP/1.1 #版本为1.1及以上，Connection:为空也开启长连接，但Connection:close时不开启Host: www.baidu.comConnection: keep-alive #Connection:keep-alive 时均开启长连接，HTTP是否为1.1以上无影响 keepalive_timeout： 第一个参数：客户端连接在服务器端空闲状态下保持的超时值（默认75s）；值为0会禁用keep-alive，也就是说默认不启用长连接；第二个参数：响应的header域中设置“Keep-Alive: timeout=time”；告知浏览器对长连接的维持时间；官方文档：keepalive_timeout keepalive_requests：默认100，某个长连接连续处理请求次数限制，超过次数则该长连接被关闭；如果需要释放某个连接占用的内存，必须关闭该链接，内存不大的情况下，不建议开大该配置；在QPS较高的场景，则有必要加大这个参数；官方文档：keepalive_requests 场景3、nginx与上游server保持长连接12345678910111213141516http { upstream BACKEND { server 127.0.0.1:8000; server 127.0.0.1:8001; server 127.0.0.1:8002; keepalive 300; //空闲连接数 keepalive_timeout 120s;//与上游空闲时间 keepalive_requests 100;//与上游请求处理最大次数 } server{ listen 8080; location /{ proxy_pass http://BACKEND; } }} keepalive：限制nginx某个worker最多空闲连接数，此处不会限制worker与上游服务长连接的总数,官方文档：keepalive keepalive_timeout：nginx与上游长连接最大空闲时间，默认值为60s；官方文档： keepalive_timeout keepalive_requests：nginx与上游长连接最大交互请求的次数，默认值为100；官方文档： keepalive_requests 除此之外，nginx与上游通信，http协议默认是走的http1.0，对客户端header头不会直接转发，且会把头部中Connection字段置为默认的”close”，要与上游保持长连接还需要加如下配置： 1234567891011http { keepalive_timeout 120s 120s; keepalive_requests 100; server { location / { proxy_http_version 1.1; //设置与上游通信的 proxy_set_header Connection &quot;&quot;; proxy_pass http://BACKEND; } }} nginx的开启长连接会带来什么问题？nginx上下游针对请求处理的超时时间配置不合理，导致报connection reset by peer问题，即低频502 此类问题主要原因为，客户端在对上游长连接fd读写时，正好此fd被上游服务器关闭了，此时会报connection reset by peer，所以需要尽量避免上游服务器主动断开连接； 参考文章 nginx优化——包括https、keepalive等 nginx的keepalive Nginx 对客户端和server端长连接控制 keepalive Nginx 支持 keepalive 长连接 nginx优化——包括https、keepalive等 Nginx——Nginx的connection、request、keepalive、pipe（pipeline）、lingering_close","link":"/2021/12/08/nginx/nginx-keep-alive/"},{"title":"nginx -s reload","text":"nginx -s reload acts : nginx master process running (not restarted) nginx worker process restarted reload –重新加载，reload会重新加载配置文件，Nginx服务不会中断。而且reload时会测试conf语法等，如果出错会rollback用上一次正确配置文件保持正常运行。 restart –重启（先stop后start），会重启Nginx服务。这个重启会造成服务一瞬间的中断，如果配置文件出错会导致服务启动失败，那就是更长时间的服务中断了。所以，如果是线上的服务，修改的配置文件一定要备份。为了保证线上服务高可用，最好使用reload。 reload 只是重新加载配置文件，不会清理nginx 的一些缓存，在有些需要清理缓存的场景需要restart ，例如upstream 后端配置的集群服务地址是域名而不是ip，当后端IP 变了，就需要清除该域名的解析缓存，此时需要重启而不是reload。 参考文章 nginx reload 与 restart 的区别","link":"/2021/12/20/nginx/nginx-s-reload/"},{"title":"nginx支持HTTP2的配置过程","text":"1./configure *** --with-http_v2_module 1listen 443 ssl http2; curl支持http2123456789101112131415161718[root@ ~]# wget https://github.com/nghttp2/nghttp2/releases/download/v1.41.0/nghttp2-1.41.0.tar.bz2[root@ ~]# tar xf nghttp2-1.41.0.tar.bz2[root@ ~]# cd nghttp2-1.41.0[root@ ~]# autoreconf -i[root@ ~]# automake[root@ ~]# autoconf [root@ ~]# ./configure --prefix=/usr/local/nghttp2-1.41.0[root@ ~]# make &amp;&amp; make install[root@ ~]# wget http://curl.haxx.se/download/curl-7.46.0.tar.bz2[root@ ~]# tar xf curl-7.46.0.tar.bz2[root@ ~]# cd curl-7.46.0[root@ ~]# ./configure --with-nghttp2=/usr/local/nghttp2-1.41.0/ --with-ssl --prefix=/usr/local/curl-7.46.0/[root@ ~]# make &amp;&amp; make install[root@ ~]# /usr/local/curl-7.46.0/bin/curl --versioncurl 7.46.0 (x86_64-pc-linux-gnu) libcurl/7.46.0 OpenSSL/1.0.2k zlib/1.2.7 nghttp2/1.41.0Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftpFeatures: IPv6 Largefile NTLM NTLM_WB SSL libz HTTP2 UnixSockets 参考文章 https://www.cnblogs.com/wshenjin/p/13522388.html https://www.cnblogs.com/bugutian/p/6628455.html","link":"/2021/12/03/nginx/nginx-suppport-http2/"},{"title":"forward_proxy &amp; reverse_proxy","text":"正向代理正向代理（forward proxy）：是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。 这种代理其实在生活中是比较常见的，比如访问外国网站技术，其用到的就是代理技术。 有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。 这个过程其实和租房子很像。 租房子的时候，一般情况下，我们很难联系到房东，因为有些房东为了图方便，只把自己的房屋信息和钥匙交给中介了。而房客想要租房子，只能通过中介才能联系到房东。而对于房东来说，他可能根本不知道真正要租他的房子的人是谁，他只知道是中介在联系他。 这里面一共有三个角色，租客（用户）、中介（代理服务器）和房东（国外网站，目标服务器）。引入中介（代理服务器）的原因是用户无法联系上房东（用户无法访问国外网站）。 所以，正向代理，其实是”代理服务器”代理了”客户端”，去和”目标服务器”进行交互。 通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的，甚至不知道访问自己的是一个代理（有时候中介也直接冒充租客）。 正向代理的用途 突破访问限制 通过代理服务器，可以突破自身IP访问限制，访问国外网站，教育网等。即，租客可以通过中介，来解决无法联系上房东的问题。 提高访问速度通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。即，中介手里留存了很多房源信息和钥匙，可以直接带租客去看房。 隐藏客户端真实IP上网者也可以通过这种方法隐藏自己的IP，免受攻击。 即，房东并不知道租客的真实身份。PS：但是中介知道了，可能骚扰更多…. 反向代理反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 我们在租房子的过程中，除了有些房源需要通过中介以外，还有一些是可以直接通过房东来租的。用户直接找到房东租房的这种情况就是我们不使用代理直接访问国内的网站的情况。 还有一种情况，就是我们以为我们接触的是房东，其实有时候也有可能并非房主本人，有可能是他的亲戚、朋友，甚至是二房东。但是我们并不知道和我们沟通的并不是真正的房东。这种帮助真正的房主租房的二房东其实就是反向代理服务器。这个过程就是反向代理。 对于常用的场景，就是我们在Web开发中用到的负载均衡服务器（二房东），客户端（租客）发送请求到负载均衡服务器（二房东）上，负载均衡服务器（二房东）再把请求转发给一台真正的服务器（房东）来执行，再把执行结果返回给客户端（租客）。所以，反向代理，其实是”代理服务器”代理了”目标服务器”，去和”客户端”进行交互。通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的，甚至不知道自己访问的是一个代理。 反向代理的用途 隐藏服务器真实IP 使用反向代理，可以对客户端隐藏服务器的IP地址。 即，租客并不房东知道的真实身份。 负载均衡 反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。即，二房东发现房主本人很忙，于是找到房主的妻子帮忙处理租房事宜。 提高访问速度 反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。即，二房东同样有房屋信息和钥匙。 提供安全保障 反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。即，二房东可以有效的保护房东的安全。 正向代理和反向代理的区别虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。 1、正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。 2、正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。 3、正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。 4、正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。 代理配置项 配置语法 12345678语法：proxy_buffering on | off;默认值：proxy_buffering on;可配置段：http, server, location作用：配置proxy缓冲区。扩展：proxy_buffer_size：设置缓冲区大小（内存页大小）proxy_buffers：设置缓冲区数量和大小（内存页数量和大小）proxy_busy_buffers_size：设置最大缓冲区大小 12345语法：proxy_redirect default; proxy_redirect off; proxy_redirect redirect replacement;默认值：proxy_redirect default;可配置段：http, server, location作用：配置proxy重定向。扩展： 12345语法：proxy_buffering on | off;默认值：proxy_buffering on;可配置段：http, server, location作用：配置proxy缓冲区。扩展： 1234567语法：proxy_set_header field value;默认值：proxy_set_header Host $proxy_host; proxy_set_header Connection close;可配置段：http, server, location作用：配置proxy头信息。扩展：proxy_hide_header：设置隐藏头信息字段；proxy_set_body：设置请求体返回信息。 1234567语法：proxy_connect_timeout time;默认值：proxy_connect_timeout 60s;可配置段：http, server, location作用：配置proxy超时。扩展：proxy_hide_header：设置隐藏头信息字段；proxy_set_body：设置请求体返回信息。 配置正向代理12345678910111213141516171819202122232425262728293031323334353637[root@proxy ~]# vi /etc/nginx/conf.d/reverse.confserver{ resolver 8.8.8.8; #配置DNS解析IP地址 resolver_timeout 30s; #超时时间（5秒） listen 82; access_log /var/log/nginx/reverse.access.log main; error_log /var/log/nginx/reverse.error.log warn; location / { proxy_pass http://$http_host$request_uri; #配置正向代理参数 proxy_set_header Host $http_host; #解决如果URL中带&quot;.&quot;后Nginx 503错误 proxy_buffers 256 4k; #配置缓存大小 proxy_max_temp_file_size 0; #关闭磁盘缓存读写减少I/O proxy_connect_timeout 30; #代理连接超时时间 proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; #配置代理服务器缓存时间 }}配置释义：1、不能有hostname。2、必须有resolver, 即dns，即上面的8.8.8.8，超时时间（30秒）可选。3、配置正向代理参数，均是由 Nginx 变量组成。proxy_pass $scheme://$host$request_uri; proxy_set_header Host $http_host; 4、配置缓存大小，关闭磁盘缓存读写减少I/O，以及代理连接超时时间。proxy_buffers 256 4k; proxy_max_temp_file_size 0; proxy_connect_timeout 30; 5、配置代理服务器 Http 状态缓存时间。proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m;配置好后，重启nginx，以浏览器为例，要使用这个代理服务器，则只需将浏览器代理设置为http://+服务器ip地址+:+82（82是刚刚设置的端口号）即可使用了。 反向代理配置123456789101112131415161718192021222324252627282930313233http {# 省略了前面一般的配置，直接从负载均衡这里开始# 设置地址池，后端3台服务器 upstream http_server_pool { server 192.168.1.2:8080 weight=2 max_fails=2 fail_timeout=30s; server 192.168.1.3:8080 weight=3 max_fails=2 fail_timeout=30s; server 192.168.1.4:8080 weight=4 max_fails=2 fail_timeout=30s; }# 一个虚拟主机，用来反向代理http_server_pool这组服务器 server { listen 80;# 外网访问的域名 server_name www.test.com; location / {# 后端服务器返回500 503 404错误，自动请求转发到upstream池中另一台服务器 proxy_next_upstream error timeout invalid_header http_500 http_503 http_404; proxy_pass http://http_server_pool; proxy_set_header Host www.test.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } access_log logs/www.test.com.access.log combined; }}最简单的反向代理演示（在一台服务器上做代理服务器，将http请求转发到另一台IIS服务器上，通过二级域名形式访问。）编辑vim nginx.confserver { listen 80; server_name test.zhoumengkang.com; location / { proxy_pass http://121.199.**.*:80; }}参考：http://www.blogjava.net/xiaomage234/archive/2011/09/08/358247.html 123456789101112131415161718192021proxy_set_header X-Real-IP $remote_addr： 把源IP【$remote_addr，建立HTTP连接header里面的信息】赋值给X-Real-IP，从而通过$X-Real-IP来获取源IP；proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for： 在nginx作为代理服务器时，设置的IP列表，会把经过的机器ip，代理机器ip都记录下来，用【，】隔开。 proxy_pass：设置代理服务器的地址，可以是主机名称、IP地址加端口号等形式。proxy_pass URL提示：1：当代理的是一组服务器时可以使用 upstream 指令来设置。2：当URL中含有uri时，（例如 &quot;http://127.0.0.1:8080/&quot;、&quot;http://127.0.0.1:8080/demo.html&quot;）不管客户端访问的是地址中的uri是什么，代理服务器都会代理到URL的地址；当URL中不包含uri时（例如：&quot;http://127.0.0.1:8080&quot;），那么当客户端访问服务器时，代理服务器会根据客户端请求的uri来访问具体的URL地址。 proxy_pass_request_body on|off：用于配置是否将客户端请求的请求体发送给代理服务器。proxy_pass_request_headers on|off：用于配置是否将客户端请求的头信息发送给代理服务器。proxy_set_header field value：可以更改nginx接收到的客户端请求的请求头信息，然后将新的请求头信息发送给被代理的服务器。proxy_set_body value：ngin接收到客户端的请求后使用该指令可以修改request中的body体，然后将请求转发给代理服务器。proxy_connect_timeout time：nginx服务器与被代理服务器之间尝试建立连接的的超时时间，默认为60s。proxy_read_timeot time：nginx服务器接收被代理服务器数据时最大的等待时间，默认为60s。proxy_send_timeout time：nginx服务器发送数据至被代理服务器的最大等待时间，例如60s内没有发出一个字节则默认断开连接，默认60s。proxy_http_version 1.0|1.1：nginx服务器提供代理服务的http协议版本。proxy_method method：nginx服务器设置请求被代理服务器时使用的请求方法，一般为POST或者GET。proxy_ignore_client_abort：当客户端中断网络请求时，nginx服务是否中断对代理服务器的请求，默认off。 参考文章 终于有人把正向代理和反向代理解释的明明白白了！ Nginx反向代理和正向代理 Nginx 正向代理与反向代理解析与实战 Nginx正反代理 nginx–❤️图解及代码实现正向代理、反向代理及负载均衡（非常实用，建议收藏❤️） Nginx代理的几种模式","link":"/2021/12/08/nginx/nginx-proxy-and-reverse-proxy/"},{"title":"python-opencv 安装","text":"install opencv-python123456789# prepare pip3 install scikit-build pip3 install cmake ln -s /usr/bin/ninja /usr/bin/ninja-build# install opencvpip3 install opencv-pythonpip3 install opencv-contrib-python 打开 Python IDLE（或 IPython）并在 Python 终端中键入以下命令。 12import cv2 as cvprint(cv.__version__) install python1234567$ sudo yum install python38 -y# 从SCL中使用python3，你需要一行命令来启用Python3：$ scl enable python38 &lt;command&gt;# 您还可以使用Python编译器来调用一个bash shell:$ scl enable python38 bash OpenCV 中文文档 4.0.0https://www.kancloud.cn/aollo/aolloopencv/259610https://www.bookstack.cn/read/opencv-doc-zh-4.0/README.mdhttps://woshicver.com/ 图像入门1. 显示图像123456789import numpy as npimport cv2 as cv＃加载彩色灰度图像img = cv.imread('messi5.jpg'，0)cv.imshow('image', img)cv.waitKey(0)cv.destroyAllWindows() 使用cv.imread()函数读取图像。图像应该在工作目录或图像的完整路径应给出。 第二个参数是一个标志，它指定了读取图像的方式。 123cv.IMREAD_COLOR： 加载彩色图像。任何图像的透明度都会被忽视。它是默认标志。cv.IMREAD_GRAYSCALE：以灰度模式加载图像cv.IMREAD_UNCHANGED：加载图像，包括alpha通道 使用函数 cv.imshow() 在窗口中显示图像。窗口自动适合图像尺寸。 第一个参数是窗口名称，它是一个字符串。第二个参数是我们的对象。你可以根据需要创建任意多个窗口，但可以使用不同的窗口名称。 cv.waitKey()是一个键盘绑定函数。 其参数是以毫秒为单位的时间。该函数等待任何键盘事件指定的毫秒。如果您在这段时间内按下任何键，程序将继续运行。如果0被传递，它将无限期地等待一次敲击键。它也可以设置为检测特定的按键，例如，如果按下键 a 等，我们将在下面讨论。 注意 除了键盘绑定事件外，此功能还处理许多其他GUI事件，因此你必须使用它来实际显示图像。 cv.destroyAllWindows()只会破坏我们创建的所有窗口。如果要销毁任何特定的窗口，请使用函数cv.destroyWindow()在其中传递确切的窗口名称作为参数。 注意 在特殊情况下，你可以创建一个空窗口，然后再将图像加载到该窗口。在这种情况下，你可以指定窗口是否可调整大小。这是通过功能cv.namedWindow()完成的。默认情况下，该标志为cv.WINDOW_AUTOSIZE。但是，如果将标志指定为cv.WINDOW_NORMAL，则可以调整窗口大小。当图像尺寸过大以及向窗口添加跟踪栏时，这将很有帮助。 2. 写入图像使用函数cv.imwrite()保存图像。 第一个参数是文件名，第二个参数是要保存的图像。 cv.imwrite(‘messigray.png’，img) 这会将图像以PNG格式保存在工作目录中。 在下面的程序中，以灰度加载图像，显示图像，按s保存图像并退出，或者按ESC键直接退出而不保存。1234567891011import numpy as npimport cv2 as cvimg = cv.imread('pig.jpg', 0)cv.imshow('image', img)k = cv.waitKey(0) &amp; 0xFFif k == 27: # 等待ESC退出 cv.destroyAllWindows()elif k == ord('s'): # 等待关键字，保存和退出 cv.imwrite('messigray.png', img) cv.destroyAllWindows() 3. 使用Matplotlibref: https://woshicver.com/ThirdSection/2_1_%E5%9B%BE%E5%83%8F%E5%85%A5%E9%97%A8/Matplotlib是Python的绘图库，可为你提供多种绘图方法。你将在接下来的文章中看到它们。在这里，你将学习如何使用Matplotlib显示图像。你可以使用Matplotlib缩放图像，保存图像等。 123456789import numpy as npimport cv2 as cvfrom matplotlib import pyplot as pltimg = cv.imread('pig.jpg', 0)plt.imshow(img, cmap='gray', interpolation='bicubic')plt.xticks([]), plt.yticks([]) # 隐藏 x 轴和 y 轴上的刻度值plt.show()","link":"/2021/10/25/opencv/opencv-install/"},{"title":"opencv 练习","text":"OpenCV中的绘图功能12345678910111213141516171819202122232425import cv2 as cvimport numpy as np# 创建黑色的图像img = np.zeros((512, 512, 3), np.uint8)# 绘制一条厚度为5的蓝色对角线cv.line(img, (0, 0), (511, 511), (255, 0, 0), 5)cv.rectangle(img, (384, 0), (510, 128), (0, 255, 0), 3)cv.circle(img, (447, 63), 63, (0, 0, 255), -1)cv.ellipse(img, (256, 256), (100, 50), 0, 0, 180, 255, -1)pts = np.array([[10, 5], [20, 30], [70, 20], [50, 10]], np.int32)pts = pts.reshape((-1, 1, 2))cv.polylines(img, [pts], True, (0, 255, 255))font = cv.FONT_HERSHEY_SIMPLEXcv.putText(img, 'OpenCV', (10, 500), font, 4, (255, 255, 255), 2, cv.LINE_AA)cv.imshow('image', img)cv.waitKey(0)cv.destroyAllWindows()","link":"/2021/10/25/opencv/opencv-practice/"},{"title":"Nginx转发，swagger误将upstream作为base url","text":"1proxy_set_header Host $host:$server_port; nginx反向代理时配置如下： 1234proxy_set_header Host $remote_addr;proxy_set_header X-Real-IP $remote_addr;proxy_set_header REMOTE-HOST $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 这就导致获取的是客户端真实的IP地址 解决办法： 屏蔽上述配置，添加以下配置： 1proxy_set_header Host $host:$server_port; 将NGINX接收到请求头中的Host和端口继续往下传递。 参考文章 https://blog.csdn.net/surite/article/details/114120794 https://www.cnblogs.com/John-2011/p/14812449.html","link":"/2021/12/03/nginx/nginx-swagger-upstream/"},{"title":"如何在 CentOS 上安装 Python 3","text":"Installing Python 3 on CentOS 8To install Python 3 on CentOS 8 run the following command as root or sudo user in your terminal: 123456789101112131415161718192021sudo dnf install python3 -y#该命令还会安装 pip 。#To verify the installation, check the Python version by typing:python3 --versionpip3 --version#Python 3 模块包的名称以“python3”为前缀。例如，要安装paramiko 模块，您将运行：sudo dnf install python3-paramiko -y# To be able to install and build Python modules with pip, you need to install the Development toolssudo yum install python3-devel -ysudo yum groupinstall 'development tools' -y install python3.8 on centos8https://computingforgeeks.com/how-to-install-python-3-python-2-7-on-rhel-8/ https://linuxize.com/post/how-to-install-python-3-8-on-centos-8/ 123456789101112131415161718192021222324252627282930313233# sudo dnf install python3# preparesudo dnf groupinstall 'development tools' -ysudo dnf install bzip2-devel expat-devel gdbm-devel \\ ncurses-devel openssl-devel readline-devel wget \\ sqlite-devel tk-devel xz-devel zlib-devel libffi-devel -y## download VERSION=3.8.1wget https://www.python.org/ftp/python/${VERSION}/Python-${VERSION}.tgztar -xf Python-${VERSION}.tgz# 该--enable-optimizations选项通过运行多个测试来优化 Python 二进制文件。这会使构建过程变慢。cd Python-${VERSION}./configure --enable-optimizations# 通过运行以下命令启动 Python 3.8 构建过程：make -j 4# 修改-j以对应于处理器中的内核数。您可以通过键入 找到该号码nproc。# 构建过程完成后，安装 Python 二进制文件：sudo make altinstallpython3.8 --versionsudo alternatives --set python /usr/bin/python3python -m pip install --upgrade pip 创建虚拟环境 or 配置Python默认版本为3.8.0创建虚拟环境Python 虚拟环境是一个独立的目录树，其中包括 Python 安装和许多附加包。它允许您将 Python 模块安装在特定项目的隔离位置，而不是全局安装。这样，您就不必担心影响其他 Python 项目。 在此示例中，我们将my_app在用户主目录中创建一个名为的新 Python 3.8 项目。 首先，创建项目目录并切换 到它： 12mkdir ~/my_app &amp;&amp; cd ~/my_app 从项目根目录内部运行以下命令以创建一个名为的虚拟环境my_app_venv： 12python3.8 -m venv my_app_venv 激活环境： 12source my_app_venv/bin/activate 激活后，shell 提示符将以环境名称为前缀。从 Python 3.4 开始，在创建虚拟环境pip 时， 默认安装 Python 的包管理器。 在虚拟环境中，您可以使用pip代替pip3.8和python代替python3.8： 12python -v Python 3.8.1完成停用环境的工作后，键入deactivate，您将返回到正常的 shell。 1deactivate 配置Python默认版本为3.8.0 https://www.jianshu.com/p/aca71ba154b6 1234ln -s /usr/local/bin/python3.8 /usr/bin/pythonpython -m pip install --upgrade pip centos 7Start by updating the repository:12sudo yum update -y 通过在终端窗口中运行以下命令来安装 Python 3：12sudo yum install -y python3 验证您是否已成功安装 Python 3：python3 --version 参考文章 https://www.liquidweb.com/kb/how-to-install-python-3-on-centos-7/ https://phoenixnap.com/kb/how-to-install-python-3-centos-7 https://linuxize.com/post/how-to-install-python-on-centos-8/ https://linuxize.com/post/how-to-install-pip-on-centos-8/","link":"/2021/12/24/python/python-centos-install/"},{"title":"study plan","text":"github BigData-Notes Hadoop Hive Spark Storm Flink HBase Kafka Zookeeper Flume Sqoop Azkaban Scalahttps://github.com/heibaiying/BigData-Notes/tree/master/notes 参考文章","link":"/2021/12/16/study/study-plan/"},{"title":"spring 事务","text":"spring 事务传播属性 常量 解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。默认的传播属性。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 前六个策略类似于EJB CMT，第七个（PROPAGATION_NESTED）是Spring所提供的一个特殊变量。它要求事务管理器或者使用JDBC 3.0 Savepoint API提供嵌套事务行为（如Spring的DataSourceTransactionManager） 事务的传播机制事务的传播性一般用在事务嵌套的场景，比如一个事务方法里面调用了另外一个事务方法，那么两个方法是各自作为独立的方法提交还是内层的事务合并到外层的事务一起提交，这就是需要事务传播机制的配置来确定怎么样执行。常用的事务传播机制如下： PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务 Spring默认的传播机制。 如果外层有事务，则当前事务加入到外层事务，一块提交，一块回滚。如果外层没有事务，新建一个事务执行 explain:123456789ServiceA { void methodA() { //外部事务 ServiceB.methodB(); } } ServiceB { void methodB() { //内部事务 } } ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED, 那么由于执行ServiceA.methodA的时候1、如果ServiceA.methodA已经起了事务，这时调用ServiceB.methodB，ServiceB.methodB看到自己已经运行在ServiceA.methodA的事务内部，就不再起新的事务。这时只有外部事务并且他们是共用的，所以这时ServiceA.methodA或者ServiceB.methodB无论哪个发生异常methodA和methodB作为一个整体都将一起回滚。2、如果ServiceA.methodA没有事务，ServiceB.methodB就会为自己分配一个事务。这样，在ServiceA.methodA中是没有事务控制的。只是在ServiceB.methodB内的任何地方出现异常，ServiceB.methodB将会被回滚，不会引起ServiceA.methodA的回滚 PROPAGATION_REQUES_NEW该事务传播机制是每次都会新开启一个事务，同时把外层事务挂起，当当前事务执行完毕，恢复上层事务的执行。如果外层没有事务，执行当前新开启的事务即可 新建的事务和挂起的事务是两个独立的事务。1.标志REQUIRES_NEW会新开启事务，外层事务不会影响内部事务的提交/回滚2.标志REQUIRES_NEW的内部事务的异常，被外部事务捕获，也可以不处理回滚操作 如果设计ServiceA.methodA事务级别定义为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED_NEW,那么，当执行到ServiceB.methodB的时候, ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会发起一个新事务， 等待 ServiceB.methodB的事务完成以后，挂起的事务才会继续执行。 它与PROPAGATION_REQUIRED的区别在于事务的回滚程度。因为ServiceB.methodB新发起一个事务，存在两个不同的事务。如果ServiceB.methodB 已经提交，那么 ServiceA.methodA 回滚失败时 ServiceB.methodB 是不会回滚的。 如果ServiceB.methodB 回滚失败，他抛出的异常被ServiceA.methodA 捕获，ServiceA.methodA的事务任然可能提交（主要看ServiceB.methodB抛出的异常是不是ServiceA.methodA会回滚的异常 ）。 PROPAGATION_SUPPORTS如果当前在事务中，即以事务的形式运行，如果当前不再一个事务中，那么就以非事务的形式运行 PROPAGATION_NOT_SUPPORT该传播机制不支持事务，如果外层存在事务则挂起，执行完当前代码，则恢复外层事务，无论是否异常都不会回滚当前的代码 当前不支持事务。比如ServiceA.methodA的事务级别是PROPAGATION_REQUIRED ，而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时，ServiceA.methodA的事务挂起，而他以非事务的状态运行完，再继续ServiceA.methodA的事务。 PROPAGATION_NEVER该传播机制不支持外层事务，即如果外层有事务就抛出异常 不能在事务中运行。假设ServiceA.methodA的事务级别是PROPAGATION_REQUIRED， 而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。 PROPAGATION_MANDATORY必须在一个事务中运行。也就是说，他只能被一个父事务调用。否则，他就要抛出异常 PROPAGATION_NESTED如果有活动的事务，则运行在一个嵌套的事务中。如果没有活动事务，则按required属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器有效。 该传播机制的特点是可以保存状态保存点，当前事务回滚到某一个点，从而避免所有的嵌套事务都回滚，即各自回滚各自的，如果子事务没有把异常吃掉，基本还是会引起全部回滚的。 比如我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_NESTED，那么当执行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会起一个新的子事务并设置savepoint，等待ServiceB.methodB的事务完成以后，他才继续执行。。因为ServiceB.methodB是外部事务的子事务，那么1、如果ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚，ServiceB.methodB也将回滚。2、如果ServiceB.methodB失败回滚，如果他抛出的异常被ServiceA.methodA的try..catch捕获并处理，ServiceA.methodA事务仍然可能提交；如果他抛出的异常未被ServiceA.methodA捕获处理，ServiceA.methodA事务将回滚。 理解Nested的关键是savepoint。他与PROPAGATION_REQUIRES_NEW的区别是：PROPAGATION_REQUIRES_NEW 完全是一个新的事务,它与外部事务相互独立；而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 嵌套事务也会被 commit, 这个规则同样适用于 roll back. 在 spring 中使用 PROPAGATION_NESTED的前提： 我们要设置 transactionManager 的 nestedTransactionAllowed 属性为 true, 注意, 此属性默认为 false!!! java.sql.Savepoint 必须存在, 即 jdk 版本要 1.4+ Connection.getMetaData().supportsSavepoints() 必须为 true, 即 jdbc drive 必须支持 JDBC 3.0 确保以上条件都满足后, 你就可以尝试使用 PROPAGATION_NESTED 了. 事务的隔离级别事务的隔离级别定义一个事务可能受其他并发务活动活动影响的程度，可以把事务的隔离级别想象为这个事务对于事物处理数据的自私程度。 在一个典型的应用程序中，多个事务同时运行，经常会为了完成他们的工作而操作同一个数据。并发虽然是必需的，但是会导致以下问题： 脏读（Dirty read）脏读发生在一个事务读取了被另一个事务改写但尚未提交的数据时。如果这些改变在稍后被回滚了，那么第一个事务读取的数据就会是无效的。 不可重复读（Nonrepeatable read）不可重复读发生在一个事务执行相同的查询两次或两次以上，但每次查询结果都不相同时。这通常是由于另一个并发事务在两次查询之间更新了数据。不可重复读重点在修改。 幻读（Phantom reads）幻读和不可重复读相似。当一个事务（T1）读取几行记录后，另一个并发事务（T2）插入了一些记录时，幻读就发生了。在后来的查询中，第一个事务（T1）就会发现一些原来没有的额外记录。幻读重点在新增或删除。 在理想状态下，事务之间将完全隔离，从而可以防止这些问题发生。然而，完全隔离会影响性能，因为隔离经常涉及到锁定在数据库中的记录（甚至有时是锁表）。完全隔离要求事务相互等待来完成工作，会阻碍并发。因此，可以根据业务场景选择不同的隔离级别。 隔离级别 含义 ISOLATION_DEFAULT 使用后端数据库默认的隔离级别 ISOLATION_READ_UNCOMMITTED 允许读取尚未提交的更改。可能导致脏读、幻读或不可重复读。 ISOLATION_READ_COMMITTED （Oracle 默认级别） 允许从已经提交的并发事务读取。可防止脏读，但幻读和不可重复读仍可能会发生。 ISOLATION_REPEATABLE_READ （MYSQL默认级别） 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻读仍可能发生。 ISOLATION_SERIALIZABLE 完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。 只读如果一个事务只对数据库执行读操作，那么该数据库就可能利用那个事务的只读特性，采取某些优化措施。通过把一个事务声明为只读，可以给后端数据库一个机会来应用那些它认为合适的优化措施。由于只读的优化措施是在一个事务启动时由后端数据库实施的， 因此，只有对于那些具有可能启动一个新事务的传播行为（PROPAGATION_REQUIRES_NEW、PROPAGATION_REQUIRED、 ROPAGATION_NESTED）的方法来说，将事务声明为只读才有意义。 事务超时为了使一个应用程序很好地执行，它的事务不能运行太长时间。因此，声明式事务的下一个特性就是它的超时。 假设事务的运行时间变得格外的长，由于事务可能涉及对数据库的锁定，所以长时间运行的事务会不必要地占用数据库资源。这时就可以声明一个事务在特定秒数后自动回滚，不必等它自己结束。 由于超时时钟在一个事务启动的时候开始的，因此，只有对于那些具有可能启动一个新事务的传播行为（PROPAGATION_REQUIRES_NEW、PROPAGATION_REQUIRED、ROPAGATION_NESTED）的方法来说，声明事务超时才有意义。 回滚规则在默认设置下，事务只在出现运行时异常（runtime exception）时回滚，而在出现受检查异常（checked exception）时不回滚（这一行为和EJB中的回滚行为是一致的）。不过，可以声明在出现特定受检查异常时像运行时异常一样回滚。同样，也可以声明一个事务在出现特定的异常时不回滚，即使特定的异常是运行时异常。 Spring声明式事务配置参考事物配置中有哪些属性可以配置?以下只是简单的使用参考 事务的传播性：@Transactional(propagation=Propagation.REQUIRED) 事务的隔离级别：@Transactional(isolation = Isolation.READ_UNCOMMITTED) 读取未提交数据(会出现脏读, 不可重复读) 基本不使用 只读：@Transactional(readOnly=true) 该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false。 事务的超时性：@Transactional(timeout=30) 回滚： 指定单一异常类：@Transactional(rollbackFor=RuntimeException.class) 指定多个异常类：@Transactional(rollbackFor={RuntimeException.class, Exception.class})","link":"/2021/10/19/spring/spring-affairs/"},{"title":"Spring Boot Embedded Tomcat Configuration","text":"12345678# HTTP Access Loggingapplication.propertiesserver.tomcat.accesslog.enabled=trueserver.tomcat.accesslog.directory=logsserver.tomcat.accesslog.file-date-format=yyyy-MM-ddserver.tomcat.accesslog.prefix=access_logserver.tomcat.accesslog.suffix=.logserver.tomcat.accesslog.rotate=true Remote Connection Properties12345678910application.propertiesserver.connection-timeout=10sserver.max-http-header-size=8KBserver.tomcat.accept-count=100server.tomcat.max-connections=10000server.tomcat.max-threads=200server.tomcat.min-spare-threads=10server.tomcat.max-swallow-size=2MBserver.tomcat.max-http-post-size=2MB server.connection-timeout Time that connectors wait for another HTTP request before closing the connection. When not set, the connector’s container-specific default is used. Use a value of -1 to indicate infinite timeout. server.max-http-header-size Maximum size of the HTTP message header. server.tomcat.accept-count Maximum queue length for incoming connection requests when all possible request processing threads are in use. server.tomcat.max-connections Maximum number of connections that the server accepts and processes at any given time. server.tomcat.max-threads Maximum amount of worker threads in server under top load. In other words, maximum number of simultaneous requests that can be handled. server.tomcat.min-spare-threads The minimum number of threads always kept running. This includes both active and idle threads. server.tomcat.max-swallow-size The maximum number of request body bytes (excluding transfer encoding overhead) that will be swallowed by Tomcat for an aborted upload. An aborted upload is when Tomcat knows that the request body is going to be ignored but the client still sends it.If Tomcat does not swallow the body the client is unlikely to see the response. If not specified the default of 2097152 (2 megabytes) will be used. A value of less than zero indicates that no limit should be enforced. server.tomcat.max-http-post-size Maximum size of the HTTP post content. HTTP Access Logging1234567application.propertiesserver.tomcat.accesslog.enabled=trueserver.tomcat.accesslog.directory=logsserver.tomcat.accesslog.file-date-format=yyyy-MM-ddserver.tomcat.accesslog.prefix=access_logserver.tomcat.accesslog.suffix=.logserver.tomcat.accesslog.rotate=true server.tomcat.accesslog.enabled – Enable access logging or not. server.tomcat.accesslog.directory – Directory in which log files are created. Can be absolute or relative to the Tomcat base dir. server.tomcat.accesslog.file-date-format – Date format to place in the log file name. server.tomcat.accesslog.prefix – Log file name prefix. server.tomcat.accesslog.suffix – Log file name suffix. server.tomcat.accesslog.rotate – Whether to enable access log rotation. 参考文章 Spring Boot Embedded Tomcat Configuration Tomcat Access Log配置","link":"/2021/12/27/spring/spring-embeded-tomcat-configruation/"},{"title":"BeanFactory和ApplicationContext的区别","text":"接口 BeanFactory 和 ApplicationContext 都是用来从容器中获取 Spring beans 的，但是，他们二者有很大不同 什么是 Spring BeanSpring beans 就是被 Spring 容器所管理的 Java 对象，来看一个简单的例子 12345678910package com.zoltanraffai; public class HelloWorld { private String message; public void setMessage(String message){ this.message = message; } public void getMessage(){ System.out.println(&quot;My Message : &quot; + message); } } 什么是 Spring 容器Spring 容器负责实例化，配置和装配 Spring beans，下面来看如何为 IoC 容器配置我们的 HelloWorld POJO 123456789&lt;?xml version = &quot;1.0&quot; encoding = &quot;UTF-8&quot;?&gt;&lt;beans xmlns = &quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi = &quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation = &quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd&quot;&gt; &lt;bean id = &quot;helloWorld&quot; class = &quot;com.zoltanraffai.HelloWorld&quot;&gt; &lt;property name = &quot;message&quot; value = &quot;Hello World!&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 现在，它已经被 Spring 容器管理了，接下来的问题是：我们怎样获取它？ BeanFactory 和 ApplicationContext 的不同点BeanFactory 接口这是一个用来访问 Spring 容器的 root 接口，要访问 Spring 容器，我们将使用 Spring 依赖注入功能，使用 BeanFactory 接口和它的子接口特性： Bean 的实例化/串联 通常情况，BeanFactory 的实现是使用懒加载的方式，这意味着 beans 只有在我们通过 getBean() 方法直接调用它们时才进行实例化实现 BeanFactory 最常用的 API 是 XMLBeanFactory这里是如何通过 BeanFactory 获取一个 bean 的例子： 1234567891011package com.zoltanraffai; import org.springframework.core.io.ClassPathResource; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.xml.XmlBeanFactory; public class HelloWorldApp{ public static void main(String[] args) { XmlBeanFactory factory = new XmlBeanFactory (new ClassPathResource(&quot;beans.xml&quot;)); HelloWorld obj = (HelloWorld) factory.getBean(&quot;helloWorld&quot;); obj.getMessage(); }} ApplicationContext 接口ApplicationContext 是 Spring 应用程序中的中央接口，用于向应用程序提供配置信息它继承了 BeanFactory 接口，所以 ApplicationContext 包含 BeanFactory 的所有功能以及更多功能！它的主要功能是支持大型的业务应用的创建特性： Bean instantiation/wiring Bean 的实例化/串联 自动的 BeanPostProcessor 注册 自动的 BeanFactoryPostProcessor 注册 方便的 MessageSource 访问（i18n） ApplicationEvent 的发布 与 BeanFactory 懒加载的方式不同，它是预加载，所以，每一个 bean 都在 ApplicationContext 启动之后实例化这里是 ApplicationContext 的使用例子： 1234567891011package com.zoltanraffai; import org.springframework.core.io.ClassPathResource; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.xml.XmlBeanFactory; public class HelloWorldApp{ public static void main(String[] args) { ApplicationContext context=new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); HelloWorld obj = (HelloWorld) context.getBean(&quot;helloWorld&quot;); obj.getMessage(); }} 总结ApplicationContext 包含 BeanFactory 的所有特性，通常推荐使用前者。但是也有一些限制情形，比如移动应用内存消耗比较严苛，在那些情景中，使用更轻量级的 BeanFactory 是更合理的。然而，在大多数企业级的应用中，ApplicationContext 是你的首选。 参考文章 面试还不知道BeanFactory和ApplicationContext的区别？","link":"/2021/11/03/spring/spring-diff-of-BeanFactory-and-ApplicationContext/"},{"title":"reactive webclient","text":"12345678WebClient.create().get() .uri(&quot;https://example.org/path&quot;) .httpRequest(httpRequest -&gt; { HttpClientRequest reactorRequest = httpRequest.getNativeRequest(); reactorRequest.responseTimeout(Duration.ofSeconds(2)); }) .retrieve() .bodyToMono(String.class); WebClient &amp; HttpClient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MyWebClient { public static void main(String[] args) throws IOException { Mono&lt;ClientResponse&gt; clientResponseMono = createWebClient(createHttpClient(&quot;webClient-pool&quot;, 30)) .get() .uri(&quot;http://localhost:8089/&quot;) // .headers(httpHeaders -&gt; httpHeaders.add(&quot;Connection&quot;, &quot;keep-alive&quot;)) .httpRequest(httpRequest -&gt; { HttpClientRequest reactorRequest = httpRequest.getNativeRequest(); reactorRequest.responseTimeout(Duration.ofSeconds(2)); }) .exchange() .doOnDiscard(PooledDataBuffer.class, DataBufferUtils::release); clientResponseMono.block(); /* ServerRequest request; createWebClient(createHttpClient(&quot;webClient-pool&quot;, 30)) .method(HttpMethod.GET) .uri(&quot;Url&quot;) .body(BodyInserters.fromDataBuffers(request.body(BodyExtractors.toDataBuffers()))) .headers(httpHeaders -&gt; httpHeaders.addAll(request.headers().asHttpHeaders())) .exchange() .doOnError(throwable -&gt; log.error(&quot;&quot;)) .doOnSuccess(clientResponse -&gt; log.info(&quot;success&quot;)) .doFinally(signalType -&gt; log.info(&quot;do on finally&quot;)) .doOnDiscard(PooledDataBuffer.class, DataBufferUtils::release); */ } private static WebClient createWebClient(HttpClient httpClient) { return WebClient.builder() .filter(new LogFilter()) .clientConnector(new ReactorClientHttpConnector(httpClient)) .exchangeStrategies(ExchangeStrategies.builder().codecs(configurer -&gt; configurer.defaultCodecs().maxInMemorySize(-1)).build()) .uriBuilderFactory(new MyUriBuilderFactory()) .build(); } private static HttpClient createHttpClient(String poolName, int timeoutSec) { return HttpClient .create(ConnectionProvider.builder(poolName) .maxConnections(20480) .maxIdleTime(Duration.of(600, ChronoUnit.SECONDS)) .build() ) .tcpConfiguration(tcpClient -&gt; tcpClient .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, (int)TimeUnit.SECONDS.toMillis(10)) .option(ChannelOption.SO_KEEPALIVE, false) .doOnConnected(connection -&gt; connection .addHandlerLast(new ReadTimeoutHandler(timeoutSec)) .markPersistent(false) ) ) .followRedirect(false) .keepAlive(false) .compress(true); }} 123456789101112131415161718192021222324import java.net.URI;import java.util.Optional;import org.springframework.web.reactive.function.client.ClientRequest;import org.springframework.web.reactive.function.client.ClientResponse;import org.springframework.web.reactive.function.client.ExchangeFilterFunction;import org.springframework.web.reactive.function.client.ExchangeFunction;import lombok.extern.slf4j.Slf4j;import reactor.core.publisher.Mono;@Slf4jpublic class LogFilter implements ExchangeFilterFunction { @Override public Mono&lt;ClientResponse&gt; filter(ClientRequest request, ExchangeFunction next) { URI url = request.url(); Optional&lt;String&gt; traceIdOption = Optional.ofNullable(request.headers().getFirst(&quot;trace-id&quot;)); log.info(&quot;{} Request: {} {}&quot;, traceIdOption.orElse(request.logPrefix()), request.method(), url); return next.exchange(request).flatMap(response -&gt; { log.info(&quot;{} Response:{} {} {}&quot;, traceIdOption.orElse(response.logPrefix()), request.method(), url, response.statusCode()); return Mono.just(response); }); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.example.demo.reactorclient;import java.io.UnsupportedEncodingException;import java.net.URI;import java.net.URISyntaxException;import java.net.URLDecoder;import java.util.Map;import java.util.function.Supplier;import org.apache.commons.codec.Charsets;import org.springframework.web.util.UriBuilderFactory;import org.springframework.web.util.UriComponentsBuilder;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class MyUriBuilderFactory implements UriBuilderFactory { public UriComponentsBuilder uriString(String uriTemplate) { return UriComponentsBuilder.fromUriString(uriTemplate); } @Override public UriComponentsBuilder builder() { return UriComponentsBuilder.newInstance(); } @Override public URI expand(String uriTemplate, Map&lt;String, ?&gt; uriVariables) { return expand(uriTemplate, () -&gt; uriVariables); } @Override public URI expand(String uriTemplate, Object... uriVariables) { return expand(uriTemplate, () -&gt; uriVariables); } public &lt;T&gt; URI expand(String uriTemplate, Supplier&lt;T&gt; uriVariablesSupplier) { T uriVariables = uriVariablesSupplier.get(); try { return new URI(UriComponentsBuilder.fromHttpUrl(uriTemplate).build().expand(uriVariables).toUriString()); } catch (URISyntaxException e) { try { String decode = URLDecoder.decode(uriTemplate, Charsets.UTF_8.name()); String encodeUrl = UriComponentsBuilder.fromHttpUrl(decode).build().expand(uriVariables).encode().toUriString(); log.warn(&quot;Url encode:[{},{}]&quot;, uriTemplate, encodeUrl); return new URI(encodeUrl); } catch (URISyntaxException | IllegalArgumentException | UnsupportedEncodingException exception) { log.error(exception.getMessage() + &quot;:&quot; + uriTemplate, exception); // log error for monitor throw new RuntimeException(&quot;bad request&quot;); } } }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;reactor-netty.version&gt;0.9.12.RELEASE&lt;/reactor-netty.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-reactor-netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;${reactor-netty.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/io.netty/netty-all --&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.69.Final&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; HttpClient keepalive configref: https://projectreactor.io/docs/netty/snapshot/api/index.html?reactor/netty/http/client/HttpClient.html 1234567891011121314151617181920private static HttpClient createHttpClient(String poolName, int timeoutSec) { return HttpClient .create(ConnectionProvider.builder(poolName) .maxConnections(20480) .maxIdleTime(Duration.of(600, ChronoUnit.SECONDS)) .build() ) .tcpConfiguration(tcpClient -&gt; tcpClient .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, (int)TimeUnit.SECONDS.toMillis(10)) .option(ChannelOption.SO_KEEPALIVE, false) .doOnConnected(connection -&gt; connection .addHandlerLast(new ReadTimeoutHandler(timeoutSec)) .markPersistent(false) ) ) .followRedirect(false) .keepAlive(false) .compress(true);} note如果 httpClient.keepalive = false,可以通过 添加 header: &quot;Connection&quot;,&quot;keep-alive&quot;, 启用 keepalive 参考文章 reactive web client Spring 5 WebClient reactor netty httpclient","link":"/2021/12/08/reactive/reactive-webclient/"},{"title":"Spring Boot Customize Whitelabel Error Page","text":"123456789@Controllerpublic class MyErrorController implements ErrorController { @RequestMapping(&quot;/error&quot;) public String handleError() { //do something like logging return &quot;error&quot;; }} ref: https://www.baeldung.com/spring-boot-custom-error-page How to use Thymeleaf with Spring Boot 参考文章 Spring Boot: Customize Whitelabel Error Page","link":"/2021/12/21/spring/spring-embeded-tomcat-custom-error-page/"},{"title":"spring log4j jdbc","text":"jdbc.sqlonly : 仅记录 SQL jdbc.sqltiming ：记录 SQL 以及耗时信息 jdbc.audit ：记录除了 ResultSet 之外的所有 JDBC 调用信息，会产生大量的记录，有利于调试跟踪具体的 JDBC 问题 jdbc.resultset ：会产生更多的记录信息，因为记录了 ResultSet 的信息 jdbc.connection ：记录连接打开、关闭等信息，有利于调试数据库连接相关问题 jdbc.sqlonlyLogs only SQL. SQL executed within a prepared statement is automaticallyshown with it’s bind arguments replaced with the data bound at that position, for greatlyincreased readability. jdbc.sqltimingLogs the SQL, post-execution, including timing statistics on how long the SQLtook to execute. jdbc.auditLogs ALL JDBC calls except for ResultSets. This is a very voluminous output, andis not normally needed unless tracking down a specific JDBC problem. jdbc.resultsetEven more voluminous, because all calls to ResultSet objects are logged. jdbc.connectionLogs connection open and close events as well as dumping all open connectionnumbers. This is very useful for hunting down connection leak problems. 参考文章 Logging with log4jdbc 如何有效地记录 Java SQL 日志？ sqlonly,sqltiming,audit,resultset,connection Spring Boot 入门之整合 log4jdbc 篇（六）","link":"/2021/12/28/spring/spring-log4j-jdbc/"},{"title":"spring中的@PostConstruct注解的用法","text":"@PostConstruct是java5的时候引入的注解，指的是在项目启动的时候执行这个方法，也可以理解为在spring容器启动的时候执行，可作为一些数据的常规化加载，比如数据字典之类的。 @PostConstruct注解使用简介简单起见，我们准备一个springboot项目快速启动。项目目录结构如下： 下面我们在cn.lay.postconstruct目录下创建一个类，并添加一个@PostConstruct的方法，如 最后，我们执行PostConstructApplication的main方法，启动项目。在控制台里，我们会看到 到这里，我们可以知道@PostConstruct注解的用途了。当一个class被注解为一个Bean，那么class上被@PostConstruct注解的方法将会在程序启动的时候执行。 知道了如何使用@PostConstruct以后，我们会产生疑问。为什么@PostConstruct注解的方法会在程序启动的时候执行呢？后续的内容将为你解开疑惑。 @PostConstruct原理 ref: https://www.cnblogs.com/lay2017/p/11735802.html 转载自：https://www.cnblogs.com/mark5/p/12767120.html被@PostConstruct修饰的方法会在服务器加载Servle的时候运行，并且只会被服务器执行一次。PostConstruct在构造函数之后执行也就是加载顺序 服务器加载Servlet -&gt; servlet 构造函数的加载 -&gt; postConstruct -&gt;init（init是在service 中的初始化方法. 创建service 时发生的事件.） -&gt;Service-&gt;destory-&gt;predestory-&gt;服务器卸载serlvet 那么问题：spring中Constructor、@Autowired、@PostConstruct的顺序 Constructor &gt;&gt; @Autowired &gt;&gt; @PostConstruct 依赖注入的字面意思就可以知道，要将对象p注入到对象a，那么首先就必须得生成对象p与对象a，才能执行注入。所以，如果一个类A中有个成员变量p被@Autowired注解，那么@Autowired注入是发生在A的构造方法执行完之后的。 @PostConstruct应用场景：如果想在生成对象时候完成某些初始化操作，而偏偏这些初始化操作又依赖于依赖注入，那么就无法在构造函数中实现。为此，可以使用@PostConstruct注解一个方法来完成初始化，@PostConstruct注解的方法将会在依赖注入完成后被自动调用。 参考文章 https://www.cnblogs.com/mark5/p/12767120.html https://www.cnblogs.com/lay2017/p/11735802.html","link":"/2021/11/03/spring/spring-postconstruct/"},{"title":"How to use Thymeleaf with Spring Boot","text":"Thymeleaf是一种流行的服务器端模板引擎，适用于 Web 和独立 Java 应用程序。 它被开发用于处理不同类型的文件，如 HTML、XML、JavaScript、CSS 和纯文本。 使用 Thymeleaf 的最大优势是它为您的开发工作流程带来了自然模板——HTML模板可以直接在浏览器中打开并仍然正确呈现为网页。这为快速开发静态原型提供了极大的灵活性，而无需在创建后端服务器上浪费时间。 与其他著名的模板引擎（如 JavaServer Pages (JSP)）相比，Thymeleaf 使整个开发过程变得非常简单和快速。在本文中，您将学习如何将 Thymeleaf 模板引擎与 Spring Boot 结合使用来提供动态 Web 内容。 依赖关系Spring Boot 对 Thymeleaf 模板引擎提供了极好的支持，使得整个集成过程非常简单明了。您需要做的只是将Thymeleaf 的Spring Boot starter包含到您的应用程序依赖项中。Spring Boot 将自动配置您使用 Thymeleaf 引擎所需的一切。要激活 Spring Boot Web 支持，请确保同时包含 Spring Boot Web starter 依赖项 ( spring-boot-starter-web)。 对于 Gradle 项目，将以下依赖项包含到您的build.gradle文件中： 12implementation 'org.springframework.boot:spring-boot-starter-thymeleaf'implementation 'org.springframework.boot:spring-boot-starter-web' 对于 Maven，将以下依赖项添加到pom.xml文件中： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 如果您是从头开始，只需使用Spring Initializr Web 工具或Spring Boot CLI即可使用上述依赖项快速引导一个新的 Spring Boot 项目。 模板Thymeleaf 模板只是HTML 静态文件（.html扩展名），可在浏览器和 Web 应用程序中使用。默认情况下，这些模板存储在src/main/resources/templates/文件夹中。Spring Boot 会在需要时自动选择并呈现这些 HTML 文件。 让我们创建我们的第一个 Thymeleaf 模板index.html，并将其放入src/main/resources/templates文件夹中： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Spring Boot Thymeleaf Web Application&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to Spring Boot Thymeleaf&lt;/h1&gt;&lt;p&gt; Hey there! &lt;th:block th:text=&quot;${message}&quot;&gt;message&lt;/th:block&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Thymeleaf 引擎将解析上述index.html文件，评估th:text表达式并替换${message}为 Spring Boot Web 控制器类提供的实际值。 Spring Boot 控制器现在让我们定义一个名为 Spring Boot 控制器类IndexController.java，它处理端点上的所有 HTTP GET请求/并返回需要作为响应呈现的视图的名称： 12345678910111213141516171819package com.attacomsian.getstarted.controllers;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;@Controllerpublic class IndexController { @GetMapping(&quot;/&quot;) public String index(Model model) { // add `message` attribute model.addAttribute(&quot;message&quot;, &quot;Thank you for visiting.&quot;); // return view name return &quot;index&quot;; }} 正如你在上面看到的，我们定义了一个简单的 Spring 控制器，它只接受端点上的GET请求/。所述@Controller注释指示注解的类是“控制器”（例如一个网络控制器）。 该@GetMapping注释被用于映射HTTP GET请求到特定的控制器的方法。在上面的例子中，它将/端点映射到index()方法上。Model是一个特殊的接口，用于在 Spring Boot 中的控制器和视图之间共享数据。我们已将message属性添加到Model视图模板中所需的对象 —index.html文件。 该index()方法以字符串形式返回视图模板的名称。Thymeleaf 将在默认文件夹 ( src/main/resources/templates/) 中搜索此模板并进行渲染。 运行和测试应用程序12345678910111213package com.attacomsian.getstarted;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 应用程序启动后，在 Web 浏览器中打开http://localhost:8080/以查看输出。这是它的样子： 更改 Thymeleaf 默认属性Spring Boot 为 Thymeleaf 模板引擎提供了默认配置。要覆盖默认属性值，您可以在application.properties或application.yml配置文件中定义属性。 更改模板文件夹位置要更改 HTML 模板的默认文件夹位置，您需要覆盖以下属性： 12# change location from `templates` to `views`spring.thymeleaf.prefix=classpath:/views/ 禁用模板缓存默认情况下，Spring Boot 会缓存 Thymeleaf 模板以提高性能。如果您希望模板在修改时自动更新，请覆盖以下属性（不推荐在生产中使用）： 12spring.thymeleaf.cache=false 参考文章 https://attacomsian.com/blog/spring-boot-thymeleaf-example","link":"/2021/12/03/spring/spring-use-thymeleaf/"},{"title":"Spring — Dynamically register beans in 4 ways At Run-Time","text":"使用 GenericBeanDefinition 进行动态 Bean 注册GenericBeanDefinition 是用于标准 bean 定义目的的一站式商店。像任何 bean 定义一样，它允许指定一个类以及可选的构造函数参数值和属性值。此外，可以通过“ parentName ”属性灵活地配置从父 bean 定义派生。通常，使用这个GenericBeanDefinition类来注册用户可见的 bean 定义（后处理器可能会对其进行操作，甚至可能重新配置父名称）。使用RootBeanDefinition / ChildBeanDefinition，其中父/子关系恰好是预先确定的。 123456789public class MyBean { private Date date; public void doSomething () { System.out.println(&quot;from my bean, date: &quot; + date); } public void setDate (Date date) { this.date = date; }} 注册上面的，使用GenericBeanDefinition动态创建的 bean 。 12345678910111213141516public class GenericBeanDefinitionExample { public static void main (String[] args) { DefaultListableBeanFactory context = new DefaultListableBeanFactory(); GenericBeanDefinition gbd = new GenericBeanDefinition(); gbd.setBeanClass(MyBean.class); MutablePropertyValues mpv = new MutablePropertyValues(); mpv.add(&quot;date&quot;, new Date()); //alternatively we can use: // gbd.getPropertyValues().addPropertyValue(&quot;date&quot;, new Date()); gbd.setPropertyValues(mpv); context.registerBeanDefinition(&quot;myBeanName&quot;, gbd); MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 1from my bean, date: Wed Jult 23 12:20:58 EDT 2019 使用 BeanDefinitionBuilder 动态注册 Bean使用构建器模式构建BeanDefinitions 的编程方法。主要用于在实现 Spring 2.0 NamespaceHandlers 时使用。这里唯一的区别是， BeanDefinitionBuilder 使用Builder Pattern。 创建另一个 bean 类。 123456789public class MyBean { private String str; public void setStr (String str) { this.str = str; } public void doSomething () { System.out.println(&quot;from MyBean &quot; + str); }} 使用BeanDefinitionBuilder动态注册 bean 的示例。 123456789101112public class BeanDefinitionBuilderExample { public static void main (String[] args) { DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); BeanDefinitionBuilder b = BeanDefinitionBuilder.rootBeanDefinition(MyBean.class) .addPropertyValue(&quot;str&quot;, &quot;myStringValue&quot;); beanFactory.registerBeanDefinition(&quot;myBean&quot;, b.getBeanDefinition()); MyBean bean = beanFactory.getBean(MyBean.class); bean.doSomething(); }} Output: 12from MyBean myStringValue 使用 BeanDefinitionBuilder 注入其他 bean 引用Creating Bean 1 123456789public class Bean1 { private Bean2 otherBean; public void setOtherBean (Bean2 otherBean) { this.otherBean = otherBean; } public void doSomething () { otherBean.doSomething(); }} Creating Bean 2 12345public class Bean2 { public void doSomething () { System.out.println(&quot;from other bean &quot;); }} Setting the Bean2 in Bean1 1234567891011121314151617181920public class InjectingOtherBeans { public static void main (String[] args) { DefaultListableBeanFactory context = new DefaultListableBeanFactory(); //define and register MyOtherBean GenericBeanDefinition beanOtherDef = new GenericBeanDefinition(); beanOtherDef.setBeanClass(Bean2.class); context.registerBeanDefinition(&quot;other&quot;, beanOtherDef); //definine and register myBean GenericBeanDefinition beanDef = new GenericBeanDefinition(); beanDef.setBeanClass(Bean1.class); MutablePropertyValues mpv = new MutablePropertyValues(); mpv.addPropertyValue(&quot;otherBean&quot;, context.getBean(&quot;other&quot;)); beanDef.setPropertyValues(mpv); context.registerBeanDefinition(&quot;myBean&quot;, beanDef); //using MyBean instance MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 1from other bean Dynamic Bean Registration With BeanFactoryPostProcessor一个BeanFactoryPostProcessor的可交互和修改bean定义，但从来没有bean实例。允许自定义修改应用程序上下文的 bean 定义，调整上下文底层 bean 工厂的 bean 属性值。应用程序上下文可以在它们的 bean 定义中自动检测BeanFactoryPostProcessor bean，并在创建任何其他 bean 之前应用它们。 创建配置1234567@Configuration public class MyConfig { @Bean MyConfigBean myConfigBean () { return new MyConfigBean(); } } BeanFactoryPostProcessor允许客户端代码自定义 bean 定义。方法BeanFactoryPostProcessor.postProcessBeanFactory在所有 bean 定义加载后由 Spring 启动过程调用，但尚未实例化任何 bean。 123456789101112public class MyConfigBean implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory ( ConfigurableListableBeanFactory beanFactory) throws BeansException { GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setBeanClass(MyBean.class); bd.getPropertyValues().add(&quot;strProp&quot;, &quot;my string property&quot;); ((DefaultListableBeanFactory) beanFactory) .registerBeanDefinition(&quot;myBeanName&quot;, bd); }} BeanFactoryPostProcessor 示例的主类。 123456789public class MyBean { private String strProp; public void setStrProp (String strProp) { this.strProp = strProp; } public void doSomething () { System.out.println(&quot;from MyBean: &quot; + strProp); }} Main class for BeanFactoryPostProcessor Example. 12345678public class BeanFactoryPostProcessorExample { public static void main (String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 123from MyBean: my string propertyWARNING: @Bean method MyConfig.myConfigBean is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details. 使用 BeanFactoryPostProcessor 动态注册 Bean对标准BeanFactoryPostProcessor SPI 的扩展，允许在常规 BeanFactoryPostProcessor 检测开始之前注册进一步的 bean 定义。特别是，BeanDefinitionRegistryPostProcessor可以注册进一步的 bean 定义，进而定义BeanFactoryPostProcessor实例。 Creating another config class. 1234567@Configurationpublic class MyConfig { @Bean MyConfigBean myConfigBean () { return new MyConfigBean(); }} 这是BeanFactoryPostProcessor的子接口（最后一个例子）。它允许注册 bean 定义。它的方法postProcessBeanDefinitionRegistry在BeanFactoryPostProcessor#postProcessBeanFactory之前被调用。该接口更侧重于 BeanDefinition 注册而不是通用BeanFactoryPostProcessor。为 BeanDefinitionRegistryPostProcessor 创建实现类。 123456789101112131415public class MyConfigBean implements BeanDefinitionRegistryPostProcessor { @Override public void postProcessBeanDefinitionRegistry (BeanDefinitionRegistry registry) throws BeansException { GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setBeanClass(MyBean.class); bd.getPropertyValues().add(&quot;strProp&quot;, &quot;my string property&quot;); registry.registerBeanDefinition(&quot;myBeanName&quot;, bd); } @Override public void postProcessBeanFactory (ConfigurableListableBeanFactory beanFactory) throws BeansException { //no op }} Creating a brand new Bean class. 123456789public class MyBean { private String strProp; public void setStrProp (String strProp) { this.strProp = strProp; } public void doSomething () { System.out.println(&quot;from MyBean: &quot; + strProp); }} Main class for BeanDefinitionRegistryPostProcessor Example. 12345678public class BeanDefinitionRegistryPostProcessorExample { public static void main (String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); MyBean bean = (MyBean) context.getBean(&quot;myBeanName&quot;); bean.doSomething(); }} Output: 123from MyBean: my string propertyWARNING: Cannot enhance @Configuration bean definition 'beanDefinitionRegistryPostProcessorExample.MyConfig' since its singleton instance has been created too early. The typical cause is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor return type: Consider declaring such methods as 'static'. Unregistering the Bean at run timeIf we need to remove registered beans at runtime, we can do the same as below.To remove or unregister the bean from spring context. 1beanRegistry.removeBeanDefinition(&quot;bean&quot;) To delete/clear the singleton bean from context. 1beanRegistry.destroySingleton(&quot;bean&quot;) 参考文章 https://medium.com/@venkivenki4b6/spring-dynamically-register-beans-in-4-ways-at-run-time-c1dc45dcbeb9 https://www.jianshu.com/p/25939d9ce832 https://www.cnblogs.com/monument/p/12933915.html SpringBoot基础篇Bean之动态注册","link":"/2021/11/03/spring/spring-register-bean-at-run-time/"},{"title":"wsl install centos","text":"参考文章 https://zhuanlan.zhihu.com/p/347461016 install centosWindows的应用商店中有一些不错的linux发行版，包括很多同学都很喜欢的ubuntu，但是个人比较熟悉使用centos，而应用商店中的centos是要收费的，不过好在github上面有CENTOS官方开源的安装包，我们这里使用github上的安装包进行安装。 如果使用应用商店中的发行版直接点击安装即可。随后便可以跳过下面的centos的安装部分。 首先我们去centos的GitHub页面下载对应的安装包：https://github.com/CentOS/sig-cloud-instance-images/blob/CentOS-8-x86_64/docker/centos-8-x86_64.tar.xz 接着我们以管理员身份打开一个powershell窗口： 1234# 安装 ChocolateySet-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))# 安装 LxRunOfflinechoco install lxrunoffline 注意这里安装完成之后需要重启powershell来进行下一步的安装 LxRunOffline.exe install -n centos -d D:\\wsl\\centos -f D:\\wsl\\centos-8-x86_64.tar.xz 12345LxRunOffline install -n 自定义系统名称 -d 安装目录路径 -f tar.xz安装包路径# 注意windows系统命令行中的文件路径和linux系统差别很大# 比如我这里的安装命令就是LxRunOffline.exe install -n centos -d D:/centos -f .\\centos-7-x86_64-docker.tar.xz# 将centos安装到D盘的centos文件夹下，并且命名为centos 接下来就可以使用下述两种方式尝试启动 12LxRunOffline run -n 自定义系统名称wsl -d 自定义系统名称 升级centos为wsl2123456# 列出已经安装的wsl的信息wsl -l -v# 将对应的wsl设为wsl2，注意&lt;Distro&gt;要和上面查询到的信息一致wsl --set-version &lt;Distro&gt; 2# 设置默认使用的发行版wsl -s &lt;Distro&gt;","link":"/2021/09/27/wsl/wsl-centos/"},{"title":"wsl install ubuntu","text":"参考文章 https://blog.csdn.net/weixin_45883933/article/details/106085184 安装前配置ref: 适用于 Linux 的 Windows 子系统安装指南 (Windows 10) 1. 启用 Windows 功能搜索并打开“启用或关闭 Windows 功能”，然后选择“适用于Linux的Windows子系统”复选框。 在windows功能中重新勾选hyper-v然后开启hyper-v模式在管理员powershell中执行 1bcdedit /set hypervisorlaunchtype auto 如果禁用了组策略里面的Device Guard虚拟化安全设置，需要打开组策略管理，本地计算机策略 &gt; 计算机配置 &gt; 管理模板&gt;系统 &gt; Device Guard打开 基于虚拟化的安全设置为“已开启”或者“未设置”随后重新开启wsl2，若不行，重启计算机。 启用虚拟机平台可选组件在 powerShell 中以管理员身份运行下面命令 1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 1dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 运行完成之后，请重启电脑完成安装. 设置WSL发行版如果想要将默认的WSL发行版设置成 WSL 2，在 powerShell 中使用下面命令 wsl --set-default-version 2如果想要设置某一个发行版为WSL2，在 powerShell 中使用下面命令，将 换成你想要设置的发行版即可，例如 Ubuntu-18.04 wsl --set-version &lt;Distro&gt; 2 wsl --set-version Ubuntu-20.04 2验证使用的WSL版本 wsl -l -v 下载安装 Ubuntu-20.04 (Windows 应用商店里)更新包目录，并使用分发版的首选包管理器升级已安装的包sudo apt update &amp;&amp; sudo apt upgrade Windows不会自动更新或升级Linux发行版：Linux用户经常意外自行控制此任务。123456789101112131415161718192021222324252627ubuntu@kylin：〜$ wslfetch ./+o+- Windows 10 Linux Subsystem yyyyy. 'yyyyyy+ root@kylin .;//+/h yyyyyyo BUILD: 19624 .++ .:/++++++/-.`sss/` BRANCH: rs_prerelease .:++o: `\\++++++++/:---:/- RELEASE: Ubuntu 20.04 LTS o:+o+:++. `````'-/ooo+++++\\ KERNEL: Linux 4.19.104-microsoft-standard .:+o:+o/. `+sssooo+\\ UPTIME: 0d 0h 2m .++/+ +oo+o:` \\sssooo; /+++//+: oo+o \\+/+o+++ o++o ydddhh+ .++.o+ +oo+:` /dddhhh; .+.o+oo:. oddhhhh+ \\+.++o+o` -,,,,.:ohdhhhhh+ `:o+++ ohhhhhhhhyo++os: .o: .syhhhhhhh'.oo++o. /osyyyyyyy.oooo+++\\ `````+oo+++o:/ `oo++'`root@kylin:~# lsb_release -a | lolcatNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 20.04 LTSRelease: 20.04Codename: focalubuntu @ kylin:/ $ sudo apt install lolcat sudo apt install lolcat lsb_release -a | lolcat wsl ubuntu config1 修改 默认的源 (更换国内源)cp /etc/apt/sources.list /etc/apt/sourses.list.bak 更换默认源为阿里源, 使用 sudo vim /etc/apt/sources.list 命令编辑，删除原来的内容，添加下面的阿里源信息 12345678910deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 更换源之后，使用下面的命令更新一下 12sudo apt-get updatesudo apt-get upgrade 2.ssh 连接 配置在WSL Ubuntu系统中安装ssh server当对Linux实现文件操作时，使用WinScp更为方便。因此需要使用ssh远程登陆 安装ssh serversudo apt-get install openssh-server 配置ssh使用 cp 命令将 SSH 相关配置备份sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak 使用 vim 编辑 sshd_config 文件 sudo vim /etc/ssh/sshd_config调整一下设置： 12345Port 22ListenAddress 0.0.0.0PermitRootLogin yesStrictModes yesPasswordAuthentication yes 12345678910111213141516171819root@summer:/# service ssh status * sshd is not runningroot@summer:/# service ssh start * Starting OpenBSD Secure Shell server sshd sshd: no hostkeys available -- exiting.root@summer:/# sshd -Tsshd: no hostkeys available -- exiting.root@summer:/# ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_keyroot@summer:/# ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_keyroot@summer:/etc/ssh# sshd -Troot@summer:/etc/ssh# service ssh start * Starting OpenBSD Secure Shell server sshd [ OK ] ＃Ubuntu的防火墙状态检测，防火墙可能限制SSH端口22root@summer:~# service ufw status * Firewall is not running... [fail]root@kylin:~# 重启ssh service 1sudo service ssh restart sshd: no hostkeys available — exiting在开启SSHD服务时报错.sshd re-exec requires execution with an absolute path用绝对路径启动,也报错如下:Could not load host key: /etc/ssh/ssh_host_keyCould not load host key: /etc/ssh/ssh_host_rsa_keyCould not load host key: /etc/ssh/ssh_host_dsa_keyDisabling protocol version 1. Could not load host keyDisabling protocol version 2. Could not load host keysshd: no hostkeys available — exiting解决过程: 123ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_keyssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key/usr/sbin/sshd 如果上述两个文件存在，仍然出现这个错误，那么试试 chmod 600 上述两个文件。之后应该可以解决。 ssh login登陆 SSH使用 SSH 指令登陆 ssh root@127.0.0.1 -p 22 运行/停止Ubuntu子系统wsl -l 列出了系统中安装的子系统名称，可以是一个或多个，本文中的子系统名称是Ubuntu-18.04-20190707，接下来针对这个默认子系统进行操作： 运行子系统wsl --distribution Ubuntu-18.04-20190707或者wsl -d Ubuntu-18.04-20190707 查看运行中的子系统-l --running12 适用于 Linux 的 Windows 子系统:Ubuntu-18.04-20190707 (默认) 停止子系统wsl -t Ubuntu-18.04-20190707或者wsl --terminate Ubuntu-18.04-20190707 备份/删除/还原子系统备份子系统非常简单，但一定要先停止子系统之后再备份wsl --export Ubuntu-18.04-20190707 c:\\temp\\Ubuntu-18.04-20190707.tar等待完成即可。备份成功后，子系统会被打包成命令中指定的tar文件。 删除子系统也是一个命令即可：wsl --unregister Ubuntu-18.04-20190707这样WSL子系统就从Windows中删除的干干净净了。 还原子系统删除了没关系，刚才做了备份，也是一个命令还原：wsl --import Ubuntu-18.04-20190707 c:\\WSL c:\\temp\\Ubuntu-18.04-20190707.tar这里注意指定还原的路径。成功后，子系统又回来了，可以用wsl -l确认一下。 install docker-engines under ubuntu.refer to: https://docs.docker.com/engine/install/ubuntu/ 12345#启动docker sudo service docker startservice --status-allsudo service docker start #WSL2下能使用 systemctl, 参考：https://www.cnblogs.com/a5idc/p/13752839.htmlsudo usermod -aG docker {$USER}，$user是linux os你创建的用户，参考：https://docs.docker.com/engine/install/linux-postinstall/docker run hello-world #检查是否安装成功 install docker-compose under ubuntu.参考： https://docs.docker.com/compose/install/ 1sudo chmod +x /usr/local/bin/docker-compose 在ubuntu下git checkout docker-compose目录，运行mysql等服务。在windows下，可直接使用localhost连接123docker-compose up #启动并运行docker-compose up -d #在后台运行docker-compose down apt-get install telnetapt-get -y install netcat-traditional","link":"/2021/09/27/wsl/wsl-ubuntu/"},{"title":"Set a Timeout in Spring 5 Webflux WebClient","text":"idle timeout: 闲置 超时时间 Response TimeoutThe response timeout is the time we wait to receive a response after sending a request. connection timeout:The connection timeout is a period within which a connection between a client and a server must be established. read &amp; write timeout:A read timeout occurs when no data was read within a certain period of time, while the write timeout when a write operation cannot finish at a specific time. Configuring Timeouts via HTTP ClientResponse Timeout 响应超时响应超时是我们 在发送请求后等待接收响应的时间。我们可以使用responseTimeout()方法为客户端配置 The response timeout is the time we wait to receive a response after sending a request. We can use the responseTimeout() method to configure it for the client:In this example, we configure the timeout for 1 second. Netty doesn’t set the response timeout by default. After that, we can supply the HttpClient to the Spring WebClient: 123456HttpClient client = HttpClient.create() .responseTimeout(Duration.ofSeconds(1));WebClient webClient = WebClient.builder().clientConnector(new ReactorClientHttpConnector(httpClient)).build(); After doing that, the WebClient inherits all the configurations provided by the underlying HttpClient for all requests sent.这样做之后，WebClient 继承了底层HttpClient 为发送的所有请求提供的所有配置。 Connection Timeout连接超时是必须在客户端和服务器之间建立连接的时间段。 The connection timeout is a period within which a connection between a client and a server must be established. We can use different channel options keys and the option() method to perform the configuration: 12HttpClient client = HttpClient.create() .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000); 提供的值以毫秒为单位，因此我们将超时配置为 10 秒。默认情况下，Netty 将该值设置为 30 秒。 此外，我们可以配置keep-alive选项，它会在连接空闲时发送TCP检查探测： 123456HttpClient client = HttpClient.create().option(ChannelOption.SO_KEEPALIVE, true).option(EpollChannelOption.TCP_KEEPIDLE, 300).option(EpollChannelOption.TCP_KEEPINTVL, 60).option(EpollChannelOption.TCP_KEEPCNT, 8);// create WebClient... 因此，我们启用了保持活动检查以在空闲 5 分钟后以 60 秒的间隔进行探测。我们还将连接下降之前的最大探测数设置为 8。 当在给定时间内未建立连接或断开连接时，将抛出ConnectTimeoutException。 Read and Write TimeoutA read timeout occurs when no data was read within a certain period of time, while the write timeout when a write operation cannot finish at a specific time. The HttpClient allows to configure additional handlers to configure those timeouts: 读超时是指在一定时间内没有读到数据，写超时是写操作无法在特定时间完成。该HttpClient的允许配置更多的处理器配置这些超时： 123456HttpClient client = HttpClient.create() .doOnConnected(conn -&gt; conn .addHandler(new ReadTimeoutHandler(10, TimeUnit.SECONDS)) .addHandler(new WriteTimeoutHandler(10)));// create WebClient... 在这种情况下，我们通过doOnConnected()方法配置了一个连接的回调，我们在其中创建了额外的处理程序。为了配置超时，我们添加了ReadTimeOutHandler 和WriteTimeOutHandle r实例。我们将它们都设置为 10 秒。 这些处理程序的构造函数接受两种参数变体。对于第一个，我们提供了一个TimeUnit规范的数字，而第二个将给定的数字转换为秒。 底层 Netty 库相应地提供ReadTimeoutException和WriteTimeoutException类来处理错误。 参考文章 Set a Timeout in Spring 5 Webflux WebClient Configure timeout for Spring WebFlux WebClient","link":"/2021/12/23/spring/spring-webflux-webclient-set-timeout/"},{"title":"wsl常用命令","text":"参考文章 https://docs.microsoft.com/zh-cn/windows/wsl/reference 设置默认版本wsl --set-default-version 2 检查分配给每个已安装的 Linux 分发版的 WSL 版本wsl -l -vwsl --list --verbose 将分发版设置为受某一 WSL 版本支持wsl --set-version &lt;distribution name&gt; &lt;versionNumber&gt; 运行/停止Ubuntu子系统wsl -l 列出了系统中安装的子系统名称，可以是一个或多个，本文中的子系统名称是Ubuntu-18.04-20190707，接下来针对这个默认子系统进行操作： 运行子系统wsl --distribution Ubuntu-18.04-20190707或者wsl -d Ubuntu-18.04-20190707 查看运行中的子系统-l --running12 适用于 Linux 的 Windows 子系统:Ubuntu-18.04-20190707 (默认) 停止子系统wsl -t Ubuntu-18.04-20190707或者wsl --terminate Ubuntu-18.04-20190707 备份/删除/还原子系统备份子系统非常简单，但一定要先停止子系统之后再备份wsl --export Ubuntu-18.04-20190707 c:\\temp\\Ubuntu-18.04-20190707.tar等待完成即可。备份成功后，子系统会被打包成命令中指定的tar文件。 删除子系统也是一个命令即可：wsl --unregister Ubuntu-18.04-20190707这样WSL子系统就从Windows中删除的干干净净了。 还原子系统删除了没关系，刚才做了备份，也是一个命令还原：wsl --import Ubuntu-18.04-20190707 c:\\WSL c:\\temp\\Ubuntu-18.04-20190707.tar这里注意指定还原的路径。成功后，子系统又回来了，可以用wsl -l确认一下。 用于运行 Linux 命令的参数 不带参数 如果未提供命令行，wsl.exe 将启动默认 shell。 –exec, -e 执行指定的命令，但不使用默认的 Linux shell。 按原样传递剩余的命令行。 上述命令也接受以下选项： –distribution, -d 运行指定的分发版。 –user, -u 以指定用户的身份运行。 用于管理适用于 Linux 的 Windows 子系统的参数 –export 将分发版导出到 tar 文件。 在标准输出中，文件名可以是 -。 –import 导入指定的 tar 文件作为新的分发版。 在标准输入中，文件名可以是 -。 –list、-l [选项] 列出分发版。 选项： –all 列出所有分发版，包括当前正在安装或卸载的分发版。 –verbose, -v 显示命令的附加信息或展开的详细信息。 –running 仅列出当前正在运行的分发版。 –set-default, -s 将分发版设置为默认值。 –terminate, -t 终止指定的分发版。 –unregister 注销分发版。 –help 显示用法信息。","link":"/2021/09/27/wsl/wsl-cmd/"},{"title":"zookeeper windows install","text":"下载zookeeperhttps://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/ 配置zookeeper解压到三个目录我们想要在单机上搭建3个server的伪集群，需要将下载好的zookeeper压缩包解压到三个目录下。 123server1 : D:\\zookeeper\\server1server2 : D:\\zookeeper\\server3server3 : D:\\zookeeper\\server3 创建配置文件（cfg文件）解压之后，分别进入conf目录，可以看到zoo_sample.cfg，log4j.properties和configuration.xsl三个文件。 在该目录下创建一个zoo.cfg文件（也可以直接使用zoo_sample.cfg），配置如下： 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server1\\\\datadataLogDir=D:\\\\zookeeper\\\\server1\\\\logs# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 以上就是zookeeper伪集群中server1的配置文件。同理在其他两个解压路径的conf目录下创建server2和server3的配置文件zoo.cfg。参数区别仅在于dataDir、dataLogDir和clientPort server2的zoo.cfg 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server2\\\\datadataLogDir=D:\\\\zookeeper\\\\server2\\\\logs# the port at which the clients will connectclientPort=2182# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 server3的zoo.cfg 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server3\\\\datadataLogDir=D:\\\\zookeeper\\\\server3\\\\logs# the port at which the clients will connectclientPort=2183# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 创建myid文件在上个步骤中，我们在dataDir中指定了快照存放目录，切换到各目录下，分别创建一个文件名为myid的文件（没有后缀名）。文件内容为一个整型数。 在server1的data目录下的myid文件，其内容为1。在server2的data目录下的myid文件，其内容为2。在server3的data目录下的myid文件，其内容为3。 启动zookeeper分别切换到三个解压路径下的bin目录，在cmd上输入zkServer.cmd启动服务，可以同时用三个cmd窗口分别启动三个server，启动顺序是server1 -&gt; server2 -&gt; server3。启动的过程中是会报错的，信息如下： 进入cmd，切换目录到 /server1/bin/，执行命令 zkServer.cmd（此时会打印错误日志，别急，这是心跳检查连接其他zk服务，等启动集群数量一半以上的zk服务后，就不报错了）进入cmd，切换目录到 /server2/bin/，执行命令 zkServer.cmd进入cmd，切换目录到 /server3/bin/，执行命令 zkServer.cmd 验证zookeeper服务是否启动cmd，切换目录到 /server1/bin，执行命令 zkCli.cmd -server localhost:2181 参考文章 ZooKeeper集群搭建 https://www.cnblogs.com/yangzhenlong/p/8270835.html https://blog.csdn.net/sinat_34596644/article/details/78289842","link":"/2021/10/28/zookeeper/zookeeper-windows-install/"},{"title":"动态规划","text":"基本思想动态规划方法的基本思想是，把求解的问题分成许多阶段或多个子问题，然后按顺序求解各子问题。最后一个子问题就是初始问题的解。 由于动态规划的问题有重叠子问题的特点，为了减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 动态规划=贪婪策略+递推(降阶)+存储递推结果 空间换取时间 递归算法效率低的主要原因是因为进行了大量的重复计算。而动态规划的基本动机就是充分利用重叠子问题(Overlapping subproblems)。 因为动态规划将以前（子问题）计算过的结果都记录下来，遇到使用子问题结果的时候只需查表。 动态规划是一种用空间换取时间的方法。因此，动态规划常常因为空间消耗太大而难以实现。 主要概念 阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节即称为阶段。 状态：某一阶段的出发位置称为状态。通俗地说状态是对问题在某一时刻的进展情况的数学描述。 决策：从某阶段的一个状态演变到下一个阶段某状态的选择。 状态转移方程：根据上一阶段的状态和决策导出本阶段的状态。这就像是“递推”。 例: 数塔问题 从顶部出发，在每一结点可以选择向左走或是向右走，一直走到底层，要求找出一条路径，使路径上的数值和最大。 阶段：每行就是一个阶段； 状态：d[i][j]，即取第i行，第j个数能够达到的最大值； 决策：取第i行第j个数，则可以有两种方案：取第i-1行第j-1个数或取第i-1行第j个数后再取第i行第j个数； 状态转移方程：d[i][j] = max (d[i+1][j]，d[i+1][j+1]) + data[i][j]；表示取第i行第j个数所能达到的最大和； 123456789int a[100][100], f[100][100];int max(int i,int j,int n){ int left,right; if ((i==n)||(j==n)) f[i][j] =a[i][j]; if (f[i][j] != -1) return f[i][j]; left=max(i+1,j,n); //左边 right=max(i+1,j+1,n); //右边 return (f[i][j] = (left&gt;right)? (left+a[i][j]):(right+a[i][j]));} 适合解决的问题的性质 动态规划算法的问题及决策应该具有两个性质：最优化原理、无后向性。 最优化原理(或称为最佳原则、最优子结构)； 无后向性(无后效性)：某阶段状态一旦确定以后，就不受这个状态以后决策的影响。即某状态以后的过程不会影响以前的状态，只与当前状态有关。 能够体现动态规划优点的性质： 子问题重叠性质； 动态规划用空间换取时间，在有大量重叠子问题的时候其优势才能充分体现出来。 例：数塔问题 最优化原理(最优子结构)9-&gt;12-&gt;10-&gt;18-&gt;10显然12-&gt;10-&gt;18-&gt;10也是12到最后一层的最大和…… 无后效性如，计算到12的最大和只要考虑到10的最大和与到6的最大和哪个更大，而不要考虑到10的最大和或者到6的最大和具体是哪几个数构成的。设计步骤设计动态规划算法的基本步骤设计一个标准的动态规划算法的步骤： 划分阶段； 选择状态； 确定决策并写出状态转移方程。实际应用当中的简化步骤： 分析最优解的性质，并刻划其结构特征。 递推地定义最优值。 以自底向上的方式或自顶向下的记忆化方法(备忘录法)计算出最优值。 根据计算最优值时得到的信息，构造问题的最优解。 例题： 数塔问题 //从顶部出发，在每一结点可以选择向左走或是向右走，一直走到底层，要求找出一条路径，使路径上的数值和最大。 12345678910111213141516171819public class Test1 { static int[][] result = new int[5][5]; public static int maxSum(int i, int j, int[][] data) { if (i == data.length - 1 || j == data.length - 1) { result[i][j] = data[i][j]; } if (result[i][j] != 0) { return result[i][j]; } return result[i][j] = Math.max(maxSum(i + 1, j, data), maxSum(i + 1, j + 1, data)) + data[i][j]; } public static void main(String[] args) { int[][] data = {{9}, {12, 15}, {10, 6, 8}, {2, 18, 9, 5}, {19, 7, 10, 4, 16}}; maxSum(0, 0, data); System.out.println(result[0][0]); }} 12345678910111213141516171819202122232425262728293031323334353637383940public class Test1 { static int[][] dp = new int[5][5]; static int n = 5; public static void maxSum(int[][] data) { // dp初始化 for (int i = 0; i &lt; n; ++i) { dp[n - 1][i] = data[n - 1][i]; } int temp_max; for (int i = n - 2; i &gt;= 0; --i) { for (int j = 0; j &lt;= i; ++j) { // 使用递推公式计算dp的值 temp_max = Math.max(dp[i + 1][j], dp[i + 1][j + 1]); dp[i][j] = temp_max + data[i][j]; } } } private static void printPath(int[][] data) { System.out.printf(&quot;最大路径： &quot; + data[0][0] + &quot;&quot;); int j = 0; for (int i = 1; i &lt; 5; ++i) { int node_value = dp[i - 1][j] - data[i - 1][j]; /* 如果node_value == dp[i][j]则说明下一步应该是data[i][j]；如果node_value == dp[i][j + 1]则说明下一步应该是data[i][j + 1]*/ if (node_value == dp[i][j + 1]) ++j; System.out.printf(&quot;-&gt;&quot; + data[i][j]); } System.out.println(); } public static void main(String[] args) { int[][] data = {{9}, {12, 15}, {10, 6, 8}, {2, 18, 9, 5}, {19, 7, 10, 4, 16}}; maxSum(data); System.out.println(&quot;最大路径和： &quot; + dp[0][0]); printPath(data); }} 资源分配问题设有资源n(n为整数),分配给m个项目,gi(x)为第i个项目分得资源x(x为整数)所得到的利润。 求总利润最大的资源分配方案，也就是解下列问题：12max z=g1(x1)+ g2(x2)+……gm(xm)x1+x2+x3+……xm = n，0≤xi≤n，i=1,2,3,……,m 函数gi(x)以数据表的形式给出。 例如：现有7万元投资到A，B，C 三个项目，利润见表,问题：求总利润最大的资源分配方案。 划分阶段或找到子问题；每个阶段增加一个项目，考察投资利润情况。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Test2 { static double[][] v = { {0, 0.11, 0.13, 0.15, 0.21, 0.24, 0.3, 0.35}, {0, 0.12, 0.16, 0.21, 0.23, 0.25, 0.24, 0.34}, {0, 0.08, 0.12, 0.2, 0.24, 0.26, 0.3, 0.35}}; static int m = 3; static int n = 7; public static void main(String[] args) { double[] q = new double[10]; //原始数据（逐行使用） double[] f = new double[10];//当前最大收益情况 double[] temp = new double[10]; //正在计算的最大收益 int[][] a = new int[10][10]; //前i个项目投资j获得最大利润时，给第i个项目分配的资源数(m*(n+1)维) int[] gain = new int[10];//在不同投资数下获最大利润时第i个工程所得资源数。 // 全部资源用于A(第一个项目) q = f = v[0]; for (int j = 0; j &lt;= n; j++) { a[1][j] = j; } // 第二阶段： 全部资源用于两个项目 // 第三阶段： 全部资源用于三个项目 for (int k = 2; k &lt;= m; k++) { for (int j = 0; j &lt;= n; j++) { temp[j] = q[j]; a[k][j] = 0; } //赋值， 第二/三个项目的收益情况 (数组下标从0开始，故此处k-1) q = v[k - 1]; for (int j = 0; j &lt;= n; j++) { for (int i = 0; i &lt;= j; i++) { if (f[j - i] + q[i] &gt; temp[j]) { temp[j] = f[j - i] + q[i]; a[k][j] = i; } } } // 更新 当前最大收益情况 for (int j = 0; j &lt;= n; j++) f[j] = temp[j]; } int rest = n; for (int i = m; i &gt;= 1; i--) { gain[i] = a[i][rest]; rest = rest - gain[i]; } for (int i = 1; i &lt;= m; i++) { System.out.print(gain[i] + &quot; &quot;); } System.out.println((f[n])); }} 资源分配问题二资源分配问题是将数量一定的一种或若干种资源(原木料、资金、设备或劳动力等)合理地分配给若干个使用者,使总收益最大。 例如,某公司有3个商店A、B、C，拟将新招聘的5名员工分配给这3个商店，各商店得到新员工后每年的赢利情况如表所示,求分配给各商各多少员工才能使公司的赢利最大?解析： 其实就是完全背包的变形 用dp[i][j]表示为前i个商店共分配j个人时盈利的最大值，状态转移方程如下（k表示为i商店分配的人数）： dp[i][j] = max(dp[i][j], dp[i-1][j-k] + c[i][k]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.example.demo;public class Test3 { public static void main(String[] args) { int[][] data = { {0, 3, 7, 9, 12, 13}, {0, 5, 10, 11, 11, 11}, {0, 4, 6, 11, 12, 12} }; int m = 3; int n = 5; int[] q = new int[10]; //原始数据（逐行使用） int[] f = new int[10];//当前最大收益情况 int[] temp = new int[10]; //正在计算的最大收益 int[][] a = new int[10][10]; //前i个项目投资j获得最大利润时，给第i个项目分配的资源数(m*(n+1)维) int[] gain = new int[10];//在不同投资数下获最大利润时第i个工程所得资源数。 // 只分配 A // k =1 q = data[0]; f = data[0]; for (int k = 2; k &lt;= 3; k++) { q = data[k - 1]; for (int j = 0; j &lt;= n; j++) { temp[j] = q[j]; } for (int j = 0; j &lt;= n; j++) { for (int i = 0; i &lt;= j; i++) { if (f[j - i] + q[i] &gt; temp[j]) { temp[j] = f[j - i] + q[i]; } } } for (int i = 0; i &lt;= n; i++) { f[i] = temp[i]; } } System.out.println(f[n]); }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.example.demo;public class Test3 { static int MAX = 30; static int[][] c = new int[MAX][MAX]; static int[][] dp = new int[MAX][MAX]; // dp[i][j]表示前i个车间共分配j个人 static int[][] pnum = new int[MAX][MAX]; static int n = 3, m = 5; public static void main(String[] args) { int[][] data = { {3, 7, 9, 12, 13}, {5, 10, 11, 11, 11}, {4, 6, 11, 12, 12} }; for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= m; j++) c[i][j] = data[i - 1][j - 1]; System.out.printf(&quot;max = %d\\n&quot;, DP_source()); print_allocate(); } static int DP_source() { // 初始化 for (int i = 0; i &lt;= n; i++) dp[i][0] = 0; for (int i = 0; i &lt;= m; i++) dp[0][i] = 0; int sel_num = 0; // 记录第i个车间分配j人时应分配的人数 for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= m; j++) { sel_num = 0; // 枚举当前车间分配k人时的最大值 for (int k = 0; k &lt;= j; k++) { if (dp[i][j] &lt; dp[i - 1][j - k] + c[i][k]) { // 更新答案 dp[i][j] = dp[i - 1][j - k] + c[i][k]; sel_num = k; } } // 循环结束后找到为前i个车间共分配j人时第i个车间应分配的人数 pnum[i][j] = sel_num; } } return dp[n][m]; } static void print_allocate() // 输出每个车间应分配的人数 { int r, s; s = pnum[n][m]; // 最后一个车间应该选择的人数 r = m - s; // 剩余人数 for (int i = n; i &gt;= 1; i--) { System.out.printf(&quot;%d 商店分配 %d 人\\n&quot;, i, s); s = pnum[i - 1][r]; r -= s; } }} 0-1背包问题（knapsack problem） 一个小偷面前有一堆（n个）财宝，每个财宝有重量w和价值v两种属性，而他的背包只能携带一定重量的财宝（Capacity），在已知所有财宝的重量和价值的情况下，如何选取财宝，可以最大限度的利用当前的背包容量，取得最大价值的财宝（或求出能够获取财宝价值的最大值）。 “填二维表”的动态规划方法1234567891011121314151617181920212223242526public class Test4 { static int MAX = 20; static int[] value = {0, 1, 6, 18, 22, 28}; //物品价值 static int[] weight = {0, 1, 2, 5, 6, 7}; //物品重量 static int[][] dp = new int[MAX][MAX]; // dp[i][j]表示容量为j, 前i个物品的总价值。 static int[] result = new int[MAX]; // 选择哪些物品 static int n = 5;//五种物品 static int C = 11; //背包容量 public static void main(String[] args) { //背包容量从 1 开始递增 到 11 for (int i = 1; i &lt;= 5; i++) { for (int j = 1; j &lt;= C; j++) { if (weight[i] &gt; j) { dp[i][j] = dp[i - 1][j]; } else { dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]); } } } System.out.println(dp[n][C]); }} 空间优化 / 填一维表”的动态规划方法 https://blog.csdn.net/weixin_41162823/article/details/87878853 dp[j] = max(dp[j], dp[j−w[i]]+v[i]) 上述状态表示，我们需要用二维数组，但事实上我们只需要一维的滚动数组就可以递推出最终答案。考虑到用dp[j]来保存每层递归的值，由于我们求dp[i][j] 的时候需要用到的是dp[ i-1 ][j] 和 dp[i-1][j-w[i]] 于是可以知道，只要我们在求 dp[j] 时不覆盖 dp[ j - w[i] ]，那么就可以不断递推至所求答案。所以我们采取倒序循环，即 v = m（m为背包总容积）伪代码如下： 123 for i = 1..N for v = V..0 f[ v ] = max{ f[ v ],f[ v-w[i] ]+val[ i ] }; ref: https://zhuanlan.zhihu.com/p/30959069 完全背包问题: 完全背包（unbounded knapsack problem）与01背包不同就是每种物品可以有无限多个：一共有N种物品，每种物品有无限多个，第i（i从1开始）种物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限 W 的情况下，能够装入背包的最大价值是多少？ 分析一 ref: https://www.cnblogs.com/mfrank/p/10803417.html 跟01背包一样，完全背包也是一个很经典的动态规划问题，不同的地方在于01背包问题中，每件物品最多选择一件，而在完全背包问题中，只要背包装得下，每件物品可以选择任意多件。从每件物品的角度来说，与之相关的策略已经不再是选或者不选了，而是有取0件、取1件、取2件…直到取⌊T/Vi⌋（向下取整）件。 12345# k为装入第i种物品的件数, k &lt;= j/w[i]dp[i][j] = max{(dp[i-1][j-k*w[i]] + k*v[i]) } ( 0 &lt;= k*v[i] &lt;= W)dp[0][j] = 0dp[i][0] = 0 我们通过对0/1背包的思路加以改进，就得到了完全背包的一种解法，这种解法时间复杂度为O（n^3），空间复杂度为O（n^2）。 时间优化时间优化：根据上述 dp[i][j] 的定义，其为前 i 种物品恰好放入容量为 v 的背包的最大权值。根据上述状态转移方程可知，我们假设的是子结果dp[i-1][j-k*w[i]] 中并没有选入第 i 种物品，所以我们需要逆序遍历（像0/1背包一样）来确保该前提；但是我们现在考虑“加选一件第 i 种物品”这种策略时，正需要一个可能已经选入第 i 种物品的子结果dp[i-1][j-k*w[i]]，于是当我们顺序遍历时，就刚好达到该要求。这种做法，使我们省去了一层循环，即第 i 种物品放入的件数k，从而时间复杂度优化为O（n^2）。 空间优化：正如0/1背包的空间优化，上述状态转移方程已经优化为：dp[i][j] = max{dp[i-1][j], (dp[i][j-k*w[i]] + k*v[i]) } ( 0 &lt;= k*v[i] &lt;= W) dp[i][j]表示将前i种物品装进限重为j的背包可以获得的最大价值, 0&lt;=i&lt;=N, 0&lt;=j&lt;=W 初始状态也是一样的，我们将dp[0][0…W]初始化为0，表示将前0种物品（即没有物品）装入书包的最大价值为0。那么当 i &gt; 0 时dp[i][j]也有两种情况： 不装入第i种物品，即dp[i−1][j]，同01背包； 装入第i种物品，此时和01背包不太一样，因为每种物品有无限个（但注意书包限重是有限的），所以此时不应该转移到dp[i−1][j−w[i]]而应该转移到dp[i][j−w[i]]，即装入第i种商品后还可以再继续装入第种商品。 所以状态转移方程为dp[i][j] = max(dp[i−1][j], dp[i][j−w[i]] + v[i]) // j &gt;= w[i] 多重背包： 第i（i从1开始）种物品的重量为w[i]，价值为v[i]。第i种物品最多有Mi件可用在总重量不超过背包承载上限 W 的情况下，能够装入背包的最大价值是多少？ // dp[i][j] : 前i种物品放入一个容量为 j 的背包获得的最大价值//对于第i种物品，我们有k种选择，0 &lt;= k &lt;= M[i] &amp;&amp; 0 &lt;= k * w[i] &lt;= j，即可以选择0、1、2…M[i]个第i种物品，所以递推表达式为：dp[i][j] = max(dp[i][j− k * w[i]]+ k * v[i]) // 0 &lt;= k &lt;= M[i] &amp;&amp; 0 &lt;= k * w[i] &lt;= j 视频： https://www.bilibili.com/video/BV18x411V7fm?from=search&amp;seid=5454260386958297352 https://www.bilibili.com/video/BV1X741127ZM?from=search&amp;seid=17606712350225562747 参考文章 动态规划–资源分配问题 动态规划应用举例—资源分配问题 动态规划之背包问题系列 背包问题九讲 pdf 背包问题-笔记整理 动态规划之背包问题系列 动态规划之01背包问题 0-1背包问题的动态规划算法 背包问题总结（上） 背包问题总结（下） 五大常用算法之二：动态规划算法 经典算法系列：动态规划 经典中的经典算法:动态规划(详细解释,从入门到实践,逐步讲解) 【常见笔试面试算法题12】动态规划算法案例分析 动态规划十大经典案例 常见动态规划题目详解 动态规划算法详解及经典例题 【动态规划】一次搞定三种背包问题 【动态规划】多重背包问题 【动态规划】01背包问题 【动态规划】01背包问题【续】 【动态规划】完全背包问题 动态规划–01背包模型","link":"/2021/11/18/algorithm_dynamic/algorithm-dynamic-programming/"},{"title":"CompletableFuture基本用法","text":"对比 Future：我们的目的都是获取异步任务的结果，但是对于Future来说，只能通过get方法或者死循环判断isDone来获取。异常情况就更是难办。 CompletableFuture：只要我们设置好回调函数即可实现： 只要任务完成，即执行我们设置的函数（不用再去考虑什么时候任务完成） 如果发生异常，同样会执行我们处理异常的函数，甚至连默认返回值都有（异常情况处理更加省力） 如果有复杂任务，比如依赖问题，组合问题等，同样可以写好处理函数来处理（能应付复杂任务的处理） FutureJDK5新增了Future接口，用于描述一个异步计算的结果。虽然 Future 以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的 CPU 资源，而且也不能及时地得到计算结果。 以前我们获取一个异步任务的结果可能是这样写的 Future 接口的局限性Future接口可以构建异步应用，但依然有其局限性。它很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的： 将多个异步计算的结果合并成一个 等待Future集合中的所有任务都完成 Future完成事件（即，任务完成以后触发执行动作） … CompletionStage CompletionStage代表异步计算过程中的某一个阶段，一个阶段完成以后可能会触发另外一个阶段 一个阶段的计算执行可以是一个Function，Consumer或者Runnable。比如：stage.thenApply(x -&gt; square(x)).thenAccept(x -&gt; System.out.print(x)).thenRun(() -&gt; System.out.println()) 一个阶段的执行可能是被单个阶段的完成触发，也可能是由多个阶段一起触发1public class CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt; CompletableFuture 在Java8中，CompletableFuture提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法。 它可能代表一个明确完成的Future，也有可能代表一个完成阶段（ CompletionStage ），它支持在计算完成以后触发一些函数或执行某些动作。 它实现了Future和CompletionStage接口 对于CompletableFuture有四个执行异步任务的方法： 1234public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor) 121. 如果我们指定线程池，则会使用我么指定的线程池；如果没有指定线程池，默认使用ForkJoinPool.commonPool()作为线程池。2. supply开头的带有返回值，run开头的无返回值。 执行异步任务（supplyAsync / runAsync）1234567891011121314151617181920import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor); System.out.println(future.get()); executor.shutdown(); }} 以上仅仅返回个随机数，如果我们要利用计算结果进一步处理呢？ 结果转换（thenApply / thenApplyAsync）123456// 同步转换public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn)// 异步转换，使用默认线程池public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)// 异步转换，使用指定线程池public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 123456789101112131415161718192021222324252627282930313233343536import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor) // 对上一步的结果进行处理 .thenApply(n -&gt; { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } int res = new Random().nextInt(100); System.out.println(String.format(&quot;如果是同步的，这条消息应该先输出。上一步结果：%s，新加：%s&quot;, n, res)); return n + res; }); System.out.println(&quot;我等了你2秒&quot;); System.out.println(future.get()); executor.shutdown(); }} 输出：如果把thenApply换成thenApplyAsync，则会输出：处理完任务以及结果，该去消费了 消费而不影响最终结果（thenAccept / thenRun / thenAcceptBoth）1234567891011public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor)public CompletableFuture&lt;Void&gt; thenRun(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action, Executor executor)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action, Executor executor) 123456789这三种的区别是：thenAccept：能够拿到并利用执行结果thenRun：不能够拿到并利用执行结果，只是单纯的执行其它任务thenAcceptBoth：能传入另一个stage，然后把另一个stage的结果和当前stage的结果作为参数去消费。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor) // 对上一步的结果进行处理 .thenApplyAsync(n -&gt; { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } int res = new Random().nextInt(100); System.out.println(String.format(&quot;如果是同步的，这条消息应该先输出。上一步结果：%s，新加：%s&quot;, n, res)); return n + res; }); // 单纯的消费执行结果，注意这个方法是不会返回计算结果的——CompletableFuture&lt;Void&gt; CompletableFuture&lt;Void&gt; voidCompletableFuture = future.thenAcceptAsync(n -&gt; { System.out.println(&quot;单纯消费任务执行结果：&quot; + n); }); // 这个无法消费执行结果，没有传入的入口，只是在当前任务执行完毕后执行其它不相干的任务 future.thenRunAsync(() -&gt; { System.out.println(&quot;我只能执行其它工作，我得不到任务执行结果&quot;); }, executor); // 这个方法会接受其它CompletableFuture返回值和当前返回值 future.thenAcceptBothAsync(CompletableFuture.supplyAsync(() -&gt; { return &quot;I'm Other Result&quot;; }), (current, other) -&gt; { System.out.println(String.format(&quot;Current：%s，Other:%s&quot;, current, other)); }); System.out.println(&quot;我等了你2秒&quot;); System.out.println(future.get()); executor.shutdown(); }} 结果： 组合任务（thenCombine / thenCompose）1234567public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor)public &lt;U&gt; CompletionStage&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) 12345这两种区别：主要是返回类型不一样。thenCombine：至少两个方法参数，一个为其它stage，一个为用户自定义的处理函数，函数返回值为结果类型。thenCompose：至少一个方法参数即处理函数，函数返回值为stage类型。 先看thenCombine 123456789101112131415161718192021222324252627282930313233343536373839import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; otherFuture = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务A：&quot; + result); return result; }, executor); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务B：&quot; + result); return result; }, executor) .thenCombineAsync(otherFuture, (current, other) -&gt; { int result = other + current; System.out.println(&quot;组合两个任务的结果：&quot; + result); return result; }); System.out.println(future.get()); executor.shutdown(); }} 执行结果：再来看thenCompose 1234567891011121314151617181920212223242526272829303132333435import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务A：&quot; + result); return result; }, executor) .thenComposeAsync((current) -&gt; { return CompletableFuture.supplyAsync(() -&gt; { int b = new Random().nextInt(100); System.out.println(&quot;任务B：&quot; + b); int result = b + current; System.out.println(&quot;组合两个任务的结果：&quot; + result); return result; }, executor); }); System.out.println(future.get()); executor.shutdown(); }} 输出： 快者优先（applyToEither / acceptEither）1有个场景，如果我们有多条渠道去完成同一种任务，那么我们肯定选择最快的那个。 1234567public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn, Executor executor)public CompletionStage&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor) 1这两种区别：仅仅是一个有返回值，一个没有（Void） 先看applyToEither 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; otherFuture = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者A：&quot; + result); try { // 故意A慢了一些 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;执行者A【&quot; + result + &quot;】&quot;; }, executor); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者B：&quot; + result); return &quot;执行者B【&quot; + result + &quot;】&quot;; }, executor) .applyToEither(otherFuture, (faster) -&gt; { System.out.println(&quot;谁最快：&quot; + faster); return faster; }); System.out.println(future.get()); executor.shutdown(); }} 输出：再看acceptEither 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; otherFuture = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者A：&quot; + result); try { // 故意A慢了一些 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;执行者A【&quot; + result + &quot;】&quot;; }, executor); CompletableFuture&lt;Void&gt; future = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者B：&quot; + result); return &quot;执行者B【&quot; + result + &quot;】&quot;; }, executor) .acceptEither(otherFuture, (faster) -&gt; { System.out.println(&quot;谁最快：&quot; + faster); }); System.out.println(future.get()); executor.shutdown(); }} 输出： 异常处理（exceptionally / whenComplete / handle）123456789public CompletionStage&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; fn);public CompletionStage&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; action);public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action);public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action, Executor executor);public &lt;U&gt; CompletionStage&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn,Executor executor); exceptionally 123456789101112131415161718192021222324252627282930import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .exceptionally(e -&gt; { System.out.println(&quot;处理异常：&quot; + e.getMessage()); return &quot;处理完毕!&quot;; }); System.out.println(future.get()); executor.shutdown(); }} 输出：whenComplete 123456789101112131415161718192021222324252627282930313233343536import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .whenComplete((result,ex) -&gt; { // 这里等待为了上一步的异常输出完毕 try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;上一步结果：&quot; + result); System.out.println(&quot;处理异常：&quot; + ex.getMessage()); }); System.out.println(future.get()); executor.shutdown(); }} 输出结果：可以看见，用whenComplete对异常情况不是特别友好。 handle 12345678910111213141516171819202122232425262728293031import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .handle((result,ex) -&gt; { System.out.println(&quot;上一步结果：&quot; + result); System.out.println(&quot;处理异常：&quot; + ex.getMessage()); return &quot;Value When Exception Occurs&quot;; }); System.out.println(future.get()); executor.shutdown(); }} 输出： 综上，如果单纯要处理异常，那就用exceptionally；如果还想处理结果（没有异常的情况），那就用handle，比whenComplete友好一些，handle不仅能处理异常还能返回一个异常情况的默认值。 参考文章 https://www.cnblogs.com/cjsblog/p/9267163.html https://www.cnblogs.com/LUA123/p/12050255.html https://www.liaoxuefeng.com/wiki/1252599548343744/1306581182447650 https://blog.csdn.net/qq_31865983/article/details/106137777 https://blog.csdn.net/finalheart/article/details/87615546 https://www.jianshu.com/p/6bac52527ca4","link":"/2021/11/10/java/java-CompletableFuture/"},{"title":"JVM内存结构","text":"概述 JVM内存结构主要有三大块：·堆内存、方法区和栈·。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 xx xxxxxxxx desc 堆（Heap） 线程共享 所有的对象实例以及数组都要在堆上分配。 回收器主要管理的对象。 方法区（Method Area） 线程共享 Non-Heap（非堆） 存储类信息、常量、静态变量、即时编译器编译后的代码。 方法栈（JVM Stack） 线程私有 存储局部变量表、操作栈、动态链接、方法出口，对象指针。 本地方法栈（Native Method Stack） 线程私有 为虚拟机使用到的Native 方法服务。如Java使用c或者c++编写的接口服务时，代码在此区运行。 程序计数器（Program Counter Register） 线程私有 PC寄存器（PC Register） 当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。 在通过一张图来了解如何通过参数来控制各区域的内存大小 1234567-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最大空间大小-XX:PermSize设置永久代最小空间大小-XX:MaxPermSize设置永久代最大空间大小-Xss设置每个线程的堆栈大小 JVMJVM = 类加载器(classloader) + 执行引擎(execution engine) + 运行时数据区域(runtime data area) 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。 JVM 内存结构 程序计数器 线程私有 程序计数器（Program Counter Register）是一块较小的内存空间，**它的作用可以看做是当前线程所执行的字节码的行号指示器**。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，**每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。** 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 异常情况此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈/方法栈线程私有 与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，**它的生命周期与线程相同。**虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。 局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 控制参数 1-Xss控制每个线程栈的大小 异常情况 在Java虚拟机规范中，对这个区域规定了两种异常状况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常 如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈）， 当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈线程私有 本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而**本地方法栈则是为虚拟机使用到的Native方法服务。**虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。 控制参数在Sun JDK中本地方法栈和方法栈是同一个，因此也可以用-Xss控制每个线程的大小。 1-Xss控制每个线程栈的大小 异常情况与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 Java堆线程共享对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。 控制参数 1234-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最小空间大小 垃圾回收此区域是垃圾回收的主要操作区域。 异常情况如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 方法区线程共享 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 控制参数12-XX:PermSize 设置最小空间 -XX:MaxPermSize 设置最大空间 垃圾回收 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 异常情况根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 HotSpot中方法区的变化 jdk版本 区别 jdk1.6及之前 有永久代，静态变量存放在永久代上 jdk1.7 有永久代，但已经逐步去“永久代”，字符串常量池、静态变量移除，保存着堆中 jdk1.8及之后 无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 运行时常量池 运行时常量池是在方法区的一部分； Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池(Constant Pool Table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放； Java虚拟机对Class文件每一部分(自然也包括常量池)的格式都有严格规定，每一个字节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、加载和执行，但是对于运行时常量池，《Java虚拟机规范》没有做任何细节的要求，不用的提供上实现的虚拟机可以按照自己的需要来实现这个内存区域，不过一般来说，除了保存Class文件中描述的符号引用外,还会把翻译出来的直接引用也存储在运行时常量池中；运行时常量池相对于Class文件常量池的另外一个重要特征就是具备动态性，Java语言并不要求常量一定只有在编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 永久代和元空间java7及以前版本JVM内存结构图 堆和方法区连在了一起，但这并不能说堆和方法区是一起的，它们在逻辑上依旧是分开的。但在物理上来说，它们又是连续的一块内存。 也就是说，方法区和前面讲到的Eden和老年代是连续的。 永久代（PermGen）对于习惯了在HotSpot虚拟机上开发、部署的程序员来说，很多都愿意将方法区称作永久代。本质上来讲两者并不等价，仅因为Hotspot将GC分代扩展至方法区，或者说使用永久代来实现方法区。在其他虚拟机上是没有永久代的概念的。也就是说方法区是规范，永久代是Hotspot针对该规范进行的实现。 理解上面的概念之后，我们对Java7及以前版本的堆和方法区的构造再进行一下变动。 对Java7及以前版本的Hotspot中方法区位于永久代中。同时，永久代和堆是相互隔离的，但它们使用的物理内存是连续的。永久代的垃圾收集是和老年代捆绑在一起的，因此无论谁满了，都会触发永久代和老年代的垃圾收集。 但在Java7中永久代中存储的部分数据已经开始转移到Java Heap或Native Memory中了。比如，符号引用(Symbols)转移到了Native Memory；字符串常量池(interned strings)转移到了Java Heap；类的静态变量(class statics)转移到了Java Heap。然后，在Java8中，时代变了，Hotspot取消了永久代。永久代真的成了永久的记忆。永久代的参数-XX:PermSize和-XX：MaxPermSize也随之失效。 元空间（Metaspace）对于Java8，HotSpots取消了永久代，那么是不是就没有方法区了呢？当然不是，方法区只是一个规范，只不过它的实现变了。在Java8中，元空间(Metaspace)登上舞台，方法区存在于元空间(Metaspace)。同时，元空间不再与堆连续，而且是存在于本地内存（Native memory）。 本地内存（Native memory），也称为C-Heap，是供JVM自身进程使用的。当Java Heap空间不足时会触发GC，但Native memory空间不够却不会触发GC。 针对Java8的调整，我们再次对内存结构图进行调整。 元空间存在于本地内存，意味着只要本地内存足够，它不会出现像永久代中java.lang.OutOfMemoryError: PermGen space这种错误。默认情况下元空间是可以无限使用本地内存的，但为了不让它如此膨胀，JVM同样提供了参数来限制它使用的使用。 -XX:MetaspaceSize class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。 -XX：MaxMetaspaceSize 可以为class metadata分配的最大空间。默认是没有限制的。 -XX：MinMetaspaceFreeRatio 在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集。 -XX:MaxMetaspaceFreeRatio 在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集。 面试官 | JVM 为什么使用元空间替换了永久代？ 表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。 当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。 直接内存在JVM的内存模型，里面并不包含直接内存，也就是说这块内存区域并不是JVM运行时数据区的一部分，但它却会被频繁的使用，原因是NIO这个包；NIO（New input/output）是JDK1.4中新加入的类，引入了一种基于通道（channel）和缓冲区（buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过堆上的DirectByteBuffer对象对这块内存进行引用和操作。 可以看出，直接内存的大小并不受到java堆大小的限制，甚至不受到JVM进程内存大小的限制。它只受限于本机总内存（RAM及SWAP区或者分页文件）大小以及处理器寻址空间的限制（最常见的就是32位/64位CPU的最大寻址空间限制不同）。 参考文章 https://juejin.cn/post/6970606107442020360 https://juejin.cn/post/6844903592374042637 https://www.cnblogs.com/ityouknow/p/5610232.html https://zhuanlan.zhihu.com/p/38348646","link":"/2021/09/28/java/java-jvm-memory/"},{"title":"AbstractQueuedSynchronizer","text":"AQS (AbstractQueuedSynchronizer) 抽象类的队列式同步器原理概览AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 基础定义 AQS 是一个用于构建锁和同步器的框架，许多同步器都可以通过AQS很容易并且高效的构造出来。 为线程的同步和等待等操作提供一个基础模板类。尽可能多的实现可重入锁，读写锁同步器所有需要的功能。队列同步器内部实现了线程的同步队列，独占或是共享的获取方式等，使其只需要少量的代码便可以实现目标功能。 一般来说，AQS的子类应以其他类的内部类的形式存在，然后使用代理模式调用子类和AQS本身的方法实现线程的同步。也就是说，使用ReentrantLock举例，外界调用ReentrantLock，ReentrantLock内部定义Sync，Sync是AQS的子类，在ReentrantLock的内部实现中调用Sync的方法，最后完成最终的功能，当然ReentrantLock内部稍复杂，又加入和公平锁和非公平锁。 抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...。AbstractQueuedSynchronizer，这个类也是在java.util.concurrent.locks下面。 AQS，全名AbstractQueuedSynchronizer，是一个抽象类的队列式同步器，它的内部通过维护一个状态volatile int state(共享资源)，一个FIFO线程等待队列来实现同步功能。 state 所有通过AQS实现功能的类都是通过修改state的状态来操作线程的同步状态。比如在ReentrantLock中，一个锁中只有一个state状态，当state为0时，代表所有线程没有获取锁，当state为1时，代表有线程获取到了锁。通过是否能把state从0设置成1，当然，设置的方式是使用CAS设置，代表一个线程是否获取锁成功。 state用关键字volatile修饰，代表着该共享资源的状态一更改就能被所有线程可见，而AQS的加锁方式本质上就是多个线程在竞争state，当state为0时代表线程可以竞争锁，不为0时代表当前对象锁已经被占有，其他线程来加锁时则会失败，加锁失败的线程会被放入一个FIFO的等待队列中，这些线程会被UNSAFE.park()操作挂起，等待其他获取锁的线程释放锁才能够被唤醒。 AQS内部维护一个线程的队列。队列由内部的节点组成。 队列的节点为Node,节点分为SHARED和EXCLUSIVE分别时共享模式的节点和独占模式的节点。 而这个等待队列其实就相当于一个CLH队列，用一张原理图来表示大致如下： AQS支持两种资源分享的方式： Exclusive（独占，只有一个线程能执行，如ReentrantLock） Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 自定义的同步器继承AQS后，只需要实现·共享资源state的获取和释放方式·即可，其他如线程队列的维护（如获取资源失败入队/唤醒出队等）等操作，AQS在顶层已经实现了， AQS代码内部提供了一系列操作锁和线程队列的方法，主要操作锁的方法包含以下几个： compareAndSetState()：利用CAS的操作来设置state的值- tryAcquire(int)：独占方式获取锁。成功则返回true，失败则返回false。 tryRelease(int)：独占方式释放锁。成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式释放锁。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式释放锁。如果释放后允许唤醒后续等待结点返回true，否则返回false。 像ReentrantLock就是实现了自定义的tryAcquire-tryRelease，从而操作state的值来实现同步效果。 除此之外，AQS内部还定义了一个静态类Node，表示CLH队列的每一个结点，该结点的作用是对每一个等待获取资源做了封装，包含了需要同步的线程本身、线程等待状态….. 我们可以看下该类的一些重点变量： 1234567891011121314151617181920static final class Node { /** 表示共享模式下等待的Node */ static final Node SHARED = new Node(); /** 表示独占模式下等待的mode */ static final Node EXCLUSIVE = null; /** 下面几个为waitStatus的具体值 */ static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; /** 表示前面的结点 */ volatile Node prev; /** 表示后面的结点 */ volatile Node next; /**当前结点装载的线程，初始化时被创建，使用后会置空*/ volatile Thread thread; /**链接到下一个节点的等待条件，用到Condition的时候会使用到*/ Node nextWaiter;} 代码里面定义了一个表示当前Node结点等待状态的字段waitStatus，该字段的取值包含了CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)、PROPAGATE(-3)、0，这五个值代表了不同的特定场景： CANCELLED：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL（记住这个-1的值，因为后面我们讲的时候经常会提到） CONDITION：表示结点等待在Condition上，当其他线程调用了Condition的SIGNAL()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。(注：Condition是AQS的一个组件，后面会细说) PROPAGATE：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。 0：新结点入队时的默认状态。 也就是说，当waitStatus为负值表示结点处于有效等待状态，为正值的时候表示结点已被取消。 在AQS内部中还维护了两个Node对象head和tail，一开始默认都为null 12private transient volatile Node head; private transient volatile Node tail; 讲完了AQS的一些基础定义，我们就可以开始学习同步的具体运行机制了，为了更好的演示，我们用ReentrantLock作为使用入口，一步步跟进源码探究AQS底层是如何运作的，这里说明一下，因为ReentrantLock底层调用的AQS是独占模式，所以下文讲解的AQS源码也是针对独占模式的操作 独占模式 ReentrantLock和synchronized功能类似，使用AQS的独占模式，只有一个线程可以获取锁。 加锁过程我们都知道，ReentrantLock的加锁和解锁方法分别为lock()和unLock()，我们先来看获取锁的方法， 123456final void lock(){ if(compareAndSetState(0,1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } 其中compareAndSetState(0, 1)如果返回true就代表着之前state是0，也就是当前无线程获取锁，同时当前线程获取锁成功了，将独占线程设置为当前线程。 如果是false就代表当前有线程占用，当前占用的线程有2个可能 当前线程在占用，因为是可重入锁，之后同样会获取锁 其他线程在占用，在其他线程占用期间，当前线程需要等待 逻辑很简单，线程进来后直接利用CAS尝试抢占锁，如果抢占成功state值回被改为1，且设置对象独占锁线程为当前线程，否则就调用acquire(1)再次尝试获取锁。 我们假定有两个线程A和B同时竞争锁，A进来先抢占到锁，此时的AQS模型图就类似这样： acquire acquire是一种以独占方式获取资源，如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。该方法是独占模式下线程获取共享资源的顶层入口。获取到资源后，线程就可以去执行其临界区代码了。 acquire方法是一种互斥模式，且忽略中断。该方法至少执行一次tryAcquire(int)方法，如果tryAcquire(int)方法返回true，则acquire直接返回，否则当前线程需要进入队列进行排队。 1234public final void acquire(int arg){ if(!tryAcquire(arg)&amp;&amp;acquireQueued(addWaiter(Node.EXCLUSIVE),arg)) selfInterrupt(); } acquire(1)包含整个获取锁，如果获取不到就等待的操作 acquire包含了几个函数的调用， tryAcquire：尝试直接获取锁，如果成功就直接返回； addWaiter：获取不到锁时,说明有其他线程目前正在占用锁, 将该线程加入等待队列FIFO的尾部，并标记为独占模式； acquireQueued：线程阻塞在等待队列中获取锁，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 selfInterrupt：自我中断，就是既拿不到锁，又在等待时被中断了，线程就会进行自我中断selfInterrupt()，将中断补上。 我们一个个来看源码，并结合上面的两个线程来做场景分析。 tryAcquire 在tryAcquire(arg)中是尝试获取锁,是由ReentrantLock提供的,逻辑比较简单当前无线程占有锁时,即state为0时,获取锁 当前有线程占有锁,但当前占有锁的线程是当前线程时,因为ReentrantLock是可重入锁,获取锁,并把state+1 1234567891011121314151617181920212223protected final boolean tryAcquire(int acquires){ return nonfairTryAcquire(acquires); }final boolean nonfairTryAcquire(int acquires){final Thread current=Thread.currentThread(); int c=getState(); if(c==0){ if(compareAndSetState(0,acquires)){ setExclusiveOwnerThread(current); return true; } }else if(current==getExclusiveOwnerThread()){ //当前占有锁的线程是当前线程时,因为ReentrantLock是可重入锁,获取锁,并把state+1 int nextc=c+acquires; if(nextc&lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 当线程B进来后，nonfairTryAcquire方法首先会获取state的值，如果为0，则正常获取该锁，不为0的话判断是否是当前线程占用了，是的话就累加state的值，这里的累加也是为了配合释放锁时候的次数，从而实现可重入锁的效果。 当然，因为之前锁已经被线程A占领了，所以这时候tryAcquire会返回false，继续下面的流程。 addWaiter获取不到锁时,说明有其他线程目前正在占用锁,将当前线程包装成节点放入同步队列 将该线程加入等待队列FIFO的尾部，并标记为独占模式； 123456789101112131415161718/** 先尝试快速入队，如果入队成功直接返回，如果失败（存在竞态）就使用cas反复入队直到成功为止 **/private Node addWaiter(Node mode){ Node node=new Node(Thread.currentThread(),mode); // Try the fast path of enq; backup to full enq on failure // //快速入队 Node pred=tail; if(pred!=null){ node.prev=pred; if(compareAndSetTail(pred,node)){ pred.next=node; return node; } } enq(node); return node; } 这段代码首先会创建一个和当前线程绑定的Node节点，Node为双向链表。此时等待队列中的tail指针为空，直接调用enq(node)方法将当前线程加入等待队列尾部，然后返回当前结点的前驱结点， enq用于将当前节点插入等待队列，如果队列为空，则初始化当前队列。整个过程以CAS自旋的方式进行，直到成功加入队尾为止。 1234567891011121314151617private Node enq(final Node node){ // CAS&quot;自旋&quot;，直到成功加入队尾 for(;;){ Node t=tail; if(t==null){ // 队列为空，初始化一个Node结点作为Head结点，并将tail结点也指向它 if(compareAndSetHead(new Node())) tail=head; }else{ // 把当前结点插入队列尾部 node.prev=t; if(compareAndSetTail(t,node)){ t.next=node; return t; } } } } 第一遍循环时，tail指针为空，初始化一个Node结点，并把head和tail结点都指向它，然后第二次循环进来之后，tail结点不为空了，就将当前的结点加入到tail结点后面，也就是这样： 如果此时有另一个线程C进来的话，发现锁已经被A拿走了，然后队列里已经有了线程B，那么线程C就只能乖乖排到线程B的后面去， 入队完成之后再判断一次当前是否有可能获得锁，也就是前一个节点是head的话， 前一个线程有可能已经释放了，再获取一次，如果获取成功，设置当前节点为头节点，整个获取过程完成。 acquireQueued接着解读方法，通过tryAcquire()和addWaiter()，我们的线程还是没有拿到资源，并且还被排到了队列的尾部，如果让你来设计的话，这个时候你会怎么处理线程呢？其实答案也很简单，能做的事无非两个： 1、循环让线程再抢资源。但仔细一推敲就知道不合理，因为如果有多个线程都参与的话，你抢我也抢只会降低系统性能 2、进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源 毫无疑问，选择2更加靠谱，acquireQueued方法做的也是这样的处理： acquireQueued()用于队列中的线程自旋地以独占且不可中断的方式获取同步状态（acquire），直到拿到锁之后再返回。该方法的实现分成两部分：如果当前节点已经成为头结点，尝试获取锁（tryAcquire）成功，然后返回；否则检查当前节点是否应该被park，然后将该线程park并且检查当前线程是否被可以被中断。 12345678910111213141516171819202122 final boolean acquireQueued(final Node node,int arg){ boolean failed=true; try{ // 标记是否会被中断 boolean interrupted=false; // CAS自旋 for(;;){// 获取当前结点的前结点 final Node p=node.predecessor(); if(p==head&amp;&amp;tryAcquire(arg)){ setHead(node); p.next=null; // help GC failed=false; return interrupted; } if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true; } }finally{ if(failed) // 获取锁失败，则将此线程对应的node的waitStatus改为CANCEL cancelAcquire(node); } } shouldParkAfterFailedAcquire(Node, Node)shouldParkAfterFailedAcquire方法通过对当前节点的前一个节点的状态进行判断，对当前节点做出不同的操作，至于每个Node的状态表示，可以参考接口文档。 12345678910111213141516171819 private static boolean shouldParkAfterFailedAcquire(Node pred,Node node){ int ws=pred.waitStatus; if(ws==Node.SIGNAL) // 前驱结点等待状态为&quot;SIGNAL&quot;，那么自己就可以安心等待被唤醒了 return true; if(ws&gt;0){ /* * 前驱结点被取消了，通过循环一直往前找，直到找到等待状态有效的结点(等待状态值小于等于0) ， * 然后排在他们的后边，至于那些被当前Node强制&quot;靠后&quot;的结点，因为已经被取消了，也没有引用链， * 就等着被GC了 */ do{ node.prev=pred=pred.prev; }while(pred.waitStatus&gt;0); pred.next=node; }else{ // 如果前驱正常，那就把前驱的状态设置成SIGNAL compareAndSetWaitStatus(pred,ws,Node.SIGNAL); } return false; }private final boolean parkAndCheckInterrupt(){ LockSupport.park(this); return Thread.interrupted(); } acquireQueued方法的流程是这样的： 1、CAS自旋，先判断当前传入的Node的前结点是否为head结点，是的话就尝试获取锁，获取锁成功的话就把当前结点置为head，之前的head置为null(方便GC)，然后返回 2、如果前驱结点不是head或者加锁失败的话，就调用 shouldParkAfterFailedAcquire，将前驱节点的waitStatus变为了SIGNAL=-1，最后执行 parkAndChecknIterrupt 方法，调用 LockSupport.park()挂起当前线程，parkAndCheckInterrupt在挂起线程后会判断线程是否被中断，如果被中断的话，就会重新跑acquireQueued方法的CAS自旋操作，直到获取资源。 ps：LockSupport.park方法会让当前线程进入waitting状态，在这种状态下，线程被唤醒的情况有两种，一是被unpark()，二是被interrupt()，所以，如果是第二种情况的话，需要返回被中断的标志，然后在acquire顶层方法的窗口那里自我中断补上 此时，因为线程A还未释放锁，所以线程B状态都是被挂起的， 到这里，加锁的流程就分析完了. 获取锁并等待的过程:当lock()执行的时候： 先快速获取锁，当前没有线程执行的时候直接获取锁 尝试获取锁，当没有线程执行或是当前线程占用锁，可以直接获取锁 将当前线程包装为node放入同步队列，设置为尾节点 前一个节点如果为头节点，再次尝试获取一次锁 将前一个有效节点设置为SIGNAL 然后阻塞直到被唤醒 为了方便你们更加清晰理解，我加多一张流程图 释放锁说完了加锁，我们来看看释放锁是怎么做的，AQS中释放锁的方法是release()，当调用该方法时会释放指定量的资源 (也就是锁) ，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。 release当ReentrantLock进行释放锁操作时，调用的是AQS的release(1)操作 123456789public final boolean release(int arg){ if(tryRelease(arg)){ Node h=head; if(h!=null&amp;&amp;h.waitStatus!=0) unparkSuccessor(h); return true; } return false; } tryRelease代码上可以看出，核心的逻辑都在tryRelease方法中，该方法的作用是释放资源，AQS里该方法没有具体的实现，需要由自定义的同步器去实现，我们看下ReentrantLock代码中对应方法的源码： 在tryRelease(arg)中会将锁释放一次，如果当前state是1，且当前线程是正在占用的线程，释放锁成功，返回true，否则因为是可重入锁，释放一次可能还在占用，应一直释放直到state为0为止 123456789101112protected final boolean tryRelease(int releases){ int c=getState()-releases; if(Thread.currentThread()!=getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free=false; if(c==0){ free=true; setExclusiveOwnerThread(null); } setState(c); return free; } tryRelease方法会减去state对应的值，如果state为0，也就是已经彻底释放资源，就返回true，并且把独占的线程置为null，否则返回false。 此时AQS中的数据就会变成这样： unparkSuccessor完全释放资源后，当前线程要做的就是唤醒CLH队列中第一个在等待资源的线程，也就是head结点后面的线程，此时调用的方法是unparkSuccessor()， 然后优先找下一个节点，如果取消了就从尾节点开始找，找到最前面一个可用的节点 将其取消阻塞状态。 123456789101112131415161718 private void unparkSuccessor(Node node){int ws=node.waitStatus;if(ws&lt; 0) //将head结点的状态置为0 compareAndSetWaitStatus(node,ws,0);//找到下一个需要唤醒的结点s Node s=node.next;//如果为空或已取消 if(s==null||s.waitStatus&gt;0){s=null;// 从后向前，直到找到等待状态小于0的结点，前面说了，结点waitStatus小于0时才有效 for(Node t=tail;t!=null&amp;&amp;t!=node;t=t.prev)if(t.waitStatus&lt;=0)s=t;}// 找到有效的结点，直接唤醒 if(s!=null)LockSupport.unpark(s.thread);//唤醒} 方法的逻辑很简单，就是先将head的结点状态置为0，避免下面找结点的时候再找到head，然后找到队列中最前面的有效结点，然后唤醒，我们假设这个时候线程A已经释放锁，那么此时队列中排最前边竞争锁的线程B就会被唤醒。然后被唤醒的线程B就会尝试用CAS获取锁，回到acquireQueued方法的逻辑， 阻塞在acquireQueued的地方在唤醒之后开始继续执行，当前节点已经是最前面的一个可用（未取消）节点了,经过不断的for循环以及在shouldParkAfterFailedAcquire中不断向前寻找可用节点，因此这个被唤醒的节点一定可以使其之前的节点为head。然后获取锁成功。 但是此时节点会与新加入的节点竞争，也就是不公平锁的由来。 在公平锁中，在tryAcquire时会判断之前是否有等待的节点hasQueuedPredecessors(),如果有就不会再去获取锁了,因此能保证顺序执行。 12345678910111213for(;;){// 获取当前结点的前结点 final Node p=node.predecessor(); if(p==head&amp;&amp;tryAcquire(arg)){ setHead(node); p.next=null; // help GC failed=false; return interrupted; } if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true; } 当线程B获取锁之后，会把当前结点赋值给head，然后原先的前驱结点 (也就是原来的head结点) 去掉引用链，方便回收，这样一来，线程B获取锁的整个过程就完成了，此时AQS的数据就会变成这样：到这里，我们已经分析完了AQS独占模式下加锁和释放锁的过程，也就是tryAccquire-&gt;tryRelease这一链条的逻辑，除此之外，AQS中还支持共享模式的同步，这种模式下关于锁的操作核心其实就是tryAcquireShared-&gt;tryReleaseShared这两个方法，我们可以简单看下 共享模式 ReentrantReadWriteLock是Java中读写锁的实现，写写互斥，读写互斥，读读共享。读写锁在内部分为读锁和写锁，因为我们要探索共享模式，因此更关注读锁。 获取锁AQS中，共享模式获取锁的顶层入口方法是acquireShared，该方法会获取指定数量的资源，成功的话就直接返回，失败的话就进入等待队列，直到获取资源， 1234public final void acquireShared(int arg){ if(tryAcquireShared(arg)&lt; 0) doAcquireShared(arg); } 该方法里包含了两个方法的调用， tryAcquireShared：尝试获取一定资源的锁，返回的值代表获取锁的状态。 doAcquireShared：进入等待队列，并循环尝试获取锁，直到成功。 tryAcquireSharedtryAcquireShared在AQS里没有实现，同样由自定义的同步器去完成具体的逻辑，像一些较为常见的并发工具Semaphore、CountDownLatch里就有对该方法的自定义实现，虽然实现的逻辑不同，但方法的作用是一样的，就是获取一定资源的资源，然后根据返回值判断是否还有剩余资源，从而决定下一步的操作。 返回值有三种定义： 负值代表获取失败； (当前有写锁，返回-1，即未获取共享锁，需要执行下一步doAcquireShared) 0代表获取成功，但没有剩余的资源，也就是state已经为0； 正值代表获取成功，而且state还有剩余，其他线程可以继续领取 当返回值小于0时，证明此次获取一定数量的锁失败了，然后就会走doAcquireShared方法 123456789101112131415protected final int tryAcquireShared(int unused){ Thread current=Thread.currentThread(); int c=getState(); if(exclusiveCount(c)!=0&amp;&amp; getExclusiveOwnerThread()!=current) return-1; int r=sharedCount(c); if(!readerShouldBlock()&amp;&amp; r&lt;MAX_COUNT &amp;&amp; compareAndSetState(c,c+SHARED_UNIT)){ //设置firstReader，计算数量，略 return 1; } return fullTryAcquireShared(current); } 设置共享锁需要修改state的数量，表示获取共享锁的线程的数量，当共享锁的获取存在竞争时，即compareAndSetState(c, c + SHARED_UNIT))可能设置失败，此时进入fullTryAcquireShared(current)进行获取共享锁的完整版操作。 也就是说共享锁获取时：如果当前没有独占锁在占用，AQS根据其实现类的tryAcquireShared来实现让一个共享锁直接获取到锁(可以直接执行)当有独占锁在占用是，让共享锁去等待直到独占锁解锁为止，也就是doAcquireShared(arg)的逻辑 doAcquireShared此方法的作用是将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回，这是它的源码： 12345678910111213141516171819202122232425262728293031323334 private void doAcquireShared(int arg){// 加入队列尾部final Node node=addWaiter(Node.SHARED); boolean failed=true; try{ boolean interrupted=false; // CAS自旋 for(;;){final Node p=node.predecessor(); // 判断前驱结点是否是head if(p==head){ // 尝试获取一定数量的锁 int r=tryAcquireShared(arg); if(r&gt;=0){ // 获取锁成功，而且还有剩余资源，就设置当前结点为head，并继续唤醒下一个线程 setHeadAndPropagate(node,r); // 让前驱结点去掉引用链，方便被GC p.next=null; // help GC if(interrupted) selfInterrupt(); failed=false; return; } } // 跟独占模式一样，改前驱结点waitStatus为-1，并且当前线程挂起，等待被唤醒 if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true; } }finally{ if(failed) cancelAcquire(node); } } doAcquireShared(arg) 除了将线程封装成节点入队外还表达了3个思想： 什么时候该执行 什么时候该传播 什么时候该等待（阻塞） 其中入队、执行和等待的逻辑基本和独占锁一样， 入队：都是加入等待队列的末尾，成为tail节点； 执行：判断当前节点的前一个节点是不是头节点，如果是的话尝试获取锁，如果获取到了就执行； 等待：获取不到或前一个节点不是头节点就代表该线程需要暂时等待，直到被叫醒为止。设置前一个节点为SIGNAL状态，然后进入等待。 其中不同的就是共享锁的传播逻辑： 想象一下，当前有一个写锁正在占用，有多个读锁在等待，当写锁释放时，第二个线程也就是想要获取读锁的线程就可以获取锁了。获取到之后当前正在用的锁就是读锁了，那后面的读锁呢，因为读锁是共享的，后面的读锁应该也能够依次获取读锁，也就是读锁的传播机制。 1234567891011 private void setHeadAndPropagate(Node node,int propagate){Node h=head;// head指向自己 setHead(node);// 如果还有剩余量，继续唤醒下一个邻居线程 if(propagate&gt;0||h==null||h.waitStatus&lt; 0){Node s=node.next;if(s==null||s.isShared())doReleaseShared();}} 将当前的节点设置为头节点，判断如果是共享锁，执行doReleaseShared()，唤醒当前节点 123456789101112131415161718private void doReleaseShared(){for(;;){Node h=head;if(h!=null&amp;&amp;h!=tail){int ws=h.waitStatus;if(ws==Node.SIGNAL){if(!compareAndSetWaitStatus(h,Node.SIGNAL,0))continue;unparkSuccessor(h);}else if(ws==0&amp;&amp;!compareAndSetWaitStatus(h,0,Node.PROPAGATE))continue;}if(h==head)break;}} 当前节点唤醒之后doAcquireShared(int arg)会继续执行,因为之前的节点被设置为头节点,如果后续是获取共享锁的节点会继续执行setHeadAndPropagate,一直传播下去直到遇到获取独占锁的节点。 看到这里，你会不会一点熟悉的感觉，这个方法的逻辑怎么跟上面那个acquireQueued() 那么类似啊？对的，其实两个流程并没有太大的差别。只是doAcquireShared()比起独占模式下的获取锁上多了一步唤醒后继线程的操作，当获取完一定的资源后，发现还有剩余的资源，就继续唤醒下一个邻居线程，这才符合”共享”的思想嘛。 这里我们可以提出一个疑问，共享模式下，当前线程释放了一定数量的资源，但这部分资源满足不了下一个等待结点的需要的话，那么会怎么样？ 按照正常的思维，共享模式是可以多个线程同时执行的才对，所以，多个线程的情况下，如果老大释放完资源，但这部分资源满足不了老二，但能满足老三，那么老三就可以拿到资源。可事实是，从源码设计中可以看出，如果真的发生了这种情况，老三是拿不到资源的，因为等待队列是按顺序排列的，老二的资源需求量大，会把后面量小的老三以及老四、老五等都给卡住。从这一个角度来看，虽然AQS严格保证了顺序，但也降低了并发能力 接着往下说吧，唤醒下一个邻居线程的逻辑在doReleaseShared()中，我们放到下面的释放锁来解析。 共享锁的获取总结如下： 尝试获取共享锁，如果当前是共享锁或无锁，设置共享锁的state,获取锁 如果当前是写锁，进入等待流程 入队，加入等待队列的末尾，成为tail节点 判断当前节点的前一个节点是不是头节点，如果是的话尝试获取锁，如果获取到了就执行 获取不到或前一个节点不是头节点就代表该线程需要暂时等待，直到被叫醒为止。设置前一个节点为SIGNAL状态，然后进入等待 如果可以获取到锁，设置头节点并进入共享锁节点传播流程 释放锁共享模式释放锁的顶层方法是releaseShared，它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码： 1234567public final boolean releaseShared(int arg){ if(tryReleaseShared(arg)){ doReleaseShared(); return true; } return false; } 该方法同样包含两部分的逻辑： tryReleaseShared：释放资源。 doAcquireShared：唤醒后继结点。 跟tryAcquireShared方法一样，tryReleaseShared在AQS中没有具体的实现，由子同步器自己去定义，但功能都一样，就是释放一定数量的资源。 释放完资源后，线程不会马上就收工，而是唤醒等待队列里最前排的等待结点。 tryReleaseShared在tryReleaseShared(arg)，基本就是tryAcquireShared(int unused)的反向操作 将设置的HoldCounter减少，firstReader设置null，state减少,将tryAcquireShared(int unused)添加的状态全部反向还原回去 当共享锁全部释放完毕，返回true，否则返回false doAcquireShared唤醒后继结点的工作在doReleaseShared()方法中完成，我们可以看下它的源码： 123456789101112131415161718192021 private void doReleaseShared(){for(;;){// 获取等待队列中的head结点 Node h=head;if(h!=null&amp;&amp;h!=tail){int ws=h.waitStatus;// head结点waitStatus = -1,唤醒下一个结点对应的线程 if(ws==Node.SIGNAL){if(!compareAndSetWaitStatus(h,Node.SIGNAL,0))continue;// loop to recheck cases// 唤醒后继结点 unparkSuccessor(h);}else if(ws==0&amp;&amp;!compareAndSetWaitStatus(h,0,Node.PROPAGATE))continue;// loop on failed CAS }if(h==head)// loop if head changed break; }} 代码没什么特别的，就是如果等待队列head结点的waitStatus为-1的话，就直接唤醒后继结点，唤醒的方法unparkSuccessor()在上面已经讲过了，这里也没必要再复述。 总的来看，AQS共享模式的运作流程和独占模式很相似。 2. Condition介绍完了AQS的核心功能，我们再扩展一个知识点，在AQS中，除了提供独占/共享模式的加锁/解锁功能，它还对外提供了关于Condition的一些操作方法。 Condition是个接口，在jdk1.5版本后设计的，基本的方法就是await()和SIGNAL()方法，功能大概就对应Object的wait()和notify()，Condition必须要配合锁一起使用，因为对共享状态变量的访问发生在多线程环境下。一个Condition的实例必须与一个Lock绑定，因此Condition一般都是作为Lock的内部实现，AQS中就定义了一个类ConditionObject来实现了这个接口，那么它应该怎么用呢？我们可以简单写个demo来看下效果 123456789101112131415161718192021222324252627282930313233public class ConditionDemo { public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Condition condition = lock.newCondition(); Thread tA = new Thread(() -&gt; { lock.lock(); try { System.out.println(&quot;线程A加锁成功&quot;); System.out.println(&quot;线程A执行await被挂起&quot;); condition.await(); System.out.println(&quot;线程A被唤醒成功&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); System.out.println(&quot;线程A释放锁成功&quot;); } }); Thread tB = new Thread(() -&gt; { lock.lock(); try { System.out.println(&quot;线程B加锁成功&quot;); condition.SIGNAL(); System.out.println(&quot;线程B唤醒线程A&quot;); } finally { lock.unlock(); System.out.println(&quot;线程B释放锁成功&quot;); } }); tA.start(); tB.start(); }} 执行main函数后结果输出为： 1234567线程A加锁成功 线程A执行await被挂起 线程B加锁成功 线程B唤醒线程A 线程B释放锁成功 线程A被唤醒成功 线程A释放锁成功 代码执行的结果很容易理解，线程A先获取锁，然后调用await()方法挂起当前线程并释放锁，线程B这时候拿到锁，然后调用SIGNAL唤醒线程A。 毫无疑问，这两个方法让线程的状态发生了变化，我们仔细来研究一下， 翻看AQS的源码，我们会发现Condition中定义了两个属性firstWaiter和lastWaiter，前面说了，AQS中包含了一个FIFO的CLH等待队列，每个Conditon对象就包含这样一个等待队列，而这两个属性分别表示的是等待队列中的首尾结点， 1234/** First node of condition queue. */private transient Node firstWaiter;/** Last node of condition queue. */private transient Node lastWaiter; 注意：Condition当中的等待队列和AQS主体的同步等待队列是分开的，两个队列虽然结构体相同，但是作用域是分开的 await先看await()的源码： 12345678910111213141516171819202122 public final void await()throws InterruptedException{if(Thread.interrupted())throw new InterruptedException();// 将当前线程加入到等待队列中 Node node=addConditionWaiter();// 完全释放占有的资源，并返回资源数 int savedState=fullyRelease(node);int interruptMode=0;// 循环判断当前结点是不是在Condition的队列中，是的话挂起 while(!isOnSyncQueue(node)){LockSupport.park(this);if((interruptMode=checkInterruptWhileWaiting(node))!=0)break;}if(acquireQueued(node,savedState)&amp;&amp;interruptMode!=THROW_IE)interruptMode=REINTERRUPT;if(node.nextWaiter!=null)// clean up if cancelled unlinkCancelledWaiters();if(interruptMode!=0)reportInterruptAfterWait(interruptMode);} 当一个线程调用 Condition.await()方法，将会以当前线程构造结点，这个结点的waitStatus赋值为Node.CONDITION， 也就是-2，并将结点从尾部加入等待队列，然后尾部结点就会指向这个新增的结点， 123456789101112131415 private Node addConditionWaiter(){Node t=lastWaiter;// If lastWaiter is cancelled, clean out. if(t!=null&amp;&amp;t.waitStatus!=Node.CONDITION){unlinkCancelledWaiters();t=lastWaiter;}Node node=new Node(Thread.currentThread(),Node.CONDITION);if(t==null)firstWaiter=node;elset.nextWaiter=node;lastWaiter=node;return node;} 我们依然用上面的demo来演示，此时，线程A获取锁并调用Condition.await()方法后，AQS内部的数据结构会变成这样：在Condition队列中插入对应的结点后，线程A会释放所持有的资源，走到while循环那层逻辑， 12345while(!isOnSyncQueue(node)){ LockSupport.park(this); if((interruptMode=checkInterruptWhileWaiting(node))!=0) break; } isOnSyncQueue方法的会判断当前的线程节点是不是在同步队列中，这个时候此结点还在Condition队列中，所以该方法返回false，这样的话循环会一直持续下去，线程被挂起，等待被唤醒，此时，线程A的流程暂时停止了。 当线程A调用await()方法挂起的时候，线程B获取到了线程A释放的资源，然后执行SIGNAL()方法： SIGNAL1234567public final void SIGNAL(){ if(!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first=firstWaiter; if(first!=null) doSIGNAL(first); } 先判断当前线程是否为获取锁的线程，如果不是则直接抛出异常。接着调用doSIGNAL()方法来唤醒线程。 12345678910111213141516171819 private void doSIGNAL(Node first){ // 循环，从队列一直往后找不为空的首结点 do{ if((firstWaiter=first.nextWaiter)==null) lastWaiter=null; first.nextWaiter=null; }while(!transferForSIGNAL(first)&amp;&amp;(first=firstWaiter)!=null); }final boolean transferForSIGNAL(Node node){ // CAS循环，将结点的waitStatus改为0 if(!compareAndSetWaitStatus(node,Node.CONDITION,0)) return false; // 上面已经分析过，此方法会把当前结点加入到等待队列中，并返回前驱结点 Node p=enq(node); int ws=p.waitStatus; if(ws&gt;0||!compareAndSetWaitStatus(p,ws,Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } 从doSIGNAL的代码中可以看出，这时候程序寻找的是Condition等待队列中首结点firstWaiter的结点，此时该结点指向的是线程A的结点，所以之后的流程作用的都是线程A的结点。 这里分析下transferForSIGNAL方法，先通过CAS自旋将结点waitStatus改为0，然后就把结点放入到同步队列 (此队列不是Condition的等待队列) 中，然后再用CAS将同步队列中该结点的前驱结点waitStatus改为Node.SIGNAL，也就是-1，此时AQS的数据结构大概如下(额…..少画了个箭头，大家就当head结点是线程A结点的前驱结点就好)：回到await()方法，当线程A的结点被加入同步队列中时，isOnSyncQueue()会返回true，跳出循环， 123456789101112 while(!isOnSyncQueue(node)){LockSupport.park(this);if((interruptMode=checkInterruptWhileWaiting(node))!=0)break;}if(acquireQueued(node,savedState)&amp;&amp;interruptMode!=THROW_IE)interruptMode=REINTERRUPT;if(node.nextWaiter!=null)// clean up if cancelled unlinkCancelledWaiters();if(interruptMode!=0)reportInterruptAfterWait(interruptMode); 接着执行acquireQueued()方法，这里就不用多说了吧，尝试重新获取锁，如果获取锁失败继续会被挂起，直到另外线程释放锁才被唤醒。 所以，当线程B释放完锁后，线程A被唤醒，继续尝试获取锁，至此流程结束。 对于这整个通信过程，我们可以画一张流程图展示下： 总结说完了Condition的使用和底层运行机制，我们再来总结下它跟普通 wait/notify 的比较，一般这也是问的比较多的，Condition大概有以下两点优势： Condition 需要结合 Lock 进行控制，使用的时候要注意一定要对应的unlock()，可以对多个不同条件进行控制，只要new 多个 Condition对象就可以为多个线程控制通信，wait/notify 只能和 synchronized 关键字一起使用，并且只能唤醒一个或者全部的等待队列； Condition 有类似于 await 的机制，因此不会产生加锁方式而产生的死锁出现，同时底层实现的是 park/unpark 的机制，因此也不会产生先唤醒再挂起的死锁，一句话就是不会产生死锁，但是 wait/notify 会产生先唤醒再挂起的死锁。 无论是独占还是共享模式，或者结合是Condition工具使用，AQS本质上的同步功能都是通过对锁和队列中结点的操作来实现的， 3. ReentrantLockReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。为了帮助大家更好地理解ReentrantLock的特性，我们先将ReentrantLock跟常用的Synchronized进行比较，其特性如下：下面通过伪代码，进行更加直观的比较： 1234567891011121314151617181920212223242526272829// **************************Synchronized的使用方式**************************// 1.用于代码块synchronized (this){}// 2.用于对象synchronized (object){}// 3.用于方法public synchronized void test(){} // 4.可重入 for(int i=0;i&lt; 100;i++){synchronized (this){} }// **************************ReentrantLock的使用方式**************************public void test()throw Exception{ // 1.初始化选择公平锁、非公平锁 ReentrantLock lock=new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try{ try{ // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100,TimeUnit.MILLISECONDS)){} }finally{ // 4.手动释放锁 lock.unlock() } }finally{ lock.unlock(); } } ReentrantLock 最基本的使用方式123456789101112class X { private final ReentrantLock lock = new ReentrantLock(); public void m() { lock.lock(); try { doSomething(); } finally { lock.unlock() } }} 当创建ReentrantLock时默认使用非公平锁，效率高于公平锁，暂不讨论公平锁。 ReentrantReadWriteLock的读锁的最基本的使用方式如下123456789101112class X { private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public void m() { rwl.readLock().lock(); try { read(); } finally { rwl.readLock().unlock(); } }} 2. synchronizesynchronized可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性。Synchronized主要有以下三个作用：保证互斥性、保证可见性、保证顺序性。 synchronize与lock的区别参考文章 图文并茂：AQS 是怎么运行的？ AQS 简介 Java技术之AQS详解 Java并发之AQS详解 从ReentrantLock的实现看AQS的原理及应用","link":"/2021/09/23/java/java_aqs/"},{"title":"RabbitMQ","text":"RabbitMQ 是一个消息代理：它接受和转发消息。 您可以将其视为邮局：当您将要投递的邮件放入邮箱时，您可以确定信件承运人最终会将邮件递送给您的收件人。 在这个比喻中，RabbitMQ 是一个邮箱、一个邮局和一个信件载体。 RabbitMQ 和邮局之间的主要区别在于它不处理纸张，而是接受、存储和转发二进制数据块 - 消息。 常见的MQ产品#ActiveMQ：基于JMS，Apache RocketMQ：（Rocket，火箭）阿里巴巴的产品，基于JMS，目前由Apache基于会维护 Kafka：分布式消息系统，亮点：吞吐量超级高，没秒中数十万的并发。 RabbitMQ：（Rabbit，兔子）由erlang语言开发，基于AMQP协议，在erlang语言特性的加持下，RabbitMQ稳定性要比其他的MQ产品好一些，而且erlang语言本身是面向高并发的编程的语言，所以RabbitMQ速度也非常快。且它基于AMQP协议，对分布式、微服务更友好。 参考文章 Downloading and Installing RabbitMQ RabbitMQ Messaging with RabbitMQ https://www.cnblogs.com/ZhuChangwu/p/14093107.html https://developer.aliyun.com/article/769883","link":"/2021/12/28/big_data/RabbitMQ/"},{"title":"filebeat","text":"Download Filebeat Filebeat 是一个轻量级的传送器，用于转发和集中日志数据。Filebeat 作为代理安装在您的服务器上，监控您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash以进行索引。 Filebeat 的工作原理如下：当您启动 Filebeat 时，它会启动一个或多个输入，这些输入会在您为日志数据指定的位置中查找。对于 Filebeat 找到的每个日志，Filebeat 都会启动一个收割机。每个收割机读取新内容的单个日志，并将新日志数据发送到 libbeat，后者聚合事件并将聚合数据发送到您为 Filebeat 配置的输出。 How Filebeat worksedit 参考文章 一篇文章搞懂filebeat（ELK） Filebeat中文指南 Filebeat 概述 Filebeat quick start: installation and configuration","link":"/2021/12/27/big_data/filebeat/"},{"title":"dubbo","text":"参考文章 第一个 Dubbo 应用 https://dubbo.apache.org/docs/v3.0/ Dubbo Background Your First Dubbo Demo","link":"/2021/12/28/big_data/dubbo/"},{"title":"elasticsearch","text":"Download Elasticsearch Install Elasticsearch with Docker docker installStarting a single node cluster with Docker1docker pull docker.elastic.co/elasticsearch/elasticsearch:7.16.2 1docker run -p 127.0.0.1:9200:9200 -p 127.0.0.1:9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.16.2 Starting a multi-node cluster with Docker ComposeCreate a docker-compose.yml file: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475version: '2.2'services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - elastic es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data networks: - elastic es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data networks: - elasticvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: elastic: driver: bridge Run docker-compose to bring up the cluster:12docker-compose up Submit a _cat/nodes request to see that the nodes are up and running:12curl -X GET &quot;localhost:9200/_cat/nodes?v=true&amp;pretty&quot; efk_elasticsearch_1 exited with code 78 when install ElasticSearch123sudo sysctl -w vm.max_map_count=262144sudo sysctl -w vm.max_map_count=524288 ref: https://techoverflow.net/2019/03/11/how-to-fix-elasticsearch-exited-with-code-78/ Download and install archive for Linux 单机修改 vm.max_map_count1sudo sysctl -w vm.max_map_count=524288 a.切换到root用户，修改sysctl.conf配置文件 12vi /etc/sysctl.conf b.添加如下配置文件 12vm.max_map_count=655360 c.执行如下脚本 12sysctl -p 创建一个非root用户ElasticSearch有个比较特殊的地方就是不能用root权限来运行，所以我们这边需要新建一个用户以及赋予对应权限。 a.新建一个elsearch用户组 12groupadd elsearch b.新建用户elsearch，并让他加入elsearch组 123useradd elsearch -g elsearch -p elsearchpasswd elsearch c.切换用户 1su elsearch d. root 权限 1234567chmod -v u+w /etc/sudoersvim /etc/sudoers# 找到Allow root to run any commands anywhere 之后添加一行'用户名' ALL=(ALL) ALL# 如需新用户使用sudo时不用输密码，把最后一个ALL改为NOPASSWD:ALL即可 创建日志文件夹12mkdir -p ~/data/logs/elasticsearchmkdir -p ~/data/elasticsearch/{data,work,plugins,scripts} 将下载的文件放在服务器如下目录: ~/apps/1234567sudo yum install -y wget vimsudo yum install perl-Digest-SHA -ywget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.2-linux-x86_64.tar.gzwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.2-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.16.2-linux-x86_64.tar.gz.sha512 tar -xzf elasticsearch-7.16.2-linux-x86_64.tar.gzcd elasticsearch-7.16.2/ 修改配置文件1234cd /home/elsearch/apps/elasticsearch-7.16.2/configvim elasticsearch.yml ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html 123456789101112131415cluster.name: summer-esnode.name: node-1network.host: 0.0.0.0 //监听访问地址为任意网段，也可以按自己的要求要设置对应的网段discovery.seed_hosts: [&quot;192.169.171.132&quot;]cluster.initial_master_nodes: [&quot;node-1&quot;] path.data: /home/elsearch/data/elasticsearch/datapath.logs: /home/elsearch/data/logs/elasticsearch #如果没有对应的插件，那么下面两个就不用配置，否则会报错#path.plugins: /data/elasticsearch/plugins#path.scripts: /data/elasticsearch/scripts 123discovery.seed_hosts：集群节点列表，每个值应采用host：port或host的形式（其中port默认为设置transport.profiles.default.port，如果未设置则返回transport.port）discovery.seed_providers：集群节点列表的提供者，作用就是获取discovery.seed_hosts，比如使用文件指定节点列表cluster.initial_master_nodes：初始化时master节点的选举列表，一般使用node.name（节点名称）配置指定，配置旨在第一次启动有效，启动之后会保存，下次启动会读取保存的数据 也可以通过如下配置来修改端口： 12http.port: 9200 完整配置 elasticsearch.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#cluster.name: summer-es## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /home/elsearch/data/elasticsearch/data## Path to log files:#path.logs: /home/elsearch/data/logs/elasticsearch## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## By default Elasticsearch is only accessible on localhost. Set a different# address here to expose this node on the network:#network.host: 0.0.0.0## By default Elasticsearch listens for HTTP traffic on the first free port it# finds starting at 9200. Set a specific HTTP port here:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.seed_hosts: [&quot;192.169.171.132&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: [&quot;node-1&quot;]## For more information, consult the discovery and cluster formation module documentation.# ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true## ---------------------------------- Security ---------------------------------- 启动任务1/home/elsearch/apps/elasticsearch-7.16.2/bin/elasticsearch 123cd /home/elsearch/apps/elasticsearch-7.16.2/bin/sh elasticsearch 或者用sh elasticsearch -d来后台启动 验证是否运行下面两者需同时满足 a. 输入如下脚本，有对应服务出现 12ps -ef|grep elasticsearch b.输入http//:ip:9200出现下图所示 1234567891011121314151617{ &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;summer-es&quot;, &quot;cluster_uuid&quot; : &quot;7PPB46ryTe-tIu2L45cM-Q&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.16.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;2b937c44140b6559905130a8650c64dbd0879cfb&quot;, &quot;build_date&quot; : &quot;2021-12-18T19:42:46.604893745Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.10.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot;} 关闭elasticsearch需要对ES节点进行重新启动或正常关机的时候，有三种方法可以关闭ES： 1.在控制台中,使用CTRL+C组合键.2.通过发送TERM信号终止服务器进程.3.使用REST APIcurl -XPOST ‘http://localhost:9200/_shutdown' 集群参考文章 Installation Elastic 快速入门 安装与启动 使用 Docker 安装 Elasticsearch ElasticSearch教程——安装 Download and install archive for Linux ElasticSearch+Kibana安装部署 ELK 架构之 Elasticsearch 和 Kibana 安装配置 Elasticsearch安装及kibana安装 ElasticSearch 7.8.1集群搭建 Elasticsearch集群搭建 【ElasticSearch】本地安装部署及集群搭建","link":"/2021/12/27/big_data/elasticsearch/"},{"title":"logstash","text":"Logstash 是一个开源数据收集引擎，具有实时流水线功能。Logstash 可以动态统一来自不同来源的数据，并将数据规范化为您选择的目的地。为各种高级下游分析和可视化用例清理和民主化您的所有数据。 集中、转换和存储你的数据Logstash是一个开源的服务器端数据处理管道，可以同时从多个数据源获取数据，并对其进行转换，然后将其发送到你最喜欢的“存储”。（当然，我们最喜欢的是Elasticsearch） 输入：采集各种样式、大小和来源的数据数据往往以各种各样的形式，或分散或集中地存在于很多系统中。Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤器：实时解析和转换数据数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 Logstash 能够动态地转换和解析数据，不受格式或复杂度的影响： 利用 Grok 从非结构化数据中派生出结构 从 IP 地址破译出地理坐标 将 PII 数据匿名化，完全排除敏感字段 整体处理不受数据源、格式或架构的影响 输出：选择你的存储，导出你的数据尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 Logstash 的强大功能编辑Elasticsearch 等的摄取主力具有强大 Elasticsearch 和 Kibana 协同作用的水平可扩展数据处理管道 可插拔管道架构混合、匹配和编排不同的输入、过滤器和输出，以在管道中和谐播放 社区可扩展且对开发人员友好的插件生态系统超过 200 个可用的插件，以及创建和贡献自己的插件的灵活性 日志和指标编辑一切开始的地方。 处理所有类型的日志数据 轻松摄取大量 Web 日志（如Apache）和应用程序日志（如Java 的 log4j） 捕获许多其他日志格式，如syslog、网络和防火墙日志等 使用Filebeat享受互补的安全日志转发功能 通过TCP和UDP 从Ganglia、collectd、 NetFlow、JMX和许多其他基础设施和应用程序平台收集指标参考文章 Logstash 介绍 Logstash介绍 Elastic 技术栈之 Logstash 基础 Download Logstash 使用 Logstash 解析日志编辑","link":"/2021/12/27/big_data/logstash/"},{"title":"kibana","text":"Kibana—your window into ElasticeditInstall Kibana with Docker Run Kibana on Docker for developmenteditTo start an Elasticsearch container for development or testing, run: 123docker network create elasticdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.16.2docker run --name es01-test --net elastic -p 127.0.0.1:9200:9200 -p 127.0.0.1:9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.16.2 To start Kibana and connect it to your Elasticsearch container, run the following commands in a new terminal session: 123docker pull docker.elastic.co/kibana/kibana:7.16.2docker run --name kib01-test --net elastic -p 127.0.0.1:5601:5601 -e &quot;ELASTICSEARCH_HOSTS=http://es01-test:9200&quot; docker.elastic.co/kibana/kibana:7.16.2 To access Kibana, go to http://localhost:5601. Install Kibana with Dockerref: https://www.elastic.co/guide/en/kibana/current/docker.html#bind-mount-config 123456version: '2'services: kibana: image: docker.elastic.co/kibana/kibana:7.16.2 volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml Install Kibana from archive on Linux1234curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.16.2-linux-x86_64.tar.gzcurl https://artifacts.elastic.co/downloads/kibana/kibana-7.16.2-linux-x86_64.tar.gz.sha512 | shasum -a 512 -c - tar -xzf kibana-7.16.2-linux-x86_64.tar.gzcd kibana-7.16.2-linux-x86_64/ 修改config/kibana.yml，添加ElasticSearch的节点配置：12/home/elsearch/apps/kibana-7.16.2-linux-x86_64cd config 1234567891011# 服务端口，默认5601server.port: 5601# 启动地址，默认localhost，如果不修改，那么远程无法访问server.host: 0.0.0.0# elasticsearch集群地址，旧版本是elasticsearch.urlelasticsearch.hosts: [&quot;http://192.168.209.128:9200&quot;,&quot;http://192.168.209.129:9200&quot;,&quot;http://192.168.209.132:9200&quot;]# 如果ES有设置账号密码，则添加下面的账号密码设置#elasticsearch.username: username#elasticsearch.password: passwor 启动1/home/elsearch/apps/kibana-7.16.2-linux-x86_64/bin/kibana 访问测试在浏览器中输入http://IP:5601会有对应的kibana界面显示 参考文章 Download Kibana Quick start Deploy an Elasticstack with SIEM with docker-compose for lab Install Kibana from archive on Linux or macOS ElasticSearch+Kibana安装部署 ElasticSearch教程——安装Kibana ElasticSearch+Kibana安装部署 ELK 架构之 Elasticsearch 和 Kibana 安装配置","link":"/2021/12/27/big_data/kibana/"},{"title":"spring_boot2.0_release_notes","text":"参考文章","link":"/2022/01/05/spring/spring-spring-boot2-0-release-notes/"},{"title":"ansible_intro","text":"Ansible 概览这部分内容对所有用户均有用。 你需要了解 Ansible 的使用背景才能在各类场景下使用他的自动化功能。本页内容是你深入理解其它内容的基础。 管理机 受控节点 Inventory 仓库 Modules 模块 Tasks 任务 Playbooks 任务剧本管理机任何安装了 Ansbile 的服务器，你都可以使用 ansible or ansible-playbook 命令。 任何安装了 Ansbile 的机器都可以做为管理节点，便携式计算机，共享桌面和服务器都可以。 你可以配置多个管理节点。唯一需要注意的是，管理节点不支持 Windows 系统。 受控节点Ansbile 管理的服务器或者网络设备都称为受控节点。 受控节点有时候也叫做 “hosts” ( 主机 ). 受控节点不需要安装 Ansible. Inventory 仓库Inventory 仓库是保存受控节点信息的列表, 因为有时候也叫 “hostfile”， 类似于系统的 hosts 文件。 Inventory 仓库可以以 IP 的方式指定受控节点。 Inventory 同样可以组织管理节点、新增、嵌套组等方式，非常便于扩展。 更多请参考 the Working with Inventory Modules 模块Modules 模块是 Ansible 执行代码的最小单元。 每个模块都是特殊用途，从特殊类型的数据库用户管理，到特殊类型的网络设备 VLAN 接口管理。 你可以在通过执行单个任务调用一个模块，也可以通过 playbook 同时调用执行钓具模块。 在链接中查看 Ansible 总共包括了多少个模块。:ref: 模块列表 &lt;modules_by_category&gt;. Tasks 任务Ansible 执行操作的最小单位。 ad-hoc 更适合临时执行命令的执行场景。 Playbooks 任务剧本Playbooks 是任务列表的组合，通常会把常用的命令列表通过正确的语法写入到 playbook中。 Playbook 可以像普通 tasks 一样调用变量， 其使用 YAML 语法，便于读、写、分享、理解。更多请参考 Intro to Playbooks. install ansibleinstall python3.8 on centos8 https://luochunhai.github.io/2021/12/24/python/python-centos-install/https://computingforgeeks.com/how-to-install-python-3-python-2-7-on-rhel-8/ https://linuxize.com/post/how-to-install-python-3-8-on-centos-8/ 123456789101112131415161718192021222324252627282930313233# sudo dnf install python3# preparesudo dnf groupinstall 'development tools' -ysudo dnf install bzip2-devel expat-devel gdbm-devel \\ ncurses-devel openssl-devel readline-devel wget \\ sqlite-devel tk-devel xz-devel zlib-devel libffi-devel -y## download VERSION=3.8.1wget https://www.python.org/ftp/python/${VERSION}/Python-${VERSION}.tgztar -xf Python-${VERSION}.tgz# 该--enable-optimizations选项通过运行多个测试来优化 Python 二进制文件。这会使构建过程变慢。cd Python-${VERSION}./configure --enable-optimizations# 通过运行以下命令启动 Python 3.8 构建过程：make -j 4# 修改-j以对应于处理器中的内核数。您可以通过键入 找到该号码nproc。# 构建过程完成后，安装 Python 二进制文件：sudo make altinstallpython3.8 --versionln -s /usr/local/bin/python3.8 /usr/bin/pythonpython -m pip install --upgrade pip 安装 Ansible on CentOSpip install12345678pip install setuptools-rustpip install paramiko## 安装 Ansible [1]:pip install ansibleansible --version yum install123yum install epel-release -yyum install sshpass -yyum install ansible -y ansible的使用基于端口，用户，密码定义主机清单格式： 12ansible基于ssh连接-i （inventory）参数后指定的远程主机时，也可以写端口，用户，密码。 如：ansible_ssh_port: 指定ssh端口ansible_ssh_user:指定 ssh 用户ansible_ssh_pass: 指定 ssh 用户登录是认证密码（明文密码不安全）ansible_sudo_pass: 指明 sudo 时候的密码 添加的内容如下： 123[root@ansible_master ansible]# grep -v ^# /etc/ansible/hosts |grep -v ^$[remote]192.168.171.136 ansible_ssh_port=22 ansible_ssh_user=root ansible_ssh_pass=summer 直接添加到文件文末就可以； 测试主机的连通性 1234yum install epel-release -yyum install sshpass -yansible -i /etc/ansible/hosts remote -m ping 可能出现的问题：Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this 1234vi /etc/ansible/ansible.cfg[defaults]forks = 8 #执行时并发数host_key_checking = False #不检测host key 查看组下所有的IP： 1ansible all --list 基于ssh密钥来访问定义主机清单设置密钥 1ssh-keygen 拷贝密钥并测试 123456# 使用ssh-keygen和ssh-copy-id三步实现SSH无密码登录 和ssh常用命令 # https://blog.csdn.net/alifrank/article/details/48241699ssh-copy-id root@192.168.171.136## 登陆测试ssh 192.168.1.163 使用ping检查‘web-servers’或者ansible节点的连通性。 1234567ansible -i /etc/ansible/hosts 'remote' -m ping# 这条命令我们也可以不指定hosts,效果是一样的，我们只要指定组即可ansible 'remote' -m ping# 有时候我们为了方便阅读也把主机组名写在最后面# remote 这个组名，放在最后面ansible -m command -a &quot;uptime&quot; 'remote' 案例1： 检查节点的内存情况 1ansible -m command -a &quot;free -m &quot; 'remote' 案例2：给节点增加用户 1ansible -m command -a &quot;useradd summer&quot; 'remote' 查看是否创建用户成功 1ansible -m command -a &quot;id summer&quot; 'remote' 参考文章 非常好的Ansible入门教程 自动化运维第一步——Ansible 使用教程 ansible基本使用教程 Ansible 文档 Ansible中文权威指南 Ansible「2.9」 中文官方文档 太厉害了，终于有人能把Ansible讲的明明白白了，建议收藏","link":"/2022/03/21/ansible/ansible-intro/"},{"title":"centos 常用命令、常见问题","text":"收集centos常见操作 cmd not found1sudo yum install net-tools -y centos7修改hostname1234567hostnamectl set-hostname my_hostname # 使用这个命令会立即生效且重启也生效hostname # 查看下# my_hostnamevim /etc/hosts # 编辑下hosts文件， 给127.0.0.1添加hostnamecat /etc/hosts # 检查#127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 centos77.magedu.com#::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 一次删除多个路径下的文件12# 删除node1 ~ node6/data 下的文件rm -rf node{1,2,3,4,5,6}/data/* 目录结构12345678910111213141516171819├── docker-compose.yaml├── node1│ ├── data│ └── redis.conf├── node2│ ├── data│ └── redis.conf├── node3│ ├── data│ └── redis.conf├── node4│ ├── data│ └── redis.conf├── node5│ ├── data│ └── redis.conf└── node6 ├── data └── redis.conf Fix Failed to download metadata for repo123456789101112#Step 1: Go to the /etc/yum.repos.d/ directory.cd /etc/yum.repos.d/#Step 2: Run the below commandssed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*#Step 3: Now run the yum updateyum update -y 在linux终端命令行模式中输入以下命令查看centos版本即可。1cat /etc/redhat-release #查看centos版本 相关操作命令：1234567uname -a #查看内核版本等信息cat /proc/cpuinfo | grep &quot;physical id&quot; | uniq | wc -l #查看cpu个数cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq #查看cpu核数cat /proc/cpuinfo | grep 'model name' |uniq #查看cpu型号 参考文章 Failed to download metadata for repo ‘AppStream’ [CentOS] centos修改主机名的正确方法","link":"/2022/03/21/centos/centos-cmd/"},{"title":"ansible 用法","text":"ansible的常用模块 command ansible的默认模块，不指定-m参数的时候，使用的就是command模块；常见的命令都可以使用，但命令的执行不是通过shell来执行的，所以&lt; &gt; | and &amp; z这些操作都不可以，不支持管道，没法批量执行命令 shell模块： 使用shell模块的时候默认是通过/bin/sh来执行的，所以在终端输入的各种命令都可以使用 scripts模块 使用scripts模块可以在本地写一个脚本，在远程服务器上执行 案例1：使用shell模块的案例 1ansible -i /etc/ansible/hosts web-servers -m shell -a &quot;source ~/.bash_profile &amp;&amp; df -h|head 案例2：使用script 模块 12345cat ~/test.sh#!/bin/bashdatehostnameecho &quot;hello world&quot; 1ansible -i /etc/ansible/hosts remote -m script -a &quot;~/test.sh&quot; copy模块的使用copy模块:实现主控端向目标主机拷贝文件，类似scp功能 案例1： 把ansible主机的/etc/hosts 拷贝到主机组机器中的/root/下 1ansible -i /etc/ansible/hosts remote -m copy -a &quot;src=~/test.sh dest=/root owner=root group=root mode=0777&quot; 查看是否执行成功： 1ansible -m command -a &quot;ls /root/&quot; 'remote' file模块案例5 给文件设置权限 1ansible -i /etc/ansible/hosts remote -m file -a &quot;path=/root/test.sh mode=0755&quot; 查看权限： 1ansible -m command -a &quot;ls -l /root&quot; 'remote' stat模块获取远程文件信息案例6 获取文件信息 1ansible -i /etc/ansible/hosts remote -m stat -a &quot;path=/root/test.sh&quot; get_url 模块案例7 实现远程主机下载指定的url地址，支持sha256sum文件校验 12ansible -i /etc/ansible/hosts remote -m get_url -a &quot;url=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm dest=/tmp/ mode=0440 force=yes&quot; 注：url=https://xxx 的等号=前后不能有空格扩展:查看force=yes的作用 yum模块 yum模块linux平台软件包管理。 yum模块可以提供的status状态： latest ，present，installed #这三个代表安装；removed, absent #这两个是卸载 案例8 使用yum模块安装httpd 1ansible -i /etc/ansible/hosts remote -m yum -a &quot;name=httpd state=latest&quot; cron模块远程管理主机crontab配置 案例9： 增加每30分钟执行 echo “hello summer” 1ansible -i /etc/ansible/hosts web-servers -m cron -a “name=‘list dir’ minute=’*/30’ job=‘echo hello summer”’” service 远程管理主机系统服务模块 service模块常用参数： （1）、name参数：此参数用于指定需要操作的服务名称，比如 nginx，httpd。 （2）、state参数：此参数用于指定服务的状态 比如，我们想要启动远程主机中的httpd，则可以将 state 的值设置为 started；如果想要停止远程主机中的服务，则可以将 state 的值设置为 stopped。此参数的可用值有 started、stopped、restarted（重启）、reloaded。 enabled参数：此参数用于指定是否将服务设置为开机 启动项，设置为 yes 表示将对应服务设置为开机启动，设置为 no 表示不会开机启动。 注：想使用service模块启动服务，被启动的服务，必须可以使用service 命令启动或关闭 案例10 使用service模块重启httpd 1ansible -i /etc/ansible/hosts remote -m service -a &quot;name=httpd state=restarted&quot; user模块 管理远程主机的用户 案例11： 使用user模块创建一个用户summer 1ansible -i /etc/ansible/hosts remote -m user -a &quot;name=summer state=present&quot; ansible 实战案例playbooks的介绍1） 在playbooks 中定义任务： name： task description #任务描述信息module_name: module_args #需要使用的模块名字： 模块参数2） ansible-playbook 执行 命令：ansible-playbook site.yml playbook是由一个或多个”play”组成的列表。play的主要功能在于将事先归为一组的主机装扮成事先通过ansible中的task定义好的角色。github上提供了大量的实例供大家参考: https://github.com/ansible/ansible-examples 实战一： 使用playbook 批量部署多台LAMP环境先介绍下： Playbook常用文件夹作用： files：存放需要同步到异地服务器的源码文件及配置文件； handlers：当服务的配置文件发生变化时需要进行的操作，比如：重启服务，重新加载配置文件，handlers [‘hændləz] 处理程序 meta：角色定义，可留空； tasks：需要进行的执行的任务； templates：用于执行lamp安装的模板文件，一般为脚本； vars：本次安装定义的变量 搭建思路思路：我们搭建lanp架构，大概需要: yum 安装服务 service 启动 copy 把网站拷贝过去 在playbooks 中定义任务：name： task description #任务描述信息module_name: module_args #需要使用的模块名字： github上提供了大量的实例供大家参考:https://github.com/ansible/ansible-examples 4.2 使用Playbook批量部署多台LAMP环境步骤我们可以在ansible服务器上安装LAMP环境，然后，再将配置文件通过ansible拷贝到远程主机上 第一步：安装httpd软件 1yum -y install httpd -y 第二步：安装MySQL 12345678910111213[root@ansible ~]# yum install mariadb-server mariadb -y #安装mysql服务[root@ansible ~]# mkdir -p /mysqldata/data/ #创建目录作为数据存放的位置[root@ansible ~]# chown -R mysql:mysql /mysqldata/ #授权[root@ansible ~]# vim /etc/my.cnf #改变数据存放目录改：# 2 datadir=/var/lib/mysql# 改为：2 datadir=/mydata/data/[root@ansible data]# systemctl start mariadb 第三步：安装PHP和php-mysql模块 1yum -y install php php-mysql 第四步：提供php的测试页 123456789 vim /var/www/html/index.php cat /var/www/html/index.php&lt;?php phpinfo();?&gt; systemctl reload httpd #启动httpd服务 httpd测试：http://{ip} 确保已经出现上面的测试页，而且，要看到MySQL已经被整合进来了，才能进行下一步操作 第五；定义组名 1234vim /etc/ansible/hosts #还使用之前定义好的，这里不用修改[webservers]192.168.171.136 然后，将公钥信息复制到被控制节点，ansible和两个节点间通过ssh进行连接。下面3个命令之前已经做过，不用执行了。 12ssh-keygen ssh-copy-id root@192.168.171.136 第六：使用playbook创建一个LAMP构建的任务1、创建相关文件 12[root@ansible ~]# mkdir -pv /etc/ansible/lamp/roles/{prepare,httpd,mysql,php}/{tasks,files,templates,vars,meta,default,handlers} 我们将上面搭建成功的LAMP环境的httpd和MySQL的配置文件拷贝到对应目录下 123456789101112131415161718[root@summer ~]# cd /etc/ansible/ [root@ansible ansible]# cp /etc/httpd/conf/httpd.conf lamp/roles/httpd/files/[root@summer ansible]# cp /etc/my.cnf lamp/roles/mysql/files/[root@summer ansible]# 写prepare（前期准备）角色的playbooks[root@summer ansible]# vim lamp/roles/prepare/tasks/main.yml[root@summer ansible]# cat lamp/roles/prepare/tasks/main.yml- name: delete yum config shell: rm -rf /etc/yum.repos.d/* #删除原有的yum配置文件- name: provide yumrepo file shell: wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #下载新的yum配置文件- name: clean the yum repo shell: yum clean all #清除原有的yum缓存信息- name: clean the iptables shell: iptables -F #清除原有防火墙规则，不然后可能上不了网[root@summer ansible]# 2、构建httpd的任务 123456789101112131415161718192021[root@summer ansible]# cd /etc/ansible/lamp/roles/[root@summer roles]# mv /var/www/html/index.php httpd/files/[root@summer roles]# vim httpd/tasks/main.yml[root@summer roles]# cat httpd/tasks/main.yml[root@summer roles]# cat httpd/tasks/main.yml- name: web server install yum: name=httpd state=present #安装httpd服务- name: provide test page copy: src=index.php dest=/var/www/html #提供测试页- name: delete apache config shell: rm -rf /etc/httpd/conf/httpd.conf #删除原有的apache配置文件，如果不删除，下面的copy任务是不会执行的，因为当源文件httpd.conf和目标文件一样时，copy命令是不执行的。如果copy命令不执行，那么notify将不调用handler。- name: provide configuration file copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf #提供httpd的配置文件 notify: restart httpd #当前面的copy复制成功后，通过notify通知名字为restart httpd的handlers运行 3、构建httpd的handlers 123456[root@summer roles]# vim httpd/handlers/main.yml[root@summer roles]# cat httpd/handlers/main.yml- name: restart httpd service: name=httpd enabled=yes state=restarted 4、部署我们的MariaDB数据库 创建MySQL服务的任务，需要安装MySQL服务，改变属主信息，启动MySQL 1234567891011121314[root@summer roles]# cd /etc/ansible/lamp/roles/[root@summer roles]# vim mysql/tasks/main.yml[root@summer roles]# cat mysql/tasks/main.yml-name: install the mysqlyum: name=mariadb-server state=present #安装mysql服务- name: mkdir date directory shell: mkdir -p /mydata/data #创建挂载点目录- name: provide configration file copy: src=my.cnf dest=/etc/my.cnf #提供mysql的配置文件- name: chage the owner shell: chown -R mysql:mysql /mydata/ #更改属主和属组- name: start mariadb service: name=mariadb enabled=yes state=started #启动mysql服务 5、构建PHP的任务 12345[root@summer roles]# vim php/tasks/main.yml- name: install php yum: name=php state=present #安装php- name: install php-mysql yum: name=php-mysql state=present #安装php与mysql交互的插件 6、定义整个的任务 1234567891011[root@summer roles]# cd /etc/ansible/lamp/roles/[root@summer roles]# vim site.yml[root@summer roles]# cat site.yml- name: LAMP build remote_user: root hosts: web-servers roles: - prepare - mysql - php - httpd 注：所有yml的配置文件中，空格必须严格对 开始部署： 1[root@summer roles]# ansible-playbook -i /etc/ansible/hosts /etc/ansible/lamp/roles/site.yml 然后，在浏览器中访问这两台节点主机，可以直接访问成功. 总结：做此实验室，需要准备干净环境，selinux、防火墙都要关闭 实战二： 使用ansible部署k8s及集群安装git命令 1yum install git 使用git下载相应的ansible-k8s-insatall 包： 1git clone https://github.com/lizhenliang/ansible-install-k8s 进入到ansbile-install-k8s目录修改hosts文件，根据规划修改对应IP和名称。 123cd ansible-install-k8svim hostsvim group_vars/all.yml 部署命令： 单Master版 1ansible-playbook -i hosts single-master-deploy.yml -uroot -k 多master版 12ansible-playbook -i hosts multi-master-deploy.yml -uroot -k 参考文章 太厉害了，终于有人能把Ansible讲的明明白白了，建议收藏","link":"/2022/03/21/ansible/ansible-advanced-usage/"},{"title":"ansible_cmd","text":"参考文章","link":"/2022/03/21/ansible/ansible-cmd/"},{"title":"ansible_inventory","text":"主机清单inventory Inventory主机清单 ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名 默认的inventory file为/etc/ansible/hosts inventory file可以有多个，且也可以通过Dynamic inventory来动态生成 介绍在大规模的配置管理工作中我们需要管理不同业务的机器，这些机器的信息都存放在ansible的inventory组件里。在我们工作中配置部署针对的主机必须先存放在inventory里，这样才能使用ansible对它进行操作。默认ansible的inventory是一个静态的ini文件/etc/ansible/hosts。亦可通过ANSIBLE_HOSTS环境变量指定或者命令运行时用-i参数临时设置。 参考示例：定义主机和主机组123456781、100.0.0.1 ansible_ssh_pass='123456'2、100.0.0.2 ansible_ssh_pass='123456'3、[docker]4、100.0.0.1[1:3]5、[docker:vars]6、ansible_ssh_pass='123456'7、[ansible:children]8、docker 第一、二行定义一个主机，指定ssh登录密码第三行定义了一个叫docker的组第四行定义了docker组下面四个主机从100.0.0.11-100.0.0.13第五、六行定义了docker组的ssh登录密码第七、八行定义了ansible组，ansible组包含docker组 inventory内置参数参考官网http://docs.ansible.com/ansible/latest/intro_inventory.html 参考 解释 例子 ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置. ansible_ssh_host=192.169.1.123 ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置. ansible_ssh_port=5000 ansible_ssh_user 默认的 ssh 用户名 ansible_ssh_user=cxpadmin ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 –ask-pass 或 SSH 密钥) ansible_ssh_pass=’123456’ ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 –ask-sudo-pass) ansible_sudo_pass=’123456’ ansible_sudo_exe sudo 命令路径(适用于1.8及以上版本) ansible_sudo_exe=/usr/bin/sudo ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 ‘smart’,’smart’ 方式会根据是否支持 ControlPersist, 来判断’ssh’ 方式是否可行. ansible_connection=local ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况. ansible_ssh_private_key_file=/root/key ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 ‘sh’ 语法,可设置为 ‘csh’ 或 ‘fish’. ansible_shell_type=zsh ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是”/usr/bin/python”,比如 *BSD, 或者 /usr/bin/python ansible_python_interpreter=/usr/bin/python2.6 不是 2.X 版本的 Python.我们不使用 “/usr/bin/env” 机制,因为这要求远程用户的路径设置正确,且要求 “python” 可执行程序名不可为 python以外的名字(实际有可能名为python26). ansible_*_interpreter 定义其他语言解释器 ansible_*_interpreter=/usr/bin/ruby ansible_sudo 定义sudo用户 ansible_sudo=cxpadmin 注：从ansible2.0开始， ansible_ssh_user, ansible_ssh_host, ansible_ssh_port已经改变为ansible_user, ansible_host, ansible_port。 参考文章 ansible基本使用教程 Inventory 使用进阶 https://ansible-tran.readthedocs.io/en/latest/docs/intro_inventory.html","link":"/2022/03/21/ansible/ansible-inventory/"},{"title":"ansible ad-hoc命令","text":"我们经常会通过命令行的形式使用ansible模块，ansible自带很多模块，可以直接使用这些模块。目前ansible已经自带了200+个模块，我们可以使用ansible-doc -l显示所有自带模块，还可以使用ansible-doc 模块名，查看模块的介绍以及案例。需要注意的是，如果使用ad-hoc命令，ansible的一些插件功能就无法使用，比如loop facts功能等。命令用法：ansible &lt;host-pattern&gt; [options] ping模块ping模块的作用与其名相同，即判断远程主机的网络是否畅通示例：ansible cluster_hosts -m ping copy模块copy模块在ansible里的角色就是把ansible执行机器上的文件拷贝到远程节点上。与fetch模块相反的操作。常用模块参数 参数名 是否必须 默认值 选项 说明 src no 用于定位ansible执行的机器上的文件，需要绝对路径。如果拷贝的是文件夹，那么文件夹会整体拷贝，如果结尾是”/”,那么只有文件夹内的东西被考过去。一切的感觉很像rsync content no 用来替代src，用于将指定文件的内容，拷贝到远程文件内 dest yes 用于定位远程节点上的文件，需要绝对路径。如果src指向的是文件夹，这个参数也必须是指向文件夹 backup no no yes/no 备份远程节点上的原始文件，在拷贝之前。如果发生什么意外，原始文件还能使用。 directory_mode no 这个参数只能用于拷贝文件夹时候，这个设定后，文件夹内新建的文件会被拷贝。而老旧的不会被拷贝 follow no no yes/no 当拷贝的文件夹内有link存在的时候，那么拷贝过去的也会有link force no yes yes/no 默认为yes,会覆盖远程的内容不一样的文件（可能文件名一样）。如果是no，就不会拷贝文件，如果远程有这个文件 group no 设定一个群组拥有拷贝到远程节点的文件权限 mode no 等同于chmod，参数可以为“u+rwx or u=rw,g=r,o=r” owner no 设定一个用户拥有拷贝到远程节点的文件权限 示例：将文件copy到测试主机 1ansible testservers -m copy -a 'src=/root/install.log dest=/tmp/install.log owner=testuser group=testgroup' 示例：copy 前先备份 12echo &quot;test &quot; &gt;&gt; /root/install.logansible testservers -m copy -a 'src=/root/install.log dest=/tmp/install.log owner=testuser group=testgroup backup=yes' 1ansible testservers -m raw -a 'ls -lrth /tmp/install*' 示例：将目录copy过去 1234ansible testservers -m copy -a 'src=/etc/ansible/testdir dest=/tmp/ owner=testuser group=testgroup backup=yes'# 查看结果ansible testservers -m command -a 'tree /tmp/testdir' 注意：发现有文件的目录copy成功，空的目录没有copy过去 常用参数返回值 参数名 参数说明 返回值 返回值类型 样例 src 位于ansible执行机上的位置 changed string /home/httpd/.ansible/tmp/ansible-tmp-1423796390.97-147729857856000/source backup_file 将原文件备份 changed and if backup=yes string /path/to/file.txt.2015-02-12@22:09~ uid 在执行后，拥有者的ID success int 100 dest 远程节点的目标目录或文件 success string /path/to/file.txt checksum 拷贝文件后的checksum值 success string 6e642bb8dd5c2e027bf21dd923337cbb4214f827 md5sum 拷贝文件后的md5 checksum值 when supported string 2a5aeecc61dc98c4d780b14b330e3282 state 执行后的状态 success string file gid 执行后拥有文件夹、文件的群组ID success int 100 mode 执行后文件的权限 success string 644 owner 执行后文件所有者的名字 success string httpd group 执行后文件所有群组的名字 success string httpd size 执行后文件大小 success int 1220 shell模块它负责在被ansible控制的节点（服务器）执行命令行。shell 模块是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样。常用参数 参数 是否必须 默认值 选项 说明 chdir no 跟command一样的，运行shell之前cd到某个目录 creates no 跟command一样的，如果某个文件存在则不运行shell removes no 跟command一样的，如果某个文件不存在则不运行shell 示例1:让所有节点运行somescript.sh并把log输出到somelog.txt。ansible -i hosts all -m shell -a &quot;sh somescript.sh &gt;&gt; somelog.txt&quot;示例2:先进入somedir/ ，再在somedir/目录下让所有节点运行somescript.sh并把log输出到somelog.txt。ansible -i hosts all -m shell -a &quot;somescript.sh &gt;&gt; somelog.txt&quot; chdir=somedir/示例3:先cd到某个需要编译的目录，执行condifgure然后,编译，然后安装。ansible -i hosts all -m shell -a &quot;./configure &amp;&amp; make &amp;&amp; make insatll&quot; chdir=/xxx/yyy/ command模块command 模块用于运行系统命令。不支持管道符和变量等（”&lt;”, “&gt;”, “|”, and “&amp;”等），如果要使用这些，那么可以使用shell模块。在使用ansible中的时候，默认的模块是-m command，从而模块的参数不需要填写，直接使用即可。常用参数 参数 是否必须 默认值 选项 说明 chdir no 运行command命令前先cd到这个目录 creates no 如果这个参数对应的文件存在，就不运行command executable no 将shell切换为command执行，这里的所有命令需要使用绝对路径 removes no 如果这个参数对应的文件不存在，就不运行command 示例1：ansible 命令调用command: ansible -i hosts all -m command -a &quot;/sbin/shutdown -t now&quot;ansible命令行调用-m command模块 -a表示使用参数 “”内的为执行的command命令，该命令为关机。那么对应的节点(192.168.10.12,127.152.112.13)都会执行关机。示例2： Run the command if the specified file does not exist.ansible -i hosts all -m command -a &quot;/usr/bin/make_database.sh arg1 arg2 creates=/path/to/database&quot;利用creates参数，判断/path/to/database这个文件是否存在，存在就跳过command命令，不存在就执行command命令。 raw模块raw模块的功能与shell和command类似。但raw模块运行时不需要在远程主机上配置python环境。示例：在10.1.1.113节点上运行hostname命令ansible 10.1.1.113 -m raw-a 'hostname|tee' fetch模块文件拉取模块主要是将远程主机中的文件拷贝到本机中，和copy模块的作用刚刚相反，并且在保存的时候使用hostname来进行保存，当文件不存在的时候，会出现错误，除非设置了选项fail_on_missing为yes 常用参数 参考文章 ansible基本使用教程 ad-hoc 命令操作指引","link":"/2022/03/21/ansible/ansible-module/"},{"title":"ansible","text":"introref: https://docs.ansible.com/ansible/latest/index.html#Ansible is an IT automation tool. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates. Ansible conceptsref: https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html Control nodeAny machine with Ansible installed.You can run Ansible commands and playbooks by invoking the ansible or ansible-playbook command from any control node. You can use any computer that has a Python installation as a control node - laptops, shared desktops, and servers can all run Ansible.However, you cannot use a Windows machine as a control node. You can have multiple control nodes. Managed nodesThe network devices (and/or servers) you manage with Ansible. Managed nodes are also sometimes called “hosts”. Ansible is not installed on managed nodes. InventoryA list of managed nodes.An inventory file is also sometimes called a “hostfile”. Your inventory can specify information like IP address for each managed node. An inventory can also organize managed nodes, creating and nesting groups for easier scaling. To learn more about inventory, see the Working with Inventory section. example default : /etc/ansible/hosts12345678910mail.example.com[webservers]foo.example.combar.example.com[dbservers]one.example.comtwo.example.comthree.example.com yaml format:12345678910111213all: hosts: mail.example.com: children: webservers: hosts: foo.example.com: bar.example.com: dbservers: hosts: one.example.com: two.example.com: three.example.com: CollectionsCollections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. You can install and use collections through Ansible Galaxy. To learn more about collections, see Using collections. ModulesThe units of code Ansible executes. Each module has a particular use, from administering users on a specific type of database to managing VLAN interfaces on a specific type of network device. You can invoke a single module with a task, or invoke several different modules in a playbook. Starting in Ansible 2.10, modules are grouped in collections. For an idea of how many collections Ansible includes, take a look at the Collection Index. TasksThe units of action in Ansible. You can execute a single task once with an ad hoc command. PlaybooksOrdered lists of tasks, saved so you can run those tasks in that order repeatedly. Playbooks can include variables as well as tasks. Playbooks are written in YAML and are easy to read, write, share and understand. To learn more about playbooks, see Intro to playbooks. Install1. yum install on centos 12$ sudo yum install epel-release$ sudo yum install ansible 2. install and upgrade Ansible with pipConnecting to remote nodesref: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html#connecting-to-remote-nodes 1. connected by port, user, passwd123[root@ansible_master ansible]# grep -v ^# /etc/ansible/hosts |grep -v ^$[web-servers]192.168.171.136 ansible_ssh_port=22 ansible_ssh_user=root ansible_ssh_pass=summer test connecting:1234# before cmd: ping , install `sshpass `yum install sshpass -y# test connectingansible -i /etc/ansible/hosts web-servers -m ping 2. connected by ssh123456789101112# generate sshkey on `Control node`ssh-keygen# copy public key to `Managed node`ssh-copy-id root@192.168.171.136# login test ssh 192.168.1.163# test connectingansible -i /etc/ansible/hosts 'web-servers' -m ping# testansible -m command -a &quot;uptime&quot; 'web-servers' simple usageref: Ansible Getting started run shell on Managed node1ansible -i /etc/ansible/hosts web-servers -m shell -a &quot;source ~/.bash_profile &amp;&amp; df -h|head run script12345cat ~/test.sh#!/bin/bashdatehostnameecho &quot;hello world&quot; 1ansible -i /etc/ansible/hosts web-servers -m script -a &quot;~/test.sh&quot; copy file: from Control node to Managed node1234ansible -i /etc/ansible/hosts web-servers -m copy -a &quot;src=~/test.sh dest=/root owner=root group=root mode=0777&quot;# check if successansible -m command -a &quot;ls /root/&quot; 'remote' set file auth123ansible -i /etc/ansible/hosts web-servers -m file -a &quot;path=/root/test.sh mode=0755&quot;# check file authansible -m command -a &quot;ls -l /root&quot; 'remote' download source from given url12ansible -i /etc/ansible/hosts web-servers -m get_url -a &quot;url=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm dest=/tmp/ mode=0440 force=yes&quot; yum install1ansible -i /etc/ansible/hosts web-servers -m yum -a &quot;name=httpd state=latest&quot; restart httpd1ansible -i /etc/ansible/hosts web-servers -m service -a &quot;name=httpd state=restarted&quot; Action: Run your first playbookIn a directory of your choice you can create your first playbook in a file called mytask.yaml: 123456---- name: My playbook hosts: all tasks: - name: Leaving a mark command: &quot;touch /tmp/ansible_was_here&quot; You can run this command as follows: 1$ ansible-playbook mytask.yaml ansible-examples 参考文章","link":"/2022/03/22/ansible/ansible-intro-en/"},{"title":"ansible playbook","text":"参考文章 https://github.com/ceph/ceph-ansible https://github.com/ansible/ansible-examples Playbooks http://www.ansible.com.cn/docs/playbooks_intro.html https://cn-ansibledoc.readthedocs.io/zh_CN/latest/user_guide/playbooks.html","link":"/2022/03/21/ansible/ansible-playbook/"},{"title":"docker-compose redis cluster host","text":"docker compose 集群 network: host prepare install docker composeref: https://docs.docker.com/compose/install/ 集群搭建编写redis.conf12345cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6379 在/root/redis-cluster目录下创建redis-1,redis2,redis-3,redis-4,redis-5,redis-6文件夹123456789101112131415mkdir -p /root/apps/redis-cluster#然后将上一步的 redis.conf 放到 ~/docker/redis/r1 目录下cd /root/apps/redis-clustermkdir redis-1cd redis-1mkdir datavim redis.conf#然后复制6个 redis-1 文件夹cd /root/apps/redis-clustercp -r redis-1 redis-2cp -r redis-1 redis-3cp -r redis-1 redis-4cp -r redis-1 redis-5cp -r redis-1 redis-6 目录结构12345678910111213141516171819202122232425├── docker-compose.yaml├── redis-1│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-2│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-3│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-4│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-5│ ├── data│ │ └── nodes.conf│ └── redis.conf└── redis-6 ├── data │ └── nodes.conf └── redis.conf 在每个redis-*文件夹下创建redis.conf文件，并写入如下内容1234567891011121314151617181920212223242526272829303132333435echo 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6379 ' &gt; /root/apps/redis-cluster/redis-1/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6380 ' &gt; /root/apps/redis-cluster/redis-2/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6381 ' &gt; /root/apps/redis-cluster/redis-3/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6382 ' &gt; /root/apps/redis-cluster/redis-4/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6383 ' &gt; /root/apps/redis-cluster/redis-5/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6384 ' &gt; /root/apps/redis-cluster/redis-6/redis.conf 编写docker-compose.yml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263version: '3.1'services: # redis1配置 redis1: image: daocloud.io/library/redis:6.0.4 container_name: redis-1 restart: always network_mode: &quot;host&quot; volumes: - ./redis-1/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-1/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis2配置 redis2: image: daocloud.io/library/redis:6.0.4 container_name: redis-2 restart: always network_mode: &quot;host&quot; volumes: - ./redis-2/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-2/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis3配置 redis3: image: daocloud.io/library/redis:6.0.4 container_name: redis-3 restart: always network_mode: &quot;host&quot; volumes: - ./redis-3/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-3/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis4配置 redis4: image: daocloud.io/library/redis:6.0.4 container_name: redis-4 restart: always network_mode: &quot;host&quot; volumes: - ./redis-4/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-4/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis5配置 redis5: image: daocloud.io/library/redis:6.0.4 container_name: redis-5 restart: always network_mode: &quot;host&quot; volumes: - ./redis-5/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-5/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis6配置 redis6: image: daocloud.io/library/redis:6.0.4 container_name: redis-6 restart: always network_mode: &quot;host&quot; volumes: - ./redis-6/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] 启动容器1234systemctl start dockerdocker-compose up -d 查看容器启动状态1docker ps 开启集群随便找一个容器进入，这里我选择redis-1进入。 12docker exec -it redis-1 bash 在进入容器后，输入如下命令开启集群 1234567891011121314151617redis-cli --cluster create 192.168.171.136:6379 \\192.168.171.136:6380 \\192.168.171.136:6381 \\192.168.171.136:6382 \\192.168.171.136:6383 \\192.168.171.136:6384 \\--cluster-replicas 1# 集群信息查看redis-cli --cluster info 192.168.171.136:6379redis-cli -h redis-1cluster-nodes redis-cli –cluster cmd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 1 创建集群主节点redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381# 2 创建集群主从节点redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381 192.168.163.132:6382 192.168.163.132:6383 192.168.163.132:6384 --cluster-replicas 1redis-cli --cluster create 172.21.0.2:6379 172.21.0.3:6379 172.21.0.4:6379 --cluster-replicas 2# 说明：--cluster-replicas 参数为数字，1表示每个主节点需要1个从节点。# 通过该方式创建的带有从节点的机器不能够自己手动指定主节点，所以如果需要指定的话，需要自己手动指定，先使用①或③创建好主节点后，再通过④来处理。# 3 添加集群主节点redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379 #说明：为一个指定集群添加节点，需要先连到该集群的任意一个节点IP（192.168.163.132:6379），再把新节点加入。该2个参数的顺序有要求：新加入的节点放前# 4 添加集群从节点redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379 --cluster-slave --cluster-master-id 117457eab5071954faab5e81c3170600d5192270#说明：把6382节点加入到6379节点的集群中，并且当做node_id为 117457eab5071954faab5e81c3170600d5192270 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。# 说明：把6380节点加入到6379节点的集群中，并且当做node_id为 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli --cluster add-node 192.168.171.136:6380 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 192.168.171.136:6381 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 172.21.0.3:6379 172.21.0.2:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7#说明：把 172.21.0.3:6379 节点加入到 172.21.0.2:6379 节点的集群中，并且当做node_id为 117457eab5071954faab5e81c3170600d5192270 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli -h redis-master# 5 删除节点redis-cli --cluster del-node 192.168.163.132:6384 f6a6957421b80409106cb36be3c7ba41f3b603ff# 说明：指定IP、端口和node_id 来删除一个节点，从节点可以直接删除，有slot分配的主节点不能直接删除。删除之后，该节点会被shutdown。# 检查集群redis-cli --cluster check 192.168.171.136:6371 --cluster-search-multiple-owners# 修复集群redis-cli --cluster fix 192.168.171.136:6371 --cluster-search-multiple-owners# 说明：检查key、slots、从节点个数的分配情况# 集群信息查看redis-cli --cluster info 192.168.171.136:6379 # 说明：把6380节点加入到6379节点的集群中，并且当做node_id为 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli --cluster add-node 192.168.171.136:6380 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 192.168.171.136:6381 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 参考文章 Redis 5.0 redis-cli –cluster help说明 基于docker-compose搭建redis集群","link":"/2022/03/24/docker/docker-compose-redis-cluster-host/"},{"title":"docker-compose-redis","text":"docker compose 部署主从复制，哨兵，集群 prepare install docker composeref: https://docs.docker.com/compose/install/ docker compose 部署主从复制12cd ~/apps/master-slavemkdir -p redis-master/data redis-slave-1/data redis-slave-2/data 1234567891011121314151617181920212223242526272829303132333435version: '3'services: master: image: redis container_name: redis-master privileged: true restart: always command: redis-server --cluster-enabled yes --cluster-announce-ip 192.168.171.134 volumes: - ./redis-master/data:/data ports: - 6379:6379 slave1: image: redis container_name: redis-slave-1 privileged: true restart: always command: redis-server --slaveof redis-master 6379 --cluster-announce-ip 192.168.171.134 volumes: - ./redis-slave-1/data:/data ports: - 6380:6379 slave2: image: redis container_name: redis-slave-2 privileged: true restart: always command: redis-server --slaveof redis-master 6379 --cluster-announce-ip 192.168.171.134 volumes: - ./redis-slave-2/data:/data ports: - 6381:6379 启动命令12345678910111213141516171819202122systemctl start dockerdocker-compose up -ddocker exec -it redis-master /bin/bash## fix slots coverageredis-cli --cluster fix 192.168.171.134:6379redis-cli -h redis-mastercluster nodes# 检查集群redis-cli --cluster check 192.168.171.134:6379 --cluster-search-multiple-owners# 修复集群redis-cli --cluster fix 192.168.171.134:6379 --cluster-search-multiple-owners# 说明：检查key、slots、从节点个数的分配情况# 集群信息查看redis-cli --cluster info 192.168.171.134:6379 安装常见问题ps命令在docker容器不存在1apt-get update &amp;&amp; apt-get install procps -y 容器 下查看redis的安装目录的方法是什么1ps -ef|grep redis 得到了进程号 xxxx，然后 ls -l /proc/xxxx/cwd Redis集群Hash槽分配异常 CLUSTERDOWN Hash slot not served的解决方式12redis-cli --cluster check 192.168.171.134:6379redis-cli --cluster fix 192.168.171.134:6379 1redis-cli -c -h 192.168.171.134 1redis-cli -h host -p port -a password 参考文章 docker compose 部署主从复制 5 分钟实现用 docker 搭建 Redis 集群模式和哨兵模式","link":"/2022/03/24/docker/docker-compose-redis/"},{"title":"docker-compose redis cluster bridge","text":"docker compose 集群 network: bridge 建议使用 network: host.由于 Redis 集群不支持网络转发，因此 Docker 搭建 Redis 集群需要注意网络的设置。搭建一个子网是没问题的，集群可以跑起来可以用，但是宿主机是无法使用集群的，只能在子网内部使用 prepare install docker composeref: https://docs.docker.com/compose/install/ 集群搭建由于 Redis 集群不支持网络转发，因此 Docker 搭建 Redis 集群需要注意网络的设置。搭建一个子网是没问题的，集群可以跑起来可以用，但是宿主机是无法使用集群的，只能在子网内部使用，如： 123456789101112131415161718# 先到 6380 映射的机器上创建 “hello”zohar@ZOHAR-LAPTOP:~$ redis-cli -c -p 6380127.0.0.1:6380&gt; pingPONG127.0.0.1:6380&gt; set hello worldOK127.0.0.1:6380&gt; exit# 再到 6381 映射的机器上取 “hello”zohar@ZOHAR-LAPTOP:~$ redis-cli -c -p 6381127.0.0.1:6381&gt; pingPONG127.0.0.1:6381&gt; get hello-&gt; Redirected to slot [866] located at 172.26.0.101:6379&gt;# 客户端卡住了 由于 hello 这个 key 已经在 6380 上被写入了，我们切到 6381 机器上查询的时候，6381 会让我们的客户的自动跳转到存储该 key 的节点上。但是因为我们定义的是内网的集群，所以跳转用的是内网的 IP 与地址，外网无法连接，所以客户端就无法使用了。所以创建 Docker 创建 Redis 集群直接使用宿主机网络最好，即使用 “host” 模式。由于基于 WSL2 的 Docker Host 模式存在问题，因此基于 Host 模式的我直接在 Debian 真机上操作，基于 Bridge 模式的我使用 WSL2 操作。 prepare12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485cd /root/apps/bridge-cluster# 删除node1 ~ node6/data 下的文件rm -rf node{1,2,3,4,5,6}/data/*## initrm -rf node*lsmkdir node1cd node1mkdir datatouch redis.conf#然后复制cd /root/apps/bridge-clustercp -r node1 node2cp -r node1 node3cp -r node1 node4cp -r node1 node5cp -r node1 node6echo 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node1/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node2/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node3/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node4/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node5/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node6/redis.conf 目录结构12345678910111213141516171819├── docker-compose.yaml├── node1│ ├── data│ └── redis.conf├── node2│ ├── data│ └── redis.conf├── node3│ ├── data│ └── redis.conf├── node4│ ├── data│ └── redis.conf├── node5│ ├── data│ └── redis.conf└── node6 ├── data └── redis.conf docker-compose.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394version: &quot;3&quot;networks: redis-cluster: driver: bridge ipam: driver: default config: - subnet: 172.26.0.0/24services: node1: image: redis container_name: redis-cluster-node-1 ports: - &quot;6371:6379&quot; volumes: - &quot;./node1/redis.conf:/etc/redis.conf&quot; - &quot;./node1/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.101 node2: image: redis container_name: redis-cluster-node-2 ports: - &quot;6372:6379&quot; volumes: - &quot;./node2/redis.conf:/etc/redis.conf&quot; - &quot;./node2/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.102 node3: image: redis container_name: redis-cluster-node-3 ports: - &quot;6373:6379&quot; volumes: - &quot;./node3/redis.conf:/etc/redis.conf&quot; - &quot;./node3/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.103 node4: image: redis container_name: redis-cluster-node-4 ports: - &quot;6374:6379&quot; volumes: - &quot;./node4/redis.conf:/etc/redis.conf&quot; - &quot;./node4/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.104 node5: image: redis container_name: redis-cluster-node-5 ports: - &quot;6375:6379&quot; volumes: - &quot;./node5/redis.conf:/etc/redis.conf&quot; - &quot;./node5/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.105 node6: image: redis container_name: redis-cluster-node-6 ports: - &quot;6376:6379&quot; volumes: - &quot;./node6/redis.conf:/etc/redis.conf&quot; - &quot;./node6/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.106 启动集群：1docker-compose up -d 进入实例内部启动集群：12345678910111213141516docker-compose up -ddocker exec -it redis-cluster-node-1 /bin/bashredis-cli --cluster create 172.26.0.101:6379 172.26.0.102:6379 172.26.0.103:6379 172.26.0.104:6379 172.26.0.105:6379 172.26.0.106:6379 --cluster-replicas 1 redis-cli --cluster create \\192.168.171.136:6371 \\192.168.171.136:6372 \\192.168.171.136:6373 \\192.168.171.136:6374 \\192.168.171.136:6375 \\192.168.171.136:6376 \\--cluster-replicas 1 查询节点信息：123redis-cli -ccluster nodes ps命令在docker容器不存在12345678apt-get update &amp;&amp; apt-get install procps -y apt install net-tools apt-get install iputils-ping -y apt-get install openbsd-inetd -y#安装 openbsd-inetd，如果已经安装过了，直接执行下面的步骤。apt-get install telnetd -y#安装 telnetd 验证集群 容器内网： 12345127.0.0.1:6379&gt; set hello worldOK127.0.0.1:6379&gt; set test redsi-&gt; Redirected to slot [6918] located at 172.26.0.102:6379OK 宿主机：1234567redis-cli -c -p 6371127.0.0.1:6371&gt; get hello&quot;world&quot;127.0.0.1:6371&gt; get test-&gt; Redirected to slot [6918] located at 172.26.0.102:6379# 卡住 无法进行服务切换。 参考文章 docker-compose部署Redis-Cluster集群 【Redis】docker compose 部署集群模式 docker-compose编排redis集群","link":"/2022/03/24/docker/docker-compose-redis-cluster-bridge/"},{"title":"docker-compose kafka","text":"docker compose kafka集群 首先通过 docker network create zookeeper_network 命令创建一个名为zookeeper_network的 Docker 网络。zookeeper 集群1234cd ~/apps/zookeepermkdir -p zoo1/data zoo1/datalogmkdir -p zoo2/data zoo2/datalogmkdir -p zoo3/data zoo3/datalog 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: '3.1'networks: default: external: name: zookeeper_networkservices: zoo1: image: zookeeper restart: always container_name: zoo1 hostname: zoo1 ports: - 2181:2181 volumes: - &quot;./zoo1/data:/data&quot; - &quot;./zoo1/datalog:/datalog&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always container_name: zoo2 hostname: zoo2 ports: - 2182:2181 volumes: - &quot;./zoo2/data:/data&quot; - &quot;./zoo2/datalog:/datalog&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always container_name: zoo3 hostname: zoo3 ports: - 2183:2181 volumes: - &quot;./zoo3/data:/data&quot; - &quot;./zoo3/datalog:/datalog&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 kafka1234cd ~/apps/kafkamkdir -p kafka1/datamkdir -p kafka2/datamkdir -p kafka3/data 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990version: '3.1'networks: default: external: name: zookeeper_networkservices: kafka1: image: wurstmeister/kafka restart: unless-stopped container_name: kafka1 hostname: kafka1 ports: - &quot;9092:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9092 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka1/data/:/kafka&quot; kafka2: image: wurstmeister/kafka restart: unless-stopped container_name: kafka2 hostname: kafka2 ports: - &quot;9093:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 2 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9093 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka2/data/:/kafka&quot; kafka3: image: wurstmeister/kafka restart: unless-stopped container_name: kafka3 hostname: kafka3 ports: - &quot;9094:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 3 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9094 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka3/data/:/kafka&quot; kafka-manager: # Kafka 图形管理界面 image: sheepkiller/kafka-manager:latest restart: unless-stopped container_name: kafka-manager hostname: kafka-manager ports: - &quot;9000:9000&quot; links: # 连接本compose文件创建的container - kafka1 - kafka2 - kafka3 external_links: # 连接外部compose文件创建的container - zoo1 - zoo2 - zoo3 environment: ZK_HOSTS: zoo1:2181,zoo2:2181,zoo3:2181 KAFKA_BROKERS: kafka1:9092,kafka2:9093,kafka3:9094 Ref docker-compose 搭建 kafka 集群 docker-compose安装Kafka集群","link":"/2022/03/24/docker/docker-compose-kafka/"},{"title":"docker-compose kafka cluster 升级版","text":"docker compose kafka集群 123456789101112mkdir ~/apps/kafka-cluster/zoomkdir ~/apps/kafka-cluster/kafkacd ~/apps/kafka-cluster/zoomkdir -p zoo1/data zoo1/datalogmkdir -p zoo2/data zoo2/datalogmkdir -p zoo3/data zoo3/datalogcd ~/apps/kafka-cluster/kafkamkdir -p kafka1/datamkdir -p kafka2/datamkdir -p kafka3/data 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141version: '3.1'networks: zookeeper_network: driver: bridge services: zoo1: image: zookeeper restart: always container_name: zoo1 hostname: zoo1 ports: - 2181:2181 volumes: - &quot;./zoo1/data:/data&quot; - &quot;./zoo1/datalog:/datalog&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always container_name: zoo2 hostname: zoo2 ports: - 2182:2181 volumes: - &quot;./zoo2/data:/data&quot; - &quot;./zoo2/datalog:/datalog&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always container_name: zoo3 hostname: zoo3 ports: - 2183:2181 volumes: - &quot;./zoo3/data:/data&quot; - &quot;./zoo3/datalog:/datalog&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 kafka1: image: wurstmeister/kafka restart: unless-stopped container_name: kafka1 hostname: kafka1 ports: - &quot;9092:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9092 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka1/data/:/kafka&quot; depends_on: - zoo1 - zoo2 - zoo3 kafka2: image: wurstmeister/kafka restart: unless-stopped container_name: kafka2 hostname: kafka2 ports: - &quot;9093:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 2 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9093 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka2/data/:/kafka&quot; depends_on: - zoo1 - zoo2 - zoo3 kafka3: image: wurstmeister/kafka restart: unless-stopped container_name: kafka3 hostname: kafka3 ports: - &quot;9094:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 3 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9094 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka3/data/:/kafka&quot; kafka-manager: # Kafka 图形管理界面 image: sheepkiller/kafka-manager:latest restart: unless-stopped container_name: kafka-manager hostname: kafka-manager ports: - &quot;9000:9000&quot; links: # 连接本compose文件创建的container - kafka1 - kafka2 - kafka3 - zoo1 - zoo2 - zoo3 environment: ZK_HOSTS: zoo1:2181,zoo2:2181,zoo3:2181 KAFKA_BROKERS: kafka1:9092,kafka2:9093,kafka3:9094 depends_on: - zoo1 - zoo2 - zoo3 Ref docker-compose 搭建 kafka 集群 docker-compose安装Kafka集群 docker-compose安装Kafka集群","link":"/2022/03/24/docker/docker-compose-kafka_2/"}],"tags":[{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"树","slug":"树","link":"/tags/%E6%A0%91/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"centos","slug":"centos","link":"/tags/centos/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"jdk","slug":"jdk","link":"/tags/jdk/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"拦截&#x2F;抓包工具","slug":"拦截-抓包工具","link":"/tags/%E6%8B%A6%E6%88%AA-%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"flink","slug":"flink","link":"/tags/flink/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"gc","slug":"gc","link":"/tags/gc/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"quarkus","slug":"quarkus","link":"/tags/quarkus/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"reactive","slug":"reactive","link":"/tags/reactive/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"study","slug":"study","link":"/tags/study/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"wsl","slug":"wsl","link":"/tags/wsl/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"java锁","slug":"java锁","link":"/tags/java%E9%94%81/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"filebeat","slug":"filebeat","link":"/tags/filebeat/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"logstash","slug":"logstash","link":"/tags/logstash/"},{"name":"kibana","slug":"kibana","link":"/tags/kibana/"},{"name":"ansible","slug":"ansible","link":"/tags/ansible/"}],"categories":[{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"动态规划","slug":"动态规划","link":"/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"树","slug":"树","link":"/categories/%E6%A0%91/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"centos","slug":"centos","link":"/categories/centos/"},{"name":"链表","slug":"链表","link":"/categories/%E9%93%BE%E8%A1%A8/"},{"name":"jdk","slug":"jdk","link":"/categories/jdk/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"nginx","slug":"nginx","link":"/categories/nginx/"},{"name":"拦截&#x2F;抓包工具","slug":"拦截-抓包工具","link":"/categories/%E6%8B%A6%E6%88%AA-%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"name":"kubernetes","slug":"kubernetes","link":"/categories/kubernetes/"},{"name":"flink","slug":"flink","link":"/categories/flink/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"gc","slug":"gc","link":"/categories/gc/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"quarkus","slug":"quarkus","link":"/categories/quarkus/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"kafka","slug":"kafka","link":"/categories/kafka/"},{"name":"js","slug":"js","link":"/categories/js/"},{"name":"netty","slug":"netty","link":"/categories/netty/"},{"name":"network","slug":"network","link":"/categories/network/"},{"name":"opencv","slug":"opencv","link":"/categories/opencv/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"study","slug":"study","link":"/categories/study/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"reactive","slug":"reactive","link":"/categories/reactive/"},{"name":"wsl","slug":"wsl","link":"/categories/wsl/"},{"name":"tomcat","slug":"tomcat","link":"/categories/tomcat/"},{"name":"zookeeper","slug":"zookeeper","link":"/categories/zookeeper/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"},{"name":"mq","slug":"mq","link":"/categories/mq/"},{"name":"filebeat","slug":"filebeat","link":"/categories/filebeat/"},{"name":"dubbo","slug":"dubbo","link":"/categories/dubbo/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/categories/elasticsearch/"},{"name":"logstash","slug":"logstash","link":"/categories/logstash/"},{"name":"kibana","slug":"kibana","link":"/categories/kibana/"},{"name":"ansible","slug":"ansible","link":"/categories/ansible/"}]}