{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"about","text":"AboutE-mail: 469608976@qq.com","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"图 DFS","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import java.util.Stack;public class Graph { class Vertex{ //顶点 public char lebel; public boolean visited; public Vertex(char lab){ lebel = lab; visited = false; } } private final int maxVertices = 20 ; //最大顶点数 private Vertex vertexList[]; private int adjMatrix[][]; private int vertexCount; private Stack theStack; public Graph(){ vertexList = new Vertex[maxVertices]; adjMatrix = new int[maxVertices][maxVertices]; vertexCount = 0; for(int y = 0 ; y &lt; maxVertices ; y++){ for(int x = 0 ; x &lt; maxVertices ; x ++){ adjMatrix[x][y] = 0; } } theStack = new Stack(); } public void addVertex(char lab){ vertexList[vertexCount++]=new Vertex(lab); } public void addEdge(int start,int end){ adjMatrix[start][end] = 1; adjMatrix[end][start] = 1; } public void displayVertex(int v){ System.out.println(vertexList[v].lebel); } public void dfs(){ vertexList[0].visited = true; displayVertex(0); theStack.push(0); while (!theStack.isEmpty()){ int v = getAdjUnvisitedVertes((int)theStack.peek()); if(v == -1){ theStack.pop(); }else { vertexList[v].visited = true; displayVertex(v); theStack.push(v); } } for(int j = 0 ; j &lt; vertexCount; j++){ vertexList[j].visited = false; } } public int getAdjUnvisitedVertes(int v){ for(int j = 0 ; j &lt; vertexCount ; j ++){ if(adjMatrix[v][j] == 1 &amp;&amp; vertexList[j].visited == false){ return j; } } return -1; } public static void main(String[] args) { int col = 9 ; int[][] a = new int[col][col]; a[0][1] = 1;a[0][5] = 1;a[1][2] = 1;a[1][6]= 1;a[1][8]= 1; a[2][3] = 1; a[2][8] = 1; a[3][8] =1; a[3][6]= 1; a[3][7] = 1;a[3][4] = 1; a[4][5] =1; a[4][7]= 1; a[5][6] = 1;a[6][7] = 1; Graph graph = new Graph(); graph.addVertex('A'); graph.addVertex('B'); graph.addVertex('C'); graph.addVertex('D'); graph.addVertex('E'); graph.addVertex('F'); graph.addVertex('G'); graph.addVertex('H'); graph.addVertex('I'); for(int y = 0 ; y &lt; col; y ++){ for(int x = 0 ; x &lt; col ; x ++ ){ if(a[y][x] == 1){ graph.addEdge(y,x); } } } graph.dfs(); }}","link":"/2021/10/25/algorithm/graph-dfs/"},{"title":"cubrid","text":"参考文章 https://www.cubrid.org/cubrid","link":"/2021/12/28/cubrid/cubrid/"},{"title":"docker-compose kafka","text":"docker compose kafka集群 首先通过 docker network create zookeeper_network 命令创建一个名为zookeeper_network的 Docker 网络。zookeeper 集群12345cd ~/apps/zookeepermkdir -p zoo1/data zoo1/datalogmkdir -p zoo2/data zoo2/datalogmkdir -p zoo3/data zoo3/datalog 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: '3.1'networks: default: external: name: zookeeper_networkservices: zoo1: image: zookeeper restart: always container_name: zoo1 hostname: zoo1 ports: - 2181:2181 volumes: - &quot;./zoo1/data:/data&quot; - &quot;./zoo1/datalog:/datalog&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always container_name: zoo2 hostname: zoo2 ports: - 2182:2181 volumes: - &quot;./zoo2/data:/data&quot; - &quot;./zoo2/datalog:/datalog&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always container_name: zoo3 hostname: zoo3 ports: - 2183:2181 volumes: - &quot;./zoo3/data:/data&quot; - &quot;./zoo3/datalog:/datalog&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 kafka1234cd ~/apps/kafkamkdir -p kafka1/datamkdir -p kafka2/datamkdir -p kafka3/data 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990version: '3.1'networks: default: external: name: zookeeper_networkservices: kafka1: image: wurstmeister/kafka restart: unless-stopped container_name: kafka1 hostname: kafka1 ports: - &quot;9092:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9092 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka1/data/:/kafka&quot; kafka2: image: wurstmeister/kafka restart: unless-stopped container_name: kafka2 hostname: kafka2 ports: - &quot;9093:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 2 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9093 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka2/data/:/kafka&quot; kafka3: image: wurstmeister/kafka restart: unless-stopped container_name: kafka3 hostname: kafka3 ports: - &quot;9094:9092&quot; external_links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 3 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.130.129:9094 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka3/data/:/kafka&quot; kafka-manager: # Kafka 图形管理界面 image: sheepkiller/kafka-manager:latest restart: unless-stopped container_name: kafka-manager hostname: kafka-manager ports: - &quot;9000:9000&quot; links: # 连接本compose文件创建的container - kafka1 - kafka2 - kafka3 external_links: # 连接外部compose文件创建的container - zoo1 - zoo2 - zoo3 environment: ZK_HOSTS: zoo1:2181,zoo2:2181,zoo3:2181 KAFKA_BROKERS: kafka1:9092,kafka2:9093,kafka3:9094 Ref docker-compose 搭建 kafka 集群 docker-compose安装Kafka集群","link":"/2022/03/24/docker/docker-compose-kafka/"},{"title":"docker_cmd","text":"docker 基本命令1234567891011121314# -a :提交的镜像作者；# -c :使用Dockerfile指令来创建镜像；# -m :提交时的说明文字；# -p :在commit时，将容器暂停。docker commit -a &quot;author&quot; -m &quot;commit msg&quot; {commitId} {name}:{tag}#docker commit -a &quot;author&quot; -m &quot;commit msg&quot; {commitId} author/myubuntu:v1docker logindocker push author/myubuntu:v1docker tag {imageId} {name}:{tag}docker run --name nginx-text -p 9090:90 -d nginx create network1docker network create --subnet 172.72.72.0/24 redisnet 设置docker开机启动1systemctl enable docker 容器使用启动容器以下命令使用 ubuntu 镜像启动一个容器，参数为以命令行模式进入该容器： 1$ docker run -it ubuntu /bin/bash 参数说明： -i: 交互式操作。 -t: 终端。 ubuntu: ubuntu 镜像。 /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。要退出终端，直接输入 exit:1root@ed09e4490c57:/# exit 启动已停止运行的容器查看所有的容器命令如下： 12$ docker ps -a 使用 docker start 启动一个已停止的容器： 1$ docker start b750bbbcfd88 后台运行在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 -d 指定容器的运行模式。 1$ docker run -itd --name ubuntu-test ubuntu /bin/bash 注：加了 -d 参数默认不会进入容器，想要进入容器需要使用指令 docker exec（下面会介绍到）。 停止一个容器停止容器的命令如下： 1$ docker stop &lt;容器 ID&gt; 停止的容器可以通过 docker restart 重启：$ docker restart &lt;容器 ID&gt; 进入容器 exec 命令1docker exec -it 243c32535da7 /bin/bash # container id or name ###导出和导入容器 导出容器 如果要导出本地某个容器，可以使用 docker export 命令。 1$ docker export 1e560fca3906 &gt; ubuntu.tar 导入容器快照 可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test/ubuntu:v1: 1$ cat docker/ubuntu.tar | docker import - test/ubuntu:v1 此外，也可以通过指定 URL 或者某个目录来导入，例如： 1$ docker import http://example.com/exampleimage.tgz example/imagerepo 删除容器删除容器使用 docker rm 命令： 1234$ docker rm -f 1e560fca3906# delete all containers docker rm -vf $(docker ps -aq) 删除 image1234docker rmi {imagename or imageId}# delete all the imagesdocker rmi -f $(docker images -aq) docker Dockerfile build and run12docker build --tag=spring-metrics .docker run -p8887:8888 message-server:latest 常见问题ps命令在docker容器不存在1apt-get update &amp;&amp; apt-get install procps -y 容器 下查看redis的安装目录的方法是什么1ps -ef|grep redis 得到了进程号 xxxx，然后 ls -l /proc/xxxx/cwd Redis集群Hash槽分配异常 CLUSTERDOWN Hash slot not served的解决方式12redis-cli --cluster check 192.168.171.134:6379redis-cli --cluster fix 192.168.171.134:6379 1redis-cli -c -h 192.168.171.134 ref Docker 容器使用","link":"/2021/09/27/docker/docker-cmd/"},{"title":"docker-compose kafka cluster 升级版","text":"docker compose kafka集群 123mkdir ~/apps/kafka-cluster 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140version: '3.1' services: zoo1: image: zookeeper restart: always container_name: zoo1 hostname: zoo1 ports: - 2181:2181 volumes: - &quot;./zoo1/data:/data&quot; - &quot;./zoo1/datalog:/datalog&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always container_name: zoo2 hostname: zoo2 ports: - 2182:2181 volumes: - &quot;./zoo2/data:/data&quot; - &quot;./zoo2/datalog:/datalog&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always container_name: zoo3 hostname: zoo3 ports: - 2183:2181 volumes: - &quot;./zoo3/data:/data&quot; - &quot;./zoo3/datalog:/datalog&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 kafka1: image: wurstmeister/kafka restart: unless-stopped container_name: kafka1 hostname: kafka1 ports: - &quot;9092:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9092 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka1/data/:/kafka&quot; depends_on: - zoo1 - zoo2 - zoo3 kafka2: image: wurstmeister/kafka restart: unless-stopped container_name: kafka2 hostname: kafka2 ports: - &quot;9093:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 2 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9093 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka2/data/:/kafka&quot; depends_on: - zoo1 - zoo2 - zoo3 kafka3: image: wurstmeister/kafka restart: unless-stopped container_name: kafka3 hostname: kafka3 ports: - &quot;9094:9092&quot; links: - zoo1 - zoo2 - zoo3 environment: KAFKA_BROKER_ID: 3 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.171.136:9094 ## 宿主机IP KAFKA_ADVERTISED_HOST_NAME: kafka3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: &quot;zoo1:2181,zoo2:2181,zoo3:2181&quot; volumes: - &quot;./kafka3/data/:/kafka&quot; kafka-manager: # Kafka 图形管理界面 image: sheepkiller/kafka-manager:latest restart: unless-stopped container_name: kafka-manager hostname: kafka-manager ports: - &quot;9000:9000&quot; links: # 连接本compose文件创建的container - kafka1 - kafka2 - kafka3 - zoo1 - zoo2 - zoo3 environment: ZK_HOSTS: zoo1:2181,zoo2:2181,zoo3:2181 KAFKA_BROKERS: kafka1:9092,kafka2:9093,kafka3:9094 depends_on: - kafka1 - kafka2 - kafka3 - zoo1 - zoo2 - zoo3 1docker exec -it kafka1 /bin/bash Ref docker-compose 搭建 kafka 集群 docker-compose安装Kafka集群 docker-compose安装Kafka集群","link":"/2022/03/24/docker/docker-compose-kafka_2/"},{"title":"docker-compose redis cluster bridge","text":"docker compose 集群 network: bridge 建议使用 network: host.由于 Redis 集群不支持网络转发，因此 Docker 搭建 Redis 集群需要注意网络的设置。搭建一个子网是没问题的，集群可以跑起来可以用，但是宿主机是无法使用集群的，只能在子网内部使用 prepare install docker composeref: https://docs.docker.com/compose/install/ 集群搭建由于 Redis 集群不支持网络转发，因此 Docker 搭建 Redis 集群需要注意网络的设置。搭建一个子网是没问题的，集群可以跑起来可以用，但是宿主机是无法使用集群的，只能在子网内部使用，如： 123456789101112131415161718# 先到 6380 映射的机器上创建 “hello”zohar@ZOHAR-LAPTOP:~$ redis-cli -c -p 6380127.0.0.1:6380&gt; pingPONG127.0.0.1:6380&gt; set hello worldOK127.0.0.1:6380&gt; exit# 再到 6381 映射的机器上取 “hello”zohar@ZOHAR-LAPTOP:~$ redis-cli -c -p 6381127.0.0.1:6381&gt; pingPONG127.0.0.1:6381&gt; get hello-&gt; Redirected to slot [866] located at 172.26.0.101:6379&gt;# 客户端卡住了 由于 hello 这个 key 已经在 6380 上被写入了，我们切到 6381 机器上查询的时候，6381 会让我们的客户的自动跳转到存储该 key 的节点上。但是因为我们定义的是内网的集群，所以跳转用的是内网的 IP 与地址，外网无法连接，所以客户端就无法使用了。所以创建 Docker 创建 Redis 集群直接使用宿主机网络最好，即使用 “host” 模式。由于基于 WSL2 的 Docker Host 模式存在问题，因此基于 Host 模式的我直接在 Debian 真机上操作，基于 Bridge 模式的我使用 WSL2 操作。 prepare12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485cd /root/apps/bridge-cluster# 删除node1 ~ node6/data 下的文件rm -rf node{1,2,3,4,5,6}/data/*## initrm -rf node*lsmkdir node1cd node1mkdir datatouch redis.conf#然后复制cd /root/apps/bridge-clustercp -r node1 node2cp -r node1 node3cp -r node1 node4cp -r node1 node5cp -r node1 node6echo 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node1/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node2/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node3/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node4/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node5/redis.confecho 'port 6379protected-mode nodaemonize no##########cluster###########cluster-enabled yescluster-node-timeout 15000' &gt; /root/apps/bridge-cluster/node6/redis.conf 目录结构12345678910111213141516171819├── docker-compose.yaml├── node1│ ├── data│ └── redis.conf├── node2│ ├── data│ └── redis.conf├── node3│ ├── data│ └── redis.conf├── node4│ ├── data│ └── redis.conf├── node5│ ├── data│ └── redis.conf└── node6 ├── data └── redis.conf docker-compose.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394version: &quot;3&quot;networks: redis-cluster: driver: bridge ipam: driver: default config: - subnet: 172.26.0.0/24services: node1: image: redis container_name: redis-cluster-node-1 ports: - &quot;6371:6379&quot; volumes: - &quot;./node1/redis.conf:/etc/redis.conf&quot; - &quot;./node1/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.101 node2: image: redis container_name: redis-cluster-node-2 ports: - &quot;6372:6379&quot; volumes: - &quot;./node2/redis.conf:/etc/redis.conf&quot; - &quot;./node2/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.102 node3: image: redis container_name: redis-cluster-node-3 ports: - &quot;6373:6379&quot; volumes: - &quot;./node3/redis.conf:/etc/redis.conf&quot; - &quot;./node3/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.103 node4: image: redis container_name: redis-cluster-node-4 ports: - &quot;6374:6379&quot; volumes: - &quot;./node4/redis.conf:/etc/redis.conf&quot; - &quot;./node4/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.104 node5: image: redis container_name: redis-cluster-node-5 ports: - &quot;6375:6379&quot; volumes: - &quot;./node5/redis.conf:/etc/redis.conf&quot; - &quot;./node5/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.105 node6: image: redis container_name: redis-cluster-node-6 ports: - &quot;6376:6379&quot; volumes: - &quot;./node6/redis.conf:/etc/redis.conf&quot; - &quot;./node6/data:/data&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] restart: always networks: redis-cluster: ipv4_address: 172.26.0.106 启动集群：1docker-compose up -d 进入实例内部启动集群：12345678910111213141516docker-compose up -ddocker exec -it redis-cluster-node-1 /bin/bashredis-cli --cluster create 172.26.0.101:6379 172.26.0.102:6379 172.26.0.103:6379 172.26.0.104:6379 172.26.0.105:6379 172.26.0.106:6379 --cluster-replicas 1 redis-cli --cluster create \\192.168.171.136:6371 \\192.168.171.136:6372 \\192.168.171.136:6373 \\192.168.171.136:6374 \\192.168.171.136:6375 \\192.168.171.136:6376 \\--cluster-replicas 1 查询节点信息：123redis-cli -ccluster nodes ps命令在docker容器不存在12345678apt-get update &amp;&amp; apt-get install procps -y apt install net-tools apt-get install iputils-ping -y apt-get install openbsd-inetd -y#安装 openbsd-inetd，如果已经安装过了，直接执行下面的步骤。apt-get install telnetd -y#安装 telnetd 验证集群 容器内网： 12345127.0.0.1:6379&gt; set hello worldOK127.0.0.1:6379&gt; set test redsi-&gt; Redirected to slot [6918] located at 172.26.0.102:6379OK 宿主机：1234567redis-cli -c -p 6371127.0.0.1:6371&gt; get hello&quot;world&quot;127.0.0.1:6371&gt; get test-&gt; Redirected to slot [6918] located at 172.26.0.102:6379# 卡住 无法进行服务切换。 参考文章 docker-compose部署Redis-Cluster集群 【Redis】docker compose 部署集群模式 docker-compose编排redis集群","link":"/2022/03/24/docker/docker-compose-redis-cluster-bridge/"},{"title":"docker-compose-redis","text":"docker compose 部署 主从复制 prepare install docker composeref: https://docs.docker.com/compose/install/ docker compose 部署主从复制12cd ~/apps/redismkdir -p redis-master/data redis-slave-1/data redis-slave-2/data 1234567891011121314151617181920212223242526272829303132333435version: '3'services: master: image: redis container_name: redis-master privileged: true restart: always command: redis-server --cluster-enabled yes --cluster-announce-ip 192.168.50.28 --requirepass summer volumes: - ./redis-master/data:/data ports: - 6379:6379 slave1: image: redis container_name: redis-slave-1 privileged: true restart: always command: redis-server --slaveof redis-master 6379 --cluster-announce-ip 192.168.50.28 --requirepass summer --masterauth summer volumes: - ./redis-slave-1/data:/data ports: - 6380:6379 slave2: image: redis container_name: redis-slave-2 privileged: true restart: always command: redis-server --slaveof redis-master 6379 --cluster-announce-ip 192.168.50.28 --requirepass summer --masterauth summer volumes: - ./redis-slave-2/data:/data ports: - 6381:6379 启动命令1234567891011121314151617181920212223systemctl start dockerdocker-compose up -ddocker exec -it redis-master /bin/bash## fix slots coverageredis-cli --cluster fix 192.168.50.28:6379 -a summerredis-cli -h redis-master -a summercluster nodes# 检查集群redis-cli --cluster check 192.168.50.28:6379 --cluster-search-multiple-owners -a summer# 修复集群redis-cli --cluster fix 192.168.50.28:6379 --cluster-search-multiple-owners -a summer# 说明：检查key、slots、从节点个数的分配情况# 集群信息查看redis-cli --cluster info 192.168.50.28:6379 -a summer 安装常见问题ps命令在docker容器不存在1apt-get update &amp;&amp; apt-get install procps -y 容器 下查看redis的安装目录的方法是什么1ps -ef|grep redis 得到了进程号 xxxx，然后 ls -l /proc/xxxx/cwd Redis集群Hash槽分配异常 CLUSTERDOWN Hash slot not served的解决方式12redis-cli --cluster check 192.168.171.134:6379redis-cli --cluster fix 192.168.171.134:6379 1redis-cli -c -h 192.168.171.134 1redis-cli -h host -p port -a password 参考文章 docker compose 部署主从复制 5 分钟实现用 docker 搭建 Redis 集群模式和哨兵模式","link":"/2022/03/24/docker/docker-compose-redis/"},{"title":"docker-compose redis cluster host","text":"docker compose 集群 network: host prepare install docker composeref: https://docs.docker.com/compose/install/ 集群搭建编写redis.conf12345cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6379 在/root/redis-cluster目录下创建redis-1,redis2,redis-3,redis-4,redis-5,redis-6文件夹123456789101112131415mkdir -p /root/apps/redis-cluster#然后将上一步的 redis.conf 放到 ~/docker/redis/r1 目录下cd /root/apps/redis-clustermkdir redis-1cd redis-1mkdir datavim redis.conf#然后复制6个 redis-1 文件夹cd /root/apps/redis-clustercp -r redis-1 redis-2cp -r redis-1 redis-3cp -r redis-1 redis-4cp -r redis-1 redis-5cp -r redis-1 redis-6 目录结构12345678910111213141516171819202122232425├── docker-compose.yaml├── redis-1│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-2│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-3│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-4│ ├── data│ │ └── nodes.conf│ └── redis.conf├── redis-5│ ├── data│ │ └── nodes.conf│ └── redis.conf└── redis-6 ├── data │ └── nodes.conf └── redis.conf 在每个redis-*文件夹下创建redis.conf文件，并写入如下内容1234567891011121314151617181920212223242526272829303132333435echo 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6379 ' &gt; /root/apps/redis-cluster/redis-1/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6380 ' &gt; /root/apps/redis-cluster/redis-2/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6381 ' &gt; /root/apps/redis-cluster/redis-3/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6382 ' &gt; /root/apps/redis-cluster/redis-4/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6383 ' &gt; /root/apps/redis-cluster/redis-5/redis.confecho 'cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yesport 6384 ' &gt; /root/apps/redis-cluster/redis-6/redis.conf 编写docker-compose.yml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263version: '3.1'services: # redis1配置 redis1: image: daocloud.io/library/redis:6.0.4 container_name: redis-1 restart: always network_mode: &quot;host&quot; volumes: - ./redis-1/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-1/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis2配置 redis2: image: daocloud.io/library/redis:6.0.4 container_name: redis-2 restart: always network_mode: &quot;host&quot; volumes: - ./redis-2/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-2/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis3配置 redis3: image: daocloud.io/library/redis:6.0.4 container_name: redis-3 restart: always network_mode: &quot;host&quot; volumes: - ./redis-3/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-3/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis4配置 redis4: image: daocloud.io/library/redis:6.0.4 container_name: redis-4 restart: always network_mode: &quot;host&quot; volumes: - ./redis-4/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-4/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis5配置 redis5: image: daocloud.io/library/redis:6.0.4 container_name: redis-5 restart: always network_mode: &quot;host&quot; volumes: - ./redis-5/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-5/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] # redis6配置 redis6: image: daocloud.io/library/redis:6.0.4 container_name: redis-6 restart: always network_mode: &quot;host&quot; volumes: - ./redis-6/redis.conf:/usr/local/etc/redis/redis.conf - ./redis-6/data:/data command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] 启动容器1234systemctl start dockerdocker-compose up -d 查看容器启动状态1docker ps 开启集群随便找一个容器进入，这里我选择redis-1进入。 12docker exec -it redis-1 bash 在进入容器后，输入如下命令开启集群 1234567891011121314151617181920redis-cli --cluster create 192.168.171.136:6379 \\192.168.171.136:6380 \\192.168.171.136:6381 \\192.168.171.136:6382 \\192.168.171.136:6383 \\192.168.171.136:6384 \\--cluster-replicas 1# 集群信息查看redis-cli --cluster info 192.168.171.136:6379# Connect redis cluster nodes with – C parameter redis-cli –c -h 172.17.0.1 –p 6391redis-cli -h redis-1cluster nodes redis-cli –cluster cmd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 1 创建集群主节点redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381# 2 创建集群主从节点redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381 192.168.163.132:6382 192.168.163.132:6383 192.168.163.132:6384 --cluster-replicas 1redis-cli --cluster create 172.21.0.2:6379 172.21.0.3:6379 172.21.0.4:6379 --cluster-replicas 2# 说明：--cluster-replicas 参数为数字，1表示每个主节点需要1个从节点。# 通过该方式创建的带有从节点的机器不能够自己手动指定主节点，所以如果需要指定的话，需要自己手动指定，先使用①或③创建好主节点后，再通过④来处理。# 3 添加集群主节点redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379 #说明：为一个指定集群添加节点，需要先连到该集群的任意一个节点IP（192.168.163.132:6379），再把新节点加入。该2个参数的顺序有要求：新加入的节点放前# 4 添加集群从节点redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379 --cluster-slave --cluster-master-id 117457eab5071954faab5e81c3170600d5192270#说明：把6382节点加入到6379节点的集群中，并且当做node_id为 117457eab5071954faab5e81c3170600d5192270 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。# 说明：把6380节点加入到6379节点的集群中，并且当做node_id为 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli --cluster add-node 192.168.171.136:6380 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 192.168.171.136:6381 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 172.21.0.3:6379 172.21.0.2:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7#说明：把 172.21.0.3:6379 节点加入到 172.21.0.2:6379 节点的集群中，并且当做node_id为 117457eab5071954faab5e81c3170600d5192270 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli -h redis-master# 5 删除节点redis-cli --cluster del-node 192.168.163.132:6384 f6a6957421b80409106cb36be3c7ba41f3b603ff# 说明：指定IP、端口和node_id 来删除一个节点，从节点可以直接删除，有slot分配的主节点不能直接删除。删除之后，该节点会被shutdown。# 检查集群redis-cli --cluster check 192.168.171.136:6371 --cluster-search-multiple-owners# 修复集群redis-cli --cluster fix 192.168.171.136:6371 --cluster-search-multiple-owners# 说明：检查key、slots、从节点个数的分配情况# 集群信息查看redis-cli --cluster info 192.168.171.136:6379 # 说明：把6380节点加入到6379节点的集群中，并且当做node_id为 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 的从节点。如果不指定 --cluster-master-id 会随机分配到任意一个主节点。redis-cli --cluster add-node 192.168.171.136:6380 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7redis-cli --cluster add-node 192.168.171.136:6381 192.168.171.136:6379 --cluster-slave --cluster-master-id 551c30a7093bcb8dc8068cd30cf6e81d9b8b47c7 参考文章 Redis 5.0 redis-cli –cluster help说明 基于docker-compose搭建redis集群","link":"/2022/03/24/docker/docker-compose-redis-cluster-host/"},{"title":"docker network","text":"网络模式 配置 说明 bridge模式 –net=bridge （默认为该模式）此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及Iptables nat表配置与宿主机通信。 host模式 –net=host 容器和宿主机共享Network namespace。 container模式 –net=container:NAME_or_ID 容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。 none模式 –net=none 该模式关闭了容器的网络功能。 Bridge模式Bridge模式的拓扑当Docker server启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配IP了，Docker会从RFC1918所定义的私有IP网段中，选择一个和宿主机不同的IP地址和子网分配给docker0，连接到docker0的容器就从这个子网中选择一个未占用的IP使用。如一般Docker会使用172.17.0.0/16这个网段，并将172.17.0.1/16分配给docker0网桥（在主机上使用ifconfig命令是可以看到docker0的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）。单机环境下的网络拓扑如下，主机地址为10.10.0.186/24。 Docker：网络模式详解Docker完成以上网络配置的过程大致是这样的： （1）在主机上创建一对虚拟网卡veth pair设备。veth设备总是成对出现的，它们组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来。因此，veth设备常用来连接两个网络设备。 （2）Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0。另一端放在主机中，以veth65f9这样类似的名字命名，并将这个网络设备加入到docker0网桥中，可以通过brctl show命令查看。 123brctl showbridge name bridge id STP enabled interfacesdocker0 8000.02425f21c208 no （3）从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 运行容器[root@server1 ~]# docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx 9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a# 查看容器[root@server1 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9582dbec7981 nginx &quot;nginx -g 'daemon ...&quot; 3 seconds ago Up 2 seconds 0.0.0.0:80-&gt;80/tcp nginx_bridge# 查看容器网络;[root@server1 ~]# docker inspect 9582dbec7981&quot;Networks&quot;: { &quot;bridge&quot;: { &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;, &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot; }}# 查看网桥信息，会看到有有一个容器[root@server1 ~]# docker network inspect bridge[ { &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;9e017f5d4724039f24acc8aec634c8d2af3a9024f67585fce0a0d2b3cb470059&quot;, &quot;Created&quot;: &quot;2019-06-09T23:20:28.061678042-04:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: { &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ { &quot;Subnet&quot;: &quot;172.17.0.0/16&quot; } ] }, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;Containers&quot;: { &quot;9582dbec7981085ab1f159edcc4bf35e2ee8d5a03984d214bce32a30eab4921a&quot;: { &quot;Name&quot;: &quot;nginx_bridge&quot;, &quot;EndpointID&quot;: &quot;81b94c1b57de26f9c6690942cd78689041d6c27a564e079d7b1f603ecc104b3b&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; } }, &quot;Options&quot;: { &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; }, &quot;Labels&quot;: {} }] bridge模式下容器的通信在bridge模式下，连在同一网桥上的容器可以相互通信（若出于安全考虑，也可以禁止它们之间通信，方法是在DOCKER_OPTS变量中设置–icc=false，这样只有使用–link才能使两个容器通信）。 Docker可以开启容器间通信（意味着默认配置–icc=false），也就是说，宿主机上的所有容器可以不受任何限制地相互通信，这可能导致拒绝服务攻击。进一步地，Docker可以通过–ip_forward和–iptables两个选项控制容器间、容器和外部世界的通信。 容器也可以与外部通信，我们看一下主机上的Iptable规则，可以看到这么一条 12-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 这条规则会将源地址为172.17.0.0/16的包（也就是从Docker容器产生的包），并且不是从docker0网卡发出的，进行源地址转换，转换成主机网卡的地址。这么说可能不太好理解，举一个例子说明一下。假设主机有一块网卡为eth0，IP地址为10.10.101.105/24，网关为10.10.101.254。从主机上一个IP为172.17.0.1/16的容器中ping百度（180.76.3.151）。IP包首先从容器发往自己的默认网关docker0，包到达docker0后，也就到达了主机上。然后会查询主机的路由表，发现包应该从主机的eth0发往主机的网关10.10.105.254/24。接着包会转发给eth0，并从eth0发出去（主机的ip_forward转发应该已经打开）。这时候，上面的Iptable规则就会起作用，对包做SNAT转换，将源地址换为eth0的地址。这样，在外界看来，这个包就是从10.10.101.105上发出来的，Docker容器对外是不可见的。 那么，外面的机器是如何访问Docker容器的服务呢？我们首先用下面命令创建一个含有web应用的容器，将容器的80端口映射到主机的80端口。 12docker run --name=nginx_bridge --net=bridge -p 80:80 -d nginx 然后查看Iptable规则的变化，发现多了这样一条规则： 12-A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 此条规则就是对主机eth0收到的目的端口为80的tcp流量进行DNAT转换，将流量发往172.17.0.2:80，也就是我们上面创建的Docker容器。所以，外界只需访问10.10.101.105:80就可以访问到容器中的服务。 除此之外，我们还可以自定义Docker使用的IP地址、DNS等信息，甚至使用自己定义的网桥，但是其工作方式还是一样的。 参考文章 docker四种网络模式 Docker网络详解——原理篇","link":"/2021/12/30/docker/docker-network/"},{"title":"在 Linux 系统上安装 Compose","text":"Docker Compose 依赖 Docker Engine 进行任何有意义的工作，因此请确保根据您的设置，在本地或远程安装了 Docker Engine。 Install using pip For alpine, the following dependency packages are needed: py-pip, python3-dev, libffi-dev, openssl-dev, gcc, libc-dev, rust, cargo, and make. Compose can be installed from pypi using pip. If you install using pip, we recommend that you use a virtualenv because many operating systems have python system packages that conflict with docker-compose dependencies. See the virtualenv tutorial to get started. 1pip3 install docker-compose 运行此命令以下载 Docker Compose 的当前稳定版本：1sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 对二进制文件应用可执行权限：1sudo chmod +x /usr/local/bin/docker-compose 注意：如果docker-compose安装后命令失败，请检查您的路径。您还可以/usr/bin在路径中创建指向或任何其他目录的符号链接。 例如： 1sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 测试安装1docker-compose --version shell12345678910## 运行此命令以下载 Docker Compose 的当前稳定版本：sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose## 对二进制文件应用可执行权限：sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose## 测试安装docker-compose --version 参考文章 https://docs.docker.com/compose/install/","link":"/2021/12/24/docker/docker-compose/"},{"title":"在 wsl ubuntu 18.04 上安装 Docker 引擎","text":"123456789101112131415161718192021222324252627# Uninstall old versions sudo apt-get remove docker docker-engine docker.io containerd runc#Set up the repository#Update the apt package index and install packages to allow apt to use a repository over HTTPS: sudo apt-get update -y sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null sudo apt-get update -y sudo apt-get install docker-ce docker-ce-cli containerd.ioservice docker start sudo systemctl enable docker sudo docker run hello-world 改用国内的镜像123456vim /etc/docker/daemon.json {&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn/&quot;,&quot;https://hub-mirror.c.163.com&quot;,&quot;https://registry.docker-cn.com&quot;],&quot;insecure-registries&quot;: [&quot;10.0.0.12:5000&quot;]}#systemctl restart docker Docker DockerfileDockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 使用 Dockerfile 定制镜像12FROM nginxRUN echo '这是一个本地构建的nginx镜像' &gt; /usr/share/nginx/html/index.html FROM 和 RUN 指令的作用FROM：定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 RUN：用于执行后面跟着的命令行命令。有以下俩种格式：ref: https://yeasy.gitbook.io/docker_practice/appendix/best_practices#run shell 格式： 12RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。 exec 格式： 123RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]# 例如：# RUN [&quot;./test.php&quot;, &quot;dev&quot;, &quot;offline&quot;] 等价于 RUN ./test.php dev offline 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 123456789101112FROM centosRUN yum -y install wgetRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot;RUN tar -xvf redis.tar.gz# 以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum -y install wget \\&amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\&amp;&amp; tar -xvf redis.tar.gz# 如上，以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。 注：最后的 . 代表本次执行的上下文路径，下一节会介绍。 1$ docker build -t nginx:v3 . 上下文路径上一节中，有提到指令最后一个 . 是上下文路径，那么什么是上下文路径呢？ 1$ docker build -t nginx:v3 . 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。 注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 指令详解COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 格式： 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] [–chown=:]：可选参数，用户改变复制到容器内文件的拥有者和属组。&lt;源路径&gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如： 12COPY hom* /mydir/COPY hom?.txt /mydir/ &lt;目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点： 在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点： 在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。 格式： 123CMD &lt;shell 命令&gt;CMD [&quot;&lt;可执行文件或命令&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...]CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。 ENTRYPOINT https://yeasy.gitbook.io/docker_practice/appendix/best_practices#entrypoint ENTRYPOINT 的最佳用处是设置镜像的主命令，允许将镜像当成命令本身来运行（用 CMD 提供默认选项）。 类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 CMD 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 格式： 12ENTRYPOINT [&quot;&lt;executeable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT [&quot;nginx&quot;, &quot;-c&quot;] # 定参CMD [&quot;/etc/nginx/nginx.conf&quot;] # 变参 1、不传参运行 12$ docker run nginx:test 容器内会默认运行以下命令，启动主进程。 12nginx -c /etc/nginx/nginx.conf 2、传参运行 1$ docker run nginx:test -c /etc/nginx/new.conf 容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件) 1nginx -c /etc/nginx/new.conf ENTRYPOINT 入口点 ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 –entrypoint 来指定。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 ““ 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： 123$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ 123$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://myip.ipip.net 后面。而 -i 根本不是命令，所以自然找不到。那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： 12$ docker run myip curl -s http://myip.ipip.net -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 这次我们再来尝试直接使用 docker run myip -i： 123456789101112131415161718$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通$ docker run myip -iHTTP/1.1 200 OKServer: nginx/1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text/html; charset=UTF-8Vary: Accept-EncodingX-Powered-By: PHP/5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 格式： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 以下示例设置 NODE_VERSION = 7.2.0 ， 在后续的指令中可以通过 $NODE_VERSION 引用： 1234ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\&amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; ARG构建参数，与 ENV 作用一致。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。格式：12VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]VOLUME &lt;路径&gt; 在启动容器 docker run 的时候，我们可以通过 -v 参数修改挂载点。 EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。格式：12EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 格式： 1WORKDIR &lt;工作目录路径&gt; USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 格式： 12USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 格式： 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这时执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 格式： ONBUILD &lt;其它指令&gt; LABELLABEL 指令用来给镜像添加一些元数据（metadata），以键值对的形式，语法格式如下： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...比如我们可以添加镜像的作者： LABEL org.opencontainers.image.authors=&quot;runoob&quot; 参考文章 https://docs.docker.com/engine/install/centos/#install-using-the-repository Orientation and setup &amp;&amp; guide Docker Dockerfile dockerfile 指令 Dockerfile 指令详解","link":"/2021/12/10/docker/docker_ubuntu_install/"},{"title":"在 CentOS 上安装 Docker 引擎","text":"1234567891011121314151617181920212223242526272829# Uninstall old versionssudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # Install Docker Enginesudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y# Start Docker.sudo systemctl start docker## 设置docker开机启动systemctl enable docker# Verify that Docker Engine is installed correctly by running the hello-world image.sudo docker run hello-world 改用国内的镜像123456vim /etc/docker/daemon.json {&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn/&quot;,&quot;https://hub-mirror.c.163.com&quot;,&quot;https://registry.docker-cn.com&quot;],&quot;insecure-registries&quot;: [&quot;10.0.0.12:5000&quot;]}#systemctl restart docker Docker DockerfileDockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 使用 Dockerfile 定制镜像12FROM nginxRUN echo '这是一个本地构建的nginx镜像' &gt; /usr/share/nginx/html/index.html FROM 和 RUN 指令的作用FROM：定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 RUN：用于执行后面跟着的命令行命令。有以下俩种格式：ref: https://yeasy.gitbook.io/docker_practice/appendix/best_practices#run shell 格式： 12RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。 exec 格式： 123RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]# 例如：# RUN [&quot;./test.php&quot;, &quot;dev&quot;, &quot;offline&quot;] 等价于 RUN ./test.php dev offline 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 123456789101112FROM centosRUN yum -y install wgetRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot;RUN tar -xvf redis.tar.gz# 以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum -y install wget \\&amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\&amp;&amp; tar -xvf redis.tar.gz# 如上，以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。 注：最后的 . 代表本次执行的上下文路径，下一节会介绍。 1$ docker build -t nginx:v3 . 上下文路径上一节中，有提到指令最后一个 . 是上下文路径，那么什么是上下文路径呢？ 1$ docker build -t nginx:v3 . 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。 注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 指令详解COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 格式： 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] [–chown=:]：可选参数，用户改变复制到容器内文件的拥有者和属组。&lt;源路径&gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如： 12COPY hom* /mydir/COPY hom?.txt /mydir/ &lt;目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点： 在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点： 在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。 格式： 123CMD &lt;shell 命令&gt;CMD [&quot;&lt;可执行文件或命令&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...]CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。 ENTRYPOINT https://yeasy.gitbook.io/docker_practice/appendix/best_practices#entrypoint ENTRYPOINT 的最佳用处是设置镜像的主命令，允许将镜像当成命令本身来运行（用 CMD 提供默认选项）。 类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 CMD 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 格式： 12ENTRYPOINT [&quot;&lt;executeable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT [&quot;nginx&quot;, &quot;-c&quot;] # 定参CMD [&quot;/etc/nginx/nginx.conf&quot;] # 变参 1、不传参运行 12$ docker run nginx:test 容器内会默认运行以下命令，启动主进程。 12nginx -c /etc/nginx/nginx.conf 2、传参运行 1$ docker run nginx:test -c /etc/nginx/new.conf 容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件) 1nginx -c /etc/nginx/new.conf ENTRYPOINT 入口点 ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 –entrypoint 来指定。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 ““ 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： 123$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ 123$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://myip.ipip.net 后面。而 -i 根本不是命令，所以自然找不到。那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： 12$ docker run myip curl -s http://myip.ipip.net -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： 12345FROM ubuntu:18.04RUN apt-get update \\&amp;&amp; apt-get install -y curl \\&amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] 这次我们再来尝试直接使用 docker run myip -i： 123456789101112131415161718$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通$ docker run myip -iHTTP/1.1 200 OKServer: nginx/1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text/html; charset=UTF-8Vary: Accept-EncodingX-Powered-By: PHP/5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 格式： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 以下示例设置 NODE_VERSION = 7.2.0 ， 在后续的指令中可以通过 $NODE_VERSION 引用： 1234ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\&amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; ARG构建参数，与 ENV 作用一致。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。格式：12VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]VOLUME &lt;路径&gt; 在启动容器 docker run 的时候，我们可以通过 -v 参数修改挂载点。 EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。格式：12EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 格式： 1WORKDIR &lt;工作目录路径&gt; USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 格式： 12USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 格式： 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这时执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 格式： ONBUILD &lt;其它指令&gt; LABELLABEL 指令用来给镜像添加一些元数据（metadata），以键值对的形式，语法格式如下： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...比如我们可以添加镜像的作者： LABEL org.opencontainers.image.authors=&quot;runoob&quot; 参考文章 https://docs.docker.com/engine/install/centos/#install-using-the-repository Orientation and setup &amp;&amp; guide Docker Dockerfile dockerfile 指令 Dockerfile 指令详解","link":"/2021/12/10/docker/docker-install/"},{"title":"http-server","text":"1npm install --global http-server 1http-server --proxy http://localhost:8080? 参考文章 https://github.com/http-party/http-server#readme https://www.npmjs.com/package/http-server","link":"/2021/10/28/frontend/node-http-server/"},{"title":"CompletableFuture基本用法","text":"对比 Future：我们的目的都是获取异步任务的结果，但是对于Future来说，只能通过get方法或者死循环判断isDone来获取。异常情况就更是难办。 CompletableFuture：只要我们设置好回调函数即可实现： 只要任务完成，即执行我们设置的函数（不用再去考虑什么时候任务完成） 如果发生异常，同样会执行我们处理异常的函数，甚至连默认返回值都有（异常情况处理更加省力） 如果有复杂任务，比如依赖问题，组合问题等，同样可以写好处理函数来处理（能应付复杂任务的处理） FutureJDK5新增了Future接口，用于描述一个异步计算的结果。虽然 Future 以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的 CPU 资源，而且也不能及时地得到计算结果。 以前我们获取一个异步任务的结果可能是这样写的 Future 接口的局限性Future接口可以构建异步应用，但依然有其局限性。它很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的： 将多个异步计算的结果合并成一个 等待Future集合中的所有任务都完成 Future完成事件（即，任务完成以后触发执行动作） … CompletionStage CompletionStage代表异步计算过程中的某一个阶段，一个阶段完成以后可能会触发另外一个阶段 一个阶段的计算执行可以是一个Function，Consumer或者Runnable。比如：stage.thenApply(x -&gt; square(x)).thenAccept(x -&gt; System.out.print(x)).thenRun(() -&gt; System.out.println()) 一个阶段的执行可能是被单个阶段的完成触发，也可能是由多个阶段一起触发1public class CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt; CompletableFuture 在Java8中，CompletableFuture提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法。 它可能代表一个明确完成的Future，也有可能代表一个完成阶段（ CompletionStage ），它支持在计算完成以后触发一些函数或执行某些动作。 它实现了Future和CompletionStage接口 对于CompletableFuture有四个执行异步任务的方法： 1234public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor) 121. 如果我们指定线程池，则会使用我么指定的线程池；如果没有指定线程池，默认使用ForkJoinPool.commonPool()作为线程池。2. supply开头的带有返回值，run开头的无返回值。 执行异步任务（supplyAsync / runAsync）1234567891011121314151617181920import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor); System.out.println(future.get()); executor.shutdown(); }} 以上仅仅返回个随机数，如果我们要利用计算结果进一步处理呢？ 结果转换（thenApply / thenApplyAsync）123456// 同步转换public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn)// 异步转换，使用默认线程池public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)// 异步转换，使用指定线程池public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 123456789101112131415161718192021222324252627282930313233343536import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor) // 对上一步的结果进行处理 .thenApply(n -&gt; { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } int res = new Random().nextInt(100); System.out.println(String.format(&quot;如果是同步的，这条消息应该先输出。上一步结果：%s，新加：%s&quot;, n, res)); return n + res; }); System.out.println(&quot;我等了你2秒&quot;); System.out.println(future.get()); executor.shutdown(); }} 输出：如果把thenApply换成thenApplyAsync，则会输出：处理完任务以及结果，该去消费了 消费而不影响最终结果（thenAccept / thenRun / thenAcceptBoth）1234567891011public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor)public CompletableFuture&lt;Void&gt; thenRun(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action, Executor executor)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action, Executor executor) 123456789这三种的区别是：thenAccept：能够拿到并利用执行结果thenRun：不能够拿到并利用执行结果，只是单纯的执行其它任务thenAcceptBoth：能传入另一个stage，然后把另一个stage的结果和当前stage的结果作为参数去消费。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { return new Random().nextInt(100); }, executor) // 对上一步的结果进行处理 .thenApplyAsync(n -&gt; { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } int res = new Random().nextInt(100); System.out.println(String.format(&quot;如果是同步的，这条消息应该先输出。上一步结果：%s，新加：%s&quot;, n, res)); return n + res; }); // 单纯的消费执行结果，注意这个方法是不会返回计算结果的——CompletableFuture&lt;Void&gt; CompletableFuture&lt;Void&gt; voidCompletableFuture = future.thenAcceptAsync(n -&gt; { System.out.println(&quot;单纯消费任务执行结果：&quot; + n); }); // 这个无法消费执行结果，没有传入的入口，只是在当前任务执行完毕后执行其它不相干的任务 future.thenRunAsync(() -&gt; { System.out.println(&quot;我只能执行其它工作，我得不到任务执行结果&quot;); }, executor); // 这个方法会接受其它CompletableFuture返回值和当前返回值 future.thenAcceptBothAsync(CompletableFuture.supplyAsync(() -&gt; { return &quot;I'm Other Result&quot;; }), (current, other) -&gt; { System.out.println(String.format(&quot;Current：%s，Other:%s&quot;, current, other)); }); System.out.println(&quot;我等了你2秒&quot;); System.out.println(future.get()); executor.shutdown(); }} 结果： 组合任务（thenCombine / thenCompose）1234567public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor)public &lt;U&gt; CompletionStage&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) 12345这两种区别：主要是返回类型不一样。thenCombine：至少两个方法参数，一个为其它stage，一个为用户自定义的处理函数，函数返回值为结果类型。thenCompose：至少一个方法参数即处理函数，函数返回值为stage类型。 先看thenCombine 123456789101112131415161718192021222324252627282930313233343536373839import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; otherFuture = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务A：&quot; + result); return result; }, executor); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务B：&quot; + result); return result; }, executor) .thenCombineAsync(otherFuture, (current, other) -&gt; { int result = other + current; System.out.println(&quot;组合两个任务的结果：&quot; + result); return result; }); System.out.println(future.get()); executor.shutdown(); }} 执行结果：再来看thenCompose 1234567891011121314151617181920212223242526272829303132333435import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;Integer&gt; future = CompletableFuture // 执行异步任务 .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;任务A：&quot; + result); return result; }, executor) .thenComposeAsync((current) -&gt; { return CompletableFuture.supplyAsync(() -&gt; { int b = new Random().nextInt(100); System.out.println(&quot;任务B：&quot; + b); int result = b + current; System.out.println(&quot;组合两个任务的结果：&quot; + result); return result; }, executor); }); System.out.println(future.get()); executor.shutdown(); }} 输出： 快者优先（applyToEither / acceptEither）1有个场景，如果我们有多条渠道去完成同一种任务，那么我们肯定选择最快的那个。 1234567public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn)public &lt;U&gt; CompletionStage&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn, Executor executor)public CompletionStage&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletionStage&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor) 1这两种区别：仅仅是一个有返回值，一个没有（Void） 先看applyToEither 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; otherFuture = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者A：&quot; + result); try { // 故意A慢了一些 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;执行者A【&quot; + result + &quot;】&quot;; }, executor); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者B：&quot; + result); return &quot;执行者B【&quot; + result + &quot;】&quot;; }, executor) .applyToEither(otherFuture, (faster) -&gt; { System.out.println(&quot;谁最快：&quot; + faster); return faster; }); System.out.println(future.get()); executor.shutdown(); }} 输出：再看acceptEither 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; otherFuture = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者A：&quot; + result); try { // 故意A慢了一些 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;执行者A【&quot; + result + &quot;】&quot;; }, executor); CompletableFuture&lt;Void&gt; future = CompletableFuture .supplyAsync(() -&gt; { int result = new Random().nextInt(100); System.out.println(&quot;执行者B：&quot; + result); return &quot;执行者B【&quot; + result + &quot;】&quot;; }, executor) .acceptEither(otherFuture, (faster) -&gt; { System.out.println(&quot;谁最快：&quot; + faster); }); System.out.println(future.get()); executor.shutdown(); }} 输出： 异常处理（exceptionally / whenComplete / handle）123456789public CompletionStage&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; fn);public CompletionStage&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; action);public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action);public CompletionStage&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action, Executor executor);public &lt;U&gt; CompletionStage&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn);public &lt;U&gt; CompletionStage&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn,Executor executor); exceptionally 123456789101112131415161718192021222324252627282930import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .exceptionally(e -&gt; { System.out.println(&quot;处理异常：&quot; + e.getMessage()); return &quot;处理完毕!&quot;; }); System.out.println(future.get()); executor.shutdown(); }} 输出：whenComplete 123456789101112131415161718192021222324252627282930313233343536import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .whenComplete((result,ex) -&gt; { // 这里等待为了上一步的异常输出完毕 try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;上一步结果：&quot; + result); System.out.println(&quot;处理异常：&quot; + ex.getMessage()); }); System.out.println(future.get()); executor.shutdown(); }} 输出结果：可以看见，用whenComplete对异常情况不是特别友好。 handle 12345678910111213141516171819202122232425262728293031import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main { public static void main(String[] args) throws Exception { ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 6, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10)); CompletableFuture&lt;String&gt; future = CompletableFuture .supplyAsync(() -&gt; { if (true){ throw new RuntimeException(&quot;Error!!!&quot;); } return &quot;Hello&quot;; }, executor) // 处理上一步发生的异常 .handle((result,ex) -&gt; { System.out.println(&quot;上一步结果：&quot; + result); System.out.println(&quot;处理异常：&quot; + ex.getMessage()); return &quot;Value When Exception Occurs&quot;; }); System.out.println(future.get()); executor.shutdown(); }} 输出： 综上，如果单纯要处理异常，那就用exceptionally；如果还想处理结果（没有异常的情况），那就用handle，比whenComplete友好一些，handle不仅能处理异常还能返回一个异常情况的默认值。 参考文章 https://www.cnblogs.com/cjsblog/p/9267163.html https://www.cnblogs.com/LUA123/p/12050255.html https://www.liaoxuefeng.com/wiki/1252599548343744/1306581182447650 https://blog.csdn.net/qq_31865983/article/details/106137777 https://blog.csdn.net/finalheart/article/details/87615546 https://www.jianshu.com/p/6bac52527ca4","link":"/2021/11/10/java/java-CompletableFuture/"},{"title":"ConfigurationProperties","text":"在 Spring Boot 项目中，我们将大量的参数配置在 application.properties 或 application.yml 文件中，通过 @ConfigurationProperties 注解，我们可以方便的获取这些参数值 使用 @ConfigurationProperties 配置模块假设我们正在搭建一个发送邮件的模块。在本地测试，我们不想该模块真的发送邮件，所以我们需要一个参数来「开关」 disable 这个功能。另外，我们希望为这些邮件配置一个默认的主题，这样，当我们查看邮件收件箱，通过邮件主题可以快速判断出这是测试邮件 在 application.properties 文件中创建这些参数:我们可以使用 @Value 注解或着使用 Spring Environment bean 访问这些属性，是这种注入配置方式有时显得很笨重。我们将使用更安全的方式(@ConfigurationProperties )来获取这些属性 @ConfigurationProperties 的基本用法非常简单:我们为每个要捕获的外部属性提供一个带有字段的类。请注意以下几点: 前缀定义了哪些外部属性将绑定到类的字段上 根据 Spring Boot 宽松的绑定规则，类的属性名称必须与外部属性的名称匹配 我们可以简单地用一个值初始化一个字段来定义一个默认值 类本身可以是包私有的 类的字段必须有公共 setter 方法 激活 @ConfigurationProperties对于 Spring Boot，创建一个 MailModuleProperties 类型的 bean，我们可以通过下面几种方式将其添加到应用上下文中 首先，我们可以通过添加 @Component 注解让 Component Scan 扫描到很显然，只有当类所在的包被 Spring @ComponentScan 注解扫描到才会生效，默认情况下，该注解会扫描在主应用类下的所有包结构 参考文章 https://blog.csdn.net/yusimiao/article/details/97622666 面试还不知道BeanFactory和ApplicationContext的区别？","link":"/2021/11/03/java/java-ConfigurationProperties/"},{"title":"apache.http.impl.client.HttpClients","text":"12345678try (CloseableHttpClient httpClient = HttpClients.custom().disableAutomaticRetries().build()) { HttpPost httpPost = new HttpPost(&quot;http://www.baidu.com&quot;); try (CloseableHttpResponse response = httpClient.execute(httpPost)) { int statusCode = response.getStatusLine().getStatusCode(); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package com.example.demo;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import org.apache.http.HttpEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpPost;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.util.EntityUtils;public class Main { public static void main(String[] args) throws IOException { try (CloseableHttpClient httpClient = HttpClients.custom().disableAutomaticRetries().build()) { HttpPost httpPost = new HttpPost(&quot;http://www.baidu.com&quot;); // HttpGet httGet = new HttpGet(&quot;http://www.baidu.com&quot;); // httpPost.setEntity(&quot;&quot;); // httpPost.setHeader(&quot;Accept&quot;, &quot;application/json&quot;); // httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); try (CloseableHttpResponse response = httpClient.execute(httpPost)) { int statusCode = response.getStatusLine().getStatusCode(); InputStream inputStream = response.getEntity().getContent(); readByChars(inputStream); InputStreamReader inputStreamReader = new InputStreamReader(inputStream); readWithBufferedReader(inputStreamReader); if (statusCode != 200) { final HttpEntity entity = response.getEntity(); final String result = EntityUtils.toString(entity); System.out.println(result); } } } } /** * 以字符为单位读取文件，常用于读文本，数字等类型的文件 */ public static void readByChars(InputStream inputStream) { InputStreamReader reader = null; // try { // System.out.println(&quot;以字符为单位读取文件内容，一次读一个字节：&quot;); // //1. 一次读一个字符 // reader = new InputStreamReader(inputStream);//可以是任意的InputStream类，不一定必须是FileInputStream // int tempchar; // while ((tempchar = reader.read()) != -1) { // if (((char)tempchar) != '\\r') { // System.out.print((char)tempchar); // } // } // reader.close(); // } catch (Exception e) { // e.printStackTrace(); // } try { System.out.println(&quot;以字符为单位读取文件内容，一次读多个字节：&quot;); //2. 一次读多个字符 char[] tempchars = new char[30]; int charread = 0; reader = new InputStreamReader(inputStream); while ((charread = reader.read(tempchars)) != -1) { for (int i = 0; i &lt; charread; i++) { if (tempchars[i] != '\\r') { System.out.print(tempchars[i]); } } } } catch (Exception e1) { e1.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } } public static void readWithBufferedReader(InputStreamReader inputStreamReader) { BufferedReader reader = null; try { reader = new BufferedReader(inputStreamReader); String tempString = null; int line = 1; // 一次读入一行，直到读入null为文件结束 while ((tempString = reader.readLine()) != null) { System.out.println(&quot;line &quot; + line + &quot;: &quot; + tempString); line++; } reader.close(); } catch (IOException e) { e.printStackTrace(); } finally { if (reader != null) { try { reader.close(); } catch (IOException e1) { } } } }} 参考文章","link":"/2021/12/08/java/java-apache-httpclient/"},{"title":"知识点总结","text":"java 类加载的过程 ？ 双亲委派模式https://blog.csdn.net/ren365880/article/details/83786535 Java 虚拟机一般使用 Java 类的流程为：首先将开发者编写的 Java 源代码（.java文件）编译成 Java 字节码（.class文件），然后类加载器会读取这个 .class 文件，并转换成 java.lang.Class 的实例。有了该 Class 实例后，Java 虚拟机可以利用 newInstance 之类的方法创建其真正对象了。ClassLoader 是 Java 提供的类加载器，绝大多数的类加载器都继承自 ClassLoader，它们被用来加载不同来源的 Class 文件。类从被加载到JVM中开始，到卸载为止，整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。其中类加载过程包括加载、验证、准备、解析和初始化五个阶段。验证、准备和解析这三个部分统称为连接（linking）。加载简单的说，类加载阶段就是由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例（Java虚拟机规范并没有明确要求一定要存储在堆区中，只是hotspot选择将Class对戏那个存储在方法区中），这个Class对象在日后就会作为方法区中该类的各种数据的访问入口。 链接链接阶段要做的是将加载到JVM中的二进制字节流的类数据信息合并到JVM的运行时状态中，经由验证、准备和解析三个阶段。 1验证验证类数据信息是否符合JVM规范，是否是一个有效的字节码文件，验证内容涵盖了类数据信息的格式验证、语义分析、操作验证等。格式验证：验证是否符合class文件规范语义验证：检查一个被标记为final的类型是否包含子类；检查一个类中的final方法视频被子类进行重写；确保父类和子类之间没有不兼容的一些方法声明（比如方法签名相同，但方法的返回值不同）操作验证：在操作数栈中的数据必须进行正确的操作，对常量池中的各种符号引用执行验证（通常在解析阶段执行，检查是否通过富豪引用中描述的全限定名定位到指定类型上，以及类成员信息的访问修饰符是否允许访问等）2准备为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内）被final修饰的静态变量，会直接赋予原值；类字段的字段属性表中存在ConstantValue属性，则在准备阶段，其值就是ConstantValue的值3解析将常量池中的符号引用转为直接引用（得到类或者字段、方法在内存中的指针或者偏移量，以便直接调用该方法），这个可以在初始化之后再执行。可以认为是一些静态绑定的会被解析，动态绑定则只会在运行是进行解析；静态绑定包括一些final方法(不可以重写),static方法(只会属于当前类)，构造器(不会被重写)初始化将一个类中所有被static关键字标识的代码统一执行一遍，如果执行的是静态变量，那么就会使用用户指定的值覆盖之前在准备阶段设置的初始值；如果执行的是static代码块，那么在初始化阶段，JVM就会执行static代码块中定义的所有操作。 哪些 ClassLoader 负责加载上面几类 Class？实际上，针对上面四种来源的类，分别有不同的加载器负责加载。首先，我们来看级别最高的 Java 核心类，即$JAVA_HOME/jre/lib 里的核心 jar 文件。这些类是 Java 运行的基础类，由一个名为 BootstrapClassLoader 加载器负责加载，它也被称作 根加载器／引导加载器。注意，BootstrapClassLoader 比较特殊，它不继承 ClassLoader，而是由 JVM 内部实现；然后，需要加载 Java 核心扩展类，即 $JAVA_HOME/jre/lib/ext 目录下的 jar 文件。这些文件由 ExtensionClassLoader 负责加载，它也被称作 扩展类加载器。当然，用户如果把自己开发的 jar 文件放在这个目录，也会被 ExtClassLoader 加载；接下来是开发者在项目中编写的类，这些文件将由 AppClassLoader 加载器进行加载，它也被称作 系统类加载器 System ClassLoader；最后，如果想远程加载如（本地文件／网络下载）的方式，则必须要自己自定义一个 ClassLoader，复写其中的 findClass() 方法才能得以实现。因此能看出，Java 里提供了至少四类 ClassLoader 来分别加载不同来源的 Class。 不同加载器是如何工作的？什么是双亲委托模型及双亲委托存在的意义。 String 类是 Java 自带的最常用的一个类，现在的问题是，JVM 将以何种方式把 String class 加载进来呢？我们来猜想下。 首先，String 类属于 Java 核心类，位于 $JAVA_HOME/jre/lib 目录下。有的朋友会马上反应过来，上文中提过了，该目录下的类会由 BootstrapClassLoader 进行加载。没错，它确实是由 BootstrapClassLoader 进行加载。但，这种回答的前提是你已经知道了 String 在 $JAVA_HOME/jre/lib 目录下。 那么，如果你并不知道 String 类究竟位于哪呢？或者我希望你去加载一个 unknown 的类呢？有的朋友这时会说，那很简单，只要去遍历一遍所有的类，看看这个 unknown 的类位于哪里，然后再用对应的加载器去加载。 是的，思路很正确。那应该如何去遍历呢？ 比如，可以先遍历用户自己写的类，如果找到了就用 AppClassLoader 去加载；否则去遍历 Java 核心类目录，找到了就用 BootstrapClassLoader 去加载，否则就去遍历 Java 扩展类库，依次类推。 这种思路方向是正确的，不过存在一个漏洞。 假如开发者自己伪造了一个 java.lang.String 类，即在项目中创建一个包java.lang，包内创建一个名为 String 的类，这完全可以做到。那如果利用上面的遍历方法，是不是这个项目中用到的 String 不是都变成了这个伪造的 java.lang.String 类吗？如何解决这个问题呢？ 当一个类加载器接收到一个类加载的任务时，不会立即展开加载，而是将加载任务委托给它的父类加载器去执行，每一层的类都采用相同的方式，直至委托给最顶层的启动类加载器为止。如果父类加载器无法加载委托给它的类，便将类的加载任务退回给下一级类加载器去执行加载。 双亲委托模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需要加载的类）时，子加载器才会尝试自己去加载。使用双亲委托机制的好处是：能够有效确保一个类的全局唯一性，当程序中出现多个限定名相同的类时，类加载器在执行加载时，始终只会加载其中的某一个类。 使用双亲委托模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委托给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种加载器环境中都是同一个类。相反，如果没有使用双亲委托模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。如果自己去编写一个与rt.jar类库中已有类重名的Java类，将会发现可以正常编译，但永远无法被加载运行。 双亲委托模型对于保证Java程序的稳定运作很重要，但它的实现却非常简单，实现双亲委托的代码都集中在java.lang.ClassLoader的loadClass()方法中，逻辑清晰易懂：先检查是否已经被加载过，若没有加载则调用父类加载器的loadClass()方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父类加载器加载失败，抛出ClassNotFoundException异常后，再调用自己的findClass方法进行加载。 类加载器的应用：自定义类加载器 自定义类加载器，它允许我们在运行时可以从本地磁盘或网络上动态加载自定义类。这使得开发者可以动态修复某些有问题的类，热更新代码。 自定义类加载器需要继承抽象类ClassLoader，实现findClass方法，该方法会在loadClass调用的时候被调用，findClass默认会抛出异常。不是loadClass()方法，因为ClassLoader提供了loadClass()（如上面的源码），它会基于双亲委托机制去搜索某个 class，直到搜索不到才会调用自身的findClass()，如果直接复写loadClass()，那还要实现双亲委托机制 findClass方法表示根据类名查找类对象loadClass方法表示根据类名进行双亲委托模型进行类加载并返回类对象defineClass方法表示跟根据类的字节码转换为类对象 NoClassDefError ClassNotFoundEException 区别Error与Exception：Error仅在java的虚拟机中发生，用户无需在程序中捕捉或者抛出Error。Exception分为一般的Exception和RuntimeException两类，其中，RuntimeException为Unchecked型，而Exception为Checked型。checked与unchecked checked： 一般是指程序不能直接控制的外界情况，是指在编译的时候就需要检查的一类exception，用户程序中必须采用try-catch机制处理或者通过throws交由调用者来处理。这类异常，主要指除了Error以及RuntimeException及其子类之外的异常。unchecked：是指那些不需要在编译的时候就要处理的一类异常。在java体系里，所有的Error以及RuntimeException及其子类都是unchecked异常。可直白的理解为：不需要try-catch等机制处理的异常，可以认为是unchecked的异常。 ClassNotFoundException为非RuntimeException(CheckedException)，也就是说该异常在程序编译前就会检查出该错误，导致无法通过编译，逼迫程序员修改代码。所以这里的ClassNotFoundException应该指的是找不到所定义的Class的代码段。 2）NoClassDefError并不是发生在编译前，而是编译后的运行期间(通常在jvm类加载过程)，通常分以下三种成因：①加载该类时发现找不到该类的.class文件或者该类的jar包不存在；②类的.class文件存在，但是在不同的域中。比如说，.class在当前的java path下不可用又或者说有多个不同的类加载器重复对该类的.class文件进行了加载，就有可能出现这样的问题；③大小写问题，因为在编译时，虽然类名可能大小写不同，但如果字母都一样，那么最后不管类名大小写是否相同，编译后都只产生一个.class文件！这样就会导致最后编译出来的文件不是我们想要的。 强引用、软引用、弱引用、虚引用强引用Object obj = new Object(); //只要obj还指向Object对象，Object对象就不会被回收 obj = null; //手动置null 只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足时，JVM也会直接抛出OutOfMemoryError，不会去回收。如果想中断强引用与对象之间的联系，可以显示的将强引用赋值为null，这样一来，JVM就可以适时的回收对象了Object obj = new Object(); 软引用软引用是用来描述一些非必需但仍有用的对象。在内存足够的时候，软引用对象不会被回收，只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常。这种特性常常被用来实现缓存技术，比如网页缓存，图片缓存等。在 JDK1.2 之后，用java.lang.ref.SoftReference类来表示软引用 SoftReference ref = new SoftReference(“hong”); 弱引用弱引用的引用强度比软引用要更弱一些，无论内存是否足够，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象都会被回收。在 JDK1.2 之后，用 java.lang.ref.WeakReference 来表示弱引用。 Obejct oj = new Object();WeakReference wf = new WeakReference(oj);oj = null; System.gc(); //下面会发现有时候直接返回null;wf.get(); 虚引用虚引用是最弱的一种引用关系，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，它随时可能会被回收，在 JDK1.2 之后，用 PhantomReference 类来表示，通过查看这个类的源码，发现它只有一个构造函数和一个 get() 方法，而且它的 get() 方法仅仅是返回一个null，也就是说将永远无法通过虚引用来获取对象，虚引用必须要和 ReferenceQueue 引用队列一起使用。 // 虚引用Object oj= new Object();ReferenceQueue req= new ReferenceQueue();PhantomReference pr= new PhantomReference(oj, req);// 每次返回NullSystem.out.println(pr.get());//返回是否被删除System.out.println(pr.isEnqueued()); StringBuffer StringBuilderStringBuffer与StringBuilder的共同之处1、都继成了AbstractStringBuilder这个抽象类，实现了CharSequence接口2、其append方法都是 super.append(str)，调用了父类AbstractStringBuilder的append(String str)方法3、初始容量都是16和扩容机制都是”旧容量*2+2”4、底层都是用char[]字符数组实现，且字符数组都是可变的，这点不同于String 不同：1 StringBuilder：线程非安全的 StringBuffer：线程安全的2 单线程，在执行速度方面的比较：StringBuilder &gt; StringBuffer3.StringBuffer比StringBuilder多了一个toStringCache字段，用来在toString方法中进行缓存，每次append操作之前都先把toStringCache设置为null，若多次连续调用toString方法，可避免每次Arrays.copyOfRange(value, 0, count)操作，节省性能。 单线程StringBuffer与StringBuilder区别这个才是我们重点讨论的，单线程下StringBuffer加了synchronized，虽然是单线程， 但是synchronized获取锁和释放锁也还是需要时间的， 而StringBuilder没有，这个就是重点区别。因此重点要讨论synchronized锁的状态，从获取锁到释放锁的过程，因此需要讨论一下锁的升级和优化。 偏向锁： 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。 为什么要引入偏向锁？ 因为经过HotSpot的作者大量的研究发现，大多数时候是不存在锁竞争的，常常是一个线程多次获得同一个锁，因此如果每次都要竞争锁会增大很多没有必要付出的代价，为了降低获取锁的代价，才引入的偏向锁。 偏向锁的升级 当线程1访问代码块并获取锁对象时，会在java对象头和栈帧中记录偏向的锁的threadID，因为偏向锁不会主动释放锁，因此以后线程1再次获取锁的时候，需要比较当前线程的threadID和Java对象头中的threadID是否一致，如果一致（还是线程1获取锁对象），则无需使用CAS来加锁、解锁；如果不一致（其他线程，如线程2要竞争锁对象，而偏向锁不会主动释放因此还是存储的线程1的threadID），那么需要查看Java对象头中记录的线程1是否存活，如果没有存活，那么锁对象被重置为无锁状态，其它线程（线程2）可以竞争将其设置为偏向锁；如果存活，那么立刻查找该线程（线程1）的栈帧信息，如果还是需要继续持有这个锁对象，那么暂停当前线程1，撤销偏向锁，升级为轻量级锁，如果线程1 不再使用该锁对象，那么将锁对象状态设为无锁状态，重新偏向新的线程。 偏向锁的取消： 偏向锁是默认开启的，而且开始时间一般是比应用程序启动慢几秒，如果不想有这个延迟，那么可以使用-XX:BiasedLockingStartUpDelay=0； 如果不想要偏向锁，那么可以通过-XX:-UseBiasedLocking = false来设置； （2）轻量级锁 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能 为什么要引入轻量级锁？ 轻量级锁考虑的是竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。因为阻塞线程需要CPU从用户态转到内核态，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了，因此这个时候就干脆不阻塞这个线程，让它自旋这等待锁释放。 （3）重量级锁 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。 轻量级锁什么时候升级为重量级锁？ 线程1获取轻量级锁时会先把锁对象的对象头MarkWord复制一份到线程1的栈帧中创建的用于存储锁记录的空间（称为DisplacedMarkWord），然后使用CAS把对象头中的内容替换为线程1存储的锁记录（DisplacedMarkWord）的地址； 如果在线程1复制对象头的同时（在线程1CAS之前），线程2也准备获取锁，复制了对象头到线程2的锁记录空间中，但是在线程2CAS的时候，发现线程1已经把对象头换了，线程2的CAS失败，那么线程2就尝试使用自旋锁来等待线程1释放锁。 但是如果自旋的时间太长也不行，因为自旋是要消耗CPU的，因此自旋的次数是有限制的，比如10次或者100次，如果自旋次数到了线程1还没有释放锁，或者线程1还在执行，线程2还在自旋等待，这时又有一个线程3过来竞争这个锁对象，那么这个时候轻量级锁就会膨胀为重量级锁。重量级锁把除了拥有锁的线程都阻塞，防止CPU空转。 *注意：为了避免无用的自旋，轻量级锁一旦膨胀为重量级锁就不会再降级为轻量级锁了；偏向锁升级为轻量级锁也不能再降级为偏向锁。一句话就是锁可以升级不可以降级，但是偏向锁状态可以被重置为无锁状态。 综上可知，StringBuffer虽然是单线程，但它是有偏向锁升级过程判断的，会耗费时间，效率固然低于StringBuilder StringBuffer与StringBuilder的应用场景当我们在字符串缓StringBuffer与StringBuilder的应用场景冲去被多个线程使用是，JVM不能保证StringBuilder的操作是安全的，虽然他的速度最快，但是可以保证StringBuffer是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用StringBuilder而不用StringBuffer的，就是速度的原因。 对于三者使用的总结：1.如果要操作少量的数据用 String2.单线程操作字符串缓冲区 下操作大量数据 StringBuilder3.多线程操作字符串缓冲区 下操作大量数据 StringBuffer ArrayList LinkedList, synchronizedListHashSetHashSet 实现了 Set 接口，由哈希表（实际是 HashMap）提供支持。HashSet 不保证集合的迭代顺序，但允许插入 null 值。HashSet 如何保证元素不重复？我们只要了解了 HashSet 执行添加元素的流程，就能知道为什么 HashSet 能保证元素不重复了？HashSet 添加元素的执行流程是：当把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现，会将对象插入到相应的位置中。但是如果发现有相同 hashcode 值的对象，这时会调用对象的 equals() 方法来检查对象是否真的相同，如果相同，则 HashSet 就不会让重复的对象加入到 HashSet 中，这样就保证了元素的不重复。 gc 垃圾回收算法线程池工作原理。 shutdown shutdownNow newSingleThreadExecutor 创建“单线程化线程池”1.单线程化的线程池中的任务，是按照提交的次序，顺序执行的2.池中的唯一线程的存活时间是无限的3.当池中的唯一线程正繁忙时，新提交的任务实例会进入内部的阻塞队列中，并且其阻塞队列是无界的。总体来说，单线程化的线程池所适用的场景是：任务按照提交次序，一个任务一个任务逐个执行的场景。 newFixedThreadPool 创建“固定数量的线程池”如果线程数量没有达到“固定数量”，则每次提交一个任务池内就创建一个新的线程，直到到达固定的数量2.线程池的大小一旦达到“固定数量”就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。3.如果池中的所有线程均在繁忙状态，对于新任务会进入阻塞队列中(无界的阻塞队列)。使用场景：需要任务长期执行的场景。“固定数量的线程池”的线程数能够比较稳定保证一个数，能够避免频繁回收线程和创建线程，故适用于处理 CPU 密集型的任务，在 CPU 被工作线程长时间使用的情况下，能确保尽可能少的分配线程。 弊端：内部使用无界队列来存放排队任务，当大量任务超过线程池最大容量需要处理时，队列无线增大，使服务器资源迅速耗尽。 newCachedThreadPool 创建“可缓存线程池”在接收新的异步任务 target 执行目标实例时，如果池内所有线程繁忙，此线程池会添加新线程来处理任务。2.此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。3.如果部分线程空闲，也就是存量线程的数量超过了处理任务数量，那么就会回收空闲（60 秒不执行任务）线程。适用场景：需要快速处理突发性强、耗时较短的任务场景，如 Netty 的NIO 处理场景、REST API 接口的瞬时削峰场景。“可缓存线程池”的线程数量不固定，只要有空闲线程就会被回收；接收到的新异步任务执行目标，查看是否有线程处于空闲状态，如果没有就直接创建新的线程。 弊端：线程池没有最大线程数量限制，如果大量的异步任务执行目标实例同时提交，可能导致创线程过多会而导致资源耗尽。newScheduledThreadPool 创建“可调度线程池” 创建的线程池的好处？1.降低资源消耗.通过重复利用自己创建的线程降低线程创建和销毁造成的消耗.2.2.提高响应速度.当任务到达时,任务可以不需要等到线程和粗昂就爱你就能立即执行.3.3.提高线程的可管理性.线程是稀缺资源,如果无限的创线程,不仅会消耗资源,还会降低系统的稳定性,使用线程池可以进行统一分配,调优和监控shutdown只是将线程池的状态设置为SHUTWDOWN状态，正在执行的任务会继续执行下去，没有被执行的则中断。而shutdownNow则是将线程池的状态设置为STOP，正在执行的任务则被停止，没被执行任务的则返回。 synchronized ReentranLock 区别 ？synchronized和ReentrantLock的区别共同点：​ 1.都是用来协调多线程对共享对象、变量的访问​ 2.都是可重入锁，同一线程可以多次获得同一个锁​ 3.都保证了可见性和互斥性 不同点：​ 1. ReentrantLock显示地获得，释放锁，synchronized隐式获得释放锁​ 2. ReentrantLock可响应中断，可轮回，synchronized是不可以响应中断的​ 3. ReentrantLock是API级别的，synchronized是JVM级别的​ 4. ReentrantLock可以实现公平锁​ 5. ReentrantLock通过Condition可以绑定多个条件​ 6. 底层实现不一样，synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略。​ 7. Lock是一个接口，而synchronized是java中的关键字，synchronized是内置的语言实现​ 8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象， 因此使用 Lock 时需要在 finally 块中释放锁。 33 ThreadLocalThreadLocal是一个关于创建线程局部变量的类。ThreadLocal的作用主要是做数据隔离，填充的数据只属于当前线程，变量的数据对别的线程而言是相对隔离的，在多线程环境下，如何防止自己的变量被其它线程篡改。隔离有什么用，会用在什么场景么? 事务隔离级别通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程则无法访问和修改。 private void testThreadLocal() {Thread t = new Thread() {ThreadLocal mStringThreadLocal = new ThreadLocal&lt;&gt;();@Overridepublic void run() { super.run(); mStringThreadLocal.set(“droidyue.com”); mStringThreadLocal.get();}};t.start();} ThreadLocal初始值为ThreadLocal设置默认的get初始值，需要重写initialValue方法，下面是一段代码，我们将默认值修改成了线程的名字ThreadLocal mThreadLocal = new ThreadLocal() { @Override protected String initialValue() { return Thread.currentThread().getName(); }}; 底层实现的原理ThreadLocal的set方法1 首先获取当前线程2 利用当前线程作为句柄获取一个ThreadLocalMap的对象3 如果上述ThreadLocalMap对象不为空，则设置值，否则创建这个ThreadLocalMap对象并设置值 源码如下 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);} 下面是一个利用Thread对象作为句柄获取ThreadLocalMap对象的代码ThreadLocalMap getMap(Thread t) { return t.threadLocals;} 上面的代码获取的实际上是Thread对象的threadLocals变量，可参考下面代码class Thread implements Runnable { /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; }而如果一开始设置，即ThreadLocalMap对象未创建，则新建ThreadLocalMap对象，并设置初始值。 void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 总结：实际上ThreadLocal的值是放入了当前线程的一个ThreadLocalMap实例中，所以只能在本线程中访问，其他线程无法访问。 ThreadLocalMap底层结构 ThreadLocalMap呢是当前线程Thread一个叫threadLocals的变量中获取的并未实现Map接口，而且他的Entry是继承WeakReference（弱引用）的，也没有看到HashMap中的next，所以不存在链表了。static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal> { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) { super(k); value = v; } } …… } 为什么需要数组呢？没有了链表怎么解决Hash冲突呢？用数组是因为，我们开发过程中可以一个线程可以有多个TreadLocal来存放不同类型的对象的，但是他们都将放到你当前线程的ThreadLocalMap里，所以肯定要数组来存。至于Hash冲突，我们先看一下源码： private void set(ThreadLocal key, Object value) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode & (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); } 我从源码里面看到ThreadLocalMap在存储的时候会给每一个ThreadLocal对象一个threadLocalHashCode，在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，int i = key.threadLocalHashCode &amp; (len-1)。 然后会判断一下：如果当前位置是空的，就初始化一个Entry对象放在位置i上； if (k == null) { replaceStaleEntry(key, value, i); return;}如果位置i不为空，如果这个Entry对象的key正好是即将设置的key，那么就刷新Entry中的value； if (k == key) { e.value = value; return;}如果位置i的不为空，而且key不等于entry，那就找下一个空位置，直到为空为止。 每个ThreadLocal对象都有一个hash值threadLocalHashCode，每初始化一个ThreadLocal对象，hash值就增加一个固定的大小0x61c88647。在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，过程如下：1、如果当前位置是空的，那么正好，就初始化一个Entry对象放在位置i上；2、不巧，位置i已经有Entry对象了，如果这个Entry对象的key正好是即将设置的key，那么重新设置Entry中的value；3、很不巧，位置i的Entry对象，和即将设置的key没关系，那么只能找下一个空位置；这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置可以发现，set和get如果冲突严重的话，效率很低，因为ThreadLoalMap是Thread的一个属性，所以即使在自己的代码中控制了设置的元素个数，但还是不能控制其它代码的行为。 这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置，set和get如果冲突严重的话，效率还是很低的。 以下是get的源码，是不是就感觉很好懂了： private Entry getEntry(ThreadLocal&lt;?&gt; key) { int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } private Entry getEntryAfterMiss(ThreadLocal key, int i, Entry e) { Entry[] tab = table; int len = tab.length; // get的时候一样是根据ThreadLocal获取到table的i值，然后查找数据拿到后会对比key是否相等 if (e != null && e.get() == key)。 while (e != null) { ThreadLocal k = e.get(); // 相等就直接返回，不相等就继续查找，找到相等位置。 if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; }对象存放在哪里 堆在Java中，栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存。而堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。 ThreadLocal实例实际上也是被其创建的类持有（更顶端应该是被线程持有）。而ThreadLocal的值其实也是被线程实例持有。它们都是位于堆上，只是通过一些技巧将可见性修改成了线程可见。真的只能被一个线程访问么 InheritableThreadLocal既然上面提到了ThreadLocal只对当前线程可见，是不是说ThreadLocal的值只能被一个线程访问呢？ 使用InheritableThreadLocal可以实现多个线程访问ThreadLocal的值。 如下，我们在主线程中创建一个InheritableThreadLocal的实例，然后在子线程中得到这个InheritableThreadLocal实例设置的值。private void testInheritableThreadLocal() { final ThreadLocal threadLocal = new InheritableThreadLocal(); threadLocal.set(“droidyue.com”); Thread t = new Thread() { @Override public void run() { super.run(); Log.i(LOGTAG, “testInheritableThreadLocal =” + threadLocal.get()); } }; t.start();}上面的代码输出的日志信息为I/MainActivity( 5046): testInheritableThreadLocal =droidyue.com使用InheritableThreadLocal可以将某个线程的ThreadLocal值在其子线程创建时传递过去。因为在线程创建过程中，有相关的处理逻辑。//Thread.java private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc) { //code goes here if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); }上面代码就是在线程创建的时候，复制父线程的inheritableThreadLocals的数据。会导致内存泄露么 弱引用 threadLocal.remove();有网上讨论说ThreadLocal会导致内存泄露，原因如下·首先ThreadLocal实例被线程的ThreadLocalMap实例持有，也可以看成被线程持有。·如果应用使用了线程池，那么之前的线程实例处理完之后出于复用的目的依然存活·所以，ThreadLocal设定的值被持有，导致内存泄露。上面的逻辑是清晰的，可是ThreadLocal并不会产生内存泄露，因为ThreadLocalMap在选择key的时候，并不是直接选择ThreadLocal实例，而是ThreadLocal实例的弱引用。（无论内存是否足够，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象都会被回收） ThreadLocal在保存的时候会把自己当做Key存在ThreadLocalMap中，正常情况应该是key和value都应该被外界强引用才对，但是现在key被设计成WeakReference弱引用了。 ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。就比如线程池里面的线程，线程都是复用的，那么之前的线程实例处理完之后，出于复用的目的线程依然存活，所以，ThreadLocal设定的value值被持有，导致内存泄露。按照道理一个线程使用完，ThreadLocalMap是应该要被清空的，但是现在线程被复用了。那怎么解决？在代码的最后使用remove就好了，我们只要记得在使用的最后用remove把值清空就好了。remove的源码很简单，找到对应的值全部置空，这样在垃圾回收器回收的时候，会自动把他们回收掉。那为什么ThreadLocalMap的key要设计成弱引用？key不设置成弱引用的话就会造成和entry中value一样内存泄漏的场景。补充一点：ThreadLocal的不足，我觉得可以通过看看netty的fastThreadLocal来弥补，大家有兴趣可以康康。使用场景1 实现单个线程单例以及单个线程上下文信息存储，比如交易id等2 实现线程安全，非线程安全的对象使用ThreadLocal之后就会变得线程安全，因为每个线程都会有一个对应的实例3 承载一些线程相关的数据，避免在方法中来回传递参数2.Spring实现事务隔离级别Spring采用Threadlocal的方式，来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别，巧妙地管理多个事务配置之间的切换，挂起和恢复。Spring框架里面就是用的ThreadLocal来实现这种隔离，主要是在TransactionSynchronizationManager这个类里面3.线程池加上ThreadLocal包装SimpleDataFormat，再调用initialValue让每个线程有一个SimpleDataFormat的副本，从而解决了线程安全的问题，也提高了性能。4.很多场景的cookie，session等数据隔离都是通过ThreadLocal去做实现的 JVM内存结构 VS Java内存模型 VS Java对象模型JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。Java虚拟机规范中定义了Java内存模型（Java Memory Model，JMM），用于屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果，JMM规范了Java虚拟机与计算机内存是如何协同工作的：规定了一个线程如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 JVM内存结构Java代码是要运行在虚拟机上的，而虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域，这些区域都有各自的用途。其中有些区域随着虚拟机进程的启动而存在，而有些区域则依赖用户线程的启动和结束而建立和销毁。 Java内存模型Java内存模型看上去和Java内存结构（JVM内存结构）差不多，很多人会误以为两者是一回事儿，这也就导致面试过程中经常答非所为。在前面的关于JVM的内存结构的图中，我们可以看到，其中Java堆和方法区的区域是多个线程共享的数据区域。也就是说，多个线程可能可以操作保存在堆或者方法区中的同一个数据。这也就是我们常说的“Java的线程间通过共享内存进行通信”。Java内存模型是根据英文Java Memory Model（JMM）翻译过来的。其实JMM并不像JVM内存结构一样是真实存在的。他只是一个抽象的概念。JMM是和多线程相关的，他描述了一组规则或规范，这个规范定义了一个线程对共享变量的写入时对另一个线程是可见的。那么，简单总结下，Java的多线程之间是通过共享内存进行通信的，而由于采用共享内存进行通信，在通信过程中会存在一系列如可见性、原子性、顺序性等问题，而JMM就是围绕着多线程通信以及与其相关的一系列特性而建立的模型。JMM定义了一些语法集，这些语法集映射到Java语言中就是volatile、synchronized等关键字。在Java中，JMM是一个非常重要的概念，正是由于有了JMM，Java的并发编程才能避免很多问题。这里就不对Java内存模型做更加详细的介绍了，想了解更多的朋友可以参考《Java并发编程的艺术》。 Java对象模型Java是一种面向对象的语言，而Java对象在JVM中的存储也是有一定的结构的。而这个关于Java对象自身的存储模型称之为Java对象模型。HotSpot虚拟机中，设计了一个OOP-Klass Model。OOP（Ordinary Object Pointer）指的是普通对象指针，而Klass用来描述对象实例的具体类型。每一个Java类，在被JVM加载的时候，JVM会给这个类创建一个instanceKlass，保存在方法区，用来在JVM层表示该Java类。当我们在Java代码中，使用new创建一个对象的时候，JVM会创建一个instanceOopDesc对象，这个对象中包含了对象头以及实例数据。这就是一个简单的Java对象的OOP-Klass模型，即Java对象模型。 总结我们再来区分下JVM内存结构、 Java内存模型 以及 Java对象模型 三个概念。JVM内存结构，和Java虚拟机的运行时区域有关。Java内存模型，和Java的并发编程有关。Java对象模型，和Java对象在虚拟机中的表现形式有关。 Java内存模型为什么要有内存模型在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型，然后再来看Java内存模型在计算机内存模型的基础上做了哪些事情。要说计算机的内存模型，就要说一下一段古老的历史，看一下为什么要有内存模型。 内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。那么我先给你介绍下他和硬件到底有啥关系。 CPU和缓存一致性我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。 刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。 这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。 可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。 所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。 那么，程序的执行过程就变成了： 当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。 而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。 按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L2），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。 这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。 那么，在有了多级缓存之后，程序的执行就变成了：当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。 随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。 单核CPU只含有一套L1，L2，L3缓存；如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。 公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工还有的公司，不断壮大，开始差分出各个子公司。各个子公司就是多个CPU了，互相之前没有共用的资源。互不影响。 下图为一个单CPU双核的缓存结构。随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。 单线程。cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。单核CPU，多线程。进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。多核CPU，多线程。每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的cache中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。 在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。如果这家公司的命令都是串行下发的话，那么就没有任何问题。如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。处理器优化和指令重排上面提到在在CPU和主存之间增加缓存，在多线程场景下会存在缓存一致性问题。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是处理器优化。 除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做指令重排。 可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。并发编程的问题前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。 其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。 这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性： 原子性是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。有序性即程序执行的顺序按照代码的先后顺序执行。 有没有发现，缓存一致性问题其实就是可见性问题。而处理器优化是可以导致原子性问题的。指令重排即会导致有序性问题。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。 什么是内存模型前面提到的，缓存一致性问题、处理器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？ 最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。 所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。 为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。什么是Java内存模型前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。 我们知道，Java程序是需要运行在Java虚拟机上面的，Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。 而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。 所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。 Java内存模型的实现了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurren包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。 在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。 原子性在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。在synchronized的实现原理文章中，介绍过，这两个字节码，在Java中对应的关键字就是synchronized。 因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 可见性Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。 有序性在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别： volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像synchronized关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用synchronized的原因。 但是synchronized是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。 内存模型是怎么解决缓存一致性问题的？http://www.hollischuang.com/archives/2662我们在文章中提到过，由于CPU和主存的处理速度上存在一定差别，为了匹配这种差距，提升计算机能力，人们在CPU和主存之间增加了多层高速缓存。每个CPU会有L1、L2甚至L3缓存，在多核计算机中会有多个CPU，那么就会存在多套缓存，那么这多套缓存之间的数据就可能出现不一致的现象。为了解决这个问题，有了内存模型。内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。 缓存一致性是由于引入缓存而导致的问题，所以，这是很多CPU厂商必须解决的问题。为了解决前面提到的缓存数据不一致的问题，人们提出过很多方案，通常来说有以下2种方案： 1、通过在总线加LOCK#锁的方式。2、通过缓存一致性协议（Cache Coherence Protocol）。在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从其内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是由于在锁住总线期间，其他CPU无法访问内存，会导致效率低下。因此出现了第二种解决方案，通过缓存一致性协议来解决缓存一致性问题。 缓存一致性协议缓存一致性协议（Cache Coherence Protocol），最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。 MESI的核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 在MESI协议中，每个缓存可能有有4个状态，它们分别是： M(Modified)：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。E(Exclusive)：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。S(Shared)：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。I(Invalid)：这行数据无效。 关于MESI的更多细节这里就不详细介绍了，读者只要知道，MESI是一种比较常用的缓存一致性协议，他可以用来解决缓存之间的数据一致性问题就可以了。 但是，值得注意的是，传统的MESI协议中有两个行为的执行成本比较大。 一个是将某个Cache Line标记为Invalid状态，另一个是当某Cache Line当前状态为Invalid时写入新的数据。所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时。当一个CPU进行写入时，首先会给其它CPU发送Invalid消息，然后把当前写入的数据写入到Store Buffer中。然后异步在某个时刻真正的写入到Cache中。 当前CPU核如果要读Cache中的数据，需要先扫描Store Buffer之后再读取Cache。 但是此时其它CPU核是看不到当前核的Store Buffer中的数据的，要等到Store Buffer中的数据被刷到了Cache之后才会触发失效操作。 而当一个CPU核收到Invalid消息时，会把消息写入自身的Invalidate Queue中，随后异步将其设为Invalid状态。 和Store Buffer不同的是，当前CPU核心使用Cache时并不扫描Invalidate Queue部分，所以可能会有极短时间的脏读问题。所以，为了解决缓存的一致性问题，比较典型的方案是MESI缓存一致性协议。MESI协议，可以保证缓存的一致性，但是无法保证实时性。内存模型内存模型（Memory Model）如果扩展开来说的话，通常指的是内存一致性模型（Memory Sequential Consistency Model） 前面我们提到过缓存一致性，这里又要说内存一致性，不是故意要把读者搞蒙，而是希望通过对比让读者更加清楚。缓存一致性（Cache Coherence），解决是多个缓存副本之间的数据的一致性问题。内存一致性（Memory Consistency），保证的是多线程程序访问内存时可以读到什么值。 我们首先看以下程序：初始：x=0 y=0Thread1：S1：x=1L1：r1=yThread2：S2：y=2L2：r2=x 其中，S1、S2、L1、L2是语句代号（S表示Store，L表示Load）；r1和r2是两个寄存器。x和y是两个不同的内存变量。两个线程执行完之后，r1和r2可能是什么值？注意到线程是并发、交替执行的，下面是可能的执行顺序和相应结果： S1 L1 S2 L2 那么r1=0 r2=2S1 S2 L1 L2 那么r1=2 r2=1S2 L2 S1 L1 那么r1=2 r2=0这些都是意料之内、情理之中的。但是在x86体系结构下，很可能得到r1=0 r2=0这样的结果。 如果没有Memory Consistency，程序员写的程序代码的输出结果是不确定的。因此，Memory Consistency就是程序员（编程语言）、编译器、CPU间的一种协议。这个协议保证了程序访问内存时会得到什么值。 简单点说，内存一致性，就是保证并发场景下的程序运行结果和程序员预期是一样的（当然，要通过加锁等方式），包括的就是并发编程中的原子性、有序性和可见性。而缓存一致性说的就是并发编程中的可见性。 在很多内存模型的实现中，关于缓存一致性的保证都是通过硬件层面缓存一致性协议来保证的。需要注意的是，这里提到的内存模型，是计算机内存模型，而非Java内存模型。 总结缓存一致性问题。硬件层面的问题，指的是由于多核计算机中有多套缓存，各个缓存之间的数据不一致性问题。PS：这里还需要再重复一遍，Java多线程中，每个线程都有自己的工作内存，需要和主存进行交互。这里的工作内存和计算机硬件的缓存并不是一回事儿，只是可以相互类比。所以，并发编程的可见性问题，是因为各个线程之间的本地内存数据不一致导致的，和计算机缓存并无关系。 缓存一致性协议。用来解决缓存一致性问题的，常用的是MESI协议。内存一致性模型。屏蔽计算机硬件问题，主要来解决并发编程中的原子性、有序性和一致性问题。实现内存一致性模型的时候可能会用到缓存一致性模型。 Synchronized的实现原理http://www.hollischuang.com/archives/1883 synchronized，是Java中用于解决并发情况下数据同步访问的一个很重要的关键字。当我们想要保证一个共享资源在同一时间只会被一个线程访问到时，我们可以在代码中使用synchronized关键字对类或者对象加锁。 反编译后，对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现同步。 方法级的同步是隐式的。同步方法的常量池中会有一个ACC_SYNCHRONIZED标志。当某个线程要访问某个方法的时候，会检查是否有ACC_SYNCHRONIZED，如果有设置，则需要先获得监视器锁，然后开始执行方法，方法执行之后再释放监视器锁。这时如果其他线程来请求执行方法，会因为无法获得监视器锁而被阻断住。值得注意的是，如果在方法执行过程中，发生了异常，并且方法内部并没有处理该异常，那么在异常被抛到方法外面之前监视器锁会被自动释放。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步。 可以把执行monitorenter指令理解为加锁，执行monitorexit理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁（执行monitorenter）后，该计数器自增变为 1 ，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁（执行monitorexit指令）的时候，计数器再自减。当计数器为0的时候。锁将被释放，其他线程便可以获得锁。 总结 同步方法通过ACC_SYNCHRONIZED关键字隐式的对方法进行加锁。当线程要执行的方法被标注上ACC_SYNCHRONIZED时，需要先获得锁才能执行该方法。 同步代码块通过monitorenter和monitorexit执行来进行加锁。当线程执行到monitorenter的时候要先获得所锁，才能执行后面的方法。当线程执行到monitorexit的时候则要释放锁。 每个对象自身维护这一个被加锁次数的计数器，当计数器数字为0时表示可以被任意线程获得锁。当计数器不为0时，只有获得锁的线程才能再次获得锁。即可重入锁。 Moniter的实现原理http://www.hollischuang.com/archives/2030 为什么synchronized无法禁止指令重排，却能保证有序性？http://www.hollischuang.com/archives/4460先我们要分析下这道题，不得不说这个面试官还是有一定的水平的，这简单的一个问题，其实里面还是包含了很多信息的，要想回答好这个问题，面试者至少要知道一下概念： Java内存模型、并发编程有序性问题、指令重排、synchronized锁、可重入锁、排它锁、as-if-serial语义、单线程&amp;多线程 所以，这道题的正确回答姿势是怎样的呢？ 这是个好问题，这个问题我曾经也思考过，也查阅过很多资料，甚至还去看过hotsopt的源码。不管三七二十一，上来先舔一波，然后表示下自己求知好学的态度。为了进一步提升计算机各方面能力，在硬件层面做了很多优化，如处理器优化和指令重排等，但是这些技术的引入就会导致有序性问题。先告诉面试官你知道什么是有序性问题，也知道是什么原因导致的有序性问题我们也知道，最好的解决有序性问题的办法，就是禁止处理器优化和指令重排，就像volatile中使用内存屏障一样。表明你知道啥是指令重排，也知道他的实现原理但是，虽然很多硬件都会为了优化做一些重排，但是在Java中，不管怎么排序，都不能影响单线程程序的执行结果。这就是as-if-serial语义，所有硬件优化的前提都是必须遵守as-if-serial语义。重点！解释下什么是as-if-serial语义，因为这是这道题的第一个关键词，答上来就对了一半了再说下synchronized，他是Java提供的锁，可以通过他对Java中的对象加锁，并且他是一种排他的、可重入的锁。装X项，不留痕迹的展示自己对锁了解的比较多所以，当某个线程执行到一段被synchronized修饰的代码之前，会先进行加锁，执行完之后再进行解锁。在加锁之后，解锁之前，其他线程是无法再次获得锁的，只有这条加锁线程可以重复获得该锁。介绍synchronized的原理，这是本题的第二个关键点，到这里基本就可以拿满分了。synchronized通过排他锁的方式就保证了同一时间内，被synchronized修饰的代码是单线程执行的。所以呢，这就满足了as-if-serial语义的一个关键前提，那就是单线程，因为有as-if-serial语义保证，单线程的有序性就天然存在了。 volatile关键字https://juejin.cn/post/6844903656274264078https://juejin.cn/post/6844903520760496141https://www.cnblogs.com/dolphin0520/p/3920373.htmlhttps://monkeysayhi.github.io/2016/11/29/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%9C%E7%94%A8%E3%80%81%E5%8E%9F%E7%90%86/ volatile的用法volatile通常被比喻成”轻量级的synchronized”，也是Java并发编程中比较重要的一个关键字。和synchronized不同，volatile是一个变量修饰符，只能用来修饰变量。无法修饰方法及代码块等。volatile的用法比较简单，只需要在声明一个可能被多线程同时访问的变量时，使用volatile修饰就可以了。public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; }} 复制代码如以上代码，是一个比较典型的使用双重锁校验的形式实现单例的，其中使用volatile关键字修饰可能被多个线程同时访问到的singleton。volatile的原理在再有人问你Java内存模型是什么，就把这篇文章发给他中我们曾经介绍过，为了提高处理器的执行速度，在处理器和内存之间增加了多级缓存来提升。但是由于引入了多级缓存，就存在缓存数据不一致问题。但是，对于volatile变量，当对volatile变量进行写操作的时候，JVM会向处理器发送一条lock前缀的指令，将这个缓存中的变量回写到系统主存中。但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议缓存一致性协议：每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。所以，如果一个变量被volatile所修饰的话，在每次数据变化之后，其值都会被强制刷入主存。而其他处理器的缓存由于遵守了缓存一致性协议，也会把这个变量的值从主存加载到自己的缓存中。这就保证了一个volatile在并发编程中，其值在多个缓存中是可见的。volatile与可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。所以，就可能出现线程1改了某个变量的值，但是线程2不可见的情况。前面的关于volatile的原理中介绍过了，Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。volatile与有序性有序性即程序执行的顺序按照代码的先后顺序执行。我们在再有人问你Java内存模型是什么，就把这篇文章发给他中分析过：除了引入了时间片以外，由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load-&gt;add-&gt;save 有可能被优化成load-&gt;save-&gt;add 。这就是可能存在有序性问题。而volatile除了可以保证数据的可见性之外，还有一个强大的功能，那就是他可以禁止指令重排优化等。普通的变量仅仅会保证在该方法的执行过程中所依赖的赋值结果的地方都能获得正确的结果，而不能保证变量的赋值操作的顺序与程序代码中的执行顺序一致。volatile可以禁止指令重排，这就保证了代码的程序会严格按照代码的先后顺序执行。这就保证了有序性。被volatile修饰的变量的操作，会严格按照代码顺序执行，load-&gt;add-&gt;save 的执行顺序就是：load、add、save。volatile与原子性原子性是指一个操作是不可中断的，要全部执行完成，要不就都不执行。线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。当一个线程获得时间片之后开始执行，在时间片耗尽之后，就会失去CPU使用权。所以在多线程场景下，由于时间片在线程间轮换，就会发生原子性问题。在上一篇文章中，我们介绍synchronized的时候，提到过，为了保证原子性，需要通过字节码指令monitorenter和monitorexit，但是volatile和这两个指令之间是没有任何关系的。所以，volatile是不能保证原子性的。 在以下两个场景中可以使用volatile来代替synchronized：1、运算结果并不依赖变量的当前值，或者能够确保只有单一的线程会修改变量的值。2、变量不需要与其他状态变量共同参与不变约束。除以上场景外，都需要使用其他方式来保证原子性，如synchronized或者concurrent包。总结与思考我们介绍过了volatile关键字和synchronized关键字。现在我们知道，synchronized可以保证原子性、有序性和可见性。而volatile却只能保证有序性和可见性。那么，我们再来看一下双重校验锁实现的单例，已经使用了synchronized，为什么还需要volatile？ public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; }} Synchronized vs volatile我们都知道synchronized其实是一种加锁机制，那么既然是锁，天然就具备以下几个缺点： 1、有性能损耗 适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等无论是使用同步方法还是同步代码块，在同步操作之前还是要进行加锁，同步操作之后需要进行解锁，这个加锁、解锁的过程是要有性能损耗的。 关于二者的性能对比，由于虚拟机对锁实行的许多消除和优化，使得我们很难量化这两者之间的性能差距，但是我们可以确定的一个基本原则是：volatile变量的读操作的性能小号普通变量几乎无差别，但是写操作由于需要插入内存屏障所以会慢一些，即便如此，volatile在大多数场景下也比锁的开销要低。 2、产生阻塞synchronize的实现原理，无论是同步方法还是同步代码块，无论是ACC_SYNCHRONIZED还是monitorenter、monitorexit都是基于Monitor实现的。 基于Monitor对象，当多个线程同时访问一段同步代码时，首先会进入Entry Set，当有一个线程获取到对象的锁之后，才能进行The Owner区域，其他线程还会继续在Entry Set等待。并且当某个线程调用了wait方法后，会释放锁并进入Wait Set等待。所以，synchronize实现的锁本质上是一种阻塞锁，也就是说多个线程要排队访问同一个共享对象。 而volatile是Java虚拟机提供的一种轻量级同步机制，他是基于内存屏障实现的。说到底，他并不是锁，所以他不会有synchronized带来的阻塞和性能损耗的问题。 volatile的附加功能除了前面我们提到的volatile比synchronized性能好以外，volatile其实还有一个很好的附加功能，那就是禁止指令重排。 我们先来举一个例子，看一下如果只使用synchronized而不使用volatile会发生什么问题，就拿我们比较熟悉的单例模式来看。 我们通过双重校验锁的方式实现一个单例，这里不使用volatile关键字： 1 public class Singleton { 2 private static Singleton singleton; 3 private Singleton (){} 4 public static Singleton getSingleton() { 5 if (singleton == null) { 6 synchronized (Singleton.class) { 7 if (singleton == null) { 8 singleton = new Singleton(); 9 } 10 } 11 } 12 return singleton; 13 } 14 }以上代码，我们通过使用synchronized对Singleton.class进行加锁，可以保证同一时间只有一个线程可以执行到同步代码块中的内容，也就是说singleton = new Singleton()这个操作只会执行一次，这就是实现了一个单例。 但是，当我们在代码中使用上述单例对象的时候有可能发生空指针异常。这是一个比较诡异的情况。 我们假设Thread1 和 Thread2两个线程同时请求Singleton.getSingleton方法的时候：Step1 ,Thread1执行到第8行，开始进行对象的初始化。Step2 ,Thread2执行到第5行，判断singleton == null。Step3 ,Thread2经过判断发现singleton ！= null，所以执行第12行，返回singleton。 Step4 ,Thread2拿到singleton对象之后，开始执行后续的操作，比如调用singleton.call()。 以上过程，看上去并没有什么问题，但是，其实，在Step4，Thread2在调用singleton.call()的时候，是有可能抛出空指针异常的。 之所有会有NPE抛出，是因为在Step3，Thread2拿到的singleton对象并不是一个完整的对象。 我们这里来分析一下，singleton = new Singleton();这行代码到底做了什么事情，大致过程如下： 1、虚拟机遇到new指令，到常量池定位到这个类的符号引用。2、检查符号引用代表的类是否被加载、解析、初始化过。3、虚拟机为对象分配内存。4、虚拟机将分配到的内存空间都初始化为零值。5、虚拟机对对象进行必要的设置。6、执行方法，成员变量进行初始化。7、将对象的引用指向这个内存区域。 我们把这个过程简化一下，简化成3个步骤：a、JVM为对象分配一块内存M b、在内存M上为对象进行初始化 c、将内存M的地址复制给singleton变量因为将内存的地址赋值给singleton变量是最后一步，所以Thread1在这一步骤执行之前，Thread2在对singleton==null进行判断一直都是true的，那么他会一直阻塞，直到Thread1将这一步骤执行完。但是，以上过程并不是一个原子操作，并且编译器可能会进行重排序，如果以上步骤被重排成：a、JVM为对象分配一块内存Mc、将内存的地址复制给singleton变量b、在内存M上为对象进行初始化这样的话，Thread1会先执行内存分配，在执行变量赋值，最后执行对象的初始化，那么，也就是说，在Thread1还没有为对象进行初始化的时候，Thread2进来判断singleton==null就可能提前得到一个false，则会返回一个不完整的sigleton对象，因为他还未完成初始化操作。 这种情况一旦发生，我们拿到了一个不完整的singleton对象，当尝试使用这个对象的时候就极有可能发生NPE异常。 那么，怎么解决这个问题呢？因为指令重排导致了这个问题，那就避免指令重排就行了。 所以，volatile就派上用场了，因为volatile可以避免指令重排。只要将代码改成以下代码，就可以解决这个问题： 1 public class Singleton { 2 private volatile static Singleton singleton; 3 private Singleton (){} 4 public static Singleton getSingleton() { 5 if (singleton == null) { 6 synchronized (Singleton.class) { 7 if (singleton == null) { 8 singleton = new Singleton(); 9 } 10 } 11 } 12 return singleton; 13 } 14 }对singleton使用volatile约束，保证他的初始化过程不会被指令重排。synchronized的有序性保证呢？看到这里可能有朋友会问了，说到底上面问题还是个有序性的问题，不是说synchronized是可以保证有序性的么，这里为什么就不行了呢？ 首先，可以明确的一点是：synchronized是无法禁止指令重排和处理器优化的。那么他是如何保证的有序性呢？ 这就要再把有序性的概念扩展一下了。Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是天然有序的。如果在一个线程中观察另一个线程，所有操作都是无序的。 以上这句话也是《深入理解Java虚拟机》中的原句，但是怎么理解呢？周志明并没有详细的解释。这里我简单扩展一下，这其实和as-if-serial语义有关。 as-if-serial语义的意思指：不管怎么重排序，单线程程序的执行结果都不能被改变。编译器和处理器无论如何优化，都必须遵守as-if-serial语义。 这里不对as-if-serial语义详细展开了，简单说就是，as-if-serial语义保证了单线程中，不管指令怎么重排，最终的执行结果是不能被改变的。 那么，我们回到刚刚那个双重校验锁的例子，站在单线程的角度，也就是只看Thread1的话，因为编译器会遵守as-if-serial语义，所以这种优化不会有任何问题，对于这个线程的执行结果也不会有任何影响。 但是，Thread1内部的指令重排却对Thread2产生了影响。 那么，我们可以说，synchronized保证的有序性是多个线程之间的有序性，即被加锁的内容要按照顺序被多个线程执行。但是其内部的同步代码还是会发生重排序，只不过由于编译器和处理器都遵循as-if-serial语义，所以我们可以认为这些重排序在单线程内部可忽略。 总结本文从两方面论述了volatile的重要性以及不可替代性： 一方面是因为synchronized是一种锁机制，存在阻塞问题和性能问题，而volatile并不是锁，所以不存在阻塞和性能问题。 另外一方面，因为volatile借助了内存屏障来帮助其解决可见性和有序性问题，而内存屏障的使用还为其带来了一个禁止指令重排的附件功能，所以在有些场景中是可以避免发生指令重排的问题的。 同步容器（如Vector）的所有操作一定是线程安全的？http://www.hollischuang.com/archives/3935为了方便编写出线程安全的程序，Java里面提供了一些线程安全类和并发工具，比如：同步容器、并发容器、阻塞队列等。最常见的同步容器就是Vector和Hashtable了，那么，同步容器的所有操作都是线程安全的吗？这个问题不知道你有没有想过，本文就来深入分析一下这个问题，一个很容易被忽略的问题。Java中的同步容器在Java中，同步容器主要包括2类：1、Vector、Stack、HashTable2、Collections类中提供的静态工厂方法创建的类本文拿相对简单的Vecotr来举例，我们先来看下Vector中几个重要方法的源码：public synchronized boolean add(E e) { modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;}public synchronized E remove(int index) { modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return oldValue;} public synchronized E get(int index) { if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index);return elementData(index);}可以看到，Vector这样的同步容器的所有公有方法全都是synchronized的，也就是说，我们可以在多线程场景中放心的使用单独这些方法，因为这些方法本身的确是线程安全的。但是，请注意上面这句话中，有一个比较关键的词：单独因为，虽然同步容器的所有方法都加了锁，但是对这些容器的复合操作无法保证其线程安全性。需要客户端通过主动加锁来保证。简单举一个例子，我们定义如下删除Vector中最后一个元素方法：public Object deleteLast(Vector v){ int lastIndex = v.size()-1; v.remove(lastIndex);}上面这个方法是一个复合方法，包括size(）和remove()，乍一看上去好像并没有什么问题，无论是size()方法还是remove()方法都是线程安全的，那么整个deleteLast方法应该也是线程安全的。但是时，如果多线程调用该方法的过程中，remove方法有可能抛出ArrayIndexOutOfBoundsException。Exception in thread “Thread-1” java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 879 at java.util.Vector.remove(Vector.java:834) at com.hollis.Test.deleteLast(EncodeTest.java:40) at com.hollis.Test$2.run(EncodeTest.java:28) at java.lang.Thread.run(Thread.java:748)我们上面贴了remove的源码，我们可以分析得出：当index &gt;= elementCount时，会抛出ArrayIndexOutOfBoundsException ，也就是说，当当前索引值不再有效的时候，将会抛出这个异常。因为removeLast方法，有可能被多个线程同时执行，当线程2通过index()获得索引值为10，在尝试通过remove()删除该索引位置的元素之前，线程1把该索引位置的值删除掉了，这时线程一在执行时便会抛出异常。￼为了避免出现类似问题，可以尝试加锁：public void deleteLast() { synchronized (v) { int index = v.size() - 1; v.remove(index); }}如上，我们在deleteLast中，对v进行加锁，即可保证同一时刻，不会有其他线程删除掉v中的元素。另外，如果以下代码会被多线程执行时，也要特别注意：for (int i = 0; i &lt; v.size(); i++) { v.remove(i);}由于，不同线程在同一时间操作同一个Vector，其中包括删除操作，那么就同样有可能发生线程安全问题。所以，在使用同步容器的时候，如果涉及到多个线程同时执行删除操作，就要考虑下是否需要加锁。同步容器的问题前面说过了，同步容器直接保证耽搁操作的线程安全性，但是无法保证复合操作的线程安全，遇到这种情况时，必须要通过主动加锁的方式来实现。而且，除此之外，同步容易由于对其所有方法都加了锁，这就导致多个线程访问同一个容器的时候，只能进行顺序访问，即使是不同的操作，也要排队，如get和add要排队执行。这就大大的降低了容器的并发能力。并发容器针对前文提到的同步容器存在的并发度低问题，从Java5开始，java.util.concurent包下，提供了大量支持高效并发的访问的集合类，我们称之为并发容器。￼针对前文提到的同步容器的复合操作的问题，一般在Map中发生的比较多，所以在ConcurrentHashMap中增加了对常用复合操作的支持，比如”若没有则添加”：putIfAbsent()，替换：replace()。这2个操作都是原子操作，可以保证线程安全。另外，并发包中的CopyOnWriteArrayList和CopyOnWriteArraySet是Copy-On-Write的两种实现。Copy-On-Write容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。CopyOnWriteArrayList中add/remove等写方法是需要加锁的，而读方法是没有加锁的。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，当然，这里读到的数据可能不是最新的。因为写时复制的思想是通过延时更新的策略来实现数据的最终一致性的，并非强一致性。但是，作为代替Vector的CopyOnWriteArrayList并没有解决同步容器的复合操作的线程安全性问题。总结本文介绍了同步容器和并发容器。同步容器是通过加锁实现线程安全的，并且只能保证单独的操作是线程安全的，无法保证复合操作的线程安全性。并且同步容器的读和写操作之间会互相阻塞。并发容器是Java 5中提供的，主要用来代替同步容器。有更好的并发能力。而且其中的ConcurrentHashMap定义了线程安全的复合操作。在多线程场景中，如果使用并发容器，一定要注意复合操作的线程安全问题。必要时候要主动加锁。在并发场景中，建议直接使用java.util.concurent包中提供的容器类，如果需要复合操作时，建议使用有些容器自身提供的复合方法。 锁分类可中断锁：在等待获取锁过程中可中断。synchronized就不是可中断锁，而Lock是可中断锁。读写锁对资源读取和写入的时候拆分为2部分处理，一个读锁和一个写锁。读的时候可以多线程一起读，写的时候必须同步地写。ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。可以通过readLock()获取读锁，通过writeLock()获取写锁。 乐观锁 (冲突检测和数据更新)很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会去判断在此期间有没有人去更新这个数据（可以使用版本号等机制）。如果因为冲突失败就重试。乐观锁适用于写比较少的情况下，即冲突比较少发生，这样可以省去了锁的开销，加大了系统的整个吞吐量。像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁的实现方式（CAS）乐观锁的实现主要就两个步骤：冲突检测和数据更新。其实现方式有一种比较典型的就是 Compare and Swap ( CAS )。CAS：CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS 操作中包含三个操作数 —— **需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)**。 如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 乐观锁是一种思想，CAS是这种思想的一种实现方式。 CAS的缺点 ABA问题 如果内存地址V初次读取的值是A，并且在准备赋值的时候检查到它的值仍然为A，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。java并发包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。因此，在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。循环时间长开销很大 自旋CAS（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 只能保证一个共享变量的原子操作。 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，因此每次拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁，效率比较低。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。 公平锁是指多个线程按照申请锁的顺序来获取锁，类似排队打饭，先来后到。 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。在高并发的情况下，有可能造成优先级反转或者饥饿现象。ReentrantLock默认是非公平锁，但是可以设置为true成为公平锁，Synchonized也是非公平锁。 可重入锁（递归锁）指的是同一线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。线程可以进入任何一个它已经拥有的锁所同步着的代码块。最大作用：避免死锁ReentrantLock和Synchonized都是可重入锁。 public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(“doAdd…”); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd… }} /**注意：Lock.lock();和Lock.unlock();个数匹配，多少个锁都可以正常运行，若是不匹配，则程序运行卡死。*/public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(“doAdd…”); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }}自旋锁指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 手动实行自旋锁 public class SpinLock { private AtomicReference atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + “ coming…”); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + “ unlock…”); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(“hahaha”); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); } } 死锁 及 如何解决什么是死锁：两个进程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是两个进程都陷入了无限的等待中。 产生死锁的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用。请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 考虑如下情形： 线程A当前持有互斥锁lock1，线程B当前持有互斥锁lock2。 线程A试图获取lock2，因为线程B正持有lock2，因此线程A会阻塞等待线程B对lock2释放。 如果此时线程B也在试图获取lock1，同理线程也会阻塞。 两者都在等待对方所持有但是双方都不释放的锁，这时便会一直阻塞形成死锁。 死锁的解决方法: 撤消陷于死锁的全部进程； 逐个撤消陷于死锁的进程，直到死锁不存在； 从陷于死锁的进程中逐个强迫放弃所占用的资源，直至死锁消失。 从另外一些进程那里强行剥夺足够数量的资源分配给死锁进程，以解除死锁状态如何确保 N 个线程可以访问 N 个资源同时又不导致死锁？使用多线程的时候，一种非常简单的避免死锁的方式就是：指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了 乐观锁的业务场景及实现方式说说线程安全的问题死锁在多道程序环境中，多个进程可以竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。有时，如果所申请的资源被其他等待进程占有，那么该等待进程有可能再也无法改变状态。这种情况称为死锁。 “当两列列车在十字路口逼近时，它们应完全停下来，并且在一列列车开走之前另一列列车不能再次启动。”死锁特征发生死锁时，进程永远不能完成，系统资源被阻碍使用，以致于阻止了其他作业开始执行。在讨论处理死锁问题的各种方法之前，我们首先深入讨论一下死锁特点。 必要条件如果在一个系统中以下四个条件同时成立，那么就能引起死锁：1 互斥：至少有一个资源必须处于非共享模式，即一次只有一个进程可使用。如果另一进程申请该资源，那么申请进程应等到该资源释放为止。2 占有并等待：—个进程应占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有。3 非抢占：资源不能被抢占，即资源只能被进程在完成任务后自愿释放。4 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有。我们强调所有四个条件必须同时成立才会出现死锁。循环等待条件意味着占有并等待条件，这样四个条件并不完全独立。 死锁处理方法一般来说，处理死锁问题有三种方法：1 通过协议来预防或避免死锁，确保系统不会进入死锁状态。2 可以允许系统进入死锁状态，然后检测它，并加以恢复。3 可以忽视这个问题，认为死锁不可能在系统内发生。 1.撤消陷于死锁的全部进程；2.逐个撤消陷于死锁的进程，直到死锁不存在；3.从陷于死锁的进程中逐个强迫放弃所占用的资源，直至死锁消失。4.从另外一些进程那里强行剥夺足够数量的资源分配给死锁进程，以解除死锁状态 如何确保 N 个线程可以访问 N 个资源同时又不导致死锁？使用多线程的时候，一种非常简单的避免死锁的方式就是：指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了 银行家算法 避免死锁 在进程提出资源申请时，先预判此分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。 算法步骤1、检查此次申请是否超过了之前声明的最大需求数2、检查此时系统剩余的可用资源是否还能满足这次请求3、试探着分配，更改数据结构4、用安全性算法检查此次分配是否会导致系统进入不安全状态 锁的四种状态与锁升级过程http://t.zoukankan.com/mingyueyy-p-13054296.html 无锁、偏向锁、轻量级锁、重量级锁并且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级（从低级别到高级别），不能锁降级（高级别到低级别），意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 在 synchronized 最初的实现方式是 “阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长”，这种方式就是 synchronized实现同步最初的方式，这也是当初开发者诟病的地方，这也是在JDK6以前 synchronized效率低下的原因，JDK6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁状态一种有四种，从级别由低到高依次是：无锁、偏向锁，轻量级锁，重量级锁，锁状态只能升级，不能降级锁状态的思路以及特点锁状态 存储内容 标志位无锁 对象的hashCode、对象分代年龄、是否是偏向锁(0) 01偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁(1) 01轻量级锁 指向栈中锁记录的指针 00重量级锁 指向互斥量的指针 11synchronized 用的锁是存在Java对象头里的，那么什么是对象头呢？Java 对象头我们以 Hotspot 虚拟机为例，Hopspot 对象头主要包括两部分数据：Mark Word（标记字段） 和 Klass Pointer（类型指针）Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。在上面中我们知道了，synchronized 用的锁是存在Java对象头里的，那么具体是存在对象头哪里呢？答案是：存在锁对象的对象头的Mark Word中，那么MarkWord在对象头中到底长什么样，它到底存储了什么呢？在64位的虚拟机中： 下面我们以 32位虚拟机为例，来看一下其 Mark Word 的字节具体是如何分配的 无锁：对象头开辟 25bit 的空间用来存储对象的 hashcode ，4bit 用于存放对象分代年龄，1bit 用来存放是否偏向锁的标识位，2bit 用来存放锁标识位为01 偏向锁： 在偏向锁中划分更细，还是开辟 25bit 的空间，其中23bit 用来存放线程ID，2bit 用来存放 Epoch，4bit 存放对象分代年龄，1bit 存放是否偏向锁标识， 0表示无锁，1表示偏向锁，锁的标识位还是01 轻量级锁：在轻量级锁中直接开辟 30bit 的空间存放指向栈中锁记录的指针，2bit 存放锁的标志位，其标志位为00 重量级锁： 在重量级锁中和轻量级锁一样，30bit 的空间用来存放指向重量级锁的指针，2bit 存放锁的标识位，为11 GC标记： 开辟30bit 的内存空间却没有占用，2bit 空间存放锁标志位为11。 其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态 关于内存的分配，我们可以在git中openJDK中 markOop.hpp 可以看出： public: // Constants enum { age_bits = 4, lock_bits = 2, biased_lock_bits = 1, max_hash_bits = BitsPerWord - age_bits - lock_bits - biased_lock_bits, hash_bits = max_hash_bits &gt; 31 ? 31 : max_hash_bits, cms_bits = LP64_ONLY(1) NOT_LP64(0), epoch_bits = 2 };age_bits： 就是我们说的分代回收的标识，占用4字节lock_bits： 是锁的标志位，占用2个字节biased_lock_bits： 是是否偏向锁的标识，占用1个字节max_hash_bits： 是针对无锁计算的hashcode 占用字节数量，如果是32位虚拟机，就是 32 - 4 - 2 -1 = 25 byte，如果是64 位虚拟机，64 - 4 - 2 - 1 = 57 byte，但是会有 25 字节未使用，所以64位的 hashcode 占用 31 bytehash_bits： 是针对 64 位虚拟机来说，如果最大字节数大于 31，则取31，否则取真实的字节数cms_bits： 不是64位虚拟机就占用 0 byte，是64位就占用 1byteepoch_bits： 就是 epoch 所占用的字节大小，2字节。 MonitorMonitor 可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为内部锁或者 Monitor 锁。 Monitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的 Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为重量级锁。 随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。JDK 1.6中默认是开启偏向锁和轻量级锁的，我们也可以通过-XX:-UseBiasedLocking=false来禁用偏向锁。 6.2 无锁无锁是指没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。无锁的特点是修改操作会在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。6.3 偏向锁初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。偏向锁是指当一段同步代码一直被同一个线程所访问时，即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能。当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行时，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁，恢复到无锁（标志位为01）或轻量级锁（标志位为00）的状态。6.4 轻量级锁（自旋锁）轻量级锁是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁，其他线程会通过自旋（关于自旋的介绍见文末）的形式尝试获取锁，线程不会阻塞，从而提高性能。 轻量级锁的获取主要由两种情况：① 当关闭偏向锁功能时；② 由于多个线程竞争偏向锁导致偏向锁升级为轻量级锁。 一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。这里要明确一下什么是锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果多个线程用一个锁，但是没有发生锁竞争，或者发生了很轻微的锁竞争，那么synchronized就用轻量级锁，允许短时间的忙等现象。这是一种折衷的想法，短时间的忙等，换取线程在用户态和内核态之间切换的开销。 6.4 重量级锁重量级锁显然，此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。 重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。 简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资 AQS（抽象队列同步器）先上一张类图，便于了解ReentrantLock、AQS之间的关系，这样对于他们之间的相互调用的关系更清楚：可以看到，ReentrantLock类中有三个内部类：Sync、FairSync（公平锁）和NonfairSync（非公平锁），Sync都是AQS的子类，FairSync和NonfairSync是Sync的子类；AQS中有一个静态内部类Node，Node相当于一个节点，用于构建同步队列用的，这个下面会讲到 ReentranLock【1】什么是可重入，什么是可重入锁? 它用来解决什么问题?【2】ReentrantLock 的核心是 AQS，那么它怎么来实现的，继承吗? 说说其类内部结构关系。【3】ReentrantLock 是如何实现公平锁的?【4】ReentrantLock 是如何实现非公平锁的?【5】ReentrantLock 默认实现的是公平还是非公平锁?【6】使用ReentrantLock 实现公平和非公平锁的示例?【7】ReentrantLock 和 Synchronized的对比? 25.redis 分布式锁分布式锁-Redis实现基础首先Redis是单线程的，这里的单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。而且Redis的性能很好，即使在多个服务争抢锁的时候也能够从容处理众多请求。 方案1加锁命令 SET [KEY] [VALUE] NX解锁命令 DEL [KEY]这是最基础的使用方式，加锁时因为存在NX关键词，所以只有当该KEY不存在的才能成功加锁。解锁时直接删除即可。这种方式也需单机Demo中能够正常运行，但是在分布式环境中就会产生其他问题。 如果某项业务在加锁后程序未执行解锁便退出了，这种情况下，将会造成死锁的情况 ，该位置的锁会永远不能解锁。 方案2基于上面的弊端与缺陷，我们改进加锁命令就有：加锁命令 SET [KEY] [VALUE] NX PX 30000解锁命令 DEL [KEY]在加锁命令中，同时为该锁设置一个过期时间，可以一定程度上避免方案1中出现的死锁情况。现方案会有两个问题： 解锁指令不够健壮，可能会导致误解锁的情况。如果加锁者与解锁者不是同一个，业务可能会导致许多问题。过期时间可能会与业务运行情况强行相关，且影响性能。过期时间设置得过短，可能在业务没运行完的时候就解锁了；过期时间设置过长，在加锁者宕机的情况下，其他服务器等待时间过长，影响性能。 方案3 #加锁命令SET [KEY] [VALUE] NX PX 30000解锁命令if redis.call (“get”,KEYS[1]) == ARGV[1] then return redis.call(“del”,KEYS[1])else return 0End修改：1.设置保护线程在加锁成功后不断的更新过期时间。2. 解锁命令由Lua脚本替代。由于解锁命令需要进行两次Redis操作，第一步为判断该KEY的VALUE和输入的VALUE是否一致，是的情况下进行第二步，删除该KEY，Redis中可以保证每一条命令是原子性的，但是连续两条命令是并不能保证，因此使用Lua脚本可以将两条命令合二为一，使解锁命令为原子操作。 Redisson - WatchDogRedisson中已经实现的WatchDog机制，也就是方案三种的守护线程的工作。 大家都知道，如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 Redisson中的WatchDog机制是一种无限递归调用的方式，该方法的定义为： updateExpireTime(){ async{ sleep(5000); setExpireTime(); updateExpireTime(); }}该方法通过异步调用形式，能够以每5min的频率更新Expire值 Redis的部署模式有3种：单机部署Master-Slave集群不论是方案3还是方案4，在单机中能够正常运行，但是并不能达到高可用性的要求。如果是主从模式，如果发生在Master节点加锁后，锁信息还未通知到Slave节点的情况下，锁信息会丢失，所以在高可用上仍然有一些问题，因此Redis的作者提出了RedLock算法来解决该问题。 RedLockantirez提出的redlock算法大概是这样的： 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。为了取到锁，客户端应该执行以下操作: · 获取当前Unix时间，以毫秒为单位。· 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。· 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。· 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。· 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。 zookeeper分布式锁分布式锁-ZooKeeper ZooKeeper可以创建4种类型的节点 #持久性节点 PERSISTENT持久性顺序节点 PERSISTENT_SEQUENTIAL临时性节点 EPHEMERAL临时性顺序节点 EPHEMERAL_SEQUENTIAL持久性节点和临时性节点的区别： 持久性节点表示只要你创建了这个节点，那不管你ZooKeeper的客户端是否断开连接，ZooKeeper的服务端都会记录这个节点；临时性节点刚好相反，一旦你ZooKeeper客户端断开了连接，那ZooKeeper服务端就不再保存这个节点；顺序性节点是指，在创建节点的时候，ZooKeeper会自动给节点编号比如0000001，0000002这种的。优化 Zookeeper有一个监听机制，客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）等，Zookeeper将会通知客户端。假设server-1，创建了一个节点 /lock，成功了，那server-1就获取了锁，server-2再去创建相同的锁，就会失败，这个时候就只能监听这个节点的变化。等到server-1处理完业务，删除节点，释放锁后，server-2就会得到通知，然后去创建同样的节点，获取锁后开始处理业务，再删除节点释放锁，后续的100台服务器与之类似。注意：这里的100台服务器并不是逐个执行上面的创建节点的操作，而是并发的，当服务器1创建成功，那么剩下的99个就都会同时注册监听这个节点，等通知，以此类推。这个时候就需要用到临时性节点了，前文提到，临时性节点的特点是客户端一旦断开，就会丢失，也就是当server-1创建了节点后，如果服务挂了，则该节点会自动被删除，这样后续的其他服务器，就可以继续去创建节点，获取锁了。另外我们还需注意的是惊群效应：举一个很简单的例子，当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到…也就是说当server-1节点有变化，会通知其余的99个服务器，但是最终只有1个服务器会创建成功，这样98还是需要等待监听，那么为了处理这种情况，就需要用到临时顺序性节点。大致意思就是，之前是所有99个服务器都监听一个节点，现在就是每一个服务器监听自己前面的一个节点。假设100个服务器同时发来请求，这个时候会在/lock节点下创建100个临时顺序性节点/lock/001，/lock/002，一直到/lock/100，这个编号就等于是已经给他们设置了获取锁的先后顺序了。一般实现 利用ZooKeeper的临时性节点，构建分布式锁。服务通过请求创建锁节点，成功则代表加锁成功，失败则代表加锁。基于临时性节点的定义，当服务离线时，由该服务创建的节点将自动删除，则完成离线自动解锁操作。Curator实现 InterProcessMutex 分布式可重入排它锁 InterProcessMutex lock = new InterProcessMutex(client, LOCK_PATH);lock.acquire();lock.release();InterProcessSemaphoreMutex 分布式排它锁 InterProcessSemaphoreMutex是一种不可重入的互斥锁，也就意味着即使是同一个线程也无法在持有锁的情况下再次获得锁，所以需要注意，不可重入的锁很容易在一些情况导致死锁。InterProcessSemaphoreMutex lock = new InterProcessSemaphoreMutex(zkClient, LOCK_PATH);lock.acquire();lock.release();InterProcessReadWriteLock 分布式读写锁 读锁和读锁不互斥，只要有写锁就互斥。InterProcessReadWriteLock lock = new InterProcessReadWriteLock(zkClient, LOCK_PATH);lock.readLock().acquire();lock.readLock().release();lock.writeLock().acquire();lock.writeLock().release();InterProcessMultiLock 将多个锁作为单个实体管理的容器 InterProcessMutex lock1 = new InterProcessMutex(zkClient, LOCK_PATH + “1”);InterProcessMutex lock2 = new InterProcessMutex(zkClient, LOCK_PATH + “2”);InterProcessMultiLock lock = new InterProcessMultiLock(Arrays.asList(lock1, lock2));lock.acquire();lock.release(); 参考文章","link":"/2022/03/18/java/java-1/"},{"title":"bind header to controller","text":"12345678910111213141516171819202122232425262728293031import javax.servlet.http.HttpServletRequest;import org.springframework.core.MethodParameter;import org.springframework.web.bind.support.WebDataBinderFactory;import org.springframework.web.context.request.NativeWebRequest;import org.springframework.web.method.support.HandlerMethodArgumentResolver;import org.springframework.web.method.support.ModelAndViewContainer;import lombok.extern.slf4j.Slf4j;import summer.webserver.util.SummerUtils;@Slf4jpublic class SummerArgumentResolver implements HandlerMethodArgumentResolver { public SummerArgumentResolver() { super(); } @Override public boolean supportsParameter(MethodParameter parameter) { return SummerHeader.class.isAssignableFrom(parameter.getParameterType()); } @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) { return SummerUtils.getSummerHeader(webRequest.getNativeRequest(HttpServletRequest.class)); }} 12345678910111213141516171819@Slf4jpublic class SummerUtils { public static SummerHeader getSummerHeader(HttpServletRequest request) { User user = (User)request.getAttribute(&quot;user&quot;); String userName = Objects.isNull(user) ? request.getHeader(USER_NAME) : user.getUserName(); String userId = Objects.isNull(user) ? request.getHeader(USER_ID) : user.getUserId(); SummerHeader summerHeader = SummerHeader.builder() .userName(userName) .userId(userId) .build(); if (log.isDebugEnabled()) { log.debug(summerHeader.toString()); } request.setAttribute(&quot;summerHeader&quot;, summerHeader); return summerHeader; }} usage1234567891011121314@Api(tags = &quot;User&quot;)@RestController()@RequestMapping(ROOT_DOMAIN + &quot;/users&quot;)@Slf4jpublic class UserController { @ApiOperation(value = &quot;delete user&quot;) @DeleteMapping(&quot;/{user-id}&quot;) @ResponseStatus(HttpStatus.OK) public void deleteUser(SummerHeader summerHeader, @ApiParam(required = true) @Length(max = 10) @PathVariable(value = &quot;user-id&quot;) String userId) { userMapper.deleteById(userId); }}","link":"/2021/10/25/java/java-bind-header-to-controller/"},{"title":"时间格式 注解 验证","text":"EnumValid.java12345678910111213@Constraint(validatedBy = DateFormatValidator.class)@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface DateFormat { String message() default &quot;&quot;; String pattern() default &quot;yyyy-MM-dd HH:mm:ss&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} 校验器EnumValidator.java1234567891011121314151617181920212223242526272829303132333435public class DateFormatValidator implements ConstraintValidator&lt;DateFormat, String&gt; { private String pattern; @Override public void initialize(DateFormat dateFormat) { this.pattern = dateFormat.pattern(); } @Override public boolean isValid(String value, ConstraintValidatorContext context) { boolean isValid = (value == null) || isValid(value); if (!isValid) { throw new RuntimeException(&quot;invalid input parameter.&quot;); } return isValid; } private boolean isValid(String value) { boolean isValid = true; try { String time = URLDecoder.decode(value, &quot;UTF-8&quot;); if (pattern.length() != time.length()) { isValid = false; } else { SimpleDateFormat dateFormat = new SimpleDateFormat(pattern); dateFormat.setLenient(false); dateFormat.parse(time); } } catch (Exception e) { isValid = false; } return isValid; }} 使用的时候，注解作用在DTO字段上：12345public class RequestDto { @DateFormat(pattern = &quot;yyyy-MM-dd&quot;) private String data;}","link":"/2021/10/14/java/java-dataformat-validator/"},{"title":"枚举类型参数验证","text":"EnumValid.java1234567891011121314@Documented@Constraint(validatedBy = EnumValidator.class)@Target({ElementType.TYPE, ElementType.FIELD, ElementType.PARAMETER})@Retention(RetentionPolicy.RUNTIME)public @interface EnumValid { Class&lt;? extends Enum&lt;?&gt;&gt; enumClass(); String message() default &quot;invalid enum item value.&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} 校验器EnumValidator.java12345678910111213141516171819202122232425262728293031323334@Slf4jpublic class EnumValidator implements ConstraintValidator&lt;EnumValid, String&gt; { private Class&lt;? extends Enum&lt;?&gt;&gt; enumClass; @Override public void initialize(EnumValid enumValid) { enumClass = enumValid.enumClass(); } @Override public boolean isValid(String value, ConstraintValidatorContext context) { if (!valid(value)) { throw new RuntimeException(&quot;invalid input parameter.&quot;); return false; } return true; } private boolean valid(String value) { try { if (enumClass.isEnum()) { Method method = enumClass.getMethod(&quot;isValidName&quot;, value.getClass()); Boolean result = (Boolean)method.invoke(null, value); return result != null &amp;&amp; result; } } catch (InvocationTargetException | NoSuchMethodException | IllegalAccessException e) { throw new RuntimeException(&quot;Enum values valid error.&quot;); } return false; }} 枚举类123456789public enum SxWhetherIntEnum { YES, NO; public static boolean isValidName(String name) { return Arrays.stream(values()).anyMatch(item -&gt; item.name().equals(name)); }} 使用的时候，注解作用在DTO字段上：123456public class RequestDto { @ApiModelProperty(value = &quot;是否可转定，1-是，2-否（补充）&quot;) @EnumValid(enumClass = SxWhetherIntEnum.class) private Integer payable;} 参考文章 https://www.cnblogs.com/wjqhuaxia/p/12153053.html https://blog.csdn.net/www_tlj/article/details/103950945 https://www.cnblogs.com/wjqhuaxia/p/12153053.html","link":"/2021/10/14/java/java-enum-valid/"},{"title":"Compare-and-Swap","text":"CAS是乐观锁的一种思想，它假设线程对资源的访问是没有冲突的，同时所有的线程执行都不需要等待，可以持续执行。如果有冲突的话，就用比较+交换的方式来检测冲突，有冲突就不断重试。 CAS的全称是Compare-and-Swap，也就是比较并交换，它包含了三个参数：V，A，B，V表示要读写的内存位置，A表示旧的预期值，B表示新值，当执行CAS时，只有当V的值等于预期值A时，才会把V的值改为B，这样的方式可以让多个线程同时去修改，但也会因为线程操作失败而不断重试，对CPU有一定程序上的开销。 参考文章 https://www.bilibili.com/read/cv8757383/","link":"/2021/09/28/java/java-cas/"},{"title":"GC算法 垃圾收集器","text":"概述jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理。 因此，我们的内存垃圾回收主要集中于 **java 堆和方法区中**，在程序运行期间，这部分内存的分配和使用都是动态的. 对象存活判断判断对象是否存活一般有两种方式： 引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。 可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。 在Java语言中，GC Roots包括： 虚拟机栈中引用的对象。 方法区中类静态属性实体引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 垃圾收集算法标记 -清除算法 “标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。 它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 Getting Started with the G1 Garbage Collector The Garbage First Garbage Collector 垃圾优先型垃圾回收器调优 Java Hotspot G1 GC的一些关键技术 一步步图解G1 徹底解剖「G1GC」実装編 Part 1: Introduction to the G1 Garbage Collector Collecting and reading G1 garbage collector logs - part 2参考文章 Java中9种常见的CMS GC问题分析与解决 一文看懂 JVM 内存布局及 GC 原理 oracle gc","link":"/2021/09/29/java/java-gc/"},{"title":"Jdk8 DNS解析","text":"Java提供InetAddress类，可以对域名-IP进行正向、逆向解析。 InetAddress解析的时候一般是调用系统自带的DNS程序。 linux 默认的DNS方式是读取/etc/resolv.conf进行DNS解析。 mac 默认的方式是向网关请求获取DNS服务器，然后直接请求DNS服务器进行解析，没有读取/etc/resolv.conf。 DNSNameService 根据sun.net.spi.nameservice.nameservers指定的name server或/etc/resolv.conf文件中配置的name server进行DNS解析 根据不同的DNS分别解析域名，因此需要动态的设置DNS。 JNDI DNS服务提供者设置官方文档 1234567891011121314151617JNDI DNS service provider settingsThese properties may not be supported in future releases.---sun.net.spi.nameservice.provider.&lt;n&gt;=&lt;default|dns,sun|...&gt;Specifies the name service provider that you can use. By default, Java will use the system configured name lookup mechanism, such as file, nis, etc. You can specify your own by setting this option. &lt;n&gt; takes the value of a positive number, it indicates the precedence order with a small number takes higher precendence over a bigger number. Aside from the default provider, the JDK includes a DNS provider named &quot;dns,sun&quot;.Prior to JDK 7, the first provider that was successfully loaded was used. In JDK 7, providers are chained, which means that if a lookup on a provider fails, the next provider in the list is consulted to resolve the name.---sun.net.spi.nameservice.nameservers=&lt;server1_ipaddr,server2_ipaddr ...&gt;You can specify a comma separated list of IP addresses that point to the DNS servers you want to use. If the sun.net.spi.nameservice.nameservers property is not defined, then the provider will use any name servers already configured in the platform DNS configurationsun.net.spi.nameservice.provider.&lt;n&gt;=&lt;default|dns,sun|...&gt; 用于设置域名服务提供者= default的时候调用系统自带的DNS= dns,sun的时候，会调用sun.net.spi.nameservice.nameservers=&lt;server1_ipaddr,server2_ipaddr ...&gt;指定的DNS来解析 参考文章 Java动态解析域名 Jdk8 DNS解析 https://docs.oracle.com/javase/8/docs/technotes/guides/net/properties.html","link":"/2021/12/06/java/java-jdk-dns-resolution/"},{"title":"hashmap","text":"参考文章https://zhuanlan.zhihu.com/p/164532324这21 个刁钻的HashMap 面试题，我把阿里面试官吊打了！https://zhuanlan.zhihu.com/p/471500229","link":"/2021/09/28/java/java-hashmap/"},{"title":"jedis read timeout","text":"二、当我们获取连接后对redis进行操作时，抛出redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed out异常。 异常代码如下： 123456redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed outat redis.clients.jedis.Protocol.process(Protocol.java:79)at redis.clients.jedis.Protocol.read(Protocol.java:131)at redis.clients.jedis.Connection.getIntegerReply(Connection.java:188)at redis.clients.jedis.Jedis.sismember(Jedis.java:1266) 这是一个比较麻烦的异常，困扰了我一天的时间。我们都知道Redis是对内存进行操作，速度应该都在毫秒级，这是我们通常的认识，所以当对Redis操作出现几秒的超时时间，你能想象吗？我们还是先分析一下Jedis的源代码吧，以sadd操作为例： 12345public Long sadd(final String key, final String... members) { checkIsInMulti(); client.sadd(key, members); return client.getIntegerReply();} client是redis.clients.jedis.Client.java的实例，继承关系如下：public class Client extends BinaryClient implements Commands；public class BinaryClient extends Connection； Connection包装了对Redis server的socket操作，命令写操作通过socket.getOutputStream()输出流将命令信息发送到redis server，当写完命令后要通过socket.getInputStream()得到的输入流将命令执行结果返回，这中间必然会有一个命令执行到结果返回的延时时间，这就是一个Jedis调用redis命令操作所用的时间。需要说明的是，Redis server是单线程执行所有连接发送过来的命令的，也就是说不管并发中有多少个client在发送命令，redis-server端是单线程处理的，并按照默认的FIFO方式处理请求， 这个可在redis.conf配置文件中配置。关于redis server的详细运行机制参见：http://redis.io/documentation 所以client.sadd(key, members);调用完后只是将命令信息发送到了redis server端，具体有没有执行要看redis server的负载情况。然后，通过client.getIntegerReply();等待（time out)返回结果。 Connection初始化socket时有多种选择，其中设置socket time out 的方法如下： 12345678public void rollbackTimeout() { try { socket.setSoTimeout(timeout); socket.setKeepAlive(false); } catch (SocketException ex) { throw new JedisException(ex); }} 由redis.clients.jedis.Protocol.DEFAULT_TIMEOUT = 2000 我们知道默认的超时时间是2秒，这个时间相对于redis操作内存毫秒级的速度来说已经很长，那我们为什么还会遇到java.net.SocketTimeoutException: Read timed out异常呢？redis操作内存虽然平均毫秒级的，但当数据量很大时未必都如此快速。在我的开发过程中就遇到过一个集合到了千万级数据量，一次操作超时时间在秒级是很正常的，而且机器性能很好的情况下已经如此，更何况我们本机开发的机器相对于生产服务器来说速度会更慢了。所以在初始化JedisPool时应该根据实际 情况通过redis.clients.jedis.JedisPoolConfig合理设置连接池参数，通过edisPool构造方法，合理设置socket读取输入InputStream的超时时间。 pool = new JedisPool(config, host, port, 100000);注意第四个参数time out，设置成我们能容忍的超时时间，单位是毫秒。但不知道为什么既然单位是毫秒，为什么参数类型是int而不是long。 设置第四个参数后，我在四千万数据量集合上操作最多一次大概超时5秒，问题基本解决。 Ref: Redis一次Read time out引发的过期key删除策略分析 常见JedisConnectionException异常分析 常见JedisConnectionException异常分析 JedisPool optimization","link":"/2021/10/25/java/java-jedis-read-timeout/"},{"title":"Java内存模型","text":"JVM内存结构Java代码是要运行在虚拟机上的，而虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域，这些区域都有各自的用途。 pc register, 栈，本地方法栈 堆，方法区 （所有线程共享） 运行时常量 Java内存模型JVM的内存结构的图中，我们可以看到，其中Java堆和方法区的区域是多个线程共享的数据区域。也就是说，多个线程可能可以操作保存在堆或者方法区中的同一个数据。这也就是我们常说的“Java的线程间通过共享内存进行通信”。 Java内存模型是根据英文Java Memory Model（JMM）翻译过来的。其实JMM并不像JVM内存结构一样是真实存在的。他只是一个抽象的概念。JSR-133: Java Memory Model and Thread Specification中描述了，JMM是和多线程相关的，他描述了一组规则或规范，这个规范定义了一个线程对共享变量的写入时对另一个线程是可见的。 那么，简单总结下，Java的多线程之间是通过共享内存进行通信的，而由于采用共享内存进行通信，在通信过程中会存在一系列如可见性、原子性、顺序性等问题，而JMM就是围绕着多线程通信以及与其相关的一系列特性而建立的模型。JMM定义了一些语法集，这些语法集映射到Java语言中就是volatile、synchronized等关键字。 Java对象模型Java是一种面向对象的语言，而Java对象在JVM中的存储也是有一定的结构的。而这个关于Java对象自身的存储模型称之为Java对象模型。 HotSpot虚拟机中，设计了一个OOP-Klass Model。OOP（Ordinary Object Pointer）指的是普通对象指针，而Klass用来描述对象实例的具体类型。 JVM内存结构，和Java虚拟机的运行时区域有关。Java内存模型，和Java的并发编程有关。Java对象模型，和Java对象在虚拟机中的表现形式有关。 JVM内存结构 VS Java内存模型 VS Java对象模型再有人问你Java内存模型是什么，就把这篇文章发给他。深入理解多线程（一）——Synchronized的实现原理 Java 内存模型对JVM内存结构的描述中，我们知道了堆和方法区是线程共享的。而局部变量，方法定义参数和异常处理器参数就不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 Java内存模型的抽象示意图如下： 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！为了具体说明，请看下面示例： 1234Processor A Processor Ba = 1; //A1 x = b; //A2 b = 2; //B1 y = a; //B2 初始状态：a = b = 0 处理器允许执行后得到结果：x = y = 0假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 **提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性**。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具体说明 happens-before 为什么要这么定义。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 参考文章 https://zhuanlan.zhihu.com/p/38348646 https://www.infoq.cn/article/java-memory-model-1/","link":"/2021/09/28/java/java-jmm/"},{"title":"AtomicInteger&amp;无锁对象引用:AtomicReference","text":"AtomicInteger介绍AtomicInteger是一个提供原子操作的Integer类，通过线程安全的方式操作加减。 AtomicInteger使用场景AtomicInteger提供原子操作来进行Integer的使用，因此十分适合高并发情况下的使用。 1.作为多个线程同时使用的原子计数器。 2.在比较和交换操作中实现非阻塞算法。 AtomicInteger作为原子计数器要将其用作计数器，AtomicInteger类提供了一些方法来原子地执行加减运算。 123456addAndGet（）：以原子方式将给定值添加到当前值，并在添加后返回新值。getAndAdd（）：以原子方式将给定值添加到当前值并返回旧值。crementAndGet（）：以原子方式将当前值增加1，并在增加之后返回新值。 它等效于++ i操作。getAndIncrement（）：以原子方式递增当前值并返回旧值。 它等效于i ++操作。decrementAndGet（）：以原子方式将当前值减1，并在减后返回新值。 它等效于i-操作。getAndDecrement（）：以原子方式减少当前值并返回旧值。 它等效于– -i操作。 AtomicInteger源码部分讲解 1234567891011121314151617public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; 以上为AtomicInteger中的部分源码，在这里说下其中的value，这里value使用了volatile关键字，volatile在这里可以做到的作用是使得多个线程可以共享变量，但是问题在于使用volatile将使得VM优化失去作用，导致效率较低，所以要在必要的时候使用，因此AtomicInteger类不要随意使用，要在使用场景下使用。 AtomicInteger的创建、塞值、取值通过调用构造函数，可以直接创建AtomicInteger。 AtomicInteger提供了两种方法来获取和设置其实例的值。 123456789//Initial value is 0AtomicInteger atomicInteger=new AtomicInteger();//Initial value is 100AtomicInteger atomicInteger=new AtomicInteger(100);int currentValue=atomicInteger.get(); //100atomicInteger.set(1234); //Now value is 1234 AtomicInteger使用总结AtomicInteger是在使用非阻塞算法实现并发控制，在一些高并发程序中非常适合，但并不能每一种场景都适合，不同场景要使用使用不同的数值类。 AtomicReference1、使用场景：解决并发修改多个属性 说到CAS理论，在java中我们第一个就想到了atomic类，一般常见的有AtomicInteger、AtomicBoolean等java.util.concurrent包下面的类，但是这个只能并发修改一个属性，如果我需要对多个属性同时进行并发修改，并且保证原子性呢？ AtomicReference和AtomicInteger非常类似，不同之处就在于AtomicInteger是对整数的封装，而AtomicReference则对应普通的对象引用，是操控多个属性的原子性的并发类。 业务场景：序列需要自增并且时间需要更新成最新的时间戳 2.简单介绍：AtomicReference类提供了一个可以原子读写的对象引用变量。 原子意味着尝试更改相同AtomicReference的多个线程（例如，使用比较和交换操作）不会使AtomicReference最终达到不一致的状态。 3、实现原理：123456private static final Unsafe unsafe = Unsafe.getUnsafe();private volatile V value;public AtomicReference(V initialValue) { value = initialValue; }public final boolean compareAndSet(V expect, V update) { return unsafe.compareAndSwapObject(this, valueOffset, expect, update); } AtomicReference的源码比较简单。它是通过”volatile”和”Unsafe提供的CAS函数实现”原子操作。 (01) value是volatile类型。这保证了：当某线程修改value的值时，其他线程看到的value值都是最新的value值，即修改之后的volatile的值。 (02) 通过CAS设置value。这保证了：当某线程池通过CAS函数(如compareAndSet函数)设置value时，它的操作是原子的，即线程在操作value时不会被中断。 4. 例子：参考文章 Java AtomicInteger 使用指南 AtomicReference 【实战Java高并发程序设计 2】无锁的对象引用：AtomicReference","link":"/2021/09/28/java/java-juc_Atomic/"},{"title":"JVM内存结构","text":"概述 JVM内存结构主要有三大块：·堆内存、方法区和栈·。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 xx xxxxxxxx desc 堆（Heap） 线程共享 所有的对象实例以及数组都要在堆上分配。 回收器主要管理的对象。 方法区（Method Area） 线程共享 Non-Heap（非堆） 存储类信息、常量、静态变量、即时编译器编译后的代码。 方法栈（JVM Stack） 线程私有 存储局部变量表、操作栈、动态链接、方法出口，对象指针。 本地方法栈（Native Method Stack） 线程私有 为虚拟机使用到的Native 方法服务。如Java使用c或者c++编写的接口服务时，代码在此区运行。 程序计数器（Program Counter Register） 线程私有 PC寄存器（PC Register） 当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。 在通过一张图来了解如何通过参数来控制各区域的内存大小 1234567-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最大空间大小-XX:PermSize设置永久代最小空间大小-XX:MaxPermSize设置永久代最大空间大小-Xss设置每个线程的堆栈大小 JVMJVM = 类加载器(classloader) + 执行引擎(execution engine) + 运行时数据区域(runtime data area) 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。 JVM 内存结构 程序计数器 线程私有 程序计数器（Program Counter Register）是一块较小的内存空间，**它的作用可以看做是当前线程所执行的字节码的行号指示器**。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，**每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。** 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 异常情况 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈/方法栈线程私有 与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，**它的生命周期与线程相同。**虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。 局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 控制参数 1-Xss控制每个线程栈的大小 异常情况 在Java虚拟机规范中，对这个区域规定了两种异常状况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常 如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈）， 当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈线程私有 本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而**本地方法栈则是为虚拟机使用到的Native方法服务。**虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。 控制参数 在Sun JDK中本地方法栈和方法栈是同一个，因此也可以用-Xss控制每个线程的大小。 1-Xss控制每个线程栈的大小 异常情况与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 Java堆线程共享对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。 控制参数 1234-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最小空间大小 垃圾回收此区域是垃圾回收的主要操作区域。 异常情况如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 方法区线程共享 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 控制参数 12-XX:PermSize 设置最小空间 -XX:MaxPermSize 设置最大空间 垃圾回收 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 异常情况根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 HotSpot中方法区的变化 jdk版本 区别 jdk1.6及之前 有永久代，静态变量存放在永久代上 jdk1.7 有永久代，但已经逐步去“永久代”，字符串常量池、静态变量移除，保存着堆中 jdk1.8及之后 无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 运行时常量池 运行时常量池是在方法区的一部分； Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池(Constant Pool Table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放； Java虚拟机对Class文件每一部分(自然也包括常量池)的格式都有严格规定，每一个字节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、加载和执行，但是对于运行时常量池，《Java虚拟机规范》没有做任何细节的要求，不用的提供上实现的虚拟机可以按照自己的需要来实现这个内存区域，不过一般来说，除了保存Class文件中描述的符号引用外,还会把翻译出来的直接引用也存储在运行时常量池中； 运行时常量池相对于Class文件常量池的另外一个重要特征就是具备动态性，Java语言并不要求常量一定只有在编译期才能产生， 也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 永久代和元空间java7及以前版本JVM内存结构图 堆和方法区连在了一起，但这并不能说堆和方法区是一起的，它们在逻辑上依旧是分开的。但在物理上来说，它们又是连续的一块内存。 也就是说，方法区和前面讲到的Eden和老年代是连续的。 永久代（PermGen）对于习惯了在HotSpot虚拟机上开发、部署的程序员来说，很多都愿意将方法区称作永久代。本质上来讲两者并不等价，仅因为Hotspot将GC分代扩展至方法区，或者说使用永久代来实现方法区。在其他虚拟机上是没有永久代的概念的。也就是说方法区是规范，永久代是Hotspot针对该规范进行的实现。 理解上面的概念之后，我们对Java7及以前版本的堆和方法区的构造再进行一下变动。 对Java7及以前版本的Hotspot中方法区位于永久代中。同时，永久代和堆是相互隔离的，但它们使用的物理内存是连续的。永久代的垃圾收集是和老年代捆绑在一起的，因此无论谁满了，都会触发永久代和老年代的垃圾收集。 但在Java7中永久代中存储的部分数据已经开始转移到Java Heap或Native Memory中了。比如，符号引用(Symbols)转移到了Native Memory；字符串常量池(interned strings)转移到了Java Heap；类的静态变量(class statics)转移到了Java Heap。然后，在Java8中，时代变了，Hotspot取消了永久代。永久代真的成了永久的记忆。永久代的参数-XX:PermSize和-XX：MaxPermSize也随之失效。 元空间（Metaspace）对于Java8，HotSpots取消了永久代，那么是不是就没有方法区了呢？当然不是，方法区只是一个规范，只不过它的实现变了。在Java8中，元空间(Metaspace)登上舞台，方法区存在于元空间(Metaspace)。同时，元空间不再与堆连续，而且是存在于本地内存（Native memory）。 本地内存（Native memory），也称为C-Heap，是供JVM自身进程使用的。当Java Heap空间不足时会触发GC，但Native memory空间不够却不会触发GC。 针对Java8的调整，我们再次对内存结构图进行调整。 元空间存在于本地内存，意味着只要本地内存足够，它不会出现像永久代中java.lang.OutOfMemoryError: PermGen space这种错误。默认情况下元空间是可以无限使用本地内存的，但为了不让它如此膨胀，JVM同样提供了参数来限制它使用的使用。 -XX:MetaspaceSize class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。 -XX：MaxMetaspaceSize 可以为class metadata分配的最大空间。默认是没有限制的。 -XX：MinMetaspaceFreeRatio 在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集。 -XX:MaxMetaspaceFreeRatio 在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集。 面试官 | JVM 为什么使用元空间替换了永久代？ 表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。 当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。 直接内存在JVM的内存模型，里面并不包含直接内存，也就是说这块内存区域并不是JVM运行时数据区的一部分，但它却会被频繁的使用，原因是NIO这个包；NIO（New input/output）是JDK1.4中新加入的类，引入了一种基于通道（channel）和缓冲区（buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过堆上的DirectByteBuffer对象对这块内存进行引用和操作。 可以看出，直接内存的大小并不受到java堆大小的限制，甚至不受到JVM进程内存大小的限制。它只受限于本机总内存（RAM及SWAP区或者分页文件）大小以及处理器寻址空间的限制（最常见的就是32位/64位CPU的最大寻址空间限制不同）。 参考文章 https://juejin.cn/post/6970606107442020360 https://juejin.cn/post/6844903592374042637 https://www.cnblogs.com/ityouknow/p/5610232.html https://zhuanlan.zhihu.com/p/38348646","link":"/2021/09/28/java/java-jvm-memory/"},{"title":"log4j2 JNDI injection_vulnerability","text":"123&lt;properties&gt; &lt;log4j2.version&gt;2.16.0&lt;/log4j2.version&gt;&lt;/properties&gt; 参考文章 Apache Log4j2 远程代码执行漏洞分析 Log4J2 Vulnerability and Spring Boot 令无数程序员加班的 Log4j2 远程执行漏洞复现 Log4j2发布2.16.0，删除Message Lookups，加固漏洞防御","link":"/2021/12/16/java/java-log4j2-jndi-injection-vulnerability/"},{"title":"JVM调优实践系列","text":"JVM——1. 运行时数据区域JVM——2. 对象及内存分配策略与分代JVM——3. 垃圾回收算法JVM——4. 常用垃圾收集器JVM——5.性能优化JVM——6.GC日志分析1(模拟对象进入老年代)JVM——7.GC日志分析2(老年代GC)JVM——8.调优工具1(jstat) 参考文章","link":"/2021/09/28/java/java-jvm-optmize/"},{"title":"java多线程那点事","text":"java多线程那点事|提升java能力阿里面试官的分享Java面试中需要准备哪些多线程并发的技术要点","link":"/2021/10/25/java/java-multi-thread/"},{"title":"java","text":"序号 内容 链接地址1 Java基础知识面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104390612 2 Java集合容器面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104588551 3 Java异常面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104390689 4 并发编程面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104863992 5 JVM面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104390752 6 Spring面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397516 7 Spring MVC面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397427 8 Spring Boot面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397299 9 Spring Cloud面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397367 10 MyBatis面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/101292950 11 Redis面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/103522351 12 MySQL数据库面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104778621 13 消息中间件MQ与RabbitMQ面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104588612 14 Dubbo面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104390006 15 Linux面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104588679 16 Tomcat面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397665 17 ZooKeeper面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104397719 18 Netty面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/104391081 19 架构设计&amp;分布式&amp;数据结构与算法面试题（2020最新版） https://thinkwon.blog.csdn.net/article/details/105870730","link":"/2022/05/18/java/java-offer/"},{"title":"some parameters that only one is not null valid","text":"注解12345678910111213141516171819202122@Documented@Target({ElementType.FIELD})@Retention(RetentionPolicy.RUNTIME)public @interface CustomValid {}@Documented@Constraint(validatedBy = OnlyOneNotNullValidator.class)@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)public @interface OnlyOneNotNull { String message() default &quot;only one filed should not be null&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {}; String[] fieldNames();} OnlyOneNotNullValidator.java12345678910111213141516171819202122232425262728293031323334353637383940414243@Component@Slf4jpublic class OnlyOneNotNullValidator implements ConstraintValidator&lt;OnlyOneNotNull, Object&gt; { private String[] fieldNames; @Override public void initialize(OnlyOneNotNull onlyOneNotNull) { this.fieldNames = onlyOneNotNull.fieldNames(); } @Override public boolean isValid(Object object, ConstraintValidatorContext context) { if (Objects.isNull(object)) { return true; } Class clazz = object.getClass(); try { List&lt;Field&gt; fields = Arrays.stream(fieldNames) .map(fieldName -&gt; ReflectionUtils.findField(clazz, fieldName)) .filter(Objects::nonNull).peek(field -&gt; field.setAccessible(true)) .filter(field -&gt; Objects.nonNull(ReflectionUtils.getField(field, object))) .collect(Collectors.toList()); boolean onlyOneNotNull = fields.size() == 1; if (!onlyOneNotNull) { invalid(context); } else if (fields.get(0).isAnnotationPresent(CustomValid.class)) { validate(fields.get(0).get(object)); } return onlyOneNotNull; } catch (IllegalAccessException e) { log.warn(e.getMessage(), e); return false; } catch (Exception e) { return false; } } private void invalid(ConstraintValidatorContext context) { throw new RuntimeException(String.format(&quot;[%s]&quot;, String.join(&quot;, &quot;, fieldNames)) + &quot; only one filed should not be null&quot;); }} 12345678910111213141516171819202122// valid object's field, for example: valid ClassA.aaa notNull. public static void validate(Object object) { if (object != null) { Class objClass = object.getClass(); try { object = objectMapper.readValue(objectMapper.writeValueAsString(object), Object.class); XssUtils.unescapeObject(object); object = objectMapper.convertValue(object, objClass); } catch (IOException e) { throw new RuntimeException(&quot;QUERY_PARAM_ERROR&quot;); } } javax.validation.Validator validator = (javax.validation.Validator)new ApplicationContextHolder().context.getBean(&quot;validator&quot;); Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = validator.validate(object); if (!violations.isEmpty()) { StringBuilder msg = new StringBuilder(); for (ConstraintViolation&lt;Object&gt; violation : violations) { msg.append(&quot;[&quot;).append(violation.getPropertyPath()).append(&quot;]&quot;).append(violation.getMessage()); } throw new RuntimeException(&quot;bad request&quot;); } } 使用123456789101112131415161718192021222324252627282930313233@Getter@Setter@Builder@NoArgsConstructor@AllArgsConstructor@OnlyOneNotNull(fieldNames = {&quot;aClass&quot;, &quot;bClass&quot;, &quot;cClass&quot;})public class RequestDto { @CustomValid private AClass aClass; @CustomValid private BClass bClass; @CustomValid private CClass cClass;}@Getter@Setter@Builder@NoArgsConstructor@AllArgsConstructorpublic class AClass { @NotNull private Boolean aaa; @NotNull private BBBB bnbb; @NotBlank @Pattern(regexp = ApiGatewayConst.PatternRegexp.METHOD_HTTP_URL) @Length(max = 1500) private String url;}","link":"/2021/10/14/java/java-onlyOneNotNull-valid/"},{"title":"常见内存溢出错误","text":"Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space 原因：对象不能被分配到堆内存中。 Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space 原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。 Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：创建的数组大于堆内存的空间。 Exception in thread “main”: java.lang.OutOfMemoryError: request bytes for . Out of swap space? 原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。 Exception in thread “main”: java.lang.OutOfMemoryError: （Native method） 原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现。 Troubleshooting Guide for HotSpot VM”, Chapter 3 on “Troubleshooting on memory leaks","link":"/2021/09/28/java/java-oom/"},{"title":"java_quarkus","text":"参考文章 试用 Quarkus 的四大理由 Quarkus框架入门之一：Quarkus框架介绍及简单示例 5分钟拥抱云原生 | SpringBoot 迁移至 Quarkus 一个简单的Quarkus web服务入门","link":"/2021/12/28/java/java-quarkus/"},{"title":"java redis","text":"基础数据类型String、Hash、List、Set、SortedSet。 String：这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。但是真实的开发环境中，很多仔可能会把很多比较复杂的结构也统一转成String去存储使用，比如有的仔他就喜欢把对象或者List转换为JSONString进行存储，拿出来再反序列话啥的。 缓存功能：String字符串是最常用的数据类型，不仅仅是Redis，各个语言都是最基本类型，因此，利用Redis作为缓存，配合其它数据库作为存储层，利用Redis支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。 计数器：许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率。 Hash： 这个是类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段。 但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。 List：List 是有序列表，这个还是可以玩儿出很多花样的。比如可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。比如可以搞个简单的消息队列，从 List 头怼进去，从 List 屁股那里弄出来。List本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。 消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。 文章列表或者数据分页展示的应用。比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用Redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。 Set：Set 是无序集合，会自动去重的那种。直接基于 Set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 JVM 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于Redis进行全局的 Set 去重。可以基于 Set 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。反正这些场景比较多，因为对比很快，操作也简单，两个查询一个Set搞定。 Sorted Set：Sorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 高级用法：Bitmap :位图是支持按 bit 位来存储信息，可以用来实现 布隆过滤器（BloomFilter）； HyperLogLog:供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV； Geospatial:可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？pub/sub：功能是订阅发布功能，可以用作简单的消息队列。 Pipeline：可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。 Redis双写一致性你有没有考虑过，如果你多个系统同时操作（并发）Redis带来的数据问题？嗯嗯这个问题我以前开发的时候遇到过，其实并发过程中确实会有这样的问题，比如下面这样的情况系统A、B、C三个系统，分别去操作Redis的同一个Key，本来顺序是1，2，3是正常的，但是因为系统A网络突然抖动了一下，B，C在他前面操作了Redis，这样数据不就错了么。就好比下单，支付，退款三个顺序你变了，你先退款，再下单，再支付，那流程就会失败，那数据不就乱了？你订单还没生成你却支付，退款了？明显走不通了，这在线上是很恐怖的事情。 那这种情况怎么解决呢？我们可以找个管家帮我们管理好数据的嘛！某个时刻，多个系统实例都去更新某个 key。可以基于 Zookeeper 实现分布式锁。每个系统通过 Zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 Key，别人都不允许读和写。你要写入缓存的数据，都是从 MySQL 里查出来的，都得写入 MySQL 中，写入 MySQL 中的时候必须保存一个时间戳，从 MySQL 查出来的时候，时间戳也查出来。每次要写之前，先判断一下当前这个 Value 的时间戳是否比缓存里的 Value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。 双写一致性你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。把一些列的操作都放到队列里面，顺序肯定不会乱，但是并发高了，这队列很容易阻塞，反而会成为整个系统的弱点，瓶颈 你了解最经典的KV、DB读写模式么？最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。更新的时候，先更新数据库，然后再删除缓存。 为什么是删除缓存，而不是更新缓存？原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？举个栗子：一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 Mybatis，Hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 List，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。 Redis 和 Memcached 有啥区别，为啥选择用Redis作为你们的缓存中间件？Redis 支持复杂的数据结构：Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。Redis 原生支持集群模式：在 redis3.x 版本中，便能支持 Cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。性能对比：由于 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis，虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Remcached，还是稍有逊色。Tip：其实面试官这么问，是想看你知道为啥用这个技术栈么？你为啥选这个技术栈，你是否做过技术选型的对比，优缺点你是否了解，你啥都不知道，只是为了用而用，那你可能就差点意思了。 Redis 的线程模型了解么？Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。文件事件处理器的结构包含 4 个部分： 多个 Socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 为啥Redis那么快么？哦，帅气迷人的面试官您好，我们可以先看一下关系型数据库跟Redis本质上的区别。Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型，非阻塞IO； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； redis是怎么进行持久化的？Redis数据都在内存中，一断电或者重启不就木有了嘛？是的，持久化的话是Redis高可用中比较重要的一个环节，因为Redis数据在内存的特性，持久化必须得有，我了解到的持久化是有两种方式的。 RDB：RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。AOF：AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog。 RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。 两种方式都可以把Redis内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，RDB更适合做冷备，AOF更适合做热备，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这灾备也就是异地容灾，地球毁灭他没办法。tip：两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。 redis是一个支持持久化的内存数据库，也就是说redis需要经常将内存中的数据同步到磁盘来保证持久化，这是相对memcache来说的一个大的优势。redis支持两种持久化方式，一种是 Snapshotting（快照）也是默认方式，另一种是Append-only file（缩写aof）的方式。Snapshotting快照是默认的持久化方式。这种方式将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以配置自动做快照持久 化的方式。 Append-only file aof 比快照方式有更好的持久化性，是由于在使用aof持久化方式时,redis会将每一个收到的写命令都通过write函数追加到文件中(默认是 appendonly.aof)。当redis重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 对方追问那如果突然机器掉电会怎样？取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。 作者：敖丙链接：https://juejin.cn/post/6844903982066827277来源：稀土掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 对方追问RDB的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 两种机制各自优缺点是啥？我先说RDB吧 优点： 他会生成多个数据文件，每个数据文件分别都代表了某一时刻Redis里面的数据，这种方式，有没有觉得很适合做冷备，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。RDB对Redis的性能影响非常小，是因为在同步数据的时候他只是fork了一个子进程去做持久化的，而且他在数据恢复的时候速度比AOF来的快。 缺点： RDB都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。AOF则最多丢一秒的数据，数据完整性上高下立判。还有就是RDB在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候fork了一个子进程去生成一个大快照，哦豁，出大问题。 我们再来说说AOF 优点： 上面提到了，RDB五分钟一次生成快照，但是AOF是一秒一次去通过一个后台的线程fsync操作，那最多丢这一秒的数据。 AOF在对日志文件进行操作的时候是以append-only的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。AOF的日志是通过一个叫非常可读的方式记录的，这样的特性就适合做灾难性数据误删除的紧急恢复了，比如公司的实习生通过flushall清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份AOF日志文件，把最后一条flushall命令删了就完事了。tip：我说的命令你们别真去线上系统操作啊，想试去自己买的服务器上装个Redis试，别到时候来说，敖丙真是个渣男，害我把服务器搞崩了，Redis官网上的命令都去看看，不要乱试！！！ 缺点： 一样的数据，AOF文件比RDB还要大。AOF开启后，Redis支持写的QPS会比RDB支持写的要低，他不是每秒都要去异步刷新一次日志嘛fsync，当然即使这样性能还是很高，我记得ElasticSearch也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，那我会告诉你这样性能可能低到没办法用的，大家可以思考下为啥哟。 Redis 集群的三种模式主从复制模式通过持久化功能，Redis保证了即使在服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。 但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。 为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。 为此， Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。 在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。 总结：引入主从复制机制的目的有两个 一个是读写分离，分担 “master” 的读写压力一个是方便做容灾恢复主从复制原理 Sentinel（哨兵）模式第一种主从同步/复制的模式，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例。哨兵模式的作用通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机；然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 Cluster 集群模式（Redis官方）Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。 Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，也就是说每台 Redis 节点上存储不同的内容。在这个图中，每一个蓝色的圈都代表着一个 redis 的服务器节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作。 集群的数据分片 Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。 Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么： 节点 A 包含 0 到 5460 号哈希槽 节点 B 包含 5461 到 10922 号哈希槽 节点 C 包含 10923 到 16383 号哈希槽 这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D ， 我需要从节点 A， B， C 中得部分槽到 D 上。如果我想移除节点 A ，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。 在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是 cluster，可以理解为是一个集群管理的插件。当我们的存取的 Key到达的时候，Redis 会根据 CRC16 的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。 Redis 集群的主从复制模型 为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。 集群的特点 所有的 redis 节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。 节点的 fail 是通过集群中超过半数的节点检测失效时才生效。 客户端与 Redis 节点直连，不需要中间代理层.客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。 主从之间的数据怎么同步的我先说下为啥要用主从这样的架构模式，前面提到了单机QPS是有上限的，而且Redis的特性就是必须支撑读高并发的，那你一台机器又读又写，这谁顶得住啊，不当人啊！但是你让这个master机器去写，数据同步给别的slave机器，他们都拿去读，分发掉大量的请求那是不是好很多，而且扩容的时候还可以轻松实现水平扩容。回归正题，他们数据怎么同步的呢？你启动一台slave 的时候，他会发送一个psync命令给master ，如果是这个slave第一次连接到master，他会触发一个全量复制。master就会启动一个线程，生成RDB快照，还会把新的写请求都缓存在内存中，RDB文件生成后，master会将这个RDB发送给slave的，slave拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后master会把内存里面缓存的那些新命名都发给slave。数据传输的时候断网了或者服务器挂了怎么办啊？传输过程中有什么网络问题啥的，会自动重连的，并且连接之后会把缺少的数据补上的。大家需要记得的就是，RDB快照的数据生成的时候，缓存区也必须同时开始接受新请求，不然你旧的数据过去了，你在同步期间的增量数据咋办？是吧？ 内存淘汰机制Redis的过期策略，是有定期删除+惰性删除两种。定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。 为啥不扫描全部设置了过期时间的key呢？ 假如Redis里面所有的key都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带where条件不走索引全表扫描一样，100ms一次，Redis累都累死了。如果一直没随机到很多key，里面不就存在大量的无效key了？ 好问题，惰性删除，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。 最后就是如果的如果，定期没删，我也没查询，那可咋整？内存淘汰机制！官网上给到的内存淘汰机制是以下几个： noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外） allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。 volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。 allkeys-random: 回收随机的键使得新添加的数据有空间存放。 volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。 volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。如果没有键满足回收的前提条件的话，策略volatile-lru, volatile-random以及volatile-ttl就和noeviction 差不多了。 至于LRU我也简单提一下，手写实在是太长了，大家可以去Redis官网看看，我把近视LUR效果给大家看看tip：Redis为什么不使用真实的LRU实现是因为这需要太多的内存。不过近似的LRU算法对于应用而言应该是等价的。使用真实的LRU算法与近似的算法可以通过下面的图像对比。注意LRU只是个预测键将如何被访问的模型。另外，如果你的数据访问模式非常接近幂定律，大部分的访问将集中在一个键的集合中，LRU的近似算法将处理得很好。 其实在大家熟悉的LinkedHashMap中也实现了Lru算法的，实现如下： 当容量超过100时，开始执行LRU策略：将最近最少未使用的 TimeoutInfoHolder 对象 evict 掉。真实面试中会让你写LUR算法，你可别搞原始的那个，那真TM多，写不完的，你要么怼上面这个，要么怼下面这个，找一个数据结构实现下Java版本的LRU还是比较容易的，知道啥原理就好了。 Redis雪崩同一时间大面积失效，那一瞬间Redis跟没有一样，那这个数量级别的请求直接打到数据库几乎是灾难性的，你想想如果打挂的是一个用户服务的库，那其他依赖他的库所有的接口几乎都会报错，如果没做熔断等策略基本上就是瞬间挂一片的节奏，你怎么重启用户都会把你打挂，等你能重启的时候，用户早就睡觉去了，并且对你的产品失去了信心，什么垃圾产品。 怎么去应对的？处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，我相信，Redis这点流量还是顶得住的。setRedis（Key，value，time + Math.random() * 10000）；复制代码 如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题，不过本渣我在生产环境中操作集群的时候，单个服务都是对应的单个Redis分片，是为了方便数据的管理，但是也同样有了可能会失效这样的弊端，失效时间随机是个好策略。或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。 缓存穿透和击穿 缓存穿透 是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。像这种你如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了。 缓存穿透我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等。从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击，但是我们要知道正常用户是不会在单秒内发起这么多次请求的，那网关层Nginx本渣我也记得有配置项，可以让运维大大对单个IP每秒访问次数超出阈值的IP都拉黑。 那你还有别的办法么？ 还有我记得Redis还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。那又有小伙伴说了如果黑客有很多个IP同时发起攻击呢？这点我一直也不是很想得通，但是一般级别的黑客没这么多肉鸡，再者正常级别的Redis集群都能抗住这种级别的访问的，小公司我想他们不会感兴趣的。把系统的高可用做好了，集群还是很能顶的。 缓存击穿 这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。 缓存击穿的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了 Bloom Filter 概念布隆过滤器（英语：Bloom Filter）是1970年由一个叫布隆的小伙子提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 Bloom Filter 原理布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。###Bloom Filter的缺点bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。 如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？使用keys指令可以扫出指定模式的key列表。对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答Redis关键的一个特性：Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。 使用过Redis做异步队列么，你是怎么用的？一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。如果对方接着追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。如果对方继续追问 pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等。如果对方究极TM追问Redis如何实现延时队列？使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 参考文章 《进大厂系列》系列-Redis常见面试题（带答案） 《吊打面试官》系列-Redis基础 《吊打面试官》系列-缓存雪崩、击穿、穿透 《吊打面试官》系列-Redis哨兵、持久化、主从、手撕LRU Redis双写一致性、并发竞争、线程模型 Redis-避免缓存穿透的利器之BloomFilter 总结一波 Redis 面试题，收藏起来！ Redis面试题 最全的 116 道 Redis 面试题解答","link":"/2022/05/18/java/java-redis/"},{"title":"读取txt文件","text":"12345678910111213141516171819202122public class ReadFileByLines { public static void main(String[] args) { try { //1.打开一个file File file = new File(&quot;E:/test.txt&quot;); //2.InputStreamReader&lt;-FileInputStream&lt;-file FileInputStream fis = new FileInputStream(file); InputStreamReader is = new InputStreamReader(fis); //3.用BufferedReader(&lt;-InputStreamReader)的readLine()方法读取 BufferedReader br = new BufferedReader(is); //4.输出 String txtLine = null; while ((txtLine = br.readLine()) != null) { System.out.println(txtLine); } br.close(); } catch (Exception e) { e.printStackTrace(); } }} 123456789101112131415161718public class ReadFileByLines { public static void main(String[] args) { try { File file = new File(&quot;E:/test.txt&quot;); BufferedReader br = new BufferedReader(new FileReader(file)); String txtLine = null; while ((txtLine = br.readLine()) != null) { System.out.println(txtLine); } br.close(); } catch (Exception e) { e.printStackTrace(); } }}","link":"/2021/10/25/java/java-read-txt-file/"},{"title":"java redis2","text":"Redis 的数据类型有哪些字符串（strings）、哈希（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等，除此之外还支持 bitmaps、hyperloglogs 和地理空间（ geospatial ）索引半径查询等功能。 Redis 持久化机制Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。 实现：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。 RDB是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）AOF：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。 缓存雪崩、缓存穿透、击穿、缓存预热、缓存更新、缓存降级等问题缓存雪崩缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。解决办法：大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开。缓存穿透缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。解决办法：最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些32bit大小的数据该如何解决？如果是64bit的呢？对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。Bitmap：典型的就是哈希表缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。布隆过滤器（推荐）就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。 缓存穿透与缓存击穿的区别缓存击穿：是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据。解决方案：在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。 给一个我公司处理的案例：背景双机拿token，token在存一份到redis，保证系统在token过期时都只有一个线程去获取token;线上环境有两台机器，故使用分布式锁实现。缓存预热缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决思路：·直接写个缓存刷新页面，上线时手工操作下；·数据量不大，可以在项目启动的时候自动进行加载；·定时刷新缓存； 缓存更新除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：·定时去清理过期的缓存；·当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。以参考日志级别设置预案：一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。 热点数据和冷数据是什么热点数据，缓存才有价值对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存 对于上面两个例子，寿星列表、导航信息都存在一个特点，就是信息修改频率不高，读取通常非常高的场景。 对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。数据更新前至少读取两次， 缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。 那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。 Memcache与Redis的区别都有哪些？1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，redis可以持久化其数据2)、数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。4). value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。5）redis的速度比memcached快很多6）Redis支持数据的备份，即master-slave模式的数据备份。 Redis 相比 Memcached 有哪些优势？Redis 相比 Memcache 有以下的优势： 数据结构：Memcache 只支持 key value 存储方式，Redis 支持更多的数据类型，比如 Key value、hash、list、set、zset；多线程：Memcache 支持多线程，Redis 支持单线程；CPU 利用方面 Memcache 优于 Redis；持久化：Memcache 不支持持久化，Redis 支持持久化；内存利用率：Memcache 高，Redis 低（采用压缩的情况下比 Memcache 高）；过期策略：Memcache 过期后，不删除缓存，会导致下次取数据数据的问题，Redis 有专门线程，清除缓存数据；适用场景：Redis 适用于对读写效率要求都很高，数据处理业务复杂和对安全性要求较高的系统。Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。Memcached 适用于在动态系统中减少数据库负载，提升性能，做缓存，提高性能（适合读多写少，对于数据量比较大，可以采用 sharding）。 单线程的redis为什么这么快(一)纯内存操作(二)单线程操作，避免了频繁的上下文切换(三)采用了非阻塞I/O多路复用机制 redis的过期策略以及内存淘汰机制redis采用的是定期删除+惰性删除策略。为什么不用定时删除策略?定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.定期删除+惰性删除是如何工作的呢?定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置maxmemory-policy volatile-lru1 该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰no-enviction（驱逐）：禁止驱逐数据，新写入操作会报错ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。 Redis 为什么是单线程的Redis 是单进程单线程的，它可以通过队列技术将并发访问变为串行访问，避免了传统数据库串行控制的开销。多线程处理会涉及到锁，并且多线程处理会涉及到线程切换而消耗 CPU。采用单线程，避免了不必要的上下文切换和竞争条件。其次 CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。 官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）Redis利用队列技术将并发访问变为串行访问 1）绝大部分请求是纯粹的内存操作（非常快速）2）采用单线程,避免了不必要的上下文切换和竞争条件3）非阻塞IO优点： 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)支持丰富数据类型，支持string，list，set，sorted set，hash支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除如何解决redis的并发竞争key问题 同时有多个子系统去set一个key。这个时候要注意什么呢？不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。·如果对这个key操作，不要求顺序：准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可·如果对这个key操作，要求顺序：分布式锁+时间戳。假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。·利用队列，将set方法变成串行访问也可以redis遇到高并发，如果保证读写key的一致性 对redis的操作都是具有原子性的,是线程安全的操作,你不用考虑并发问题,redis内部已经帮你处理好并发的问题了。 有没有尝试进行多机redis 的部署？如何保证数据一致的？主从复制，读写分离一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 对于大量的请求怎么样处理redis是一个单线程程序，也就说同一时刻它只能处理一个客户端请求；redis是通过IO多路复用（select，epoll, kqueue，依据不同的平台，采取不同的实现）来处理多个客户端请求的 Redis 常见性能问题和解决方案？(1) Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件(2) 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次(3) 为了主从复制的速度和连接的稳定性， Master 和 Slave 最好在同一个局域网内(4) 尽量避免在压力很大的主库上增加从库(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;-Slave3… 讲解下Redis线程模型文件事件处理器包括分别是套接字、 I/O 多路复用程序、 文件事件分派器（dispatcher）、 以及事件处理器。使用 I/O 多路复用程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。I/O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。工作原理：I/O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。尽管多个文件事件可能会并发地出现， 但 I/O 多路复用程序总是会将所有产生事件的套接字都入队到一个队列里面， 然后通过这个队列， 以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字。如果一个套接字又可读又可写的话， 那么服务器将先读套接字， 后写套接字. 为什么Redis的操作是原子性的，怎么保证原子性的？对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。Redis的操作之所以是原子性的，是因为Redis是单线程的。（Redis新版本已经引入多线程，这里基于旧版本的Redis）Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。多个命令在并发中也是原子性的吗？不一定， 将get和set改成单命令操作，incr 。使用Redis的事务，或者使用Redis+Lua==的方式实现. Redis 最适合的场景？Redis 是一个开源（BSD 许可），基于内存，支持多种数据结构的存储系统。可以作为数据库、缓存和消息中间件。它支持的数据结构有字符串（strings）、哈希（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等，除此之外还支持 bitmaps、hyperloglogs 和地理空间（ geospatial ）索引半径查询等功能。根据它的特性，它适用的场景有： 会话缓存会话（Session）是存储在服务端的，但是可以设置存储的时候不以文件的方式存储，而是存到 Redis 中，而且 Redis 支持数据持久化，不用担心数据因为服务器重启导致 Session 数据丢失的问题。这样做的好处不只是提高获取会话的速度，也对网站的整体性能有很大的提升。 数据缓存Redis 支持多种数据结构，经常被用来做缓存中间件使用。缓存的数据不只是包括数据库中的数据，也可以缓存一些需要临时存储的数据，例如 token、会话数据等。 队列Redis 是支持列表（lists）功能的，可以简单实现一个队列的功能，对数据进行入队、出队操作。实现的队列可以应用到电商的秒杀场景中。 排行榜、计数器Redis 提供了有序集合，可以对数据进行排名，实现排行榜功能。 其次 Redis 中提供了 incr 对数字加 1 命令，也提供了 decr 对数字减 1 命令，所以可以实现一个简单的计数器功能。 发布、订阅功能Redis 中提供了发布订阅相关的命令，可以用来做一些跟发布订阅相关的场景应用等。例如简单的消息队列功能等。什么是 Redis 事务？原理是什么？Redis 中的事务是一组命令的集合，是 Redis 的最小执行单位。它可以保证一次执行多个命令，每个事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序地执行。服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。它的原理是先将属于一个事务的命令发送给 Redis，然后依次执行这些命令。Redis 事务的注意点有哪些？需要注意的点有：Redis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行；Redis 服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部执行完毕才会执行其他客户端的命令。Redis 为什么不支持回滚？Redis 的事务不支持回滚，但是执行的命令有语法错误，Redis 会执行失败，这些问题可以从程序层面捕获并解决。但是如果出现其他问题，则依然会继续执行余下的命令。这样做的原因是因为回滚需要增加很多工作，而不支持回滚则可以保持简单、快速的特性。Redis 如何设置密码及验证密码？Redis 密码设置有两种方式：修改配置文件，需要重启 Redis。在 redis.conf 中可以找到 requirepass 参数，设置 Redis 的访问密码。配置方法为：requirepass 访问密码。使用命令设置，不需要重启 Redis。使用命令设置的方法为：config set requirepass 访问密码。如果需要查询密码，可以使用 config get requirepass 命令。如果需要验证密码，可以使用 auth 访问密码，再执行 config get requirepass 获取。需要注意的是，通过这种方式设置访问密码，如果 redis.conf 配置文件中没有设置对应的访问密码，那么服务器重启后访问密码会失效。Redis 单点吞吐量有多少？单点 TPS 达到 8 万/秒，QPS 达到 10 万/秒。TPS 和 QPS 的意思：QPS：应用系统每秒钟最大能接受的用户访问量。每秒钟处理完请求的次数，注意这里是处理完，具体是指发出请求到服务器处理完成功返回结果。可以理解在 Server 中有个 counter，每处理一个请求加 1，1s 后 counter=QPS。TPS：每秒钟最大能处理的请求数。每秒钟处理完的事务次数，一个应用系统 1s 能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用 QPS 比较合理。 Redis 中管道有什么用？使用 pipeline（管道）的好处在于可以将多次 I/O 往返的时间缩短为一次，但是要求管道中执行的指令间没有因果关系。 修改配置不重启 Redis 会实时生效吗？因为 Redis 在重启才能加载配置项中的配置，所以需要重启才能生效。针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 ‘CONFIG GET *’ 命令获取更多信息。但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。 分布式锁-Redis实现基础首先Redis是单线程的，这里的单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。而且Redis的性能很好，即使在多个服务争抢锁的时候也能够从容处理众多请求。 方案1加锁命令 SET [KEY] [VALUE] NX解锁命令 DEL [KEY]这是最基础的使用方式，加锁时因为存在NX关键词，所以只有当该KEY不存在的才能成功加锁。解锁时直接删除即可。这种方式也需单机Demo中能够正常运行，但是在分布式环境中就会产生其他问题。 如果某项业务在加锁后程序未执行解锁便退出了，这种情况下，将会造成死锁的情况 ，该位置的锁会永远不能解锁。 方案2基于上面的弊端与缺陷，我们改进加锁命令就有：加锁命令 SET [KEY] [VALUE] NX PX 30000解锁命令 DEL [KEY]在加锁命令中，同时为该锁设置一个过期时间，可以一定程度上避免方案1中出现的死锁情况。现方案会有两个问题： 解锁指令不够健壮，可能会导致误解锁的情况。如果加锁者与解锁者不是同一个，业务可能会导致许多问题。过期时间可能会与业务运行情况强行相关，且影响性能。过期时间设置得过短，可能在业务没运行完的时候就解锁了；过期时间设置过长，在加锁者宕机的情况下，其他服务器等待时间过长，影响性能。 方案3 #加锁命令SET [KEY] [VALUE] NX PX 30000解锁命令if redis.call (“get”,KEYS[1]) == ARGV[1] then return redis.call(“del”,KEYS[1])else return 0End修改：1.设置保护线程在加锁成功后不断的更新过期时间。2. 解锁命令由Lua脚本替代。由于解锁命令需要进行两次Redis操作，第一步为判断该KEY的VALUE和输入的VALUE是否一致，是的情况下进行第二步，删除该KEY，Redis中可以保证每一条命令是原子性的，但是连续两条命令是并不能保证，因此使用Lua脚本可以将两条命令合二为一，使解锁命令为原子操作。 Redisson - WatchDogRedisson中已经实现的WatchDog机制，也就是方案三种的守护线程的工作。 大家都知道，如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 Redisson中的WatchDog机制是一种无限递归调用的方式，该方法的定义为： updateExpireTime(){ async{ sleep(5000); setExpireTime(); updateExpireTime(); }}该方法通过异步调用形式，能够以每5min的频率更新Expire值 Redis的部署模式有3种：单机部署Master-Slave集群不论是方案3还是方案4，在单机中能够正常运行，但是并不能达到高可用性的要求。如果是主从模式，如果发生在Master节点加锁后，锁信息还未通知到Slave节点的情况下，锁信息会丢失，所以在高可用上仍然有一些问题，因此Redis的作者提出了RedLock算法来解决该问题。 RedLockantirez提出的redlock算法大概是这样的： 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。 为了取到锁，客户端应该执行以下操作: · 获取当前Unix时间，以毫秒为单位。· 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。· 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。· 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。· 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。 参考文章 《进大厂系列》系列-Redis常见面试题（带答案） 《吊打面试官》系列-Redis基础 《吊打面试官》系列-缓存雪崩、击穿、穿透 《吊打面试官》系列-Redis哨兵、持久化、主从、手撕LRU Redis双写一致性、并发竞争、线程模型 Redis-避免缓存穿透的利器之BloomFilter 总结一波 Redis 面试题，收藏起来！ Redis面试题 最全的 116 道 Redis 面试题解答","link":"/2022/05/18/java/java-redis2/"},{"title":"java 单例模式的写法","text":"饱汉模式饱汉是变种最多的单例模式。我们从饱汉出发，通过其变种逐渐了解实现单例模式时需要关注的问题。 基础的饱汉饱汉，即已经吃饱，不着急再吃，饿的时候再吃。所以他就先不初始化单例，等第一次使用的时候再初始化，即·“懒加载”·。 12345678910111213// 饱汉// UnThreadSafepublic class Singleton1 { private static Singleton1 singleton = null; private Singleton1() { } public static Singleton1 getInstance() { if (singleton == null) { singleton = new Singleton1(); } return singleton; }} 饱汉模式的核心就是懒加载。好处是更启动 速度快、节省资源，一直到实例被第一次访问，才需要初始化单例；小坏处是写起来麻烦，大坏处是线程不安全，if语句存在竞态条件。 写起来麻烦不是大问题，可读性好啊。因此，单线程环境下，基础饱汉是最好。但多线程环境下，基础饱汉就彻底不可用了。下面的几种变种都在试图解决基础饱汉线程不安全的问题。 饱汉 - 变种 1最粗暴的犯法是用synchronized关键字修饰getInstance()方法，这样能达到绝对的线程安全。 12345678910111213// 饱汉// ThreadSafepublic class Singleton1_1 { private static Singleton1_1 singleton = null; private Singleton1_1() { } public synchronized static Singleton1_1 getInstance() { if (singleton == null) { singleton = new Singleton1_1(); } return singleton; }} 变种1的好处是写起来简单，且绝对线程安全；坏处是并发性能极差，事实上完全退化到了串行。单例只需要初始化一次，但就算初始化以后，synchronized的锁也无法避开，从而getInstance()完全变成了串行操作。性能不敏感的场景建议使用。 饱汉 - 变种 2变种2是“臭名昭著”的DCL 1.0。 针对变种1中单例初始化后锁仍然无法避开的问题，变种2在变种1的外层又套了一层check，加上synchronized内层的check，即所谓“双重检查锁”（Double Check Lock，简称DCL）。 123456789101112131415161718192021// 饱汉// UnThreadSafepublic class Singleton1_2 { private static Singleton1_2 singleton = null; public int f1 = 1; // 触发部分初始化问题 public int f2 = 2; private Singleton1_2() { } public static Singleton1_2 getInstance() { // may get half object if (singleton == null) { synchronized (Singleton1_2.class) { if (singleton == null) { singleton = new Singleton1_2(); } } } return singleton; }} 变种2的核心是DCL，看起来变种2似乎已经达到了理想的效果：懒加载+线程安全。可惜的是，正如注释中所说，DCL仍然是线程不安全的，由于指令重排序，你可能会得到“半个对象”，即”部分初始化“问题。 参考：volatile关键字的作用、原理 饱汉 - 变种 3变种3专门针对变种2，可谓DCL 2.0。 针对变种3的“半个对象”问题，变种3在instance上增加了volatile关键字，原理见上述参考。 123456789101112131415161718192021// 饱汉// ThreadSafepublic class Singleton1_3 { private static volatile Singleton1_3 singleton = null; public int f1 = 1; // 触发部分初始化问题 public int f2 = 2; private Singleton1_3() { } public static Singleton1_3 getInstance() { if (singleton == null) { synchronized (Singleton1_3.class) { // must be a complete instance if (singleton == null) { singleton = new Singleton1_3(); } } } return singleton; }} 多线程环境下，变种3更适用于性能敏感的场景。但后面我们将了解到，就算是线程安全的，还有一些办法能破坏单例。 当然，还有很多方式，能通过与volatile类似的方式防止部分初始化。读者可自行阅读内存屏障相关内容，但面试时不建议主动装逼。猴子后面会专门整理一篇文章讨论内存屏障，此处不表。 饿汉模式与饱汉相对，饿汉很饿，只想着尽早吃到。所以他就在最早的时机，即类加载时初始化单例，以后访问时直接返回即可。 12345678910// 饿汉// ThreadSafepublic class Singleton2 { private static final Singleton2 singleton = new Singleton2(); private Singleton2() { } public static Singleton2 getInstance() { return singleton; }} 饿汉的好处是天生的线程安全（得益于类加载机制），写起来超级简单，使用时没有延迟；坏处是有可能造成资源浪费（如果类加载后就一直不使用单例的话）。 值得注意的时，单线程环境下，饿汉与饱汉在性能上没什么差别；但多线程环境下，由于饱汉需要加锁，饿汉的性能反而更优。 Holder模式我们既希望利用饿汉模式中静态变量的方便和线程安全；又希望通过懒加载规避资源浪费。Holder模式满足了这两点要求：核心仍然是静态变量，足够方便和线程安全；通过静态的Holder类持有真正实例，间接实现了懒加载。 123456789101112131415// Holder模式// ThreadSafepublic class Singleton3 { private static class SingletonHolder { private static final Singleton3 singleton = new Singleton3(); private SingletonHolder() { } } private Singleton3() { } public static Singleton3 getInstance() { return SingletonHolder.singleton; }} 相对于饿汉模式，Holder模式仅增加了一个静态内部类的成本，与饱汉的变种3效果相当（略优），都是比较受欢迎的实现方式。同样建议考虑。 枚举模式用枚举实现单例模式，相当好用，但可读性是不存在的。 基础的枚举将枚举的静态成员变量作为单例的实例： 12345// 枚举// ThreadSafepublic enum Singleton4 { SINGLETON;} 代码量比饿汉模式更少。但用户只能直接访问实例Singleton4.SINGLETON——事实上，这样的访问方式作为单例使用也是恰当的，只是牺牲了静态工厂方法的优点，如无法实现懒加载。 丑陋但好用的语法糖Java的枚举是一个“丑陋但好用的语法糖”。 枚举型单例模式的本质通过反编译（jad，源码|String拼接操作”+”的优化？也用到了）打开语法糖，就看到了枚举类型的本质，简化如下： 1234567// 枚举// ThreadSafepublic class Singleton4 extends Enum&lt;Singleton4&gt; { ... public static final Singleton4 SINGLETON = new Singleton4(); ...} 本质上和饿汉模式相同，区别仅在于公有的静态成员变量。 用枚举实现一些trick这一部分与单例没什么关系，可以跳过。如果选择阅读也请认清这样的事实：虽然枚举相当灵活，但如何恰当的使用枚举有一定难度。一个足够简单的典型例子是TimeUnit类，建议有时间耐心阅读。 上面已经看到，枚举型单例的本质仍然是一个普通的类。实际上，我们可以在枚举型型单例上增加任何普通类可以完成的功能。要点在于枚举实例的初始化，可以理解为实例化了一个匿名内部类。为了更明显，我们在Singleton4_1中定义一个普通的私有成员变量，一个普通的公有成员方法，和一个公有的抽象成员方法，如下： 123456789101112131415161718192021// 枚举// ThreadSafepublic enum Singleton4_1 { SINGLETON(&quot;enum is the easiest singleton pattern, but not the most readable&quot;) { public void testAbsMethod() { print(); System.out.println(&quot;enum is ugly, but so flexible to make lots of trick&quot;); } }; private String comment = null; Singleton4_1(String comment) { this.comment = comment; } public void print() { System.out.println(&quot;comment=&quot; + comment); } abstract public void testAbsMethod(); public static Singleton4_1 getInstance() { return SINGLETON; }} 这样，枚举类Singleton4_1中的每一个枚举实例不仅继承了父类Singleton4_1的成员方法print()，还必须实现父类Singleton4_1的抽象成员方法testAbsMethod()。 总结上面的分析都忽略了反射和序列化的问题。通过反射或序列化，我们仍然能够访问到私有构造器，创建新的实例破坏单例模式。此时，只有枚举模式能天然防范这一问题。反射和序列化猴子还不太了解，但基本原理并不难，可以在其他模式上手动实现。 下面继续忽略反射和序列化的问题，做个总结回味一下： 实现方式 关键点 资源浪费 线程安全 多线程环境的性能足够优化 基础饱汉 懒加载 否 否 - 饱汉变种1 懒加载、同步 否 是 否 饱汉变种2 懒加载、DCL 否 否 - 饱汉变种3 懒加载、DCL、volatile 否 是 是 饿汉 静态变量初始化 是 是 是 Holder 静态变量初始化、holder 否 是 是 枚举 枚举本质、静态变量初始化 否 是 是","link":"/2021/09/23/java/java-singleton/"},{"title":"ThreadPoolTaskExecutor","text":"1234567891011121314151617181920212223242526import java.util.concurrent.ThreadPoolExecutor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;@Configuration@EnableAsyncpublic class ThreadPool { public static final int DEFAULT_THREADS_NUMS = 2 * Runtime.getRuntime().availableProcessors(); @Bean(&quot;taskExecutor&quot;) public ThreadPoolTaskExecutor taskExecutor() { ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor(); int maxPoolSize = 2 * DEFAULT_THREADS_NUMS; threadPoolTaskExecutor.setCorePoolSize(DEFAULT_THREADS_NUMS); threadPoolTaskExecutor.setMaxPoolSize(maxPoolSize); threadPoolTaskExecutor.setQueueCapacity(maxPoolSize); threadPoolTaskExecutor.setKeepAliveSeconds(60); threadPoolTaskExecutor.setThreadNamePrefix(&quot;Async-Thread-&quot;); threadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); return threadPoolTaskExecutor; }} 参考文章","link":"/2021/11/10/java/java-threadpool/"},{"title":"volatile2","text":"参考文章 内存屏障 volatile关键字的作用、原理 深入理解Java中的volatile关键字 面试官最爱的volatile关键字 Java并发编程：volatile关键字解析","link":"/2021/09/28/java/java-voliate2/"},{"title":"volatile","text":"定义volatile变量规则：对volatile变量的写入操作必须在对该变量的读操作之前执行。 volatile变量规则只是一种标准，要求JVM实现保证volatile变量的偏序语义。结合程序顺序规则、传递性，该偏序语义通常表现为两个作用： 保持可见性 禁用重排序（读操作禁止重排序之后的操作，写操作禁止重排序之前的操作） 补充： 程序顺序规则：如果程序中操作A在操作B之前，那么在线程中操作A将在操作B之前执行。 传递性：如果操作A在操作B之前执行，并且操作B在操作C之前执行，那么操作A必须在操作C之前执行。 对于可见性、有序性及原子性问题，通常情况下我们可以通过Synchronized关键字来解决这些个问题。 不过如果对Synchronized原理有了解的话，应该知道Synchronized是一个比较重量级的操作，对系统的性能有比较大的影响，所以，如果有其他解决方案，我们通常都避免使用Synchronized来解决问题。 而volatile关键字就是Java中提供的另一种解决可见性和有序性问题的方案。对于原子性，需要强调一点，也是大家容易误解的一点：对volatile变量的单次读/写操作可以保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。 保持内存可见性内存可见性（Memory Visibility）：所有线程都能看到共享内存的最新状态。 问题：可见性问题主要指一个线程修改了共享变量值，而另一个线程却看不到 解决原理： 修改volatile变量时会强制将修改后的值刷新的主内存中。 修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。 注：volatile并不保证变量更新的原子性 失效数据以下是一个简单的可变整数类：1234567891011public class MutableInteger { private int value; public int get(){ return value; } public void set(int value){ this.value = value; }} MutableInteger不是线程安全的，因为get和set方法都是在没有同步的情况下进行的。如果线程1调用了set方法，那么正在调用的get的线程2可能会看到更新后的value值，也可能看不到。 解决方法很简单，将value声明为volatile变量： 1private volatile int value; 神奇的volatile关键字神奇的volatile关键字解决了神奇的失效数据问题。 Java变量的读写Java通过几种原子操作完成工作内存和主内存的交互： lock：作用于主内存，把变量标识为线程独占状态。 unlock：作用于主内存，解除独占状态。 read：作用主内存，把一个变量的值从主内存传输到线程的工作内存。 load：作用于工作内存，把read操作传过来的变量值放入工作内存的变量副本中。 use：作用工作内存，把工作内存当中的一个变量值传给执行引擎。 assign：作用工作内存，把一个从执行引擎接收到的值赋值给工作内存的变量。 store：作用于工作内存的变量，把工作内存的一个变量的值传送到主内存中。 write：作用于主内存的变量，把store操作传来的变量的值放入主内存的变量中。 volatile如何保持内存可见性volatile的特殊规则就是： read、load、use动作必须连续出现。 assign、store、write动作必须连续出现。 所以，使用volatile变量能够保证: 每次读取前必须先从主内存刷新最新的值。 每次写入后必须立即同步回主内存当中。 也就是说，volatile关键字修饰的变量看到的随时是自己的最新值。线程1中对变量v的最新修改，对线程2是可见的。 防止重排序 后文，如果仅涉及可见性，则指明“可见性”；如果二者均涉及，则以“偏序”代称。重排序一定会带来可见性问题，因此，不会出现单独讨论重排序的场景。 问题：在基于偏序关系的Happens-Before内存模型中，指令重排技术大大提高了程序执行效率，但同时也引入了一些问题。 一个指令重排的问题——被部分初始化的对象 懒加载单例模式和竞态条件一个懒加载的单例模式实现如下： 123456789101112class Singleton { private static Singleton instance; private Singleton(){} public static Singleton getInstance() { if (instance == null) { // 这里存在竞态条件 instance = new Singleton(); } return instance; }} 竞态条件会导致instance引用被多次赋值，使用户得到两个不同的单例。 DCL(Double Check Lock)和被部分初始化的对象 为了解决这个问题，可以使用synchronized关键字将getInstance方法改为同步方法；但这样串行化的单例是不能忍的。所以我猿族前辈设计了 DCL（Double Check Lock，双重检查锁）机制，使得大部分请求都不会进入阻塞代码块： 12345678910111213141516171819class Singleton { private static Singleton instance; public int f1 = 1; // 触发部分初始化问题 public int f2 = 2; private Singleton(){} public static Singleton getInstance() { if (instance == null) { // 当instance不为null时，可能指向一个“被部分初始化的对象” synchronized (Singleton.class) { if ( instance == null ) { instance = new Singleton(); } } } return instance; }} “看起来”非常完美：既减少了阻塞，又避免了竞态条件。不错，但实际上仍然存在一个问题——当instance不为null时，仍可能指向一个&quot;被部分初始化的对象&quot;。 如果Singleton没有字段，自然也不会有部分初始化之说。因此，这里添加了两个字段，已触发部分初始化问题。 问题出在这行简单的赋值语句： 1instance = new Singleton(); 它并不是一个原子操作。事实上，它可以”抽象“为下面几条JVM指令： 123memory = allocate(); //1：分配对象的内存空间initInstance(memory); //2：初始化对象（对f1、f2初始化）instance = memory; //3：设置instance指向刚分配的内存地址 上面操作2依赖于操作1，但是操作3并不依赖于操作2，所以JVM可以以“优化”为目的对它们进行重排序，经过重排序后如下： 123memory = allocate(); //1：分配对象的内存空间instance = memory; //3：设置instance指向刚分配的内存地址（此时对象还未初始化）ctorInstance(memory); //2：初始化对象 可以看到指令重排之后，操作 3 排在了操作 2 之前，即引用instance指向内存memory时，这段崭新的内存还没有初始化——即，引用instance指向了一个”被部分初始化的对象”。此时，如果另一个线程调用getInstance方法，由于instance已经指向了一块内存空间，从而if条件判为false，方法返回instance引用，用户得到了没有完成初始化的“半个”单例。解决这个该问题，只需要将instance声明为volatile变量： 1private static volatile Singleton instance; 也就是说，在只有DCL没有volatile的懒加载单例模式中，仍然存在着并发陷阱。我确实不会拿到两个不同的单例了，但我会拿到“半个”单例（未完成初始化）。然而，许多面试书籍中，涉及懒加载的单例模式最多深入到DCL，却只字不提volatile。这“看似聪明”的机制，曾经被我广大初入Java世界的猿胞大加吹捧——我在大四实习面试跟谁学的时候，也得意洋洋的从饱汉、饿汉讲到Double Check，现在看来真是傻逼。对于考查并发的面试官而言，单例模式的实现就是一个很好的切入点，看似考查设计模式，其实期望你从设计模式答到并发和内存模型。 volatile如何防止指令重排volatile关键字通过“内存屏障”来防止指令被重排序。 不同CPU架构对内存屏障的实现不同，则JVM对volatile的实现也不同。一种最简单的实现方式是： 在每个volatile写操作的后面插入一个Full Barriers。 在每个volatile读操作的前面插入一个Full Barriers。勘误：不同CPU架构对内存屏障的实现不同，但是这里的实现怎么看都不对。特改为一种正确实现，建议阅读本文开头指向的新文章；以下是原文。 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。然而，对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，Java内存模型采取保守策略。 下面是基于保守策略的JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障。在每个volatile写操作的后面插入一个StoreLoad屏障。在每个volatile读操作的后面插入一个LoadLoad屏障。在每个volatile读操作的后面插入一个LoadStore屏障。 如果存在这种重排序问题，那么synchronized代码块内部不是也可能出现相同的问题吗？ 即这种情况： 123456789101112class Singleton { ... if (instance == null) { // 可能发生不期望的指令重排 synchronized (Singleton.class) { if ( instance == null ) { instance = new Singleton(); System.out.println(instance.toString()); //程序顺序规则发挥效力的地方 } } } ...} 难道调用instance.toString()方法时，instance也可能未完成初始化吗？ 首先还请放宽心，synchronized代码块内部虽然会重排序，但不会在代码块的范围内导致线程安全问题。 Happens-Before内存模型和程序顺序规则程序顺序规则：如果程序中操作A在操作B之前，那么线程中操作A将在操作B之前执行。 前面说过，只有在Happens-Before内存模型中才会出现这样的指令重排序问题。Happens-Before内存模型维护了几种Happens-Before规则，·程序顺序规则·最基本的规则。程序顺序规则的目标对象是一段程序代码中的两个操作A、B，其保证此处的指令重排不会破坏操作A、B在代码中的先后顺序，但与不同代码甚至不同线程中的顺序无关。 因此，在synchronized代码块内部，instance = new Singleton()仍然会指令重排序，但重排序之后的所有指令，仍然能够保证在instance.toString()之前执行。进一步的，单线程中，if ( instance == null )能保证在synchronized代码块之前执行；但多线程中，线程1中的if ( instance == null )却与线程2中的synchronized代码块之间没有偏序关系，因此线程2中synchronized代码块内部的指令重排对于线程1是不期望的，导致了此处的并发陷阱。 类似的Happens-Before规则还有 volatile变量规则、监视器锁规则等。程序猿可以借助（Piggyback）现有的Happens-Before规则来保持内存可见性和防止指令重排。 注意点上面简单讲解了volatile关键字的作用和原理，但对volatile的使用过程中很容易出现的一个问题是： 错把volatile变量当做原子变量。 出现这种误解的原因，主要是volatile关键字使变量的读、写具有了“原子性”。然而这种”原子性”仅限于变量（包括引用）的读和写，无法涵盖变量上的任何操作，即： 基本类型的自增（如count++）等操作不是原子的。 对象的任何非原子成员调用（包括成员变量和成员方法）不是原子的。如果希望上述操作也具有原子性，那么只能采取锁、原子变量更多的措施。 严格来说，volatile的读、写也不是原子的，但从可见性的角度上看，与原子性表现一致。 volatile使用建议相对于synchronized块的代码锁，volatile应该是提供了一个轻量级的针对共享变量的锁，当我们在多个线程间使用共享变量进行通信的时候需要考虑将共享变量用volatile来修饰。 volatile是一种稍弱的同步机制，在访问volatile变量时不会执行加锁操作，也就不会执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。使用建议：在两个或者更多的线程需要访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile。由于使用volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。 volatile和synchronized区别 1.volatile不会进行加锁操作：volatile变量是一种稍弱的同步机制在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。 volatile变量作用类似于同步变量读写操作：从内存可见性的角度看，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。 3.volatile不如synchronized安全：在代码中如果过度依赖volatile变量来控制状态的可见性，通常会比使用锁的代码更脆弱，也更难以理解。仅当volatile变量能简化代码的实现以及对同步策略的验证时，才应该使用它。一般来说，用同步机制会更安全些。 volatile无法同时保证内存可见性和原子性：加锁机制（即同步机制）既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性，原因是声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count = count+1”。 当且仅当满足以下所有条件时，才应该使用volatile变量： 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量没有包含在具有其他变量的不变式中。 总结：在需要同步的时候，第一选择应该是synchronized关键字，这是最安全的方式，尝试其他任何方式都是有风险的。尤其在、jdK1.5之后，对synchronized同步机制做了很多优化，如：自适应的自旋锁、锁粗化、锁消除、轻量级锁等，使得它的性能明显有了很大的提升。 内存屏障 内存屏障（Memory Barrier）与内存栅栏（Memory Fence）是同一个概念，不同的叫法。 通过volatile标记，可以解决编译器层面的可见性与重排序问题。而内存屏障则解决了硬件层面的可见性与重排序问题。 标准先简单了解两个指令： Store：将处理器缓存的数据刷新到内存中。Load：将内存存储的数据拷贝到处理器的缓存中。 屏障类型 指令示例 说明 LoadLoad Barriers Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 StoreStore Barriers Store1;StoreStore;Store2 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 LoadStore Barriers Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Barriers Store1;StoreLoad;Load2 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 StoreLoad Barriers同时具备其他三个屏障的效果，因此也称之为全能屏障（mfence），是目前大多数处理器所支持的；但是相对其他屏障，该屏障的开销相对昂贵。 然而，除了mfence，不同的CPU架构对内存屏障的实现方式与实现程度非常不一样。相对来说，Intel CPU的强内存模型比DEC Alpha的弱复杂内存模型（缓存不仅分层了，还分区了）更简单。x86架构是在多线程编程中最常见的，下面讨论x86架构中内存屏障的实现。 参考文章 内存屏障 volatile关键字的作用、原理 深入理解Java中的volatile关键字 面试官最爱的volatile关键字 Java并发编程：volatile关键字解析","link":"/2021/09/28/java/java-voliate/"},{"title":"AbstractQueuedSynchronizer","text":"AQS (AbstractQueuedSynchronizer) 抽象类的队列式同步器J.U.C是基于AQS实现的，AQS是一个同步器，设计模式是模板模式。核心数据结构：双向链表 + state(锁状态)底层操作：CAS 原理概览AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 基础定义 AQS 是一个用于构建锁和同步器的框架，许多同步器都可以通过AQS很容易并且高效的构造出来。 为线程的同步和等待等操作提供一个基础模板类。尽可能多的实现可重入锁，读写锁同步器所有需要的功能。队列同步器内部实现了线程的同步队列，独占或是共享的获取方式等，使其只需要少量的代码便可以实现目标功能。 一般来说，AQS的子类应以其他类的内部类的形式存在，然后使用代理模式调用子类和AQS本身的方法实现线程的同步。也就是说，使用ReentrantLock举例，外界调用ReentrantLock，ReentrantLock内部定义Sync，Sync是AQS的子类，在ReentrantLock的内部实现中调用Sync的方法，最后完成最终的功能，当然ReentrantLock内部稍复杂，又加入和公平锁和非公平锁。 抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...。AbstractQueuedSynchronizer，这个类也是在java.util.concurrent.locks下面。 AQS，全名AbstractQueuedSynchronizer，是一个抽象类的队列式同步器，它的内部通过维护一个状态volatile int state(共享资源)，一个FIFO线程等待队列来实现同步功能。 state 所有通过AQS实现功能的类都是通过修改state的状态来操作线程的同步状态。比如在ReentrantLock中，一个锁中只有一个state状态，当state为0时，代表所有线程没有获取锁，当state为1时，代表有线程获取到了锁。通过是否能把state从0设置成1，当然，设置的方式是使用CAS设置，代表一个线程是否获取锁成功。 state用关键字volatile修饰，代表着该共享资源的状态一更改就能被所有线程可见，而AQS的加锁方式本质上就是多个线程在竞争state，当state为0时代表线程可以竞争锁，不为0时代表当前对象锁已经被占有，其他线程来加锁时则会失败，加锁失败的线程会被放入一个FIFO的等待队列中，这些线程会被UNSAFE.park()操作挂起，等待其他获取锁的线程释放锁才能够被唤醒。 AQS内部维护一个线程的队列。队列由内部的节点组成。 队列的节点为Node,节点分为SHARED和EXCLUSIVE分别时共享模式的节点和独占模式的节点。 而这个等待队列其实就相当于一个CLH队列，用一张原理图来表示大致如下： AQS简介中提到了AQS内部维护着一个FIFO队列，该队列就是CLH同步队列。 CLH同步队列是一个FIFO双向队列，AQS依赖它来完成同步状态的管理，当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点唤醒（公平锁），使其再次尝试获取同步状态。 在CLH同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、状态（waitStatus）、前驱节点（prev）、后继节点（next） AQS支持两种资源分享的方式： Exclusive（独占，只有一个线程能执行，如ReentrantLock） Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 自定义的同步器继承AQS后，只需要实现共享资源state的获取和释放方式即可，其他如线程队列的维护（如获取资源失败入队/唤醒出队等）等操作，AQS在顶层已经实现了， AQS代码内部提供了一系列操作锁和线程队列的方法，主要操作锁的方法包含以下几个： compareAndSetState()：利用CAS的操作来设置state的值- tryAcquire(int)：独占方式获取锁。成功则返回true，失败则返回false。 tryRelease(int)：独占方式释放锁。成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式获取锁。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式释放锁。如果释放后允许唤醒后续等待结点返回true，否则返回false。 像ReentrantLock就是实现了自定义的tryAcquire-tryRelease，从而操作state的值来实现同步效果。 除此之外，AQS内部还定义了一个静态类Node，表示·CLH队列的每一个结点·，该结点的作用是对每一个等待获取资源做了封装，包含了需要同步的线程本身、线程等待状态….. 我们可以看下该类的一些重点变量： 1234567891011121314151617181920static final class Node { /** 表示共享模式下等待的Node */ static final Node SHARED = new Node(); /** 表示独占模式下等待的mode */ static final Node EXCLUSIVE = null; /** 下面几个为waitStatus的具体值 */ static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; /** 表示前面的结点 */ volatile Node prev; /** 表示后面的结点 */ volatile Node next; /**当前结点装载的线程，初始化时被创建，使用后会置空*/ volatile Thread thread; /**链接到下一个节点的等待条件，用到Condition的时候会使用到*/ Node nextWaiter;} 代码里面定义了一个表示当前Node结点等待状态的字段waitStatus，该字段的取值包含了CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)、PROPAGATE(-3)、0，这五个值代表了不同的特定场景： CANCELLED：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL（记住这个-1的值，因为后面我们讲的时候经常会提到） CONDITION：表示结点等待在Condition上，当其他线程调用了Condition的SIGNAL()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。(注：Condition是AQS的一个组件，后面会细说) PROPAGATE：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。 0：新结点入队时的默认状态。 也就是说，当waitStatus为负值表示结点处于有效等待状态，为正值的时候表示结点已被取消。 在AQS内部中还维护了两个Node对象head和tail，一开始默认都为null 12private transient volatile Node head; private transient volatile Node tail; 讲完了AQS的一些基础定义，我们就可以开始学习同步的具体运行机制了，为了更好的演示，我们用ReentrantLock作为使用入口，一步步跟进源码探究AQS底层是如何运作的，这里说明一下，因为ReentrantLock底层调用的AQS是独占模式，所以下文讲解的AQS源码也是针对独占模式的操作 独占模式 ReentrantLock和synchronized功能类似，使用AQS的独占模式，只有一个线程可以获取锁。 加锁过程我们都知道，ReentrantLock的加锁和解锁方法分别为lock()和unLock()，我们先来看获取锁的方法， 123456final void lock(){ if(compareAndSetState(0,1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } 其中compareAndSetState(0, 1)如果返回true就代表着之前state是0，也就是当前无线程获取锁，同时当前线程获取锁成功了，将独占线程设置为当前线程。 如果是false就代表当前有线程占用，当前占用的线程有2个可能 当前线程在占用，因为是可重入锁，之后同样会获取锁 其他线程在占用，在其他线程占用期间，当前线程需要等待 逻辑很简单，线程进来后直接利用CAS尝试抢占锁，如果抢占成功state值回被改为1，且设置对象独占锁线程为当前线程，否则就调用acquire(1)再次尝试获取锁。 我们假定有两个线程A和B同时竞争锁，A进来先抢占到锁，此时的AQS模型图就类似这样： acquire1234public final void acquire(int arg){ if(!tryAcquire(arg)&amp;&amp;acquireQueued(addWaiter(Node.EXCLUSIVE),arg)) selfInterrupt(); } acquire是一种以独占方式获取资源，如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。该方法是独占模式下线程获取共享资源的顶层入口。获取到资源后，线程就可以去执行其临界区代码了。 acquire方法是一种互斥模式，且忽略中断。该方法至少执行一次tryAcquire(int)方法，如果tryAcquire(int)方法返回true，则acquire直接返回，否则当前线程需要进入队列进行排队。 acquire(1)包含整个获取锁，如果获取不到就等待的操作 acquire包含了几个函数的调用， tryAcquire：尝试直接获取锁，如果成功就直接返回； addWaiter：获取不到锁时,说明有其他线程目前正在占用锁, 将该线程加入等待队列FIFO的尾部，并标记为独占模式； acquireQueued：线程阻塞在等待队列中获取锁，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 selfInterrupt：自我中断，就是既拿不到锁，又在等待时被中断了，线程就会进行自我中断selfInterrupt()，将中断补上。 我们一个个来看源码，并结合上面的两个线程来做场景分析。 tryAcquire 就是为了再次尝试获取锁 在tryAcquire(arg)中是尝试获取锁,是由ReentrantLock提供的,逻辑比较简单 当前无线程占有锁时,即state为0时,获取锁; 当前有线程占有锁,但当前占有锁的线程是当前线程时,因为ReentrantLock是可重入锁,获取锁,并把state+1 1234567891011121314151617181920212223protected final boolean tryAcquire(int acquires){ return nonfairTryAcquire(acquires); }final boolean nonfairTryAcquire(int acquires){ final Thread current=Thread.currentThread(); int c=getState(); if(c==0){ if(compareAndSetState(0,acquires)){ setExclusiveOwnerThread(current); return true; } }else if(current==getExclusiveOwnerThread()){ //当前占有锁的线程是当前线程时,因为ReentrantLock是可重入锁,获取锁,并把state+1 int nextc=c+acquires; if(nextc&lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} 当线程B进来后，nonfairTryAcquire方法首先会获取state的值，如果为0，则正常获取该锁，不为0的话判断是否是当前线程占用了，是的话就累加state的值，这里的累加也是为了配合释放锁时候的次数，从而实现可重入锁的效果。 当然，因为之前锁已经被线程A占领了，所以这时候tryAcquire会返回false，继续下面的流程。 addWaiter获取不到锁时,说明有其他线程目前正在占用锁,将当前线程包装成节点放入同步队列 将该线程加入等待队列FIFO的尾部，并标记为独占模式； 123456789101112131415161718/** 先尝试快速入队，如果入队成功直接返回，如果失败（存在竞态）就使用cas反复入队直到成功为止 **/private Node addWaiter(Node mode){ Node node=new Node(Thread.currentThread(),mode); // Try the fast path of enq; backup to full enq on failure // //快速入队 Node pred=tail; if(pred!=null){ node.prev=pred; if(compareAndSetTail(pred,node)){ pred.next=node; return node; } } enq(node); return node;} 这段代码首先会创建一个和当前线程绑定的Node节点，Node为双向链表。此时等待队列中的tail指针为空，直接调用enq(node)方法将当前线程加入等待队列尾部，然后返回当前结点的前驱结点， enq用于将当前节点插入等待队列，如果队列为空，则初始化当前队列。整个过程以CAS自旋的方式进行，直到成功加入队尾为止。 12345678910111213141516private Node enq(final Node node){ // CAS&quot;自旋&quot;，直到成功加入队尾 for(;;){ Node t=tail; if(t==null){ // 队列为空，初始化一个Node结点作为Head结点，并将tail结点也指向它 if(compareAndSetHead(new Node())) tail=head; }else{ // 把当前结点插入队列尾部 node.prev=t; if(compareAndSetTail(t,node)){ t.next=node; return t; } } }} 第一遍循环时，tail指针为空，初始化一个Node结点，并把head和tail结点都指向它，然后第二次循环进来之后，tail结点不为空了，就将当前的结点加入到tail结点后面，也就是这样： 如果此时有另一个线程C进来的话，发现锁已经被A拿走了，然后队列里已经有了线程B，那么线程C就只能乖乖排到线程B的后面去， 入队完成之后再判断一次当前是否有可能获得锁，也就是前一个节点是head的话， 前一个线程有可能已经释放了，再获取一次，如果获取成功，设置当前节点为头节点，整个获取过程完成。 acquireQueued接着解读方法，通过tryAcquire()和addWaiter()，我们的线程还是没有拿到资源，并且还被排到了队列的尾部，如果让你来设计的话，这个时候你会怎么处理线程呢？其实答案也很简单，能做的事无非两个： 1、循环让线程再抢资源。但仔细一推敲就知道不合理，因为如果有多个线程都参与的话，你抢我也抢只会降低系统性能 2、进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源 毫无疑问，选择2更加靠谱，acquireQueued方法做的也是这样的处理： acquireQueued()用于队列中的线程自旋地以独占且不可中断的方式获取同步状态（acquire），直到拿到锁之后再返回。该方法的实现分成两部分：如果当前节点已经成为头结点，尝试获取锁（tryAcquire）成功，然后返回；否则检查当前节点是否应该被park，然后将该线程park并且检查当前线程是否被可以被中断。 12345678910111213141516171819202122 final boolean acquireQueued(final Node node,int arg){ boolean failed=true; try{ // 标记是否会被中断 boolean interrupted=false; // CAS自旋 for(;;){ // 获取当前结点的前结点 final Node p=node.predecessor(); if(p==head&amp;&amp;tryAcquire(arg)){ setHead(node); p.next=null; // help GC failed=false; return interrupted; } if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true; }}finally{ if(failed) // 获取锁失败，则将此线程对应的node的waitStatus改为CANCEL cancelAcquire(node); } } acquireQueued方法的流程是这样的： 1、CAS自旋，先判断当前传入的Node的前结点是否为head结点，是的话就尝试获取锁，获取锁成功的话就把当前结点置为head，之前的head置为null(方便GC)，然后返回 2、如果前驱结点不是head或者加锁失败的话，就调用 shouldParkAfterFailedAcquire，将前驱节点的waitStatus变为了SIGNAL=-1，最后执行 parkAndChecknIterrupt 方法，调用 LockSupport.park()挂起当前线程，parkAndCheckInterrupt在挂起线程后会判断线程是否被中断，如果被中断的话，就会重新跑acquireQueued方法的CAS自旋操作，直到获取资源。 ps：LockSupport.park方法会让当前线程进入waitting状态，在这种状态下，线程被唤醒的情况有两种，一是被unpark()，二是被interrupt()，所以，如果是第二种情况的话，需要返回被中断的标志，然后在acquire顶层方法的窗口那里自我中断补上 此时，因为线程A还未释放锁，所以线程B状态都是被挂起的， shouldParkAfterFailedAcquire(Node, Node)shouldParkAfterFailedAcquire方法通过对当前节点的前一个节点的状态进行判断，对当前节点做出不同的操作，至于每个Node的状态表示，可以参考接口文档。 12345678910111213141516171819 private static boolean shouldParkAfterFailedAcquire(Node pred,Node node){ int ws=pred.waitStatus; if(ws==Node.SIGNAL) // 前驱结点等待状态为&quot;SIGNAL&quot;，那么自己就可以安心等待被唤醒了 return true; if(ws&gt;0){ /* * 前驱结点被取消了，通过循环一直往前找，直到找到等待状态有效的结点(等待状态值小于等于0) ， * 然后排在他们的后边，至于那些被当前Node强制&quot;靠后&quot;的结点，因为已经被取消了，也没有引用链， * 就等着被GC了 */ do{ node.prev=pred=pred.prev; }while(pred.waitStatus&gt;0); pred.next=node; }else{ // 如果前驱正常，那就把前驱的状态设置成SIGNAL compareAndSetWaitStatus(pred,ws,Node.SIGNAL); } return false;} private final boolean parkAndCheckInterrupt(){ LockSupport.park(this); return Thread.interrupted();} 到这里，加锁的流程就分析完了. 获取锁并等待的过程:当lock()执行的时候： 先快速获取锁，当前没有线程执行的时候直接获取锁 尝试获取锁，当没有线程执行或是当前线程占用锁，可以直接获取锁 将当前线程包装为node放入同步队列，设置为尾节点 前一个节点如果为头节点，再次尝试获取一次锁 将前一个有效节点设置为SIGNAL 然后阻塞直到被唤醒 为了方便你们更加清晰理解，我加多一张流程图 释放锁说完了加锁，我们来看看释放锁是怎么做的，AQS中释放锁的方法是release()，当调用该方法时会释放指定量的资源 (也就是锁) ，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。 release当ReentrantLock进行释放锁操作时，调用的是AQS的release(1)操作 123456789public final boolean release(int arg){ if(tryRelease(arg)){ Node h=head; if(h!=null&amp;&amp;h.waitStatus!=0) unparkSuccessor(h); return true; } return false;} tryRelease代码上可以看出，核心的逻辑都在tryRelease方法中，该方法的作用是释放资源，AQS里该方法没有具体的实现，需要由自定义的同步器去实现，我们看下ReentrantLock代码中对应方法的源码： 在tryRelease(arg)中会将锁释放一次，如果当前state是1，且当前线程是正在占用的线程，释放锁成功，返回true，否则因为是可重入锁，释放一次可能还在占用，应一直释放直到state为0为止 1234567891011121314@ReservedStackAccessprotected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} tryRelease方法会减去state对应的值，如果state为0，也就是已经彻底释放资源，就返回true，并且把独占的线程置为null，否则返回false。 此时AQS中的数据就会变成这样： 完全释放资源后，当前线程要做的就是唤醒CLH队列中第一个在等待资源的线程，也就是head结点后面的线程，此时调用的方法是unparkSuccessor()， 然后优先找下一个节点，如果取消了就从尾节点开始找，找到最前面一个可用的节点将其取消阻塞状态。 123456789101112131415161718 private void unparkSuccessor(Node node){ _int ws=node.waitStatus; if(ws&lt; 0) //将head结点的状态置为0 compareAndSetWaitStatus(node,ws,0); //找到下一个需要唤醒的结点s Node s=node.next; //如果为空或已取消 if(s==null||s.waitStatus&gt;0){ s=null; // 从后向前，直到找到等待状态小于0的结点，前面说了，结点waitStatus小于0时才有效 for(Node t=tail;t!=null&amp;&amp;t!=node;t=t.prev) if(t.waitStatus&lt;=0) s=t; } // 找到有效的结点，直接唤醒 if(s!=null) LockSupport.unpark(s.thread);//唤醒_} 方法的逻辑很简单，就是先将head的结点状态置为0，避免下面找结点的时候再找到head，然后找到队列中最前面的有效结点，然后唤醒，我们假设这个时候线程A已经释放锁，那么此时队列中排最前边竞争锁的线程B就会被唤醒。然后被唤醒的线程B就会尝试用CAS获取锁，回到acquireQueued方法的逻辑， 阻塞在acquireQueued的地方在唤醒之后开始继续执行，当前节点已经是最前面的一个可用（未取消）节点了,经过不断的for循环以及在shouldParkAfterFailedAcquire中不断向前寻找可用节点，因此这个被唤醒的节点一定可以使其之前的节点为head。然后获取锁成功。 但是此时节点会与新加入的节点竞争，也就是不公平锁的由来。 在公平锁中，在tryAcquire时会判断之前是否有等待的节点hasQueuedPredecessors(),如果有就不会再去获取锁了,因此能保证顺序执行。 12345678910111213for(;;){ // 获取当前结点的前结点 final Node p=node.predecessor(); if(p==head&amp;&amp;tryAcquire(arg)){ setHead(node); p.next=null; // help GC failed=false; return interrupted; } if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true;} 当线程B获取锁之后，会把当前结点赋值给head，然后原先的前驱结点 (也就是原来的head结点) 去掉引用链，方便回收，这样一来，线程B获取锁的整个过程就完成了，此时AQS的数据就会变成这样：到这里，我们已经分析完了AQS独占模式下加锁和释放锁的过程，也就是tryAccquire-&gt;tryRelease这一链条的逻辑，除此之外，AQS中还支持共享模式的同步，这种模式下关于锁的操作核心其实就是tryAcquireShared-&gt;tryReleaseShared这两个方法，我们可以简单看下 共享模式 ReentrantReadWriteLock是Java中读写锁的实现，写写互斥，读写互斥，读读共享。读写锁在内部分为读锁和写锁，因为我们要探索共享模式，因此更关注读锁。 获取锁AQS中，共享模式获取锁的顶层入口方法是acquireShared，该方法会获取指定数量的资源，成功的话就直接返回，失败的话就进入等待队列，直到获取资源， 1234public final void acquireShared(int arg){ if(tryAcquireShared(arg)&lt; 0) doAcquireShared(arg);} 该方法里包含了两个方法的调用， tryAcquireShared：尝试获取一定资源的锁，返回的值代表获取锁的状态。 doAcquireShared：进入等待队列，并循环尝试获取锁，直到成功。 tryAcquireSharedtryAcquireShared在AQS里没有实现，同样由自定义的同步器去完成具体的逻辑，像一些较为常见的并发工具Semaphore、CountDownLatch里就有对该方法的自定义实现，虽然实现的逻辑不同，但方法的作用是一样的，就是获取一定资源的资源，然后根据返回值判断是否还有剩余资源，从而决定下一步的操作。 返回值有三种定义： 负值代表获取失败； (当前有写锁，返回-1，即未获取共享锁，需要执行下一步doAcquireShared) 0代表获取成功，但没有剩余的资源，也就是state已经为0； 正值代表获取成功，而且state还有剩余，其他线程可以继续领取 当返回值小于0时，证明此次获取一定数量的锁失败了，然后就会走doAcquireShared方法 123456789101112protected final int tryAcquireShared(int unused){ Thread current=Thread.currentThread(); int c=getState(); if(exclusiveCount(c)!=0&amp;&amp;getExclusiveOwnerThread()!=current) return-1; int r=sharedCount(c); if(!readerShouldBlock()&amp;&amp;r&lt;MAX_COUNT &amp;&amp;compareAndSetState(c,c+SHARED_UNIT)){ //设置firstReader，计算数量，略 return 1; } return fullTryAcquireShared(current);} 设置共享锁需要修改state的数量，表示获取共享锁的线程的数量，当共享锁的获取存在竞争时，即compareAndSetState(c, c + SHARED_UNIT))可能设置失败，此时进入fullTryAcquireShared(current)进行获取共享锁的完整版操作。 也就是说共享锁获取时：如果当前没有独占锁在占用，AQS根据其实现类的tryAcquireShared来实现让一个共享锁直接获取到锁(可以直接执行)当有独占锁在占用是，让共享锁去等待直到独占锁解锁为止，也就是doAcquireShared(arg)的逻辑 doAcquireShared此方法的作用是将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回，这是它的源码： 12345678910111213141516171819202122232425262728293031323334private void doAcquireShared(int arg){ // 加入队列尾部 final Node node=addWaiter(Node.SHARED); boolean failed=true; try{ boolean interrupted=false; // CAS自旋 for(;;){ final Node p=node.predecessor(); // 判断前驱结点是否是head if(p==head){ // 尝试获取一定数量的锁 int r=tryAcquireShared(arg); if(r&gt;=0){ // 获取锁成功，而且还有剩余资源，就设置当前结点为head，并继续唤醒下一个线程 setHeadAndPropagate(node,r); // 让前驱结点去掉引用链，方便被GC p.next=null; // help GC if(interrupted) selfInterrupt(); failed=false; return; }} // 跟独占模式一样，改前驱结点waitStatus为-1，并且当前线程挂起，等待被唤醒 if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;parkAndCheckInterrupt()) interrupted=true; } }finally{ if(failed) cancelAcquire(node); }} doAcquireShared(arg) 除了将线程封装成节点入队外还表达了3个思想： 什么时候该执行 什么时候该传播 什么时候该等待（阻塞） 其中入队、执行和等待的逻辑基本和独占锁一样， 入队：都是加入等待队列的末尾，成为tail节点； 执行：判断当前节点的前一个节点是不是头节点，如果是的话尝试获取锁，如果获取到了就执行； 等待：获取不到或前一个节点不是头节点就代表该线程需要暂时等待，直到被叫醒为止。设置前一个节点为SIGNAL状态，然后进入等待。 其中不同的就是共享锁的传播逻辑： 想象一下，当前有一个写锁正在占用，有多个读锁在等待，当写锁释放时，第二个线程也就是想要获取读锁的线程就可以获取锁了。获取到之后当前正在用的锁就是读锁了，那后面的读锁呢，因为读锁是共享的，后面的读锁应该也能够依次获取读锁，也就是读锁的传播机制。 1234567891011 private void setHeadAndPropagate(Node node,int propagate){ Node h=head; // head指向自己 setHead(node); // 如果还有剩余量，继续唤醒下一个邻居线程 if(propagate&gt;0||h==null||h.waitStatus&lt; 0){ Node s=node.next; if(s==null||s.isShared()) doReleaseShared(); }} 将当前的节点设置为头节点，判断如果是共享锁，执行doReleaseShared()，唤醒当前节点 1234567891011121314151617 private void doReleaseShared(){ for(;;){ Node h=head; if(h!=null&amp;&amp;h!=tail){ int ws=h.waitStatus; if(ws==Node.SIGNAL){ if(!compareAndSetWaitStatus(h,Node.SIGNAL,0)) continue; unparkSuccessor(h); } else if(ws==0&amp;&amp;!compareAndSetWaitStatus(h,0,Node.PROPAGATE)) continue; } if(h==head) break; }} 当前节点唤醒之后doAcquireShared(int arg)会继续执行,因为之前的节点被设置为头节点,如果后续是获取共享锁的节点会继续执行setHeadAndPropagate,一直传播下去直到遇到获取独占锁的节点。 看到这里，你会不会一点熟悉的感觉，这个方法的逻辑怎么跟上面那个acquireQueued() 那么类似啊？对的，其实两个流程并没有太大的差别。只是doAcquireShared()比起独占模式下的获取锁上多了一步唤醒后继线程的操作，当获取完一定的资源后，发现还有剩余的资源，就继续唤醒下一个邻居线程，这才符合”共享”的思想嘛。 这里我们可以提出一个疑问，共享模式下，当前线程释放了一定数量的资源，但这部分资源满足不了下一个等待结点的需要的话，那么会怎么样？ 按照正常的思维，共享模式是可以多个线程同时执行的才对，所以，多个线程的情况下，如果老大释放完资源，但这部分资源满足不了老二，但能满足老三，那么老三就可以拿到资源。可事实是，从源码设计中可以看出，如果真的发生了这种情况，老三是拿不到资源的，因为等待队列是按顺序排列的，老二的资源需求量大，会把后面量小的老三以及老四、老五等都给卡住。从这一个角度来看，虽然AQS严格保证了顺序，但也降低了并发能力 接着往下说吧，唤醒下一个邻居线程的逻辑在doReleaseShared()中，我们放到下面的释放锁来解析。 共享锁的获取总结如下： 尝试获取共享锁，如果当前是共享锁或无锁，设置共享锁的state,获取锁 如果当前是写锁，进入等待流程 入队，加入等待队列的末尾，成为tail节点 判断当前节点的前一个节点是不是头节点，如果是的话尝试获取锁，如果获取到了就执行 获取不到或前一个节点不是头节点就代表该线程需要暂时等待，直到被叫醒为止。设置前一个节点为SIGNAL状态，然后进入等待 如果可以获取到锁，设置头节点并进入共享锁节点传播流程 释放锁共享模式释放锁的顶层方法是releaseShared，它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码： 1234567public final boolean releaseShared(int arg){ if(tryReleaseShared(arg)){ doReleaseShared(); return true; } return false;} 该方法同样包含两部分的逻辑： tryReleaseShared：释放资源。 doAcquireShared：唤醒后继结点。 跟tryAcquireShared方法一样，tryReleaseShared在AQS中没有具体的实现，由子同步器自己去定义，但功能都一样，就是释放一定数量的资源。 释放完资源后，线程不会马上就收工，而是唤醒等待队列里最前排的等待结点。 tryReleaseShared在tryReleaseShared(arg)，基本就是tryAcquireShared(int unused)的反向操作 将设置的HoldCounter减少，firstReader设置null，state减少,将tryAcquireShared(int unused)添加的状态全部反向还原回去 当共享锁全部释放完毕，返回true，否则返回false doAcquireShared唤醒后继结点的工作在doReleaseShared()方法中完成，我们可以看下它的源码： 1234567891011121314151617181920private void doReleaseShared(){ for(;;){// 获取等待队列中的head结点 Node h=head; if(h!=null&amp;&amp;h!=tail){ int ws=h.waitStatus; // head结点waitStatus = -1,唤醒下一个结点对应的线程 if(ws==Node.SIGNAL){ if(!compareAndSetWaitStatus(h,Node.SIGNAL,0)) continue; // loop to recheck cases // 唤醒后继结点 unparkSuccessor(h); }else if(ws==0&amp;&amp;!compareAndSetWaitStatus(h,0,Node.PROPAGATE)) continue; // loop on failed CAS } if(h==head) // loop if head changed break; }} 代码没什么特别的，就是如果等待队列head结点的waitStatus为-1的话，就直接唤醒后继结点，唤醒的方法unparkSuccessor()在上面已经讲过了，这里也没必要再复述。 总的来看，AQS共享模式的运作流程和独占模式很相似。 2. Condition介绍完了AQS的核心功能，我们再扩展一个知识点，在AQS中，除了提供独占/共享模式的加锁/解锁功能，它还对外提供了关于Condition的一些操作方法。 Condition是个接口，在jdk1.5版本后设计的，基本的方法就是await()和SIGNAL()方法，功能大概就对应Object的wait()和notify()，Condition必须要配合锁一起使用，因为对共享状态变量的访问发生在多线程环境下。一个Condition的实例必须与一个Lock绑定，因此Condition一般都是作为Lock的内部实现，AQS中就定义了一个类ConditionObject来实现了这个接口，那么它应该怎么用呢？我们可以简单写个demo来看下效果 123456789101112131415161718192021222324252627282930313233public class ConditionDemo { public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Condition condition = lock.newCondition(); Thread tA = new Thread(() -&gt; { lock.lock(); try { System.out.println(&quot;线程A加锁成功&quot;); System.out.println(&quot;线程A执行await被挂起&quot;); condition.await(); System.out.println(&quot;线程A被唤醒成功&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); System.out.println(&quot;线程A释放锁成功&quot;); } }); Thread tB = new Thread(() -&gt; { lock.lock(); try { System.out.println(&quot;线程B加锁成功&quot;); condition.SIGNAL(); System.out.println(&quot;线程B唤醒线程A&quot;); } finally { lock.unlock(); System.out.println(&quot;线程B释放锁成功&quot;); } }); tA.start(); tB.start(); }} 执行main函数后结果输出为： 1234567线程A加锁成功 线程A执行await被挂起 线程B加锁成功线程B唤醒线程A 线程B释放锁成功 线程A被唤醒成功 线程A释放锁成功 代码执行的结果很容易理解，线程A先获取锁，然后调用await()方法挂起当前线程并释放锁，线程B这时候拿到锁，然后调用SIGNAL唤醒线程A。 毫无疑问，这两个方法让线程的状态发生了变化，我们仔细来研究一下， 翻看AQS的源码，我们会发现Condition中定义了两个属性firstWaiter和lastWaiter，前面说了，AQS中包含了一个FIFO的CLH等待队列，每个Conditon对象就包含这样一个等待队列，而这两个属性分别表示的是等待队列中的首尾结点， 1234/** First node of condition queue. */private transient Node firstWaiter;/** Last node of condition queue. */private transient Node lastWaiter; 注意：Condition当中的等待队列和AQS主体的同步等待队列是分开的，两个队列虽然结构体相同，但是作用域是分开的 await先看await()的源码： 123456789101112131415161718192021 public final void await()throws InterruptedException{ if(Thread.interrupted()) throw new InterruptedException(); // 将当前线程加入到等待队列中 Node node=addConditionWaiter(); // 完全释放占有的资源，并返回资源数 int savedState=fullyRelease(node); int interruptMode=0; // 循环判断当前结点是不是在Condition的队列中，是的话挂起 while(!isOnSyncQueue(node)){ LockSupport.park(this); if((interruptMode=checkInterruptWhileWaiting(node))!=0) break; } if(acquireQueued(node,savedState)&amp;&amp;interruptMode!=THROW_IE) interruptMode=REINTERRUPT; if(node.nextWaiter!=null)// clean up if cancelled unlinkCancelledWaiters(); if(interruptMode!=0) reportInterruptAfterWait(interruptMode);} 当一个线程调用 Condition.await()方法，将会以当前线程构造结点，这个结点的waitStatus赋值为Node.CONDITION， 也就是-2，并将结点从尾部加入等待队列，然后尾部结点就会指向这个新增的结点， 123456789101112131415 private Node addConditionWaiter(){ Node t=lastWaiter; // If lastWaiter is cancelled, clean out. if(t!=null&amp;&amp;t.waitStatus!=Node.CONDITION){ unlinkCancelledWaiters(); t=lastWaiter; } Node node=new Node(Thread.currentThread(),Node.CONDITION); if(t==null) firstWaiter=node; else t.nextWaiter=node; lastWaiter=node; return node;} 我们依然用上面的demo来演示，此时，线程A获取锁并调用Condition.await()方法后，AQS内部的数据结构会变成这样：在Condition队列中插入对应的结点后，线程A会释放所持有的资源，走到while循环那层逻辑， 12345 while(!isOnSyncQueue(node)){ LockSupport.park(this); if((interruptMode=checkInterruptWhileWaiting(node))!=0) break;} isOnSyncQueue方法的会判断当前的线程节点是不是在同步队列中，这个时候此结点还在Condition队列中，所以该方法返回false，这样的话循环会一直持续下去，线程被挂起，等待被唤醒，此时，线程A的流程暂时停止了。 当线程A调用await()方法挂起的时候，线程B获取到了线程A释放的资源，然后执行SIGNAL()方法： SIGNAL1234567 public final void SIGNAL(){ if(!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first=firstWaiter; if(first!=null) doSIGNAL(first);} 先判断当前线程是否为获取锁的线程，如果不是则直接抛出异常。接着调用doSIGNAL()方法来唤醒线程。 12345678910111213141516171819 private void doSIGNAL(Node first){ // 循环，从队列一直往后找不为空的首结点 do{ if((firstWaiter=first.nextWaiter)==null) lastWaiter=null; first.nextWaiter=null; }while(!transferForSIGNAL(first)&amp;&amp;(first=firstWaiter)!=null);`} final boolean transferForSIGNAL(Node node){ // CAS循环，将结点的waitStatus改为0 if(!compareAndSetWaitStatus(node,Node.CONDITION,0)) return false; // 上面已经分析过，此方法会把当前结点加入到等待队列中，并返回前驱结点 Node p=enq(node); int ws=p.waitStatus; if(ws&gt;0||!compareAndSetWaitStatus(p,ws,Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} 从doSIGNAL的代码中可以看出，这时候程序寻找的是Condition等待队列中首结点firstWaiter的结点，此时该结点指向的是线程A的结点，所以之后的流程作用的都是线程A的结点。 这里分析下transferForSIGNAL方法，先通过CAS自旋将结点waitStatus改为0，然后就把结点放入到同步队列 (此队列不是Condition的等待队列) 中，然后再用CAS将同步队列中该结点的前驱结点waitStatus改为Node.SIGNAL，也就是-1，此时AQS的数据结构大概如下(额…..少画了个箭头，大家就当head结点是线程A结点的前驱结点就好)： 回到await()方法，当线程A的结点被加入同步队列中时，isOnSyncQueue()会返回true，跳出循环， 1234567891011while(!isOnSyncQueue(node)){ LockSupport.park(this); if((interruptMode=checkInterruptWhileWaiting(node))!=0) break;}if(acquireQueued(node,savedState)&amp;&amp;interruptMode!=THROW_IE) interruptMode=REINTERRUPT;if(node.nextWaiter!=null) // clean up if cancelled unlinkCancelledWaiters();if(interruptMode!=0) reportInterruptAfterWait(interruptMode); 接着执行acquireQueued()方法，这里就不用多说了吧，尝试重新获取锁，如果获取锁失败继续会被挂起，直到另外线程释放锁才被唤醒。 所以，当线程B释放完锁后，线程A被唤醒，继续尝试获取锁，至此流程结束。 对于这整个通信过程，我们可以画一张流程图展示下： 总结说完了Condition的使用和底层运行机制，我们再来总结下它跟普通 wait/notify 的比较，一般这也是问的比较多的，Condition大概有以下两点优势： Condition 需要结合 Lock 进行控制，使用的时候要注意一定要对应的unlock()，可以对多个不同条件进行控制，只要new 多个 Condition对象就可以为多个线程控制通信，wait/notify 只能和 synchronized 关键字一起使用，并且只能唤醒一个或者全部的等待队列； Condition 有类似于 await 的机制，因此不会产生加锁方式而产生的死锁出现，同时底层实现的是 park/unpark 的机制，因此也不会产生先唤醒再挂起的死锁，一句话就是不会产生死锁，但是 wait/notify 会产生先唤醒再挂起的死锁。 无论是独占还是共享模式，或者结合是Condition工具使用，AQS本质上的同步功能都是通过对锁和队列中结点的操作来实现的， 3. ReentrantLockReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。为了帮助大家更好地理解ReentrantLock的特性，我们先将ReentrantLock跟常用的Synchronized进行比较，其特性如下：下面通过伪代码，进行更加直观的比较： 1234567891011121314151617181920212223242526272829 // **************************Synchronized的使用方式************************** // 1.用于代码块 synchronized (this){} // 2.用于对象 synchronized (object){} // 3.用于方法 public synchronized void test(){}// 4.可重入for(int i=0;i&lt; 100;i++){ synchronized (this){}} // **************************ReentrantLock的使用方式************************** public void test()throw Exception{ // 1.初始化选择公平锁、非公平锁 ReentrantLock lock=new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try{ try{ // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100,TimeUnit.MILLISECONDS)){} }finally{ // 4.手动释放锁 lock.unlock() } }finally{ lock.unlock(); }} ReentrantLock 最基本的使用方式123456789101112class X { private final ReentrantLock lock = new ReentrantLock(); public void m() { lock.lock(); try { doSomething(); } finally { lock.unlock() } }} 当创建ReentrantLock时默认使用非公平锁，效率高于公平锁，暂不讨论公平锁。 ReentrantReadWriteLock的读锁的最基本的使用方式如下123456789101112class X { private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public void m() { rwl.readLock().lock(); try { read(); } finally { rwl.readLock().unlock(); } }} 2. synchronizesynchronized可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，同时它还可以保证共享变量的内存可见性。Synchronized主要有以下三个作用：保证互斥性、保证可见性、保证顺序性。 3. synchronize与lock的区别参考文章 图文并茂：AQS 是怎么运行的？ AQS 简介 Java技术之AQS详解 Java并发之AQS详解 从ReentrantLock的实现看AQS的原理及应用","link":"/2021/09/23/java/java_aqs/"},{"title":"centos install kubernetes (standalone)","text":"单机版kubernetes 1. 安装 etcd , kubernetes.1sudo yum install -y etcd kubernetes 2. 修改配置文件1sudo vim /etc/sysconfig/docker OPTIONS 内容设置为 : 1OPTIONS='--selinux-enabled=false --insecure-registry gcr.io' 1sudo vim /etc/kubernetes/apiserver 1把 --admission_control参数中的 ServiceAccount删除。 或者 ref: https://blog.csdn.net/a506681571/article/details/86087456Generate a signing key: 1openssl genrsa -out /tmp/serviceaccount.key 2048 Update /etc/kubernetes/apiserver: 1KUBE_API_ARGS=&quot;--service_account_key_file=/tmp/serviceaccount.key&quot; Update /etc/kubernetes/controller-manager: 1KUBE_CONTROLLER_MANAGER_ARGS=&quot;--service_account_private_key_file=/tmp/serviceaccount.key&quot; 3，按顺序启动所有服务：1234567sudo systemctl start etcdsudo systemctl start dockersudo systemctl start kube-apiserversudo systemctl start kube-controller-managersudo systemctl start kube-schedulersudo systemctl start kubeletsudo systemctl start kube-proxy 参考文章","link":"/2021/12/23/kubenetes/kubenetes-centos-standalone-k8s/"},{"title":"kubernetes 基础知识","text":"什么是 Kubernetes？Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化工作负载和服务，有助于声明式配置和自动化。它拥有庞大且快速发展的生态系统。Kubernetes 服务、支持和工具随处可见。 传统部署时代早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况， 结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。 虚拟化部署时代作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。 虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。 每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。 容器部署时代容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。 容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处： 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。 可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 Kubernetes 为您提供： 服务发现和负载平衡 Kubernetes 可以使用 DNS 名称或使用自己的 IP 地址公开容器。如果容器的流量很高，Kubernetes 能够负载均衡和分配网络流量，从而使部署稳定。 存储编排 Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。 自动推出和回滚 您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 为您的部署创建新容器、删除现有容器并将其所有资源用于新容器。 自动装箱 您为 Kubernetes 提供了一组节点，可用于运行容器化任务。您告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。Kubernetes 可以将容器安装到您的节点上，以充分利用您的资源。 自我修复 Kubernetes 会重启失败的容器、替换容器、杀死不响应用户定义的健康检查的容器，并且在它们准备好提供服务之前不会向客户端通告它们。 秘密和配置管理 Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 SSH 密钥。您可以部署和更新机密和应用程序配置，而无需重建容器映像，也无需在堆栈配置中公开机密。 参考文章 什么是 Kubernetes？ Kubernetes 组件 Kubernetes是什么 Kubernetes 基础知识入门","link":"/2021/12/29/kubenetes/kubernetes-base/"},{"title":"java 压缩","text":"GZIP https://nowjava.com/book/java-example/11374 Java GZIP Example – Compress and Decompress File java GZIP压缩与解压缩 https://blog.csdn.net/wenqisun/article/details/51121460 string123456789101112131415public static byte[] compress(String str, String encoding) { if (str == null || str.length() == 0) { return null; } ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip; try { gzip = new GZIPOutputStream(out); gzip.write(str.getBytes(encoding)); gzip.close(); } catch ( Exception e) { e.printStackTrace(); } return out.toByteArray(); } 123456789101112131415161718public static byte[] uncompress(byte[] bytes) { if (bytes == null || bytes.length == 0) { return null; } ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); try { GZIPInputStream ungzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n; while ((n = ungzip.read(buffer)) &gt;= 0) { out.write(buffer, 0, n); } } catch (Exception e) { e.printStackTrace(); } return out.toByteArray(); } file compress-a-file-in-gzip-format-in-java/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.util.zip.GZIPOutputStream; public class CompressFileGzip { public static void main(String[] args) { String source_filepath = &quot;C:\\\\Users\\\\nikos7\\\\Desktop\\\\files\\\\test.txt&quot;; String destinaton_zip_filepath = &quot;C:\\\\Users\\\\nikos7\\\\Desktop\\\\files\\\\test.gzip&quot;; CompressFileGzip gZipFile = new CompressFileGzip(); gZipFile.gzipFile(source_filepath, destinaton_zip_filepath); } public void gzipFile(String source_filepath, String destinaton_zip_filepath) { byte[] buffer = new byte[1024]; try { FileOutputStream fileOutputStream =new FileOutputStream(destinaton_zip_filepath); GZIPOutputStream gzipOuputStream = new GZIPOutputStream(fileOutputStream); FileInputStream fileInput = new FileInputStream(source_filepath); int bytes_read; while ((bytes_read = fileInput.read(buffer)) &gt; 0) { gzipOuputStream.write(buffer, 0, bytes_read); } fileInput.close(); gzipOuputStream.finish(); gzipOuputStream.close(); System.out.println(&quot;The file was compressed successfully!&quot;); } catch (IOException ex) { ex.printStackTrace(); } } } compressing-decompressing-files-using-gzip-format-java/1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.util.zip.GZIPInputStream; class GeeksForGeeks{ static final String INPUT_FILE = &quot;/home/saket/Desktop/GeeksforGeeks/compress.gz&quot;; static final String OUTPUT_FILE = &quot;/home/saket/Desktop//GeeksforGeeks/decompress.java&quot;; static void decompress() { byte[] buffer = new byte[1024]; try { GZIPInputStream is = new GZIPInputStream(new FileInputStream(INPUT_FILE)); FileOutputStream out = new FileOutputStream(OUTPUT_FILE); int totalSize; while((totalSize = is.read(buffer)) &gt; 0 ) { out.write(buffer, 0, totalSize); } out.close(); is.close(); System.out.println(&quot;File Successfully decompressed&quot;); } catch (IOException e) { e.printStackTrace(); } } public static void main (String[] args) { decompress(); }} Deflater / Inflater https://cloud.tencent.com/developer/article/1673594 https://www.cnblogs.com/zohnn/p/12899931.html JDK 之 Deflater 压缩与 Inflater 解压 关于Inflater和Deflater的简单用法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.io.ByteArrayOutputStream;import java.io.IOException;import java.util.Random;import java.util.zip.DataFormatException;import java.util.zip.Deflater;import java.util.zip.Inflater;public class DeflaterDemo2 { public static void main(String[] args) throws DataFormatException, IOException { StringBuilder builder = new StringBuilder(); for (int i = 0; i &lt; 100000; i++) { builder.append(&quot;Welcome to TutorialsPoint.com&quot; + (new Random().nextInt() * 26)); } String text = builder.toString(); byte[] compres = compress(text.getBytes(), true); System.out.println(compres.length + &quot; : &quot; + text.getBytes().length); String res = uncompress(compres, true); System.out.println(res.equals(text)); byte[] compres2 = compress(text.getBytes(), false); System.out.println(compres2.length + &quot; : &quot; + text.getBytes().length); String res2 = uncompress(compres2, false); System.out.println(res2.equals(text)); } public static String uncompress(byte[] input, boolean nowrap) throws IOException { Inflater inflater = new Inflater(nowrap); inflater.setInput(input); ByteArrayOutputStream baos = new ByteArrayOutputStream(input.length); try { byte[] buff = new byte[1024]; while (!inflater.finished()) { int count = inflater.inflate(buff); baos.write(buff, 0, count); } } catch (Exception e) { e.printStackTrace(); } finally { baos.close(); } inflater.end(); byte[] output = baos.toByteArray(); return new String(output); } public static byte[] compress(byte[] data, boolean nowrap) throws IOException { byte[] output; Deflater compress = new Deflater(Deflater.DEFAULT_COMPRESSION, nowrap); compress.reset(); compress.setInput(data); compress.finish(); ByteArrayOutputStream bos = new ByteArrayOutputStream(data.length); try { byte[] buf = new byte[1024]; while (!compress.finished()) { int i = compress.deflate(buf); bos.write(buf, 0, i); } output = bos.toByteArray(); } catch (Exception e) { output = data; e.printStackTrace(); } finally { bos.close(); } compress.end(); return output; }} ZIP Zipping and Unzipping in Java org.apache.commons.codec.binary.Base64 Java字符串的压缩与解压缩的两种方法1234567891011121314151617181920212223/** * 使用org.apache.commons.codec.binary.Base64压缩字符串 * @param str 要压缩的字符串 * @return */public static String compress(String str) { if (str == null || str.length() == 0) { return str; }//加入Java开发交流君样：756584822一起吹水聊天 return Base64.encodeBase64String(str.getBytes());} /** * 使用org.apache.commons.codec.binary.Base64解压缩 * @param compressedStr 压缩字符串 * @return */public static String uncompress(String compressedStr) { if (compressedStr == null) { return null; } return Base64.decodeBase64(compressedStr);} 注意事项 在web项目中，服务器端将加密后的字符串返回给前端，前端再通过ajax请求将加密字符串发送给服务器端处理的时候，在http传输过程中会改变加密字符串的内容，导致服务器解压压缩字符串发生异常： java.util.zip.ZipException: Not in GZIP format解决方法： 在字符串压缩之后，将压缩后的字符串BASE64加密，在使用的时候先BASE64解密再解压即可。 参考文章 Java压缩字符串的方法收集 压缩算法进行字符串压缩 Java字符串的压缩与解压缩的两种方法 Java中关于超长字符串压缩，解压缩问题","link":"/2021/09/23/java/java_zip/"},{"title":"kubernetes install","text":"参考文章 使用Kubeadm工具快速安装K8S集群 使用kubeadm在Centos8上部署kubernetes1.18 https://www.kubernetes.org.cn/5904.html Ubuntu 18.04 离线安装Kubernetes v1.11.1 centos7使用kubeadm安装kubernetes 1.11版本多主高可用 kubernetes1.11.0安装","link":"/2021/12/10/kubenetes/kubenetes-install/"},{"title":"kubernetes demo","text":"准备工作Docker拉取mysql镜像和tomcat镜像 1sudo docker pull mysql:5.7 1sudo docker pull kubeguide/tomcat-app:v1 为了解决， kubernetes pod卡在ContainerCreating的问题 12sudo docker pull registry.cn-hangzhou.aliyuncs.com/sunyuki/pod-infrastructuresudo docker tag f66f4bd9b894 registry.access.redhat.com/rhel7/pod-infrastructure:latest 创建 rc, svc yaml1vim mysql-rc.yaml 123456789101112131415161718192021apiVersion: v1kind: ReplicationControllermetadata: name: mysqlspec: replicas: 1 selector: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: &quot;123456&quot; 1vim mysql-svc.yaml 123456789apiVersion: v1kind: Servicemetadata: name: mysqlspec: ports: - port: 3306 selector: app: mysql 1vim myweb-rc.yaml 1234567891011121314151617181920212223apiVersion: v1kind: ReplicationControllermetadata: name: mywebspec: replicas: 1 selector: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: kubeguide/tomcat-app:v1 ports: - containerPort: 8080 env: - name: MYSQL_SERVICE_HOST value: &quot;mysql&quot; - name: MYSQL_SERVICE_PORT value: &quot;3306&quot; 1vim myweb-svc.yaml 1234567891011apiVersion: v1kind: Servicemetadata: name: mywebspec: type: NodePort ports: - port: 8080 nodePort: 30001 selector: app: myweb 1234sudo kubectl create -f mysql-rc.yamlsudo kubectl create -f mysql-svc.yamlsudo kubectl create -f myweb-rc.yamlsudo kubectl create -f myweb-svc.yaml 1234sudo kubectl delete -f mysql-rc.yamlsudo kubectl delete -f mysql-svc.yamlsudo kubectl delete -f myweb-rc.yamlsudo kubectl delete -f myweb-svc.yaml 1234sudo kubectl get rcsudo kubectl get svcsudo kubectl get podssudo kubectl get ep 1234567 kubectl get ep[root@localhost ~]# kubectl exec -ti myweb-qrjsd -- /bin/bashroot@myweb-qrjsd:/usr/local/tomcat# echo $MYSQL_SERVICE_HOSTmysqlroot@myweb-qrjsd:/usr/local/tomcat# echo &quot;172.17.0.2 mysql&quot; &gt;&gt; /etc/hostsroot@myweb-qrjsd:/usr/local/tomcat# 使用127.0.0.1:30001/demo打开页面 参考文章","link":"/2021/12/23/kubenetes/kubernetes-hello-world/"},{"title":"Kubernetes 组件","text":"控制平面组件（Control Plane Components） – master控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于多 VM 控制平面设置的示例。 kube-apiserverAPI 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 etcdetcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 kube-scheduler控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 kube-controller-manager运行控制器进程的控制平面组件。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应 任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod) 服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌cloud-controller-manager云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 Node 组件节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 kube-proxykube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 容器运行时（Container Runtime）容器运行环境是负责运行容器的软件。 Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 podPod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。Pod 的共享上下文包括一组 Linux 名字空间、控制组（cgroup）和可能一些其他的隔离 方面，即用来隔离 Docker 容器的技术。 在 Pod 的上下文中，每个独立的应用可能会进一步实施隔离。 就 Docker 概念的术语而言，Pod 类似于共享名字空间和文件系统卷的一组 Docker 容器。 每个 Pod 都有一个特殊的被称为“根容器＂的 Pause 容器 。Pause 器对应的镜像属于 Kubernetes 平台的一部分，除了 Pause 容器，每个 Pod 都还包含一个或多个紧密相关的用户业务容器。 Kubernete 为每个 Pod 分配了唯一 IP 地址，称之为 Pod IP, 一个 Pod 里的 多个容器共享 Pod IP 地址 Kubernetes 要求底层网络支待集群内任意两个 Pod 之间的 TCP/IP直接通信，这通常采用虚拟二层网络技术实现，例如 Flannel Open vSwitch 等，因此我们需要牢记一点 Kubernetes 里， 一个 Pod 里的容器与另外主机上的 Po 容器能够直接通信。 Pod 其实有两种类型：普通的 Pod 及静态 Pod (Static Pod)。后者比较特殊，它并没被 存放在 Kubernetes etcd 中，而是被存放在某个具体的 Node 上的 一个具体文件中，并且只能在此 Node 启动、运行。而普通的 Pod 旦被创建，就会被放入 etcd 中存储。 Pod Volume, Pod Volume 是被定义在 Pod 上，然后被各个容器挂载到自己的文件系统中 的。 Volume 单来说就是被挂载到 Pod 里的文件目录。 pod 与 deploymentendpointPod IP 加上这里的容器端口 (containerPort ） 状态的应用集群 StatefulSets StatefulSet 基础StatefulSet 之前曾用过 PetSet 这个名称，很多人都知道，在IT 世界里，有状态的应用被类比 宠物 Pet ，无状态的应用则被类比为牛羊，每个宠物在主人那里都是“唯一的存在＂，宠物生病了，我们是要 很多钱去治疗 ，需要我们用照料，而无差别 牛羊则没有这个待遇 总结下来，在有状态集群中一般有如下特殊共性 每个节点都有固定的身份 ID, 通过这个 ID 集群中的成员可以相互发现并通信 集群的规模是比较固定的，集群规模不能随意变动 集群中 每个节点都是有状态的，通常会待久 数据到永久存储中，每个节点在 重启后都需要使用原有的持久化数据 集群中成员节点的启动顺序（以及关闭顺序 ）通常也是确定的 如果磁盘损坏，则集群里的某个节点无法正常运行，集群功能受损 StatefulSet 是用来管理有状态应用的工作负载 API 对象。 StatefulSet 用来管理某 Pod 集合的部署和扩缩， 并为这些 Pod 提供持久存储和持久标识符。 和 Deployment 类似， StatefulSet 管理基于相同容器规约的一组 Pod。但和 Deployment 不同的是， StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。 StatefulSet 里的每个 Pod 都有稳定 唯一的网络标识，可以用来发现集群内的其他成员假设 StatefulSet 的名称为 kafka, 那么第1个 Pod 叫 kafka-0, 第2个叫 kafka-1,以此类推 StatefulSet 控制的 Pod 副本的启停顺序是受控的，操作第n个Pod 时，前 n-1 Pod 经是运行且准备好的状态 StatefulSet Pod 采用稳定的持久化存储卷，通过 PV PVC 来实现，删除 Pod 默认不会删除与 StatefulSet 相关的存储卷 （为了保证数据安全） 批处理应用 Jobhttps://kubernetes.io/zh/docs/concepts/workloads/controllers/job/ ConfigMap 配置中心https://kubernetes.io/zh/docs/concepts/configuration/configmap/ 存储卷卷示例：使用 Persistent Volumes 部署 WordPress 和 MySQL 参考文章 什么是 Kubernetes？ Kubernetes 组件 Kubernetes是什么 Kubernetes 基础知识入门","link":"/2021/12/29/kubenetes/kubernetes-components/"},{"title":"Kubernetes网络原理及方案","text":"前置知识Docker的网络模型 名词解释1、网络的命名空间：Linux在网络栈中引入网络命名空间，将独立的网络协议栈隔离到不同的命令空间中，彼此间无法通信；docker利用这一特性，实现不容器间的网络隔离。 2、Veth设备对：也叫虚拟网络接口对。Veth设备对的引入是为了实现在不同网络命名空间的通信。 3、Iptables/Netfilter：Netfilter负责在内核中执行各种挂接的规则(过滤、修改、丢弃等)，运行在内核 模式中；Iptables模式是在用户模式下运行的进程，负责协助维护内核中Netfilter的各种规则表；通过二者的配合来实现整个Linux网络协议栈中灵活的数据包处理机制。 4、网桥：网桥是一个二层网络设备,通过网桥可以将linux支持的不同的端口连接起来,并实现类似交换机那样的多对多的通信。 5、路由：Linux系统包含一个完整的路由功能，当IP层在处理数据发送或转发的时候，会使用路由表来决定发往哪里。 kubernetes网络模型Kubernetes 网络设计的一个基本原则是：每个Pod 都有一个全局唯一的IP, 而且假定所有的Pod 都在一个可以直接连通的，扁平的网络空间中，Pod 之间可以跨主机通信，按照这种网络原则抽象出来的一个Pod 对应一个IP的设计模型也被称作IP-per-Pod 模型。 相比于Docker 原生的NAT方式来说，这样使得容器在网络层面更像虚拟机或者物理机，复杂度整体降低，更加容易实现服务发现，迁移，负载均衡等功能。 容器间的通信同一个Pod的容器共享同一个网络命名空间，它们之间的访问可以用localhost地址 + 容器端口就可以访问。 这种情况下，同一个pod内共享网络命名空间，容器之间通过访问127.0.0.1:（端口）即可。图中的veth*即指veth对的一端（另一端未标注，但实际上是成对出现），该veth对是由Docker Daemon挂载在docker0网桥上，另一端添加到容器所属的网络命名空间，图上显示是容器中的eth0。 图中演示了bridge模式下的容器间通信。docker1向docker2发送请求，docker1，docker2均与docker0建立了veth对进行通讯。 当请求经过docker0时，由于容器和docker0同属于一个子网，因此请求经过docker2与docker0的veth*对，转发到docker2，该过程并未跨节点，因此不经过eth0。 Pod 间的通信 同一Node中Pod间通信：同一Node中Pod的默认路由都是docker0的地址，由于它们关联在同一个docker0网桥上，地址网段相同，所有它们之间应当是能直接通信的。 由于Pod内共享网络命名空间（由pause容器创建），所以本质上也是同节点容器间的通信。同时，同一Node中Pod的默认路由都是docker0的地址，由于它们关联在同一个docker0网桥上，地址网段相同，所有它们之间应当是能直接通信的。来看看实际上这一过程如何实现。如上图，Pod1中容器1和容器2共享网络命名空间，因此对pod外的请求通过pod1和Docker0网桥的veth对（图中挂在eth0和ethx上）实现。 不同Node中Pod间通信：不同Node中Pod间通信要满足2个条件： Pod的IP不能冲突； 将Pod的IP和所在的Node的IP关联起来，通过这个关联让Pod可以互相访问。 跨节点通信 CNI：容器网络接口 CNI 是一种标准，它旨在为容器平台提供网络的标准化。不同的容器平台（比如目前的 kubernetes、mesos 和 rkt）能够通过相同的接口调用不同的网络组件。 目前kubernetes支持的CNI组件种类很多，例如：bridge calico calico-ipam dhcp flannel host-local ipvlan loopback macvlan portmap ptp sample tuning vlan。在docker中，主流的跨主机通信方案主要有一下几种： 1）基于隧道的overlay网络：按隧道类型来说，不同的公司或者组织有不同的实现方案。docker原生的overlay网络就是基于vxlan隧道实现的。ovn则需要通过geneve或者stt隧道来实现的。flannel最新版本也开始默认基于vxlan实现overlay网络。 2）基于包封装的overlay网络：基于UDP封装等数据包包装方式，在docker集群上实现跨主机网络。典型实现方案有weave、flannel的早期版本。 3）基于三层实现SDN网络：基于三层协议和路由，直接在三层上实现跨主机网络，并且通过iptables实现网络的安全隔离。典型的方案为Project Calico。同时对不支持三层路由的环境，Project Calico还提供了基于IPIP封装的跨主机网络实现 集群内跨节点通信涉及到不同的子网间通信，仅靠docker0无法实现，这里需要借助CNI网络插件来实现。图中展示了使用flannel实现跨节点通信的方式。 简单说来，flannel的用户态进程flanneld会为每个node节点创建一个flannel.1的网桥，根据etcd或apiserver的全局统一的集群信息为每个node分配全局唯一的网段，避免地址冲突。同时会为docker0和flannel.1创建veth对，docker0将报文丢给flannel.1,。 Flanneld维护了一份全局node的网络表，通过flannel.1接收到请求后，根据node表，将请求二次封装为UDP包，扔给eth0，由eth0出口进入物理网路发送给目的node。 在另一端以相反的流程。Flanneld解包并发往docker0，进而发往目的Pod中的容器。 Pod 到Service 通信 当一个 Service 对象在 Kubernetes 集群中被定义出来时，集群内的客户端应用就可以通过服务 IP 访问到 体的 Pod 容器提供 的服务了。从服务 IP 到后 Pod 的负载均衡机制，则是由每个 Node 上的 kube-proxy 负责实现的。 kube-proxyKube-proxy是一个简单的网络代理和负载均衡器，它的作用主要是负责Service的实现，具体来说，就是实现了内部从Pod到Service和外部的从NodePort向Service的访问。 实现方式： userspace是在用户空间，通过kuber-proxy实现LB的代理服务，这个是kube-proxy的最初的版本，较为稳定，但是效率也自然不太高。 iptables是纯采用iptables来实现LB，是目前kube-proxy默认的方式。 kube-proxy 通过设置 Linux Kernel的 iptables 规则，实现从 Service到后端 Endpoint 列表的负载分发规则，效率很高 但是，如果某个后端 Endpoint在转发时不可用，此次客户端请求就会得到失败的响应，相对于 userspace 模式来说更不可靠。 此时应该通过为 Pod 设置 readinessprobe （服务可用性健康检查）来保证只有达到 ready 状态的 Endpoint 才会被设置为 Service 的后端 Endpoint. ipvs 模式：在 Kubernetes 11 本中达到 Stable 阶段， kube-proxy 通过设置 LinuxKernel netlink 接口设置 IPVS 规则，转发效率和支持的吞吐率都是最高的。 ipvs模式要求 Linux Kernel 启用 IPVS 模块，如果操作系统未启用 IPVS 内核模块，kube-proxy 则会自动切换至 iptables 模式 同时， ipvs 模式支持更多的负载均衡策略，如下所述 rr: round-robi n, 轮询 le: least connection, 最小连接数 dh: destination hashing, 目的地址哈希 sh: source has ing, 源地址哈希 sed: shortest expected delay 最短期望延时 nq: never queue, 永不排队。下面是iptables模式下Kube-proxy的实现方式： 在这种模式下，kube-proxy监视Kubernetes主服务器添加和删除服务和端点对象。对于每个服务，它安装iptables规则，捕获到服务的clusterIP（虚拟）和端口的流量，并将流量重定向到服务的后端集合之一。对于每个Endpoints对象，它安装选择后端Pod的iptables规则。 默认情况下，后端的选择是随机的。可以通过将service.spec.sessionAffinity设置为“ClientIP”（默认为“无”）来选择基于客户端IP的会话关联。 与用户空间代理一样，最终结果是绑定到服务的IP:端口的任何流量被代理到适当的后端，而客户端不知道关于Kubernetes或服务或Pod的任何信息。这应该比用户空间代理更快，更可靠。然而，与用户空间代理不同，如果最初选择的Pod不响应，则iptables代理不能自动重试另一个Pod，因此它取决于具有工作准备就绪探测。 外部到内部的通信 从集群外访问集群有多种方式，比如loadbalancer，Ingress，nodeport，nodeport和loadbalancer是service的两个基本类型，是将service直接对外暴露的方式，ingress则是提供了七层负载均衡，其基本原理将外部流量转发到内部的service，再转发到后端endpoints，在平时的使用中，我们可以依据具体的业务需求选用不同的方式。 Kubernetes 支持两种对外服务的Service 的Type 定义：NodePort 和LoadBalancer。 NodePort：在每个Node 上打开一个端口并且每个Node 的端口都是一样的，通过:NodePort 的方式，Kubernetes 集群外部的程序可以访问Service；LoadBalancer:通过外部的负载均衡器来访问。 Ingress Ingress是推荐在生产环境使用的方式，它起到了七层负载均衡器和Http方向代理的作用，可以根据不同的url把入口流量分发到不同的后端Service。外部客户端只看到http://foo.bar.com这个服务器，屏蔽了内部多个Service的实现方式。采用这种方式，简化了客户端的访问，并增加了后端实现和部署的灵活性，可以在不影响客户端的情况下对后端的服务部署进行调整。 其部署的yaml可以参考如下模板 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: ingress.kubernetes.io/rewrite-target: /spec: rules: - host: test.name.com http: paths: - path: /test backend: serviceName: service-1 servicePort: 8118 - path: /name backend: serviceName: service-2 servicePort: 8228 这里我们定义了一个ingress模板，定义通过http://test.name.com来访问服务，在虚拟主机http://test.name.com下面定义了两个Path，其中/test被分发到后端服务s1，/name被分发到后端服务s2。 集群中可以定义多个ingress，来完成不同服务的转发，这里需要一个ingress controller来管理集群中的Ingress规则。Ingress Contronler 通过与 Kubernetes API 交互，动态的去感知集群中 Ingress 规则变化，然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段 Nginx 配置，再写到 Nginx-ingress-control的 Pod 里，这个 Ingress Contronler 的pod里面运行着一个nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，然后 reload使用配置生效。 Kubernetes提供的Ingress Controller模板如下： 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: ingress.kubernetes.io/rewrite-target: /spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 Kube-dns介绍Kube-dns用来为kubernetes service分配子域名，在集群中可以通过名称访问service；通常kube-dns会为service赋予一个名为“service名称.namespace.svc.cluster.local”的A记录，用来解析service的clusterip。 Kube-dns组件： 在Kubernetes v1.4版本之前由“Kube2sky、Etcd、Skydns、Exechealthz”四个组件组成。 在Kubernetes v1.4版本及之后由“Kubedns、dnsmasq、exechealthz”三个组件组成。 Kubedns 接入SkyDNS，为dnsmasq提供查询服务。 替换etcd容器，使用树形结构在内存中保存DNS记录。 通过K8S API监视Service资源变化并更新DNS记录。 服务10053端口。 Dnsmasq Dnsmasq是一款小巧的DNS配置工具。 在kube-dns插件中的作用是： 通过kubedns容器获取DNS规则，在集群中提供DNS查询服务 提供DNS缓存，提高查询性能 降低kubedns容器的压力、提高稳定性 Dockerfile在GitHub上Kubernetes组织的contrib仓库中，位于dnsmasq目录下。 在kube-dns插件的编排文件中可以看到，dnsmasq通过参数–server=127.0.0.1:10053指定upstream为kubedns。 Exechealthz 在kube-dns插件中提供健康检查功能。 源码同样在contrib仓库中，位于exec-healthz目录下。 新版中会对两个容器都进行健康检查，更加完善。 Flannel容器网络：Flannel之所以可以搭建kubernets依赖的底层网络，是因为它可以实现以下两点： 它给每个node上的docker容器分配相互不想冲突的IP地址； 它能给这些IP地址之间建立一个覆盖网络，同过覆盖网络，将数据包原封不动的传递到目标容器内。 Flannel介绍 Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。 在默认的Docker配置中，每个节点上的Docker服务会分别负责所在节点容器的IP分配。这样导致的一个问题是，不同节点上容器可能获得相同的内外IP地址。并使这些容器之间能够之间通过IP地址相互找到，也就是相互ping通。 Flannel的设计目的就是为集群中的所有节点重新规划IP地址的使用规则，从而使得不同节点上的容器能够获得“同属一个内网”且”不重复的”IP地址，并让属于不同节点上的容器能够直接通过内网IP通信。 Flannel实质上是一种“覆盖网络(overlaynetwork)”，也就是将TCP数据包装在另一种网络包里面进行路由转发和通信，目前已经支持udp、vxlan、host-gw、aws-vpc、gce和alloc路由等数据转发方式，默认的节点间数据通信方式是UDP转发。 Calico容器网络：Calico介绍 Calico是一个纯3层的数据中心网络方案，而且无缝集成像OpenStack这种IaaS云架构，能够提供可控的VM、容器、裸机之间的IP通信。Calico不使用重叠网络比如flannel和libnetwork重叠网络驱动，它是一个纯三层的方法，使用虚拟路由代替虚拟交换，每一台虚拟路由通过BGP协议传播可达信息（路由）到剩余数据中心。 Calico在每一个计算节点利用Linux Kernel实现了一个高效的vRouter来负责数据转发，而每个vRouter通过BGP协议负责把自己上运行的workload的路由信息像整个Calico网络内传播——小规模部署可以直接互联，大规模下可通过指定的BGP route reflector来完成。 Calico节点组网可以直接利用数据中心的网络结构（无论是L2或者L3），不需要额外的NAT，隧道或者Overlay Network。 Calico基于iptables还提供了丰富而灵活的网络Policy，保证通过各个节点上的ACLs来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。Calico架构图 参考文章 Kubernetes网络原理及方案 Kubernetes初探：网络技术原理 Kubernetes网络介绍 一篇文章为你图解kubernetes网络通信原理","link":"/2021/12/31/kubenetes/kubernetes-network/"},{"title":"Fibonacci","text":"斐波那契数列大家都知道斐波那契数列，现在要求输入一个正整数 n ，请你输出斐波那契数列的第 n 项。 输入：4返回值：3 说明：根据斐波那契数列的定义可知，fib(1)=1,fib(2)=1,fib(3)=fib(3-1)+fib(3-2)=2,fib(4)=fib(4-1)+fib(4-2)=3，所以答案为3。 动态规划1234567891011public class Solution { public int Fibonacci(int n) { int[] dp = new int[n + 1]; dp[1] = 1; dp[2] = 1; for (int i = 3; i &lt;= n; i++) { dp[i] = dp[i - 1] + dp[i - 2]; } return dp[n]; }} 1234567891011121314151617import java.util.Scanner;// 注意类名必须为 Main, 不要有任何 package xxx 信息public class Main { public static void main(String[] args) { Scanner in = new Scanner(System.in); int n = in.nextInt(); int[] dp = new int[n + 1]; dp[1] = 1; dp[2] = 1; for (int i = 3; i &lt;= n; i++) { dp[i] = dp[i - 1] + dp[i - 2]; } System.out.println(dp[n]); }} 递归12345678public class Solution { public int Fibonacci(int n) { if (n == 1 || n == 2) { return 1; } return Fibonacci(n - 1) + Fibonacci(n - 2); }} 跳台阶一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个 n 级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 1234567891011121314151617public class Solution { public int jumpFloor(int target) { int[] dp = new int[40]; if(target ==1){ return 1; } if(target == 2){ return 2; } dp[1]=1; dp[2]=2; for(int i =3;i&lt;=target; i++){ dp[i]=dp[i-1] + dp[i-2]; } return dp[target]; }} 最小花费爬楼梯描述给定一个整数数组 cost ，其中 cost[i] 是从楼梯第i 个台阶向上爬需要支付的费用，下标从0开始。一旦你支付此费用，即可选择向上爬一个或者两个台阶。 你可以选择从下标为 0 或下标为 1 的台阶开始爬楼梯。 输入：[1,100,1,1,1,90,1,1,80,1]返回值：6说明：你将从下标为 0 的台阶开始。1.支付 1 ，向上爬两个台阶，到达下标为 2 的台阶。2.支付 1 ，向上爬两个台阶，到达下标为 4 的台阶。3.支付 1 ，向上爬两个台阶，到达下标为 6 的台阶。4.支付 1 ，向上爬一个台阶，到达下标为 7 的台阶。5.支付 1 ，向上爬两个台阶，到达下标为 9 的台阶。6.支付 1 ，向上爬一个台阶，到达楼梯顶部。总花费为 6 。 12345678910111213141516171819public class Solution { /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param cost int整型一维数组 * @return int整型 */ public int minCostClimbingStairs (int[] cost) { // write code here int[] dp = new int[100001]; dp[0]=0; dp[1]=0; for(int i=2;i&lt;=cost.length;i++){ dp[i]=Math.min(dp[i-1]+cost[i-1],dp[i-2]+cost[i-2]); } return dp[cost.length]; }}","link":"/2021/10/25/leetcode/leetcode_Fibonacci/"},{"title":"BM4 合并两个排序的链表","text":"描述 输入两个递增的链表，单个链表的长度为n，合并这两个链表并使新链表中的节点仍然是递增排序的。数据范围： 0≤n≤1000，−1000≤节点值≤1000要求：空间复杂度 O(1)，时间复杂度 O(n) 如输入{1,3,5},{2,4,6}时，合并后的链表为{1,2,3,4,5,6}，所以对应的输出为{1,2,3,4,5,6}，转换过程如下图所示：输入：{1,3,5},{2,4,6} 返回值：{1,2,3,4,5,6} 递归解题思路：特殊情况：如果有一个链表为空，返回另一个链表如果pHead1 节点值比小pHead2，下一个节点应该是 pHead1，应该return pHead1，在return之前，指定pHead1的下一个节点应该是pHead1.next和pHead2俩链表的合并后的头结点如果pHead1 节点值比pHead2大，下一个节点应该是pHead2，应该return pHead2，在return之前，指定pHead2的下一个节点应该是pHead1和pHead2.next俩链表的合并后的头结点 123456789101112131415161718public class Solution { public ListNode Merge(ListNode list1,ListNode list2) { // list1 list2为空的情况 if(list1 == null || list2 == null){ return list1 != null ? list1 : list2; } // 两个链表元素依次对比 if(list1.val &lt;= list2.val){ // 递归计算 list1.next, list2 list1.next = Merge(list1.next, list2); return list1; }else{ // 递归计算 list1, list2.next list2.next = Merge(list1, list2.next); return list2; } }} 借助额外数组解题思路：(1) 创建额外存储数组 nums(2) 依次循环遍历 pHead1, pHead2，将链表中的元素存储到 nums中，再对nums进行排序(3) 依次对排序后的数组 nums取数并构建合并后的链表 123456789101112131415161718192021222324252627282930313233public class Solution { public ListNode Merge(ListNode list1,ListNode list2) { // list1 list2为空的情况 if(list1==null) return list2; if(list2==null) return list1; if(list1 == null &amp;&amp; list2 == null){ return null; } //将两个两个链表存放在list中 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 遍历存储list1 while(list1!=null){ list.add(list1.val); list1 = list1.next; } // 遍历存储list2 while(list2!=null){ list.add(list2.val); list2 = list2.next; } // 对 list 排序 Collections.sort(list); // 将list转换为 链表 ListNode newHead = new ListNode(list.get(0)); ListNode cur = newHead; for(int i=1;i&lt;list.size();i++){ cur.next = new ListNode(list.get(i)); cur = cur.next; } // 输出合并链表 return newHead; }} 迭代设置result为哑结点，放置于新链表之前，最后返回的就是result.next；设置cur为当前节点，从result开始当两个链表都非空时进入循环，令新链表的下一个节点cur.next为val更小的节点，相应的链表节点后移一位，每次循环记得cur也要后移一位如果循环结束后还有链表非空，cur指向非空链表，返回result.next 123456789101112131415161718192021222324252627282930# -*- coding:utf-8 -*-# class ListNode:# def __init__(self, x):# self.val = x# self.next = None class Solution: # 返回合并后列表 def Merge(self, pHead1, pHead2): # write code here if not pHead1: return pHead2 if not pHead2: return pHead1 result = ListNode(-1) cur = result while pHead1 and pHead2: # 元素对比 if pHead1.val &lt;= pHead2.val: cur.next = pHead1 pHead1 = pHead1.next else: cur.next = pHead2 pHead2 = pHead2.next # 指针右移动一位 cur = cur.next # 拼接未对比的链表 cur.next = pHead1 if pHead1 else pHead2 return result.next self12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.company;public class Merge { public static void main(String[] args) { ListNode listNode1 = new ListNode(1); ListNode listNode2 = new ListNode(2); ListNode listNode3 = new ListNode(3); ListNode listNode4 = new ListNode(4); ListNode listNode5 = new ListNode(5); ListNode listNode6 = new ListNode(6); listNode1.next = listNode3; listNode3.next = listNode5; listNode2.next = listNode4; listNode4.next = listNode6; ListNode result = Merge(listNode1, listNode2); System.out.println(&quot;111&quot;); } public static ListNode Merge(ListNode list1, ListNode list2) { ListNode result = new ListNode(-1); ListNode p = result; ListNode p1 = list1; ListNode p2 = list2; while (true) { if (p1 == null) { p.next = p2; break; } if (p2 == null) { p.next = p1; break; } if (p1.val &lt;= p2.val) { p.next = p1; p = p.next; p1 = p1.next; } else { p.next = p2; p = p.next; p2 = p2.next; } } return result.next; }}","link":"/2021/10/25/leetcode/leetcode_Merge/"},{"title":"二维数组中的查找","text":"描述 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 123456[ [1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]] 给定 target = 7，返回 true。 给定 target = 3，返回 false。 数据范围：矩阵的长宽满足 0≤n,m≤500 ， 矩阵中的值满足 0 ≤val≤10^9 进阶：空间复杂度 O(1) ，时间复杂度 O(n+m) 示例1输入：7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]返回值：true说明：存在7，返回true 示例2输入：1,[[2]]返回值：false 示例3 输入：3,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]返回值：false 说明：不存在3，返回false","link":"/2021/10/25/leetcode/leetcode_find/"},{"title":"kubernetes service","text":"Service是一组Pod的服务抽象，相当于一组Pod的LB，负责将请求分发给对应的 Pod；Service会为这个LB提供一个IP，一般称为ClusterIP。 service 概述 Kubernetes 里的 Service 具有一个全局唯一的虚拟 ClusterIP 地址，Service 一旦被创建， Kubernetes 就会自动为它分配一个可用的 clusterIP 地址，而且在 Service 整个生命周期中，它的 clusterIP 地址都不会改变，客户端可以通过这个虚拟 IP 地址+服务的端口直接访问该服务, 再通过部署 Kubernetes 集群的 DNS 服务，就可以实现 Service Name（域名）到 clusterIP 地址的 DNS 映射功能，我们只要使用服务的名称（ DNS 名称 ）即可完成到目标服务的访问请求 。“ 服务发现“这个传统架构中的棘手问题在这里首次得以完美解决，同时，凭借 lusterIP 地址的独特设计， kubernetes 进一 步实现了 Service 的透明负载均衡和故障自动恢复的高级特性。 Service: Cluster IP 每个 Pod 都会被分配一个单独的 IP 地址，而且每 Pod 都提供了一个独立的 Endpoint (Pod IP + container port) 以被客户端访问，那么现在多个 Pod 副本组成了一个集群来提供服务，客户端如何访问它们呢？ 传统的做法是部署一个负载均衡器（软件或硬件），为这组 Pod 开启一个对外的服务端口如 8000 端口，并且将这些 Pod Endpoint 表加入 8000 端口的转发列表中，客户端就可以通过负载均衡器的对外IP地址＋8000 端口访问此服务了。kubernetes 也是类似的做法，Kubernetes 内部在每个 Node 上都运行了一套全局的虚拟负载均衡器 kube-proxy ，自动注入并自动实时更新集群中所有 Service 的路由表，通过iptables 或者 IP 机制, 把对 Service 的请求转发到其后端对应的某个 Pod 实例上，并在内部实现服务的负载均衡与会话保待机制 不仅如此， Kubernetes 还采用了 种很巧妙又影响深远的设计一Cluster IP 地址 .我们知道， pod的Endpoint 地址会随着 Pod 的销毁和重新创建而发生改变， 因为新 Pod IP 地址与之前旧 Pod 的不同 ，Service 一旦被创建，Kubernetes 就会自动为它 配一个全局唯一的虚拟 IP 地址——Cluster 地址，而且在Service 的整个生命周期内，ClusterIP 地址不会发生改变，这样一来，每个服务就变成了具备唯一 IP 的通信节 ，远程服务之间的通信间题就变成了基础的 TCP 网络通信问题。 查看cluster ip1kubectl get svc tomcat-service -o yaml Service是一组Pod的服务抽象，相当于一组Pod的LB，负责将请求分发给对应的 Pod；Service会为这个LB提供一个IP，一般称为ClusterIP。 service 定义1234567891011apiVersion: v1kind: Servicemetadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 上述配置创建一个名称为 “my-service” 的 Service 对象，它会将请求代理到使用 TCP 端口 9376，并且具有标签 “app=MyApp” 的 Pod 上。ports 定义部分指定了 Service 本身的端口号为 8080, targetPort 则用来指定 后端 Pod 的容器端口号 Kubernetes 为该服务分配一个 ClusterIP 地址（有时称为 “集群IP”），该 IP 地址由服务代理使用。 服务选择算符的控制器不断扫描与其选择器匹配的 Pod，然后将所有更新发布到也称为 “my-service” 的 Endpoint 对象。 service typeClusterIP 通过集群的内部 IP 暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的 ServiceType。当然，用户也可手工指定一个 ClusterIP 地址，不过需要确保该 IP 在 Kubernetes 集群设置 clusterIP 地址范围内（通过 kube-apiserver 服务的启 动参数– service-cluster-ip-range 设置），并且没有被其他 Service 使用 NodePort 将 Service 的端口号映射到每个 Node 一个端口号上，这样集群中的 任意 Node 都可以作为 Service 访问入口地址，即 NodeIP:NodePort. 通过每个节点上的 IP 和静态端口（NodePort）暴露服务。 NodePort 服务会路由到自动创建的 ClusterIP 服务。 通过请求 &lt;节点 IP&gt;:&lt;节点端口&gt;，你可以从集群的外部访问一个 NodePort 服务。 123456789101112131415apiVersion: v1kind: Servicemetadata: name: my-servicespec: type: NodePort selector: app: MyApp ports: # 默认情况下，为了方便起见，`targetPort` 被设置为与 `port` 字段相同的值。 - port: 80 targetPort: 80 # 可选字段 # 默认情况下，为了方便起见，Kubernetes 控制平面会从某个范围内分配一个端口号（默认：30000-32767） nodePort: 30007 通过将Service的类型设置为NodePort，就可以在Cluster中的主机上通过一个指定端口暴露服务。注意通过Cluster中每台主机上的该指定端口都可以访问到该服务，发送到该主机端口的请求会被kubernetes路由到提供服务的Pod上。采用这种服务类型，可以在kubernetes cluster网络外通过主机IP：端口的方式访问到服务。 1234567891011kind: ServiceapiVersion: v1metadata: name: influxdbspec: type: NodePort ports: - port: 8086 nodePort: 31112 selector: name: influxdb LoadBalancer 将 Service 映射到一个已存在的负载均衡器的 IP 地址上，通常在公有云环境中使用. 在使用支持外部负载均衡器的云提供商的服务时，设置 type 的值为 “LoadBalancer”， 将为 Service 提供负载均衡器。 负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过 Service 的 status.loadBalancer 字段发布出去。 实例： 1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 192.0.2.127 来自外部负载均衡器的流量将直接重定向到后端 Pod 上，不过实际它们是如何工作的，这要依赖于云提供商。 某些云提供商允许设置 loadBalancerIP。 在这些情况下，将根据用户设置的 loadBalancerIP 来创建负载均衡器。 如果没有设置 loadBalancerIP 字段，将会给负载均衡器指派一个临时 IP。 如果设置了 loadBalancerIP，但云提供商并不支持这种特性，那么设置的 loadBalancerIP 值将会被忽略掉。 ExternalName 将Service 映射为 一个外部域名地址 ，通过 externalName 字段进行设置。 通过返回 CNAME 和对应值，可以将服务映射到 externalName 字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理。 headless service有时不需要或不想要负载均衡，以及单独的 Service IP。 遇到这种情况，可以通过指定 Cluster IP（spec.clusterIP）的值为 “None” 来创建 Headless Service。 你可以使用无头 Service 与其他服务发现机制进行接口，而不必与 Kubernetes 的实现捆绑在一起。 对这无头 Service 并不会分配 Cluster IP，kube-proxy 不会处理它们， 而且平台也不会为它们进行负载均衡和路由。 DNS 如何实现自动配置，依赖于 Service 是否定义了选择算符。 带选择算符的服务对定义了选择算符的无头服务，Endpoint 控制器在 API 中创建了 Endpoints 记录， 并且修改 DNS 配置返回 A 记录（IP 地址），通过这个地址直接到达 Service 的后端 Pod 上。 无选择算符的服务对没有定义选择算符的无头服务，Endpoint 控制器不会创建 Endpoints 记录。 然而 DNS 系统会查找和配置，无论是： 对于 ExternalName 类型的服务，查找其 CNAME 记录对所有其他类型的服务，查找与 Service 名称相同的任何 Endpoints 的记录 在 spec.ports 的定义中， targetPort 属性用来确定提供该服务的容器所悬露 (Expose)的端口号，即具体的业务进程在容器内的 targetPort 上提供 TCP/IP 接入； port 属性则定义Service 的端口。前面定义 Tomcat 服务时并没有指定 targetPort, 所以 targetPort 默认与port 相同。除了正常的 service ，还有一种特殊的 Service – Headless service ，只要在 Service的定义中设置了 clusterIP: None, 就定义了一个 Headless service, 它与普通 service 的关键区别在于它没有 ClusterIP 地址，如果解析 Headless service DNS 域名，则返回的是该Service 对应的全部 Pod Endpoint 列表，这意味着客户端是直接与后端的 pod建立 TCP/IP连接进行通信的，没有通过虚拟 clusterIP 地址进行转发，因此通信性能最高，等同千”原生网络通信”。 Service 的外网访问问题 Service 暴霓到集群外部 Kubernetes Service 创建的 ClusterIP 地址是对后端 Pod 列表的一层抽象，对于集群外部来说并没有意义，但有许多 Service 是需要对集群外部提供服务的， Kubernetes 提供了多种机制将 Service 暴露出去，供集群外部的客户端访问 这可以通过 Service 资源对象的类型字段 “type：【clusterIp, NodePort, LoadBalancer, ExternalName】” 进行设置。 前面提到，服务的 lusterIP 地址在 Kubernetes 集群内才能被访问，那么如何让集群外的应用访问我们的服务呢？这也是一个相对复杂的问题 要弄明白这个问题的解决思路和解决方法，我们需要先弄明白 Kubernetes 的三种 IP, 这三种 IP 分别如下 Node IP: Node IP 地址 Pod IP: Pod IP 地址 Service IP: Service IP 地址 首先， Node IP 是 Kubernetes 集群中每个节点的物理网卡的 IP 地址，是 个真实存在的物理网络，所有属于这个网络的服务器都能通过这个网络直接通信，不管其中是否有部分节点不属于这个 Kubernetes 集群 这也表明 ubernetes 集群之外的节点访问 Kubernetes集群内的某个节点或者 TCP/I 务时，都必须通过 Node IP.其次， Pod IP 是每个 Pod IP 地址，在使用 Docker 作为容器支持引擎的情况下，它Docker Engine 艰据 dockerO 网桥的 IP 地址段进行分配的，通常是一个虚拟二层网络。前面说过， Kubernetes 要求位于不同 Node的Pod 能够彼此直接通信，所以 Kubernetes中一个 Pod 里的容器访问另外一个 Pod 里的容器时， 就是通过 Pod IP 所在的虚拟二层网络进行通信的，而真实的 TCP IP 流童是通过 Node IP 所在的物理网卡流出的. 在Kubernetes 集群内， Service ClusterIP 地址属于集群内的地址，无法在 群外接使用这个地址 为了解决这个问题， Kubernetes 首先引入了 NodePort 这个概念， NodePort也是解决集群外的应用访问集群内服务的直接、有效的常见做法 NodePort 负载均衡器组件独立于 Kubernetes 集群之外 参考文章","link":"/2021/12/31/kubenetes/kubernetes-service/"},{"title":"BM5 合并k个已排序的链表","text":"描述合并 k 个升序的链表并将结果作为一个升序的链表返回其头节点。 数据范围：节点总数满足 0≤n≤10^5 ，链表个数满足1≤k≤10^5 ，每个链表的长度满足1≤len≤200 ，每个节点的值满足 |val| &lt;= 1000 要求：时间复杂度 O(nlogk) 输入：[{1,2},{1,4,5},{6}]返回值：{1,1,2,4,5,6} 辅助数组解题思路主要采用将列表中的链表结点值遍历存储到辅助数组中，再对数组进行排序，根据排序后的数组元素一次构建新链表1、遍历列表，分别将每一个链表的元素值存储到数组tmp中2、对tmp进行排序3、依次遍历数组元素创新新链表 123456789101112131415161718192021class Solution: def mergeKLists(self , lists ): # write code here # 将所有链表元素存放到list中，排序后再转换为链表 tmp = [] for head in lists: while head: # 将链表结点存放到tmp中 tmp.append(head.val) head = head.next if not tmp: return None # tmp进行排序 tmp.sort() res = ListNode(-1) cur = res # 根据tmp生成新的链表 for i in range(len(tmp)): cur.next = ListNode(tmp[i]) cur = cur.next return res.next 顺序合并解题思路1、将k个链表配对并将同一对中的链表进行合并（采用顺序合并的方法）2、第一轮合并后，k个链表合并成了 k/2 个链表，平均长度 2n/k ，然后是 k/4、k/8…等等3、重复这一过程，知道获取最终的有序链表 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.*;/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { public ListNode mergeKLists(ArrayListlists) { // 采用分治进行合并链表 return mergeList( lists , 0 , lists.size() - 1 ); } // 分治进行链表两两合并 public ListNode mergeList(ArrayListlists , int L ,int R){ if(L == R){ return lists.get(L); } if(L &gt; R){ return null; } int mid = L + ((R - L) &gt;&gt; 1); return merge( mergeList(lists,L,mid) , mergeList(lists,mid+1,R)); } // 合并两个链表，对比合并 public ListNode merge(ListNode l1 , ListNode l2){ if(l1 == null || l2 == null){ return l1 == null ? l2 : l1; } ListNode dummy = new ListNode(-1); ListNode cur = dummy; while( l1 != null &amp;&amp; l2 != null){ if(l1.val &lt; l2.val){ cur.next = l1; l1 = l1.next; }else{ cur.next = l2; l2 = l2.next; } cur = cur.next; } cur.next = (l1 == null ? l2 : l1); return dummy.next; } } 优先队列解题思路使用优先队列去存储所有链表。按照链表头结点值，进行从小到大的排序，最小的头结点的链表在堆顶。1、每次将堆顶的链表取出2、将头结点从取出的链表上去除，并插在所需目标链表的尾部。3、将取出的链表放回堆中。若链表为null，则不放回。重复1，2，3过程，直到堆为空，循环终止。 123456789101112131415161718192021import heapqclass Solution: def mergeKLists(self , lists ): # write code here dummy = ListNode(0) p = dummy head = [] for i in range(len(lists)): if lists[i] : heapq.heappush(head, (lists[i].val, i)) lists[i] = lists[i].next while head: val, idx = heapq.heappop(head) p.next = ListNode(val) p = p.next if lists[idx]: heapq.heappush(head, (lists[idx].val, idx)) lists[idx] = lists[idx].next return dummy.next self12345678910111213141516171819202122232425262728293031323334353637import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.stream.Collectors;/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { public ListNode mergeKLists(ArrayList&lt;ListNode&gt; lists) { List&lt;Integer&gt; tmp = lists.stream().map(v -&gt; { List&lt;Integer&gt; temp = new ArrayList&lt;&gt;(); while (v != null) { temp.add(v.val); v = v.next; } return temp; }) .flatMap(List::stream) .collect(Collectors.toList()); Collections.sort(tmp); ListNode result = new ListNode(-1); ListNode p = result; for (Integer integer : tmp) { p.next = new ListNode(integer); p = p.next; } return result.next; }}","link":"/2021/10/25/leetcode/leetcode_mergeKLists/"},{"title":"BM2 链表内指定区间反转","text":"描述 将一个节点数为 size 链表 m 位置到 n 位置之间的区间反转，要求时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)。例如：给出的链表为 1→2→3→4→5→NULL, m=2,n=4m=2,n=4,返回 1→4→3→2→5→NULL. 数据范围： 链表长度 0 &lt;&lt;size≤1000，0&lt;m≤n≤size，链表中每个节点的值满足 ∣val∣≤1000要求：时间复杂度 O(n) ，空间复杂度 O(n)进阶：时间复杂度 O(n)，空间复杂度 O(1)示例1输入：{1,2,3,4,5},2,4返回值：{1,4,3,2,5} 示例2输入： {5},1,1返回值： {5} 解法一：双指针(两次遍历)思路步骤：要反转局部链表，可以将该局部部分当作完整链表进行反转 再将已经反转好的局部链表与其他节点建立连接，重构链表 建议使用虚拟头节点的技巧，可以避免对头节点复杂的分类考虑，简化操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.*;/* * public class ListNode { * int val; * ListNode next = null; * } */public class Solution { /** * * @param head ListNode类 * @param m int整型 * @param n int整型 * @return ListNode类 */ // 解法一：双指针(两次遍历) //说明：方便理解，以下注释中将用left，right分别代替m,n节点 public ListNode reverseBetween (ListNode head, int m, int n) { //设置虚拟头节点 ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; //1.走left-1步到left的前一个节点 for(int i=0;i&lt;m-1;i++){ pre = pre.next; } //2.走roght-left+1步到right节点 ListNode rigthNode = pre; for(int i=0;i&lt;n-m+1;i++){ rigthNode = rigthNode.next; } //3.截取出一个子链表 ListNode leftNode = pre.next; ListNode cur = rigthNode.next; //4.切断链接 pre.next=null; rigthNode.next=null; //5.反转局部链表 reverseLinkedList(leftNode); //6.接回原来的链表 pre.next = rigthNode; leftNode.next = cur; return dummyNode.next; } //反转局部链表 private void reverseLinkedList(ListNode head){ ListNode pre = null; ListNode cur = head; while(cur!=null){ //Cur_next 指向cur节点的下一个节点 ListNode Cur_next = cur.next; cur.next = pre; pre = cur; cur = Cur_next ; } }} 解法二：一次遍历（对解法一的优化）解法一一个明显不足在于，当所给子区间[m,n]范围过大，恰好等于链表头尾节点是，遍历成本变大。 解法二的思路在于，固定子区间外的节点。 在需要反转的区间里，每遍历到一个节点，让这个新节点来到反转部分的起始位置。 curr：指向待反转区域的第一个节点 left；Cur_next：永远指向 curr 的下一个节点，循环过程中，curr 变化以后 Cur_next 会变化；pre：永远指向待反转区域的第一个节点 left 的前一个节点，在循环过程中不变。 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.*;/* * public class ListNode { * int val; * ListNode next = null; * } */public class Solution { /** * * @param head ListNode类 * @param m int整型 * @param n int整型 * @return ListNode类 */ // //说明：方便理解，以下注释中将用left，right分别代替m,n节点 public ListNode reverseBetween (ListNode head, int m, int n) { //设置虚拟头节点 ListNode dummyNode = new ListNode(-1); dummyNode.next =head; ListNode pre = dummyNode; for(int i=0;i&lt;m-1;i++){ pre = pre.next; } ListNode cur = pre.next; ListNode Cur_next ; for(int i=0;i&lt;n-m;i++){ Cur_next = cur.next; cur.next = Cur_next.next; Cur_next .next = pre.next; pre.next = Cur_next ; } return dummyNode.next; }} 方法三：递归的思想求解求解思路对于反转链表，我们使用递归的思想，将大问题转换为小问题，然后进行相应的求解即可。对于递归过程，判断n的数值，当n为1时返回head指针，否则进行递归，并且反转链表，最后进行拼接，返回拼接之后的链表。 我们来看看另一种分析：如果m == 1，就相当于反转链表的前nnn元素；如果 m != 1，我们把 head 的索引视为 1，那么我们是想从第 mmm 个元素开始反转，如果把 head.next 的索引视为1，那相对于 head.next的反转的区间应该是从第 m−1m - 1m−1 个元素开始的，以此类推，反转区间的起点往后就是一个子问题，我们可以使用递归处理： 终止条件： 当m == 1，就可以直接反转前n个元素。 返回值： 将已经反转后的子问题头节点返回给上一级。 本级任务： 递归地缩短区间，拼接本级节点与子问题已经反转的部分。12//从头开始往后去掉前面不反转的部分ListNode node = reverseBetween(head.next, m - 1, n - 1) 而每次反转，如果n == 1，相当于只颠倒第一个节点，如果不是，则进入后续节点（子问题），因此反转过程也可以使用递归： 终止条件： 当n == 1时，只反转当前头节点即可。 返回值： 将子问题反转后的节点头返回。 本级任务： 缩短nnn进入子问题反转，等子问题回到本级再反转当前节点与后续节点的连接。 12//颠倒后续的节点，直到n=1为最后一个ListNode node = reverse(head.next, n - 1) 具体做法： step 1：准备全局变量temp，最初等于null，找到递归到第nnn个节点时，指向其后一个位置，要将反转部分的起点（即反转后的尾）连接到这个指针。 step 2：按照第一个递归的思路缩短子问题找到反转区间的起点，将反转后的部分拼接到前面正常的后面。 step 3：按照第二个递归的思路缩短终点的子问题，从第nnn个位置开始反转，反转过程中每个子问题作为反转后的尾，都要指向temp。 1234567891011121314151617181920212223242526272829import java.util.*;public class Solution { ListNode temp = null; public ListNode reverse(ListNode head, int n){ //只颠倒第一个节点，后续不管 if(n == 1){ temp = head.next; return head; } //进入子问题 ListNode node = reverse(head.next, n - 1); //反转 head.next.next = head; //每个子问题反转后的尾拼接第n个位置后的节点 head.next = temp; return node; } public ListNode reverseBetween (ListNode head, int m, int n) { //从第一个节点开始 if(m == 1) return reverse(head, n); //缩减子问题 ListNode node = reverseBetween(head.next, m - 1, n - 1); //拼接已翻转 head.next = node; return head; }}","link":"/2021/10/25/leetcode/leetcode_reverseBetween/"},{"title":"链表中的节点每k个一组翻转","text":"描述将给出的链表中的节点每 k 个一组翻转，返回翻转后的链表如果链表中的节点数不是 k 的倍数，将最后剩下的节点保持原样你不能更改节点中的值，只能更改节点本身。 数据范围： 0≤n≤2000 ， 1≤k≤2000 ，链表中每个元素都满足 0≤val≤1000要求空间复杂度 O(1)，时间复杂度 O(n)例如：给定的链表是 1→2→3→4→5对于 k = 2k=2 , 你应该返回 2→1→4→3→5对于 k = 3k=3 , 你应该返回 3→2→1→4→5 方法一 模拟法将一条链表分块分为链表长度/k块链表，如果处不尽则说明后面会有剩下的那一块是不满长度为k的。在最初的时候需要定义两个NodeList表示result(结果)和 now(当前所到达的结果链表的位置)。之后遍历块的长度，对每一个链表块进行翻转，再翻转完后将完成的链表插入到now链表的下一个，再将now链表更新到最前即可。 1234567891011121314151617181920212223242526272829303132333435363738394041public class Solution { /** * * @param head ListNode类 * @param k int整型 * @return ListNode类 */ public ListNode reverseKGroup (ListNode head, int k) { // write code here if(k &lt;= 1) return head; if(head == null) return head; ListNode node = head; int len = length(head); head = node; int sx = len / k; //分成sx块向下取整（默认向下） 因为处不尽的后面必然凑不满k个 ListNode result = new ListNode(0); ListNode now = result; int cnt = 0; for(int i = 0; i &lt; sx; i ++){ ListNode tmp = null; for(int j = 0; j &lt; k; j ++){ //将第i块的元素翻转 ListNode bl = head.next; head.next = tmp; tmp = head; head = bl; } now.next = tmp; while(now.next != null) now = now.next; //将now更新到最前的一个点 } now.next = head; return result.next; } public int length(ListNode now){ //获取链表长度 int cnt = 0; if(now != null) cnt = 1; while(now.next != null){ cnt ++; now = now.next; } return cnt; }} 方法二 栈和方法一一样将链表分成每段长度为k的子链表，将每个链表存入栈中，当栈中有k个元素即可一一取出，之后按取出的顺序重组链表就是这一段中翻转的链表，要注意的是处理尾部不满长度为k的链表块时直接取栈底的元素做为最后一段即可。时间复杂度 O(n) 遍历了整个链表并且重组链表使用了时间为2n空间复杂度 O(k) 栈中存入最大有k个ListNode 123456789101112131415161718192021222324252627282930public ListNode reverseKGroup (ListNode head, int k) { // write code here if(k &lt;= 1 || head == null) return head; Deque&lt;ListNode&gt; st = new ArrayDeque&lt;ListNode&gt;(); //模拟栈 ListNode result = new ListNode(0); ListNode now = result; int cnt = 0; while(true){ for(int i = 0; i &lt; k; i ++){ //将当前链表前k个存入栈中 st.push(head); head = head.next; cnt ++; if(head == null) break; } if(cnt == k){ //如果当前栈中有k个元素则一一取出存入链表 while(!st.isEmpty()){ now.next = st.pop(); now = now.next; now.next = null; } } if(head == null) break; //如果链表取完了跳出循环 cnt = 0; } ListNode end = null; while(!st.isEmpty()){ //如果栈中还有剩下的就说明是最后的一块直接取栈底即可 end = st.pop(); } now.next = end; return result.next; } 方法：递归（推荐使用）思路： 现在我们想一想，如果拿到一个链表，想要像上述一样分组翻转应该做些什么？首先肯定是分段吧，至少我们要先分成一组一组，才能够在组内翻转，之后就是组内翻转，最后是将反转后的分组连接。 但是连接的时候遇到问题了：首先如果能够翻转，链表第一个元素一定是第一组，它翻转之后就跑到后面去了，而第一组的末尾元素才是新的链表首，我们要返回的也是这个元素，而原本的链表首要连接下一组翻转后的头部，即翻转前的尾部，如果不建立新的链表，看起来就会非常难。但是如果我们从最后的一个组开始翻转，得到了最后一个组的链表首，是不是可以直接连在倒数第二个组翻转后的尾（即翻转前的头）后面，这样从后往前是不是看起来就容易多了。 怎样从后往前呢？我们这时候可以用到自上而下再自下而上的递归或者说栈。接下来我们说说为什么能用递归？如果这个链表有nnn个分组可以反转，我们首先对第一个分组反转，那么是不是接下来将剩余n−1n-1n−1个分组反转后的结果接在第一组后面就行了，那这剩余的n−1n-1n−1组就是一个子问题。我们来看看递归的三段式模版： 终止条件： 当进行到最后一个分组，即不足k次遍历到链表尾（0次也算），就将剩余的部分直接返回。 返回值： 每一级要返回的就是翻转后的这一分组的头，以及连接好它后面所有翻转好的分组链表。 本级任务： 对于每个子问题，先遍历k次，找到该组结尾在哪里，然后从这一组开头遍历到结尾，依次翻转，结尾就可以作为下一个分组的开头，而先前指向开头的元素已经跑到了这一分组的最后，可以用它来连接它后面的子问题，即后面分组的头。具体做法： step 1：每次从进入函数的头节点优先遍历链表k次，分出一组，若是后续不足k个节点，不用反转直接返回头。 step 2：从进入函数的头节点开始，依次反转接下来的一组链表，反转过程同BM1.反转链表。 step 3：这一组经过反转后，原来的头变成了尾，后面接下一组的反转结果，下一组采用上述递归继续。图示 link 1234567891011121314151617181920212223242526272829import java.util.*;public class Solution { public ListNode reverseKGroup (ListNode head, int k) { //找到每次翻转的尾部 ListNode tail = head; //遍历k次到尾部 for(int i = 0; i &lt; k; i++){ //如果不足k到了链表尾，直接返回，不翻转 if(tail == null) return head; tail = tail.next; } //翻转时需要的前序和当前节点 ListNode pre = null; ListNode cur = head; //在到达当前段尾节点前 while(cur != tail){ //翻转 ListNode temp = cur.next; cur.next = pre; pre = cur; cur = temp; } //当前尾指向下一段要翻转的链表 head.next = reverseKGroup(tail, k); return pre; }} self123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.company;public class reverseKGroup { public static void main(String[] args) { ListNode listNode1 = new ListNode(1); ListNode listNode2 = new ListNode(2); ListNode listNode3 = new ListNode(3); ListNode listNode4 = new ListNode(4); ListNode listNode5 = new ListNode(5); listNode1.next = listNode2; // listNode2.next = listNode3; // listNode3.next = listNode4; // listNode4.next = listNode5; ListNode result = reverseKGroup(listNode1, 2); System.out.println(result); } public static ListNode reverseKGroup(ListNode head, int k) { if (head == null) { return null; } ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; ListNode cur = head; ListNode left = null; ListNode right = null; while (cur != null &amp;&amp; cur.next != null) { left = cur; int i = 0; for (; i &lt; k - 1; i++) { if (cur.next == null) { break; } cur = cur.next; } if (cur.next == null &amp;&amp; i &lt; k - 1) { break; } right = cur; cur = cur.next; right.next = null; revert(left); pre.next = right; left.next = cur; pre = left; } return dummyNode.next; } public static ListNode revert(ListNode head) { ListNode pre = null; ListNode cur = head; while (cur != null) { ListNode cur_next = cur.next; cur.next = pre; pre = cur; cur = cur_next; } return pre; } public static class ListNode { int val; ListNode next = null; ListNode(int val) { this.val = val; } }}","link":"/2021/10/25/leetcode/leetcode_reverseKGroup/"},{"title":"BM1 反转链表","text":"反转链表 给定一个单链表的头结点pHead(该头节点是有值的，比如在下图，它的val是1)，长度为n，反转该链表后，返回新链表的表头。 数据范围： 0≤n≤1000要求：空间复杂度 O(1) ，时间复杂度 O(n) 。 如当输入链表{1,2,3}时，经反转后，原链表变为{3,2,1}，所以对应的输出为{3,2,1}。 栈1234567891011121314151617181920212223242526import java.util.Stack;public class Solution { public ListNode ReverseList(ListNode head) { Stack&lt;ListNode&gt; stack= new Stack&lt;&gt;(); //把链表节点全部摘掉放到栈中 while (head != null) { stack.push(head); head = head.next; } if (stack.isEmpty()) return null; ListNode node = stack.pop(); ListNode dummy = node; //栈中的结点全部出栈，然后重新连成一个新的链表 while (!stack.isEmpty()) { ListNode tempNode = stack.pop(); node.next = tempNode; node = node.next; } //最后一个结点就是反转前的头结点，一定要让他的next //等于空，否则会构成环 node.next = null; return dummy; }} 双链表求解双链表求解是把原链表的结点一个个摘掉，每次摘掉的链表都让他成为新的链表的头结点，然后更新新链表。下面以链表1→2→3→4为例画个图来看下。 12345678910111213141516171819public ListNode ReverseList(ListNode head) { //新链表 ListNode newHead = null; while (head != null) { //先保存访问的节点的下一个节点，保存起来 //留着下一步访问的 ListNode temp = head.next; //每次访问的原链表节点都会成为新链表的头结点， //其实就是把新链表挂到访问的原链表节点的 //后面就行了 head.next = newHead; //更新新链表 newHead = head; //重新赋值，继续访问 head = temp; } //返回新链表 return newHead;} 递归迭代在遍历链表时，将当前节点的next 指针改为指向前一个节点。由于节点没有引用其前一个节点，因此必须事先存储其前一个节点。在更改引用之前，还需要存储后一个节点。最后返回新的头引用。 12345678910111213141516171819202122232425262728293031/*public class ListNode { int val; ListNode next = null; ListNode(int val) { this.val = val; }}*/public class Solution { public ListNode ReverseList(ListNode head) { //pre指针：用来指向反转后的节点，初始化为null ListNode pre = null; //当前节点指针 ListNode cur = head; //循环迭代 while(cur!=null){ //Cur_next 节点，永远指向当前节点cur的下一个节点 // 断开链表 ListNode Cur_next = cur.next; //反转的关键：当前的节点指向其前一个节点(注意这不是双向链表，没有前驱指针) cur.next = pre; //更新pre pre = cur; //更新当前节点指针 cur = Cur_next ; } //为什么返回pre？因为pre是反转之后的头节点 return pre; }} 自己实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.company;public class RevertLinkedList { public static void main(String[] args) { ListNode listNode1 = new ListNode(1); ListNode listNode2 = new ListNode(2); ListNode listNode3 = new ListNode(3); // listNode1.next = listNode2; // listNode2.next = listNode3; ListNode result = ReverseList(listNode1); System.out.println(result); } public static ListNode ReverseList(ListNode head) { if(head == null){ return null; } if(head.next == null){ return head; } ListNode p = head; ListNode q = head.next; ListNode s = q.next; q.next = p; p.next = null; while (s != null) { p = q; q = s; s = s.next; q.next = p; } return q; } public static class ListNode { int val; ListNode next = null; ListNode(int val) { this.val = val; } }}","link":"/2021/10/25/leetcode/leetcode_reverseList/"},{"title":"","text":"","link":"/2021/10/25/leetcode/leetcode_template/"},{"title":"mysql 数据库事务","text":"事务四大属性原子性（Atomicity）事务包含的所有操作要么全部成功，要么全部失败回滚 一致性（Consistency）一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。举例来说，假设用户A和用户B两者的钱加起来一共是1000，那么不管A和B之间如何转账、转几次账，事务结束后两个用户的钱相加起来应该还得是1000，这就是事务的一致性。 隔离性（Isolation）隔离性是当多个用户并发访问数据库时，比如同时操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性（Durability）持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务已经正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成。否则的话就会造成我们虽然看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。这是不允许的。 事务的隔离级别现在来看看MySQL数据库为我们提供的四种隔离级别： 1234 ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 为什么要设置隔离级别在数据库操作中，在并发的情况下可能出现如下问题： 更新丢失（Lost update）如果多个线程操作，基于同一个查询结构对表中的记录进行修改，那么后修改的记录将会覆盖前面修改的记录，前面的修改就丢失掉了，这就叫做更新丢失。这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来。 第1类丢失更新：事务A撤销时，把已经提交的事务B的更新数据覆盖了。 第2类丢失更新：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。 解决方法：对行加锁，只允许并发一个更新事务。 脏读（Dirty Reads）脏读（Dirty Read）：A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。 解决办法：如果在第一个事务提交前，任何其他事务不可读取其修改过的值，则可以避免该问题。 不可重复读（Non-repeatable Reads）一个事务对同一行数据重复读取两次，但是却得到了不同的结果。事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值。 解决办法：如果只有在修改事务完全提交之后才可以读取数据，则可以避免该问题。 幻象读指两次执行同一条 select 语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中。一般情况下，幻象读应该正是我们所需要的。但有时候却不是，如果打开的游标，在对游标进行操作时，并不希望新增的记录加到游标命中的数据集中来。隔离级别为 游标稳定性 的，可以阻止幻象读。例如：目前工资为1000的员工有10人。那么事务1中读取所有工资为1000的员工，得到了10条记录；这时事务2向员工表插入了一条员工记录，工资也为1000；那么事务1再次读取所有工资为1000的员工共读取到了11条记录。 解决办法：如果在操作事务完成数据处理之前，任何其他事务都不可以添加新数据，则可避免该问题。 正是为了解决以上情况，数据库提供了几种隔离级别。 事务的隔离级别数据库事务的隔离级别有4个，由低到高依次为Read uncommitted(未授权读取、读未提交)、Read committed（授权读取、读提交）、Repeatable read（可重复读取）、Serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻象读这几类问题。 Read uncommitted(未授权读取、读未提交)：如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。Read committed（授权读取、读提交）：读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。 Repeatable read（可重复读取）：可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。 Serializable（序列化）：提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed。它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读和第二类丢失更新这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。MySQL的默认隔离级别就是Repeatable read。 悲观锁和乐观锁虽然数据库的隔离级别可以解决大多数问题，但是灵活度较差，为此又提出了悲观锁和乐观锁的概念。 悲观锁悲观锁，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度。因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制。也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统的数据访问层中实现了加锁机制，也无法保证外部系统不会修改数据。 使用场景举例：以MySQL InnoDB为例 商品t_items表中有一个字段status，status为1代表商品未被下单，status为2代表商品已经被下单（此时该商品无法再次下单），那么我们对某个商品下单时必须确保该商品status为1。假设商品的id为1。如果不采用锁，那么操作方法如下： 123456//1.查询出商品信息select status from t_items where id=1;//2.根据商品信息生成订单,并插入订单表 t_orders insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_items set status=2; 但是上面这种场景在高并发访问的情况下很可能会出现问题。例如当第一步操作中，查询出来的商品status为1。但是当我们执行第三步Update操作的时候，有可能出现其他人先一步对商品下单把t_items中的status修改为2了，但是我们并不知道数据已经被修改了，这样就可能造成同一个商品被下单2次，使得数据不一致。所以说这种方式是不安全的。 使用悲观锁来解决问题 在上面的场景中，商品信息从查询出来到修改，中间有一个处理订单的过程，使用悲观锁的原理就是，当我们在查询出t_items信息后就把当前的数据锁定，直到我们修改完毕后再解锁。那么在这个过程中，因为t_items被锁定了，就不会出现有第三者来对其进行修改了。需要注意的是，要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。我们可以使用命令设置MySQL为非autocommit模式：set autocommit=0;设置完autocommit后，我们就可以执行我们的正常业务了。具体如下： 12345678910//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select status from t_items where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_items set status=2;//4.提交事务commit;/commit work; 上面的begin/commit为事务的开始和结束，因为在前一步我们关闭了mysql的autocommit，所以需要手动控制事务的提交。上面的第一步我们执行了一次查询操作：select status from t_items where id=1 for update;与普通查询不一样的是，我们使用了select…for update的方式，这样就通过数据库实现了悲观锁。此时在t_items表中，id为1的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。需要注意的是，在事务中，只有SELECT … FOR UPDATE 或LOCK IN SHARE MODE 操作同一个数据时才会等待其它事务结束后才执行，一般SELECT … 则不受此影响。拿上面的实例来说，当我执行select status from t_items where id=1 for update;后。我在另外的事务中如果再次执行select status from t_items where id=1 for update;则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但是如果我是在第二个事务中执行select status from t_items where id=1;则能正常查询出数据，不会受第一个事务的影响。 Row Lock与Table Lock 使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认Row-Level Lock，所以只有「明确」地指定主键或者索引，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。举例如下：1、select * from t_items where id=1 for update; 这条语句明确指定主键（id=1），并且有此数据（id=1的数据存在），则采用row lock。只锁定当前这条数据。2、select * from t_items where id=3 for update; 这条语句明确指定主键，但是却查无此数据，此时不会产生lock（没有元数据，又去lock谁呢？）。3、select * from t_items where name='手机' for update; 这条语句没有指定数据的主键，那么此时产生table lock，即在当前事务提交前整张数据表的所有字段将无法被查询。4、select * from t_items where id&gt;0 for update; 或者select * from t_items where id&lt;&gt;1 for update;（注：&lt;&gt;在SQL中表示不等于）上述两条语句的主键都不明确，也会产生table lock。5、select * from t_items where status=1 for update;（假设为status字段添加了索引）这条语句明确指定了索引，并且有此数据，则产生row lock。6、select * from t_items where status=3 for update;（假设为status字段添加了索引）这条语句明确指定索引，但是根据索引查无此数据，也就不会产生lock。 悲观锁小结 悲观锁并不是适用于任何场景，它也有它存在的一些不足，因为悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。如果加锁的时间过长，其他用户长时间无法访问，影响了程序的并发访问性，同时这样对数据库性能开销影响也很大，特别是对长事务而言，这样的开销往往无法承受。所以与悲观锁相对的，我们有了乐观锁。 乐观锁乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以只会在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回用户错误的信息，让用户决定如何去做。实现乐观锁一般来说有以下2种方式： 使用版本号 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 使用时间戳 乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。 参考文章: https://www.cnblogs.com/limuzi1994/p/9684083.html","link":"/2021/10/19/mysql/mysql-affairs/"},{"title":"mongodb intro","text":"一. 概览插件式存储引擎， MongoDB 3.0引入了插件式存储引擎API，为第三方的存储引擎厂商加入MongoDB提供了方便目前除了早期的MMAP存储引擎外，WiredTiger和RocksDB 均 已完成了对MongoDB的支持， 1.1 compare MMAPv1 and WiredTiger ； 以及WiredTiger 新特性 文档级别并发控制多个客户端请求同时更新一个集合内存的多个文档，再也不需要在排队等待 库级别的写锁。 Snapshot Checkpoints（快照和检查点）:mongoDB每60秒或日志文件【jonurnal】达到2G会创建一个检查点(产生一个snapshot[快照])，该Snapshot呈现的是内存中数据的一致性视图，当向Disk写入数据时，WiredTiger将Snapshot中的所有数据以一致性方式写入到数据文件（Disk Files）中 Journal（日志）: 开启 journal 后，每次写入会记录一条操作日志（通过journal可以重新构造出写入的数据），一次写入，会对应数据、索引，oplog的修改，而这3个修改，会对应一条journal操作日志 磁盘数据压缩WiredTiger 支持对所有集合和索引进行Block压缩和前缀压缩（如果数据库启用了journal，journal文件一样会压缩）， MemoryUse（内存使用）从MongoDB 3.2 版本开始，WiredTiger内部缓存的使用量，默认值是：1GB 或 60% of RAM - 1GB，取两值中的较大值；文件系统缓存的使用量不固定，MongoDB自动使用系统空闲的内存，这些内存不被WiredTiger缓存和其他进程使用，数据在文件系统缓存中是压缩存储的。 基础数据结构 典型的B-Tree数据结构B-Tree是为磁盘或其它辅助存储设备而设计的一种数据结构，目的是为了在查找数据的过程中减少磁盘I/O的次数 从上往下 Root结点 -&gt; 内部结点 -&gt; 叶子结点，每个结点就是一个Page，数据以Page为单位在内存和磁盘间进行调度，每个Page的大小决定了相应结点的分支数量，每条索引记录会包含一个数据指针，指向一条数据记录所在文件的偏移量。 磁盘上的基础数据结构 B-Tree对于WiredTiger存储引擎来说，集合所在的数据文件和相应的索引文件都是按B-Tree结构来组织的，不同之处在于数据文件对应的B-Tree叶子结点上除了存储键名外（keys），还会存储真正的集合数据（values） WiredTiger有一个块设备管理的模块，用来为page分配block。如果要定位某一行数据（key/value）的位置，可以先通过block的位置找到此page（相对于文件起始位置的偏移量），再通过page找到行数据的相对位置，最后可以得到行数据相对于文件起始位置的偏移量offsets。由于offsets是一个8字节大小的变量，所以WiredTiger磁盘文件的大小，其最大值可以非常大(264bit)。 内存上的基础数据结构内存会构造相应的B-Tree来存储这些数据按需将磁盘的数据以page为单位加载到内存 为了高效的支撑CRUD等操作以及将内存里面发生变化的数据持久化到磁盘上，WiredTiger也会在内存里面维护其它几种数据结构， 存储引擎是如何将数据加载到内存，然后如何通过相应数据结构来支持查询、插入、修改操作的。 rootpage、internal page和leaf page，前两者包含指向其子页的page index指针，不包含集合中的真正数据，leaf page包含集合中的真正数据即keys/values和指向父页的home指针 WAL what is wal ?预写式日志Write Ahead Log简称WAL，在分布式存储系统中的元数据更新中应用得十分广泛。WAL的主要意思是说在将元数据的变更操作写入到持久稳定的db之前，先预先写入到一个log中，然后再由另外的操作将log apply到外部的持久db里去。这种模式会减少掉每次的db写入操作，尤其当系统要处理大量的transaction操作的时候，WAL的方式相比较于实时同步db的方式有着更高的效率。WAL还有一点很重要的帮助是可以在disaster recovery过程中起到状态恢复的作用，系统在load完元数据db后，再把未来得及提交的WAL apply进来，就能恢复成和之前最终一致的状态。 WAL 的优点 读和写可以完全地并发执行，不会互相阻塞（但是写之间仍然不能并发）。 WAL 在大多数情况下，拥有更好的性能（因为无需每次写入时都要写两个文件）。 磁盘 I/O 行为更容易被预测。 使用更少的 fsync()操作，减少系统脆弱的问题。 Checkpoint包含的关键信息事务一.索引索引支持MongoDB中查询的高效执行。如果没有索引，MongoDB必须执行集合扫描 介绍当你往某各个集合插入多个文档后，每个文档在经过底层的存储引擎持久化后，会有一个位置信息，通过这个位置信息，就能从存储引擎里读出该文档。mmapv1引擎里，位置信息是『文件id + 文件内offset 』，wiredtiger存储引擎（一个KV存储引擎）里，位置信息是wiredtiger在存储文档时生成的一个key，通过这个key能 文本索引 使用 $text 查询操作符在一个有 text index 的集合上执行文本检索。 $text 将会使用空格和标点符号作为分隔符对检索字符串进行分词， 并且对检索字符串中所有的分词结果进行一个逻辑上的 OR 操作。使用下面的查询语句来找到所有包含 “coffee”, “shop”, 以及 “java” 列表中任何词语的商店： 精确检索 您也可以通过将它们包括在双引号中来进行精确检索。例如，下列的命令将会找到所有包含”java” 或者 “coffee shop” 的文档： 词语排除 为了排除一个词语，您可以在前面加上一个 “-” 字符。例如，为了找到所有包含 “java” 或者 “shop” 但是不包含 “coffee” 的商店，使用下面的命令： 排序MongoDB默认返回未经排序的结果。然而，文本检索查询将会对每个文档计算一个相关性分数，表明该文档与查询的匹配程度。 为了使用相关性分数进行排序，您必须显式地对 $meta textScore字段进行映射然后基于该字段进行排序。 二. 复制集MongoDB选举的原理MongoDB的节点分为三种类型，分别为标准节点（host）、被动节点（passive）和仲裁节点（arbiter） 只有标准节点才有可能被选举为活跃节点（主节点），拥有选举权。被动节点有完整副本，不可能成为活跃节点，具有选举权。仲裁节点不复制数据，不可能成为活跃节点，只有选举权。说白了就是只有标准节点才有可能被选举为主节点，即使在一个复制集中说有的标准节点都宕机，被动节点和仲裁节点也不会成为主节点。后续有示例演示验证。标准节点与被动节点的区别：priority值高者是标准节点，低者则为被动节点选举规则是票数高的获胜，priority是优先权 0~1000 的值，相当于额外增加 0~1000 的票数。选举结果：票数高者获胜；若票数相同，数据新者获胜。 如果启用复制集的话，在内存中会多一个OPLOG区域，是在节点之间进行同步的一个手段，它会把操作日志放到OPLOG中来，然后OPLOG会复制到从节点上。从节点接收并执行OPLOG中的操作日志来达到数据的同步操作。 客户端的数据进来； 数据操作写入到日志缓冲； 数据写入到数据缓冲； 把日志缓冲中的操作日志放到OPLOG中来； 返回操作结果到客户端（异步）； 后台线程进行OPLOG复制到从节点，这个频率是非常高的，比日志刷盘频率还要高，从节点会一直监听主节点，OPLOG一有变化就会进行复制操作； 后台线程进行日志缓冲中的数据刷盘，非常频繁（默认100）毫秒，也可自行设置（30-60）； 后台线程进行数据缓冲中的数据刷盘，默认是60秒； Oplog的数据结构ts：操作发生时的时间戳，这个时间戳包含两部分内容t和i，t是标准的时间戳（自1970年1月1日 00:00:00 GMT 以来的毫秒数）。而i是一个序号，目的是为了保证t与i组合出的Mongo时间戳ts可以唯一的确定一条操作记录。 h：此操作的独一无二的ID。 v：oplog的版本。 op：操作类型（insert、update、delete、db cmd、null），紧紧代表一个消息信息。 ns：操作所处的命名空间（db_name.coll_name）。 o：操作对应的文档，文档在更新前的状态（“msg” 表示信息）。 o2：仅update操作时有，更新操作的变更条件（只记录更改数据）。 Oplog大小及意义当你第一次启动复制集中的节点时，MongoDB会用默认大小建立Oplog。这个默认大小取决于你的机器的操作系统。大多数情况下，默认的oplog大小是足够的。在 mongod 建立oplog之前，我们可以通过设置 oplogSizeMB 选项来设定其大小。但是，如果已经初始化过复制集，已经建立了Oplog了，我们需要通过修改Oplog大小中的方式来修改其大小。 OpLog的默认大小：在64位Linux、Windows操作系统上为当前分区可用空间的5%，但最大不会超过50G。在64位的OS X系统中，MongoDB默认分片183M大小给Oplog。在32位的系统中，MongoDB分片48MB的空间给Oplog。 Oplog大小应随着实际使用压力而增加如果我能够对我复制集的工作情况有一个很好地预估，如果可能会出现以下的情况，那么我们就可能需要创建一个比默认大小更大的oplog。相反的，如果我们的应用主要是读，而写操作很少，那么一个小一点的oplog就足够了。 下列情况我们可能需要更大的oplog。 同时更新大量的文档。 Oplog为了保证 幂等性 会将多项更新（multi-updates）转换为一条条单条的操作记录。这就会在数据没有那么多变动的情况下大量的占用oplog空间。 删除了与插入时相同大小的数据 如果我们删除了与我们插入时同样多的数据，数据库将不会在硬盘使用情况上有显著提升，但是oplog的增长情况会显著提升。 大量In-Place更新 如果我们会有大量的in-place更新，数据库会记录下大量的操作记录，但此时硬盘中数据量不会有所变化。 Oplog幂等性 Oplog有一个非常重要的特性——幂等性（idempotent）。即对一个数据集合，使用oplog中记录的操作重放时，无论被重放多少次，其结果会是一样的。举例来说，如果oplog中记录的是一个插入操作，并不会因为你重放了两次，数据库中就得到两条相同的记录。 Oplog的状态信息 我们可以通过 rs.printReplicationInfo() 来查看oplog的状态，包括大小、存储的操作的时间范围。关于oplog的更多信息可以参考Check the Size of the Oplog。 复制集数据同步过程Mongodb复制集里的Secondary会从Primary上同步数据，以保持副本集所有节点的数据保持一致，数据同步主要包含2个过程 initial sync先通过initial sync同步全量数据，再通过replication不断重放Primary上的oplog同步增量数据。 initial sync 初始同步会将完整的数据集复制到各个节点上，Secondary启动后，如果满足以下条件之一，会先进行initial sync。 Secondary上oplog为空，比如新加入的空节点。 local.replset.minvalid集合里_initialSyncFlag标记被设置。当initial sync开始时，同步线程会设置该标记，当initial sync结束时清除该标记，故如果initial sync过程中途失败，节点重启后发现该标记被设置，就知道应该重新进行initial sync。 BackgroundSync:: _initialSyncRequestedFlag被设置。当向节点发送resync命令时，该标记会被设置，此时会强制重新initial sync。 initial sync同步流程 minValid集合设置_initialSyncFlag（db.replset.minvalid.find()）。 获取同步源当前最新的oplog时间戳t0。 从同步源克隆所有的集合数据。 获取同步源最新的oplog时间戳t1。 同步t0~t1所有的oplog。 获取同步源最新的oplog时间戳t2。 同步t1~t2所有的oplog。 从同步源读取index信息，并建立索引（除了_id ，这个之前已经建立完成）。 获取同步源最新的oplog时间戳t3。 同步t2~t3所有的oplog。 minValid集合清除_initialSyncFlag，initial sync结束。 当完成了所有操作后，该节点将会变为正常的状态secondary。 replication (sync oplog) initial sync结束后，Secondary会建立到Primary上local.oplog.rs的tailable cursor，不断从Primary上获取新写入的oplog，并应用到自身。Tailable cursor每次会获取到一批oplog，Secondary采用多线程重放oplog以提高效率，通过将oplog按照所属的namespace进行分组，划分到多个线程里，保证同一个namespace的所有操作都由一个线程来replay，以保证统一namespace的操作时序跟primary上保持一致（如果引擎支持文档锁，只需保证同一个文档的操作时序与primary一致即可）。 Server Side Public License (SSPL)13.提供程序即服务。如果您将本程序或修改版的功能作为服务提供给第三方，则必须根据本许可的条款，通过网络下载免费向所有人提供服务源代码。 将本程序或修改版本的功能作为服务提供给第三方可以包括但不限于使第三方能够通过计算机网络与本程序或修改版本的功能进行远程交互， 从而提供其全部或全部价值的服务。主要来自程序或修订版的价值，或提供给用户以实现程序或修订版的主要目的的服务。 “服务源代码”是指本程序或经修改的版本的相应源，以及您用于使本程序或经修改的版本作为服务可用的所有程序的相应源， 包括但不限于管理软件，用户界面，应用程序界面，自动化软件，监视软件，备份软件，存储软件和托管软件， 所有这些使用户可以使用您提供的服务源代码运行服务实例。 使用MongoDB作为数据库的其他SaaS应用程序没有copyleft条件。新许可证对使用MongoDB构建并作为服务（SaaS）提供的应用程序有什么影响？仅当您向第三方提供MongoDB的功能或MongoDB的修改版本时，SSPL第13节的copyleft条件才适用。 使用MongoDB作为数据库的其他SaaS应用程序没有copyleft条件。","link":"/2021/09/23/mongodb/mongo_intro/"},{"title":"二分查找-I","text":"描述请实现无重复数字的升序数组的二分查找 给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1 数据范围：0 ≤len(nums)≤2×10^5 ， 数组中任意值满足 |val| ≤ 10^9 进阶：时间复杂度 O(logn) ，空间复杂度 O(1) 示例1输入：[-1,0,3,4,6,10,13,14],13 返回值：6说明：13 出现在nums中并且下标为 6示例2输入：[],3 返回值：-1 说明：nums为空，返回-1示例3输入：[-1,0,3,4,6,10,13,14],2 返回值：-1 说明：2 不存在nums中因此返回 -1 二分法（推荐使用）1234567891011121314151617181920212223import java.util.*;public class Solution { public int search (int[] nums, int target) { int l = 0; int r = nums.length - 1; //从数组首尾开始，直到二者相遇 while(l &lt;= r){ //每次检查中点的值 int m = (l + r) / 2; if(nums[m] == target) return m; //进入左的区间 if(nums[m] &gt; target) r = m - 1; //进入右区间 else l = m + 1; } //未找到 return -1; }} self12345678910111213141516171819202122public static int search(int[] nums, int target) { if (nums.length == 0) { return -1; } // write code here int i = 0; int j = nums.length-1; while (i &lt;= j) { int mid = (i + j) / 2; if (nums[mid] == target) { return mid; } if (nums[mid] &gt; target) { j = mid - 1; } if (nums[mid] &lt; target) { i = mid + 1; } } return -1;}","link":"/2021/10/25/leetcode/leetcode_search/"},{"title":"SQL语句不走索引时的排查利器 explain extended + show warnings","text":"索引字段出现隐式字符集转换,索引失效如果索引字段出现隐式字符集转换的话，那么索引将失效，进而转为全表扫描，查询效率将大大降低，要避免出现隐式字符集转换； 隐式字符集转换导致索引失效的原因MySQL索引的数据结构是 B+Tree，想要走索引查询必须要满足其 最左前缀原则 ，否则无法通过索引树进行查找，只能进行全表扫描； 例如：下面的这个SQL由于在 索引字段 上使用函数进行运算，导致索引失效 1select * from t_user where SUBSTR(name, 1, 2) = '李彤' 上面的这个SQL怎么改造才能使索引生效呢？如下所示： 1select * from t_user where name like '李彤%' 通过上面的小例子可以知道，如果在索引字段上使用函数运算，则会导致索引失效，而索引字段的 隐式字符集转换 由于MySQL会自动的在索引字段上加上 转换函数 ，进而会导致索引失效；那接下来我们就通过模拟的实际场景来具体看看是不是由于MySQL自动给加上了转换函数而导致索引失效的； explain extended + show warningsEXTENDED关键字的具体查阅资料：https://dev.mysql.com/doc/refman/5.7/en/explain-extended.html 模拟隐式字符集转换的场景：首先创建两个字符集不一样的表： 1234567891011121314151617181920CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `de_no` varchar(32) NOT NULL, `info` varchar(200) DEFAULT NULL, `de_name` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_de_no` (`de_no`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8mb4;CREATE TABLE `t_employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `em_no` varchar(32) NOT NULL, `de_no` varchar(32) NOT NULL, `age` int(11) DEFAULT NULL, `info` varchar(200) DEFAULT NULL, `em_name` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_em_no` (`de_no`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8; 然后使用存储过程构造数据： 1234567891011121314151617# 如果存储过程存在则删除DROP PROCEDURE IF EXISTS proc_initData;DELIMITER $# 创建存储过程CREATE PROCEDURE proc_initData()BEGINDECLARE i INT DEFAULT 1;WHILE i&lt;=30 DO# 新增数据INSERT INTO t_employees ( em_no, de_no, info, em_name , age) VALUES ( CONCAT('001', i), '003', 'test11', 'test2', i ); #执行的sql语句SET i = i+1;END WHILE;END $# 调用存储过程CALL proc_initData(); 注意：在构造数据时，记得将 t_employees 表中的 de_no 字段值构造的 离散些 ，因为如果索引字段值的 区分度很低 的话，那么MyQSL优化器通过采样统计分析时，发现索引查询和全表扫描性能差不多，就会直接进行全表扫描了； 索引失效的查询SQL语句： 将表和数据构造完后，我们使用SQL语句进行查询下，然后再看看其执行计划； 12explainselect * from t_department a LEFT JOIN t_employees b on a.de_no = b.de_no where a.id = 16 其执行计划如下：发现 t_employees 表中的 de_no 字段有索引，但是没有走索引查询，type=ALL 走的全表扫描. 使用利器快速排查问题： 注意：explain 后面跟的关键字 EXTENDED（扩展信息） 在MySQL5.7及之后的版本中废弃了，但是该语法仍被识别为向后兼容，所以在5.7版本及后续版本中，可以不用在 explain 后面添加 EXTENDED 了； 具体使用方法如下：1 首先在MySQL的可视化工具中打开一个 命令列介面 ：工具 –&gt; 命令列介面2 然后输入下面的SQL并按回车： 12explain EXTENDEDselect * from t_department a LEFT JOIN t_employees b on a.de_no = b.de_no where a.id = 4019; 3 然后紧接着输入命令 show warnings; 并回车，会出现如下图所示内容：通过展示出的执行SQL扩展信息，发现MySQL在字符集不一致时自动添加上字符集转换函数，因为是在 索引字段 de_no 上添加的转换函数，所以就导致了索引失效；而如果我们没看扩展信息的话，那么可能直到我们查看表结构的时候才会发现是由于字符集不一致导致的，这样就会花费很多的时间； 扩展：隐式类型转换咱们聊完上面的隐式字符集转换导致索引失效的情况，再来简单聊聊另一种 隐式类型转换 导致索引失效的情况； 隐式类型转换：简单的说就是字段的类型与其赋值的类型不一致时会进行隐式的转换； 小例如下： 1select * from t_employees where em_name = 123; 上面的SQL中 em_name 为索引字段，字段类型是 varchar，为其赋 int 类型的值时，会发现索引失效，这里也可以通过 explain extended + show warnings 查看，会发现如下图所示内容：","link":"/2021/10/15/mysql/mysql-explain/"},{"title":"查询SQL具体的执行流程","text":"MySql的整体架构描述 Server层各节点描述Server层中主要由 连接器、查询缓存、解析器/分析器、优化器、执行器 连接器客户端想要对数据库进行操作时，前提是与数据库建立好连接；而连接器就是用来负责跟客户端建立连接、获取权限、维持和管理连接的。 连接方式： 短连接就是操作完毕后，马上close关掉。 长连接可以保持打开，减少服务端创建和释放连接的消耗，后面的程序访问的时候还可以使用这个连接。 一般我们会在连接池中使用长连接。 长连接使用时的注意事项：客户端与服务器建立长连接，默认有效时间是 8小时 ，超过8小时MySql服务器就会将连接断开了，那么客户端再次请求的话，就会报 连接已断开的问题 ；并且保持长连接会消耗内存。长时间不活动的连接，MySQL服务器会断开。 查看长连接的超时时间 12345-- 非交互式超时时间，如 JDBC 程序show global variables like 'wait_timeout'; -- 交互式超时时间，如数据库工具show global variables like' interactive_timeout'; 执行后得到下图结果：默认都是28800秒，8小时 。一般项目中使用的连接池中的连接都是长连接的；（例如：druid、c3p0、dbcp等） 长连接超时断的解决方案 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存MySQL缓存是默认关闭的，也就是说不推荐使用缓存，为什么呢？ MySql为什么默认不开启缓存呢？主要是由于它的使用场景限制的： 缓存中数据存储格式：key（sql语句）-value（数据值）；所以如果SQL语句（key）只要存在一点不同之处就会直接进行数据库查询了； 由于表中的数据不是一成不变的，大多数是经常变化的，而当数据库中的数据变化了，那么相应的与此表相关的缓存数据就需要移除掉； MySQL 8.0 版本直接将查询缓存的整块功能删掉了。 解析器/分析器分析器的工作主要是对要执行的SQL语句进行解析，最终得到抽象语法书，然后再使用预处理器判断抽象语法树中的表是否存在，如果存在的话，在接着判断select投影列字段是否在表中存在等。 词法分析词法分析用于将SQL拆解为不可再分的原子符号，称为Token。并根据不同数据库方言所提供的字典，将其归类为关键字，表达式，字面量和操作符。 语法分析语法分析就是根据词法分析拆解出来的Token（原子符号）将SQL语句转换为抽象语法树。下面就直接举例说明，看一个SQL它的抽象语法书到底长神魔样： SQL语句： 1SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age &gt; 18 然后上面的SQL语句经过词法分析、语法分析后得到的抽象语法书如下：注意，为了便于理解，抽象语法树中的关键字的Token用绿色表示，变量的Token用红色表示，灰色表示需要进一步拆分。 预处理器预处理是用来对生成的 抽象语法树 进行语义校验，语义校验就是对查询的表、select投影列字段进行校验，判断表、字段是否存在等； 优化器优化器的作用：主要是将SQL经过词法解析/语法解析后得到的语法树，通过MySQL的数据字典和统计信息的内容，经过 一系列运算 ，从而得出一个 执行计划 。 在优化过程中，经过的一系列运算是什么呢？下面简单说下： 逻辑变换：例如SQL的where条件中存在 8&gt;9，那逻辑转换就是将语法树中存在的这种常量表达式直接进行化简，化简为 false；除了化简还有常量表达式计算等。 代价优化：就是通过付出一些数据统计分析的代价，来得到这个SQL执行是否可以走索引，以及走哪些索引；除此之外，在多表关联查询中，确定最终表join的顺序等； 在分析是否走索引查询时，是通过进行 动态数据采样统计分析 出来；只要是统计分析出来的，那就可能会存在分析错误的情况，所以在SQL执行不走索引时，也要考虑到这方面的因素。 MySql执行计划怎么查看呢？在执行的SQL语句前添加上 explain 关键字即可； 扩展： Oracle怎么查看执行计划？ 参考此文章 Oracle通过执行计划查看查询语句是否使用索引 执行器MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。开始执行的时候，要先判断一下建立连接的对象对这个表有没有执行操作的权限，如果没有，就会返回没有权限的错误；如果有，就按照生成的执行计划进行执行。 通过文章最开始的架构图可知，执行器下面连接的就是存储引擎了，执行器就是通过调用存储引擎提供的API接口进行调用操作数据的。 存储引擎描述存储引擎是对底层物理数据执行实际操作的组件，为Server服务器层提供各种操作数据的 API。MySQL 支持插件式的存储引擎，包括 InnoDB 、MyISAM、Memory 等。一般情况下，MySQL默认使用的存储引擎是 InnoDB 。 InnoDB 存储引擎支持的功能总览 扩展其整体架构图：如下图所示，InnoDB存储引擎整体分为内存架构（Memory Structures）和磁盘架构（Disk Structures）。 深入学习，请参考此文章 你居然还不知道Mysql存储引擎InnoDB分为内存架构、磁盘架构？","link":"/2021/10/15/mysql/mysql-execute-process/"},{"title":"MySQL vs MongoDB","text":"Analysis and designApp 的数据特点及可能的挑战 APP 的用户群体巨大， 后期登陆微信小程序，用户量预期会呈指数增长 app 内容主要为：文本内容, 图片, (小视频)，评论， 消息, 数量巨大 用户操作，对数据库的读和写要求很高，写操作频繁。(上传图片，写twitter, 发表评论) 用户场景变更，需求变化频繁，对数据库表字段的增加，修改提出了很高的要求. 用户的数据价值较低 (非银行记录钱，财务数据类)，对事务性要求不高. App 具有三高的特征： High performance - 对数据库高并发读写的需求。 Huge Storage - 对海量数据的高效率存储和访问的需求。 High Scalability &amp;&amp; High Availability- 对数据库的高可扩展性和高可用性的需求。 MongoDB可应对“三高”需求，传统的关系型数据库（如MySQL），在数据操作的“三高”需求以及应对Web2.0的网站需求面前，显得力不从心。 MySQL vs MongoDB一个是以MySQL为代表的传统关系数据库一个是以MongoDB为代表的文档数据存储 1. 强制模式与无模式MySQL作为关系数据存储区，其数据模型需要严格的架构：所有表均应使用定义的列来创建。 只有这样，才能使用SQL语言存储和查询数据。 由于每次需要修改数据模型时，都应先更改架构，然后再迁移数据，这使开发和部署过程变得有些复杂。 相比之下，MongoDB不会对存储在集合中的文档强加任何架构。 这是应用程序的责任，MongoDB唯一的限制就是受支持的数据类型。 它可以立即使用MongoDB存储任何形状的JSON文档，从而大大加快了开发过程。 2. 集群和分片/分区MySQL Cluster的名声过于复杂，难以配置，监视和维护。与独立的MySQL部署相比，数据架构的设计方式应考虑到数据分片/分区，否则数据存储的性能将受到很大影响。 MongoDB文档数据存储使用分片集群的概念开箱即用地支持分片/分区。 MongoDB分片/分区的强项是配置简单。它在水平方向上可以很好地缩放。 3. 复写复制是一种确保数据安全（通过在许多数据存储实例之间复制数据）并在许多情况下提高处理此数据的应用程序的可伸缩性和容错能力的一项重要技术。 MySQL支持传统的主/从复制，默认情况下是异步的，但也可以使用半同步和延迟复制模式。 MongoDB通过引入副本集来实现复制。基本上，它是主/从复制，但是MongoDB使用一些不同的术语。主服务器称为主服务器，接收所有写操作，而从服务器称为辅助服务器，从主服务器应用操作。副本集支持的最大功能之一是自动故障转移：当主副本不与副本集的其他成员通信时，副本集将尝试选择另一个成员成为新的主副本。 4. 全文搜索可以使用自然语言搜索（短语搜索），布尔搜索（术语搜索）在MySQL中进行全文搜索，其中要搜索的单词可能被标记为必须存在''或必须不存在’’以及查询扩展 搜索（对自然语言搜索的略微修改）。 但是，目前群集的MySQL部署中不支持全文本索引（有关MySQL群集的简短讨论，请参见群集和分片/分区）。 MongoDB中引入了全文搜索支持。 与MySQL相似，它是使用字符串内容（或字符串数组）上特殊类型的索引来实现的。 MongoDB还支持短语搜索，术语搜索和布尔搜索的组合。 它易于使用且实现优雅，但并非没有限制。 5. 部署方式 MySQL和MongoDB均可在大多数主要操作系统上使用。在大多数情况下，MySQL是从特定于平台的软件包中安装的，需要对系统的特权访问。尽管也提供了可下载的存档，但取决于操作系统，配置和版本（例如MySQL Cluster），安装可能会变得非常复杂且不直观（但是可能不需要特权访问系统）。 相反，在大多数情况下，MongoDB是作为可下载的存档分发的，可以将其解压缩并立即使用。明智的默认设置在这里起着至关重要的作用，因为它需要最少的配置，只需运行MongoDB服务器并开始用文档填充数据存储即可。 在许多方面，可以说MongoDB是为Web构建的：拥抱JSON，学习时间非常短，快速开发的基础，每个发行版都添加了新功能。 MySQL经过了久经考验的，保守的和过时的方式，但是随着关系数据存储试图调整自身以适应现代应用程序需求，事情发生了迅速的变化。 6. 用法 MySQL MongoDB 最适合包含表和行的数据 最适合非结构化数据 适用于小型数据集 适用于大型数据集 经常更新 高写入负载 强烈依赖多行交易 不稳定环境中的高可用性 修改大量记录 基于数据位置 如何选择如果你的数据对你的业务至关重要，则MySQL很可能是一个更安全的选择：ACID属性的存在是有原因的。但是每个应用程序都是不同的。内容管理系统，日志管理，分析，论坛和博客，事件存储，产品目录，库存管理，那些类型的应用程序可能会受益于MongoDB作为数据存储。 无模式数据模型是快速开发的推动力：只需随需引入新属性，而无需执行模式演变和数据迁移。可以说，但是MongoDB处理文档和运行查询的风格对开发人员更友好（而且，它不需要像SQL一样学习任何语言）。与MySQL集群的配置（和管理）相比，配置MongoDB的副本集和分片集群非常容易和快捷。 Solution description选择 mongoDB 的几个理由： 需求变化频繁：开发更加敏捷，开发成本和维护成本更低，能够快速地更新进化 客户端/api支持，开发容易上手 部署简单 扩展能力强， 选择mongo进行分库分表操作时，就会变得很简单。 节省系统资源，对cpu等资源耗费较小 使用JSON风格语法，易于掌握和理解 简单易用的查询方式：直接使用JSON，支持范围查询、正则表达式查询。 CRUD更加简单，支持in-place update：只要定义一个数组，然后传递给MongoDB的insert/update方法就可自动插入或更新 所有的属性类型都支持索引，甚至数组 性能高效，速度快： MongoDB使用c++/boost编写，在多数场合，其查询速度对比MySQL要快的多，对于CPU占用非常小。部署也很简单，对大多数系统，只需下载后二进制包解压就可以直接运行，几乎是零配置。 Mongo本身就拥有高可用及分区的解决方案，设置主从服务器非常方便，除此之外Mongo还可以快速并且安全的实现故障节点的转移。 不存在sql注入 不选择 mongoDB 的几个理由： MongoDB是个nosql数据，所以关系能力薄弱 不支持事务操作 磁盘占用空间过大 MongoDB没有如MySQL那样成熟的维护工具 无法进行关联表查询，不适用于关系多的数据 复杂聚合操作通过mapreduce创建，速度慢 模式自由，自由灵活的文件存储格式带来的数据错误 虽然速度被公布为MongoDB的一大优点，但只有您有正确的索引，才能实现。如果最终的索引是错误的或复合索引的顺序不正确，MongoDB可能是最慢的数据库之一。 重复的数据， 由于MongoDB不支持明确定义的关系，因此可能会出现大量重复数据。 团队没有丰富的使用经验，增加学习成本。 选择 MySQL 的几个理由: MySQL 发展了很长一段时间，拥有非常成熟的体系 支持事物的操作，保证数据的一致性，可以通过SQL语句完成复杂的操作 团队拥有成熟的使用经验 不选择 MySQL的几个理由： 使用过程中当数据量到达一定程度时，关系型数据库的效率会有明显的下降。一个复杂的查询操作，一系列的组合索引都会消耗非常多的内存空间，此时我们需要对数据库进行读写分离操作，或者将数据库结构进行拆分(水平拆分、垂直拆分)将请求压力分担在不同的库中。 表结构字段难以适应需求的快速变化。 Areas affected and ensured References 适用于现代应用程序的数据库 为什么要使用MongoDB？ MySQL与MongoDB：选择数据管理解决方案 MongoDB 与 MySQL，你选择谁 SQL和 NoSQL数据库之间的差异：MySQL（VS）MongoDB 我为什么放弃MySQL？选择了MongoDB","link":"/2021/09/23/mongodb/mongodb_vs_mysql/"},{"title":"connection_closed_before_response","text":"reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE responseSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: desc:PrematureCloseException caused by : customer request with header: connection:close gateway send all customer request headers to endpoint , so include connection:close endpoint response without connection header, so release TCP to pool connect instead of close. but endpoint closed the TCP connection fix:when request endpoint, don’t include customer’s connection header, proxy or gateway set keep-alive . ref: https://tools.ietf.org/html/rfc7230#section-6 The “Connection” header field allows the sender to indicate desiredcontrol options for the current connection. In order to avoidconfusing downstream recipients, a proxy or gateway MUST remove orreplace any received connection options before forwarding themessage. 参考文章 Connection has been closed BEFORE response, while sending request body Connection has been closed BEFORE response, while sending request body - keepalive timeout reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE response解决方案","link":"/2021/12/09/netty/netty-connection-closed-before-response/"},{"title":"select...for update","text":"作用：select for update 是为了在查询时,避免其他用户以该表进行插入,修改或删除等操作,造成表的不一致性.该语句用来锁定特定的行（如果有where子句，就是满足where条件的那些行）。当这些行被锁定后，其他会话可以选择这些行，但不能更改或删除这些行，直到该语句的事务被commit语句或rollback语句结束为止。 for update的使用场景如果遇到存在高并发并且对于数据的准确性很有要求的场景，是需要了解和使用for update的。 比如涉及到金钱、库存等。一般这些操作都是很长一串并且是开启事务的。如果库存刚开始读的时候是1，而立马另一个进程进行了update将库存更新为0了，而事务还没有结束，会将错的数据一直执行下去，就会有问题。所以需要for upate 进行数据加锁防止高并发时候数据出错。 记住一个原则：一锁二判三更新 SELECT…FOR UPDATE 语句的语法如下：12345SELECT ... FOR UPDATE [OF column_list][WAIT n|NOWAIT][SKIP LOCKED];-- 其中：-- OF 子句用于指定即将更新的列，即锁定行上的特定列。-- WAIT 子句指定等待其他用户释放锁的秒数，防止无限期的等待。 使用”FOR UPDATE WAIT”子句的优点如下： 1 防止无限期地等待被锁定的行； 2 允许应用程序中对锁的等待时间进行更多的控制。 3 对于交互式应用程序非常有用，因为这些用户不能等待不确定 4 若使用了skip locked，则可以越过锁定的行，不会报告由wait n 引发的‘资源忙’异常报告 For Example: select * from t for update 会等待行锁释放之后，返回查询结果。 select * from t for update nowait 不等待行锁释放，提示锁冲突，不返回结果 select * from t for update wait 5 等待5秒，若行锁仍未释放，则提示锁冲突，不返回结果 select * from t for update skip locked 查询返回查询结果，但忽略有行锁的记录 排他锁的申请前提没有线程对该结果集中的任何行数据使用排他锁或共享锁，否则申请会阻塞。 for update仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。 场景分析假设有一张商品表 goods，它包含 id，商品名称，库存量三个字段，表结构如下： 1234567CREATE TABLE `goods` (`id` int(11) NOT NULL AUTO_INCREMENT,`name` varchar(100) DEFAULT NULL,`stock` int(11) DEFAULT NULL,PRIMARY KEY (`id`),UNIQUE KEY `idx_name` (`name`) USING HASH) ENGINE=InnoDB 插入如下数据： 123456789INSERT INTO `goods` VALUES ('1', 'prod11', '1000');INSERT INTO `goods` VALUES ('2', 'prod12', '1000');INSERT INTO `goods` VALUES ('3', 'prod13', '1000');INSERT INTO `goods` VALUES ('4', 'prod14', '1000');INSERT INTO `goods` VALUES ('5', 'prod15', '1000');INSERT INTO `goods` VALUES ('6', 'prod16', '1000');INSERT INTO `goods` VALUES ('7', 'prod17', '1000');INSERT INTO `goods` VALUES ('8', 'prod18', '1000');INSERT INTO `goods` VALUES ('9', 'prod19', '1000'); 一、数据一致性假设有A、B两个用户同时各购买一件 id=1 的商品，用户A获取到的库存量为 1000，用户B获取到的库存量也为 1000，用户A完成购买后修改该商品的库存量为 999，用户B完成购买后修改该商品的库存量为 999，此时库存量数据产生了不一致。 有两种解决方案： 悲观锁方案： 每次获取商品时，对该商品加排他锁。也就是在用户A获取获取 id=1 的商品信息时对该行记录加锁，期间其他用户阻塞等待访问该记录。悲观锁适合写入频繁的场景。 1234begin;select * from goods where id = 1 for update;update goods set stock = stock - 1 where id = 1;commit; 乐观锁方案： 每次获取商品时，不对该商品加锁。在更新数据的时候需要比较程序中的库存量与数据库中的库存量是否相等，如果相等则进行更新，反之程序重新获取库存量，再次进行比较，直到两个库存量的数值相等才进行数据更新。乐观锁适合读取频繁的场景。 123456#不加锁获取 id=1 的商品对象select * from goods where id = 1begin;#更新 stock 值，这里需要注意 where 条件 “stock = cur_stock”，只有程序中获取到的库存量与数据库中的库存量相等才执行更新update goods set stock = stock - 1 where id = 1 and stock = cur_stock;commit; 如果我们需要设计一个商城系统，该选择以上的哪种方案呢？ 查询商品的频率比下单支付的频次高，基于以上我可能会优先考虑第二种方案（当然还有其他的方案，这里只考虑以上两种方案）。 二、行锁与表锁InnoDB默认是行级别的锁，当有明确指定的主键时候，是行级锁。否则是表级别。 for update的注意点 for update 仅适用于InnoDB，并且必须开启事务，在begin与commit之间才生效。 要测试for update的锁表情况，可以利用MySQL的Command Mode，开启二个视窗来做测试。 1、只根据主键进行查询，并且查询到数据，主键字段产生行锁。 123begin;select * from goods where id = 1 for update;commit; 2、只根据主键进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 for update;commit; 3、根据主键、非主键含索引（name）进行查询，并且查询到数据，主键字段产生行锁，name字段产生行锁。 123begin;select * from goods where id = 1 and name='prod11' for update;commit; 4、根据主键、非主键含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 and name='prod12' for update;commit; 5、根据主键、非主键不含索引（name）进行查询，并且查询到数据，如果其他线程按主键字段进行再次查询，则主键字段产生行锁，如果其他线程按非主键不含索引字段进行查询，则非主键不含索引字段产生表锁，如果其他线程按非主键含索引字段进行查询，则非主键含索引字段产生行锁，如果索引值是枚举类型，mysql也会进行表锁，这段话有点拗口，大家仔细理解一下。 123begin;select * from goods where id = 1 and name='prod11' for update;commit; 6、根据主键、非主键不含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where id = 1 and name='prod12' for update;commit; 7、根据非主键含索引（name）进行查询，并且查询到数据，name字段产生行锁。 123begin;select * from goods where name='prod11' for update;commit; 8、根据非主键含索引（name）进行查询，没有查询到数据，不产生锁。 123begin;select * from goods where name='prod11' for update;commit; 9、根据非主键不含索引（stock）进行查询，并且查询到数据，stock字段产生表锁。 123begin;select * from goods where stock='1000' for update;commit; 10、根据非主键不含索引（stock）进行查询，没有查询到数据，stock字段产生表锁。 123begin;select * from goods where stock='2000' for update;commit; 11、只根据主键进行查询，查询条件为不等于，并且查询到数据，主键字段产生表锁。 123begin;select * from goods where id &lt;&gt; 1 for update;commit; 12、只根据主键进行查询，查询条件为不等于，没有查询到数据，主键字段产生表锁。 123begin;select * from goods where id &lt;&gt; 1 for update;commit; 13、只根据主键进行查询，查询条件为 like，并且查询到数据，主键字段产生表锁。 123begin;select * from goods where id like '1' for update;commit; 14、只根据主键进行查询，查询条件为 like，没有查询到数据，主键字段产生表锁。 123begin;select * from goods where id like '1' for update;commit; 测试环境数据库版本：5.1.48-community数据库引擎：InnoDB Supports transactions, row-level locking, and foreign keys数据库隔离策略：REPEATABLE-READ（系统、会话） 总结1、InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。 2、由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。 3、当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 4、即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 5、检索值的数据类型与索引字段不同，虽然MySQL能够进行数据类型转换，但却不会使用索引，从而导致InnoDB使用表锁。通过用explain检查两条SQL的执行计划，我们可以清楚地看到了这一点。 参考文章 https://blog.csdn.net/ll594317566/article/details/103869619 https://zhuanlan.zhihu.com/p/143866444 https://www.cnblogs.com/wxgblogs/p/6849064.html","link":"/2021/10/26/mysql/mysql-select-for-update/"},{"title":"netty hello_world","text":"1curl --location --request GET 'http://localhost:8089' 创建一个Springboot project pom.xml 添加netty 依赖 123456 &lt;!-- https://mvnrepository.com/artifact/io.netty/netty-all --&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.69.Final&lt;/version&gt;&lt;/dependency&gt; NettyServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.ChannelPipeline;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.http.HttpServerCodec;import io.netty.handler.logging.LogLevel;import io.netty.handler.logging.LoggingHandler;public class NettyServer { private static final int PORT = 8089; public static void main(String[] args) { // Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.option(ChannelOption.SO_BACKLOG, 1024); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { ChannelPipeline p = socketChannel.pipeline(); p.addLast(new HttpServerCodec()); p.addLast(new HttpHelloWorldServerHandler()); } }); Channel ch = b.bind(PORT).sync().channel(); ch.closeFuture().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }} HttpHelloWorldServerHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import static io.netty.handler.codec.http.HttpHeaderNames.*;import static io.netty.handler.codec.http.HttpHeaderValues.*;import static io.netty.handler.codec.http.HttpHeaderValues.KEEP_ALIVE;import static io.netty.handler.codec.http.HttpResponseStatus.*;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.handler.codec.http.DefaultFullHttpResponse;import io.netty.handler.codec.http.FullHttpResponse;import io.netty.handler.codec.http.HttpObject;import io.netty.handler.codec.http.HttpRequest;import io.netty.handler.codec.http.HttpUtil;public class HttpHelloWorldServerHandler extends SimpleChannelInboundHandler&lt;HttpObject&gt; { private static final byte[] CONTENT = { 'H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd' }; @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void channelRead0(ChannelHandlerContext ctx, HttpObject msg) { if (msg instanceof HttpRequest) { HttpRequest req = (HttpRequest) msg; boolean keepAlive = HttpUtil.isKeepAlive(req); System.out.println(&quot;=======================&quot;); System.out.println(&quot;keep alive is:&quot;+keepAlive); FullHttpResponse response = new DefaultFullHttpResponse(req.protocolVersion(), OK, Unpooled.wrappedBuffer(CONTENT)); response.headers() .set(CONTENT_TYPE, TEXT_PLAIN) .setInt(CONTENT_LENGTH, response.content().readableBytes()); if (keepAlive) { if (!req.protocolVersion().isKeepAliveDefault()) { response.headers().set(CONNECTION, KEEP_ALIVE); } } else { // Tell the client we're going to close the connection. response.headers().set(CONNECTION, CLOSE); } ChannelFuture f = ctx.write(response); if (!keepAlive) { f.addListener(ChannelFutureListener.CLOSE); } } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); }} run or debug NettyServer.main参考文章","link":"/2021/11/16/netty/netty-helloworld/"},{"title":"python-opencv 安装","text":"install opencv-python123456789# prepare pip3 install scikit-build pip3 install cmake ln -s /usr/bin/ninja /usr/bin/ninja-build# install opencvpip3 install opencv-pythonpip3 install opencv-contrib-python 打开 Python IDLE（或 IPython）并在 Python 终端中键入以下命令。 12import cv2 as cvprint(cv.__version__) install python1234567$ sudo yum install python38 -y# 从SCL中使用python3，你需要一行命令来启用Python3：$ scl enable python38 &lt;command&gt;# 您还可以使用Python编译器来调用一个bash shell:$ scl enable python38 bash OpenCV 中文文档 4.0.0https://www.kancloud.cn/aollo/aolloopencv/259610https://www.bookstack.cn/read/opencv-doc-zh-4.0/README.mdhttps://woshicver.com/ 图像入门1. 显示图像123456789import numpy as npimport cv2 as cv＃加载彩色灰度图像img = cv.imread('messi5.jpg'，0)cv.imshow('image', img)cv.waitKey(0)cv.destroyAllWindows() 使用cv.imread()函数读取图像。图像应该在工作目录或图像的完整路径应给出。 第二个参数是一个标志，它指定了读取图像的方式。 123cv.IMREAD_COLOR： 加载彩色图像。任何图像的透明度都会被忽视。它是默认标志。cv.IMREAD_GRAYSCALE：以灰度模式加载图像cv.IMREAD_UNCHANGED：加载图像，包括alpha通道 使用函数 cv.imshow() 在窗口中显示图像。窗口自动适合图像尺寸。 第一个参数是窗口名称，它是一个字符串。第二个参数是我们的对象。你可以根据需要创建任意多个窗口，但可以使用不同的窗口名称。 cv.waitKey()是一个键盘绑定函数。 其参数是以毫秒为单位的时间。该函数等待任何键盘事件指定的毫秒。如果您在这段时间内按下任何键，程序将继续运行。如果0被传递，它将无限期地等待一次敲击键。它也可以设置为检测特定的按键，例如，如果按下键 a 等，我们将在下面讨论。 注意 除了键盘绑定事件外，此功能还处理许多其他GUI事件，因此你必须使用它来实际显示图像。 cv.destroyAllWindows()只会破坏我们创建的所有窗口。如果要销毁任何特定的窗口，请使用函数cv.destroyWindow()在其中传递确切的窗口名称作为参数。 注意 在特殊情况下，你可以创建一个空窗口，然后再将图像加载到该窗口。在这种情况下，你可以指定窗口是否可调整大小。这是通过功能cv.namedWindow()完成的。默认情况下，该标志为cv.WINDOW_AUTOSIZE。但是，如果将标志指定为cv.WINDOW_NORMAL，则可以调整窗口大小。当图像尺寸过大以及向窗口添加跟踪栏时，这将很有帮助。 2. 写入图像使用函数cv.imwrite()保存图像。 第一个参数是文件名，第二个参数是要保存的图像。 cv.imwrite(‘messigray.png’，img) 这会将图像以PNG格式保存在工作目录中。 在下面的程序中，以灰度加载图像，显示图像，按s保存图像并退出，或者按ESC键直接退出而不保存。1234567891011import numpy as npimport cv2 as cvimg = cv.imread('pig.jpg', 0)cv.imshow('image', img)k = cv.waitKey(0) &amp; 0xFFif k == 27: # 等待ESC退出 cv.destroyAllWindows()elif k == ord('s'): # 等待关键字，保存和退出 cv.imwrite('messigray.png', img) cv.destroyAllWindows() 3. 使用Matplotlibref: https://woshicver.com/ThirdSection/2_1_%E5%9B%BE%E5%83%8F%E5%85%A5%E9%97%A8/Matplotlib是Python的绘图库，可为你提供多种绘图方法。你将在接下来的文章中看到它们。在这里，你将学习如何使用Matplotlib显示图像。你可以使用Matplotlib缩放图像，保存图像等。 123456789import numpy as npimport cv2 as cvfrom matplotlib import pyplot as pltimg = cv.imread('pig.jpg', 0)plt.imshow(img, cmap='gray', interpolation='bicubic')plt.xticks([]), plt.yticks([]) # 隐藏 x 轴和 y 轴上的刻度值plt.show()","link":"/2021/10/25/opencv/opencv-install/"},{"title":"网关、网卡、网桥","text":"网关是邮电局,所有的信息必须通过这里的打包、封箱、寻址，才能发出去与收进来；网卡是设备，也就是邮电局邮筒，你家的信箱；网桥是邮递员，但他只负责一个镇里面(局域网)不负责广域网。 网关 网关实质上是一个网络通向其他网络的IP地址 网关是一种充当转换重任的计算机系统或设备,又叫网间连接器、协议转换器 从一个房间走到另一个房间，必然要经过一扇门。同样，从一个网络向另一个网络发送信息，也必须经过一道“关口”，这道关口就是网关。顾名思义，网关（Gateway） [1] 就是一个网络连接到另一个网络的“关口”。也就是网络关卡。 网关(Gateway)又称网间连接器、协议转换器。网关在网络层以上实现网络互连，是复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。使用在不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同层–应用层。 【说明：由于历史的原因，许多有关TCP/IP的文献曾经把网络层使用的路由器称为网关，在今天很多局域网采用都是路由来接入网络，因此通常指的网关就是路由器的IP！】 案例 那么网关到底是什么呢？网关实质上是一个网络通向其他网络的IP地址。比如有网络A和网络B，网络A的IP地址范围为“192.168.1.1 ~ 92. 168.1.254”，子网掩码为255.255.255.0；网络B的IP地址范围为“192.168.2.1~192.168.2.254”，子网掩码为255.255.255.0。在没有路由器的情况下，两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP协议也会根据子网掩码（255.255.255.0）与主机的IP 地址作 “与” 运算的结果不同判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关。如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机（如附图所示）。网络A向网络B转发数据包的过程。 所以说，只有设置好网关的IP地址，TCP/IP协议才能实现不同网络之间的相互通信。那么这个IP地址是哪台机器的IP地址呢？网关的IP地址是具有路由功能的设备的IP地址，具有路由功能的设备有路由器、启用了路由协议的服务器（实质上相当于一台路由器）、代理服务器（也相当于一台路由器）。 在和 Novell NetWare 网络交互操作的上下文中，网关在 Windows 网络中使用的服务器信息块 (SMB) 协议以及NetWare网络使用的 NetWare 核心协议 (NCP) 之间起着桥梁的作用。网关也被称为 IP路由器。 案例 网卡 网卡是一块被设计用来允许计算机在计算机网络上进行通讯的计算机硬件。 一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的MAC地址 主要功能 1、数据的封装与解封 发送时将上一层传递来的数据加上首部和尾部，成为以太网的帧。接收时将以太网的帧剥去首部和尾部，然后送交上一层 2、链路管理 主要是通过CSMA/CD（Carrier Sense Multiple Access with Collision Detection ，带冲突检测的载波监听多路访问）协议来实现 3、数据编码与译码 即曼彻斯特编码与译码。其中曼彻斯特码，又称数字双向码、分相码或相位编码(PE)，是一种常用的的二元码线路编码方式之一，被物理层使用来编码一个同步位流的时钟和数据。在通信技术中，用来表示所要发送比特 流中的数据与定时信号所结合起来的代码。 常用在以太网通信，列车总线控制，工业总线等领域。 网桥网桥也叫桥接器，是连接两个局域网的一种存储/转发设备，它能将一个大的LAN)分割为多个网段，或将两个以上的LAN互联为一个逻辑LAN，使LAN上的所有用户都可访问服务器。 LAN 一般指局域网WLAN 指无线局域网 原理网桥将两个相似的网络连接起来，并对网络数据的流通进行管理。它工作于数据链路层，不但能扩展网络的距离或范围，而且可提高网络的性能、可靠性和安全性。网络1 和网络2 通过网桥连接后，网桥接收网络1 发送的数据包，检查数据包中的地址，如果地址属于网络1 ，它就将其放弃，相反，如果是网络2 的地址，它就继续发送给网络2.这样可利用网桥隔离信息，将同一个网络号划分成多个网段（属于同一个网络号），隔离出安全网段，防止其他网段内的用户非法访问。由于网络的分段，各网段相对独立（属于同一个网络号），一个网段的故障不会影响到另一个网段的运行。网桥可以是专门硬件设备，也可以由计算机加装的网桥软件来实现，这时计算机上会安装多个网络适配器（网卡）。 网桥的功能在延长网络跨度上类似于中继器，然而它能提供智能化连接服务，即根据帧的终点地址处于哪一网段来进行转发和滤除。网桥对站点所处网段的了解是靠“自学习”实现的，有透明网桥、转换网桥、封装网桥、源路由选择网桥。网桥示意如图1所示。 简述网桥、网关、网卡之间的联系和区别网桥，是把两个不同物理层，不同MAC子层，不同速率的局域网连接在一起。比如说10MB/S与100MB/S的局域网。因为它有储存转化功能。网桥是一种链路层产品. 网卡是电脑的一个接收信息 转换信息 暂储信息的一个硬件。它是把接受到信息递交给上层，如（CUP）的一个接口。 网关(Gateway)又称网间连接器、协议转换器。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。在使用不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关也可以提供过滤和安全功能。大多数网关运行在OSI 7层协议的顶层–应用层。 所以生动的表示以下: 网关是邮电局,所有的信息必须通过这里的打包、封箱、寻址，才能发出去与收进来； 网卡是设备，也就是邮电局邮筒，你家的信箱； 网桥是邮递员，但他只负责一个镇里面(局域网)不负责广域网。 参考文章 网关 网桥 网关、网卡、网桥、","link":"/2021/12/31/network/network-gateway-bridge-network-card/"},{"title":"netty HttpClient","text":"netty httpclient support http/2. HTTP/2ref: https://projectreactor.io/docs/netty/release/reference/index.html#_http2_2 By default, the HTTP client supports HTTP/1.1. If you need HTTP/2, you can get it through configuration. In addition to the protocol configuration, if you need H2 but not H2C (cleartext), you must also configure SSL. 12345678910111213141516171819202122232425import io.netty.handler.codec.http.HttpHeaders;import reactor.core.publisher.Mono;import reactor.netty.http.HttpProtocol;import reactor.netty.http.client.HttpClient;import reactor.util.function.Tuple2;public class H2Application { public static void main(String[] args) { HttpClient client = HttpClient.create() .protocol(HttpProtocol.H2) .secure(); Tuple2&lt;String, HttpHeaders&gt; response = client.get() .uri(&quot;https://example.com/&quot;) .responseSingle((res, bytes) -&gt; bytes.asString() .zipWith(Mono.just(res.responseHeaders()))) .block(); System.out.println(&quot;Used stream ID: &quot; + response.getT2().get(&quot;x-http2-stream-id&quot;)); System.out.println(&quot;Response: &quot; + response.getT1()); }} simple usage123456789101112131415161718192021HttpClient.create() .baseUrl(&quot;https://example.com&quot;) .get() .response() .block();HttpClient.create() .post() .uri(&quot;https://example.com&quot;) .send(Flux.just(bb1, bb2, bb3)) .responseSingle((res, content) -&gt; Mono.just(res.status().code())) .block();HttpClient.create() .baseUri(&quot;https://example.com&quot;) .post() .send(ByteBufFlux.fromString(flux)) .responseSingle((res, content) -&gt; Mono.just(res.status().code())) .block(); 参考文章 https://projectreactor.io/docs/netty/release/api/reactor/netty/http/client/HttpClient.html netty http2 https://www.baeldung.com/httpclient-guide https://projectreactor.io/docs/netty/release/reference/index.html#_http2_2","link":"/2021/12/03/netty/netty-httpclient/"},{"title":"MySQL和Oracle的区别","text":"参考文章 https://zhuanlan.zhihu.com/p/335264917 https://blog.csdn.net/baidu_37107022/article/details/77043959 https://segmentfault.com/a/1190000038924007 https://www.cnblogs.com/yougewe/p/13662695.html","link":"/2022/05/24/oracle/oracle-vs_mysql/"},{"title":"nginx access.log format","text":"$upstream_addr保留 IP 地址和端口，或上游服务器的 UNIX 域套接字的路径。如果在请求处理期间联系了多个服务器，则它们的地址用逗号分隔，例如“ 192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock”。如果发生从一个服务器组到另一个服务器组的内部重定向，由“X-Accel-Redirect”或 error_page 发起，则来自不同组的服务器地址用冒号分隔，例如“ 192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock : 192.168.10.1:80, 192.168.10.2:80”。如果无法选择服务器，该变量将保留服务器组的名称。 $proxy_portproxy_pass指令中指定的代理服务器的端口 ，或协议的默认端口； $server_port接受请求的服务器端口 12345678910111213141516171819变量 含义$bytes_sent 发送给客户端的总字节数$body_bytes_sent 发送给客户端的字节数，不包括响应头的大小$connection 连接序列号$connection_requests 当前通过连接发出的请求数量$msec 日志写入时间，单位为秒，精度是毫秒$pipe 如果请求是通过http流水线发送，则其值为&quot;p&quot;，否则为“.&quot;$request_length 请求长度（包括请求行，请求头和请求体）$request_time 请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止$status 响应状态码$time_iso8601 标准格式的本地时间,形如“2017-05-24T18:31:27+08:00”$time_local 通用日志格式下的本地时间，如&quot;24/May/2017:18:31:27 +0800&quot;$http_referer 请求的referer地址。$http_user_agent 客户端浏览器信息。$remote_addr 客户端IP$http_x_forwarded_for 当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。$request 完整的原始请求行，如 &quot;GET / HTTP/1.1&quot;$remote_user 客户端用户名称，针对启用了用户认证的请求$request_uri 完整的请求地址，如 &quot;https://daojia.com/&quot; 12345678http { access_log /var/logs/nginx-access.log main log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; ...} 我们使用log_format指令定义了一个main的格式，并在access_log指令中引用了它。假如客户端有发起请求：https://suyunfe.com/，我们看一下我截取的一个请求的日志记录: 1112.195.209.90 - - [20/Feb/2018:12:12:14 +0800] &quot;GET / HTTP/1.1&quot; 200 190 &quot;-&quot; &quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36&quot; &quot;-&quot; 参考文章 https://docs.nginx.com/nginx/admin-guide/monitoring/logging/ Nginx日志配置详解 Alphabetical index of variables","link":"/2021/12/23/nginx/nginx-accesslog-format/"},{"title":"nginx conf if","text":"nginx支持if语法，语法和平常的代码格式差不多： 123456 if ($http_x_user = &quot;summer&quot;) { return 401;} if ($remote_addr = &quot;192.168.2.2&quot;) { return 401;} 只是和代码不同的是，if条件语句判断相等只要一个等号，不是==。 nginx虽然有if，但是却不支持else，如果想要构造else语法，可以使用下面的这个“小诀窍”： 12345678910111213141516171819202122232425server {server_name *.maqian.io;listen 80; location / { set $is_matched 0; if ($host = a.maqian.io) { proxy_pass https://127.0.0.1:1001/; set $is_matched 1; } if ($host = b.maqian.io) { proxy_pass https://127.0.0.1:1002/; set $is_matched 1; } # 没有匹配到，跳转到默认页面 if ($is_matched = 0) { proxy_pass https://127.0.0.1; } # xxx # xxx # xxx }} 参考文章https://docs.nginx.com/nginx/admin-guide/load-balancer/using-proxy-protocol/https://nginx.org/en/docs/http/ngx_http_core_module.html?&amp;_ga=2.71427731.14852861.1651803177-1904749950.1651803177#var_proxy_protocol_addr","link":"/2021/12/20/nginx/nginx-conf-if/"},{"title":"oracle intro","text":"Oracle Database，又名 Oracle RDBMS，简称 Oracle。Oracle 数据库系统是美国 Oracle 公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器（client/server）或B/S体系结构的数据库之一，比如 SilverStream 就是基于数据库的一种中间件。Oracle 数据库是目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系型数据库，它是一个完备关系的产品；作为分布式数据库它实现了分布式处理功能，只要在一种机型上学习了 操作Oracle 的知识，便能在各种类型的机器上使用它。 Oracle体系结构Oracle数据库实际上是一个数据的物理储存系统，这其中包括数据文件（ora/dbf）、参数文件、控制文件、联机日志等。 实例：一个操作系统只有一个Oracle数据库，但是可以安装多个Oracle实例，一个Oracle实例对应着一系列的后台进程（Backguound Processes)和内存结构（Memory Structures)。 数据文件： 数据文件是数据库的物理存储单位，而表空间TableSpace则是数据库的逻辑组成部分。数据库的数据是存储在表空间中的，而一个表空间可以由一个或多个数据文件组成，一个数据文件只能属于一个表空间。一旦数据文件被加入到某个表空间后，就不能删除这个文件，如果要删除某个数据文件，只能删除其所属于的表空间才行。 Oracle数据文件是数据存储的物理单位，数据库的数据是存储在表空间中的。而一个表空间可以由一个或多个数据文件组成，一个数据文件只能属于一个表空间，一旦数据文件被加入到某个表空间后，就不能删除这个文件，如果要删除某个数据文件，只能删除其所属于的表空间才 行。 表空间： 表空间是 Oracle 对物理数据库上相关数据文件（ORA 或者 DBF 文件）的逻辑映射。一个数据库在逻辑上被划分成一到若干个表空间，每个表空间包含了在逻辑上相关联的一组结构。每个数据库至少有一个表空间（称之为 system 表空间）。每个表空间由同一磁盘上的一个或多个文件组成，这些文件叫数据库文件（datafile）。一个数据文件只能属于一个表空间。 表空间是Oracle 对物理数据库数据文件（ora/dbf）的逻 辑映射。一个数据库在逻辑上被划分成一到若干个表空间，每个表空间由同一磁盘上的一个或多个数据文件（datafile）组成，一个数据文件只能属于一个表空间。 oracle用户：表当中的数据是有Oracle用户放入到表空间当中的，而这些表空间会随机的把数据放入到一个或者多个数据文件当中。oracle对表数据的管理是通过用户对表的管理去查询，而不是直接对数据文件或表空间进行查询。因为不同用户可以在同一个表空间上面建立相同的表名。但是通过不同的用户管理自己的表数据。 用户是在实例下建立的。不同实例中可以建相同名字的用户。注意！表的数据，是由用户放入某一个表空间的，而这个表空间会随机把这些表数据放到一个或者多个数据文件中。由于 Oracle 的数据库不是普通的概念，oracle 是由用户和表空间对数据进行管理和存放的。但是表不是由表空间去查询的，而是由用户去查的。因为不同用户可以在同一个表空间建立同一个名字的表！这里区分就是用户了！ Oracle体系概要图如下： 数据库和实例Oracle 数据库服务器由一个数据库和至少一个数据库实例组成。数据库是一组存储数据的文件，而数据库实例则是管理数据库文件的内存结构。此外，数据库是由后台进程组成。数据库和实例是紧密相连的，所以我们一般说的 Oracle 数据库，通常指的就是实例和数据库。 下图说明了 Oracle 数据库服务器体系结构： 在这种体系结构中，Oracle 数据库服务器包括两个主要部分：**文件(Oracle 数据库)和内存(Oracle 实例)**。 1.Oracle数据库Oracle 数据库的一个基本任务是存储数据，以下部分简要地介绍 Oracle 数据库的物理和逻辑存储结构。 1.1.物理存储结构物理存储结构是存储数据的纯文件。当执行一个 CREATE DATABASE 语句来创建一个新的数据库时，将创建下列文件： ● 数据文件：数据文件包含真实数据，例如销售订单和客户等。逻辑数据库结构(如表和索引)的数据被物理存储在数据文件中。 ● 控制文件：每个 Oracle 数据库都有一个包含元数据的控制文件。元数据用来描述包括数据库名称和数据文件位置的数据库物理结构。 ● 联机重做日志文件：每个 Oracle 数据库都有一个联机重做日志，里面包含两个或多个联机重做日志文件。联机重做日志由重做条目组成，能够记录下所有对数据所做的更改。 除这些文件外，Oracle 数据库还包括如参数文件、网络文件、备份文件以及用于备份和恢复的归档重做日志文件等重要文件。 1.2.逻辑存储结构Oracle 数据库使用逻辑存储结构对磁盘空间使用情况进行精细控制。以下是 Oracle 数据库中的逻辑存储结构： ● **数据块(Data blocks)**：Oracle 将数据存储在数据块中。数据块也被称为逻辑块，Oracle 块或页，对应于磁盘上的字节数。 ● **范围(Extents)**：范围是用于存储特定类型信息的逻辑连续数据块的具体数量。 ● **段(Segments)**：段是分配用于存储用户对象(例如表或索引)的一组范围。 ● **表空间(Tablespaces)**：数据库被分成称为表空间的逻辑存储单元。 表空间是段的逻辑容器。 每个表空间至少包含一个数据文件。 下图说明了表空间中的段，范围和数据块： 下图显示了逻辑和物理存储结构之间的关系： 数据结构逻辑关系如下图： 2.Oracle实例Oracle 实例是客户端应用程序(用户)和数据库之间的接口。Oracle 实例由三个主要部分组成：系统全局区 (SGA)，程序全局区 (PGA) 和后台进程。如下图所示 ： DBWr（DBWR）在后来允许多进程写data file,所以改成DBWn了。 SGA 是实例启动时分配的共享内存结构，关闭时释放。 SGA 是一组包含一个数据库实例的数据和控制信息的共享内存结构。 不同于所有进程都可用的 SGA，PGA 是会话开始时为每个会话分配的私有内存区，当会话结束时释放。 主要的Oracle数据库的后台进程以下是 Oracle 实例的主要后台进程： ● PMON 是 Oracle 数据库中最活跃的一个进程，是调节所有其他进程的进程监视器。PMON 能够清理异常连接的数据库连接，并自动向侦听器进程注册数据库实例。 ● SMON 是执行系统级清理操作的系统监视进程。它有两个主要职责，包括在发生故障的情况下自动恢复实例，例如断电和清理临时文件。 ● DBWn 是数据库编写器。Oracle 在内存中执行每个操作而不是磁盘。因为在内存中的处理速度比在磁盘上快。DBWn 进程从磁盘读取数据并将其写回到磁盘。 一个 Oracle 实例有许多数据库编写器，如：DBW0，DBW1，DBW2等等。 ● CKPT 是检查点进程。 在 Oracle 中，磁盘上的数据称为块，内存中的数据称为缓冲区。 当该块写入缓冲区并更改时，缓冲区变脏，需要将其写入磁盘。CKPT 进程使用检查点信息更新控制和数据文件头，并向脏盘写入脏缓冲区的信号。 请注意，Oracle 12c 允许全面和增量检查点。 LGWR 是日志写入过程，是可恢复架构的关键。 在数据库中发生的每一个变化都被写出到一个名为 redo 日志文件中用于恢复目的。 而这些变化是由 LGWR 进程编写和记录的。 LGWR 进程首先将更改写入内存，然后将磁盘写入重做日志，然后将其用于恢复。 ● ARCn 是归档进程，它将重做日志的内容复制到归档重做日志文件。存档程序进程可以有多个进程，如：ARC0，ARC1 和 ARC3，允许存档程序写入多个目标，如 D：驱动器，E：驱动器或其他存储。 ● MMON 是收集性能指标的可管理性监控流程。 ● MMAN 是自动管理 Oracle 数据库内存的内存管理器。 ● LREG 是监听器注册过程，它使用 Oracle Net Listener 在数据库实例和调度程序进程上注册信息。 oracle数据库的优势ORACLE 数据库系统能够在业内独占鳌头并不是空穴来风，下面我们来细数一下 ORACLE 数据库的优势所在： 完整的数据管理功能： 数据的大量性 数据的保存的持久性 数据的共享性 数据的可靠性完备关系的产品： 信息准则—关系型 DBMS 的所有信息都应在逻辑上用一种方法，即表中的值显式地表示 保证访问的准则 视图更新准则—只要形成视图的表中的数据变化了，相应的视图中的数据同时变化 数据物理性和逻辑性独立准则分布式处理功能： ORACLE 数据库自第5版起提供了分布式处理能力，到第7版有比较完善的分布式数据库功能了，一个ORACLE 分布式数据库由 oraclerdbms、sqlNet、SQLCONNECT 和其他非 ORACLE 的关系型产品构成。 用 ORACLE 能轻松的实现数据仓库的操作以上是 Oracle 数据库的优势，从这些优势中不难看出这是一款功能强大的数据库系统。 create user这是oracle_12版本的特性，有兴趣的朋友可以查阅下 官方文档在CDB容器中用户名必须加c##前缀才能创建成功： 123create user c##lingd identifed by 123456;grant connect, resource to c##lingd; // 用户授权 Oracle字段数据类型常用的Oracle列字段的数据类型如下： 数据类型 类型解释 VARCHAR2(length) 字符串类型：存储可变的长度的字符串，length:是字符串的最大长度，默认不填的时候是1，最大长度不超过4000。 CHAR(length) 字符串类型：存储固定长度的字符串，length:字符串的固定长度大小，默认是1，最大长度不超过2000。 NUMBER(a,b) 数值类型：存储数值类型，可以存整数，也可以存浮点型。a代表数值的最大位数：包含小数位和小数点，b代表小数的位数。例子： number(6,2)，输入123.12345，实际存入：123.12 。 number(4,2)，输入12312.345，实际春如：提示不能存入，超过存储的指定的精度。 DATA 时间类型：存储的是日期和时间，包括年、月、日、时、分、秒。例子： 内置函数sysdate获取的就是DATA类型 TIMESTAMP 时间类型：存储的不仅是日期和时间，还包含了时区。例子： 内置函数systimestamp获取的就是timestamp类型 CLOB 大字段类型：存储的是大的文本，比如：非结构化的txt文本，字段大于4000长度的字符串。 BLOB 二进制类型：存储的是二进制对象，比如图片、视频、声音等转换过来的二进制对象 参考文章 Oracle建表(create table) Oracle 教程 Oracle 教程","link":"/2022/05/24/oracle/oracle-intro/"},{"title":"opencv 练习","text":"OpenCV中的绘图功能12345678910111213141516171819202122232425import cv2 as cvimport numpy as np# 创建黑色的图像img = np.zeros((512, 512, 3), np.uint8)# 绘制一条厚度为5的蓝色对角线cv.line(img, (0, 0), (511, 511), (255, 0, 0), 5)cv.rectangle(img, (384, 0), (510, 128), (0, 255, 0), 3)cv.circle(img, (447, 63), 63, (0, 0, 255), -1)cv.ellipse(img, (256, 256), (100, 50), 0, 0, 180, 255, -1)pts = np.array([[10, 5], [20, 30], [70, 20], [50, 10]], np.int32)pts = pts.reshape((-1, 1, 2))cv.polylines(img, [pts], True, (0, 255, 255))font = cv.FONT_HERSHEY_SIMPLEXcv.putText(img, 'OpenCV', (10, 500), font, 4, (255, 255, 255), 2, cv.LINE_AA)cv.imshow('image', img)cv.waitKey(0)cv.destroyAllWindows()","link":"/2021/10/25/opencv/opencv-practice/"},{"title":"nginx错误分析 Connection reset by peer","text":"nginx上下游针对请求处理的超时时间配置不合理，导致报connection reset by peer问题，即低频502，如图： 此类问题主要原因为，客户端在对上游长连接fd读写时，正好此fd被上游服务器关闭了，此时会报connection reset by peer，所以需要尽量避免上游服务器主动断开连接； 故障描述 根据tomcat官方文档说明，keepAliveTimeout默认等于connectionTimeout，我们这里配置的是20s。 参数 解释 keepAliveTimeout The number of milliseconds this Connector will wait for another HTTP request before closing the connection. The default value is to use the value that has been set for the connectionTimeout attribute. Use a value of -1 to indicate no (i.e. infinite) timeout. maxKeepAliveRequests The maximum number of HTTP requests which can be pipelined until the connection is closed by the server. Setting this attribute to 1 will disable HTTP/1.0 keep-alive, as well as HTTP/1.1 keep-alive and pipelining. Setting this to -1 will allow an unlimited amount of pipelined or keep-alive HTTP requests. If not specified, this attribute is set to 100. connectionTimeout The number of milliseconds this Connector will wait, after accepting a connection, for the request URI line to be presented. Use a value of -1 to indicate no (i.e. infinite) timeout. The default value is 60000 (i.e. 60 seconds) but note that the standard server.xml that ships with Tomcat sets this to 20000 (i.e. 20 seconds). Unless disableUploadTimeout is set to false, this timeout will also be used when reading the request body (if any). tomcat官方文档 https://tomcat.apache.org/tomcat-7.0-doc/config/http.htmlnginx(nginx-ingress-controller)中的配置 由于没有显示的配置，所以使用的是nginx的默认参数配置，默认是60s。 12345678http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive_timeout Syntax: keepalive_timeout timeout;Default: keepalive_timeout 60s;Context: upstreamThis directive appeared in version 1.15.3.Sets a timeout during which an idle keepalive connection to an upstream server will stay open. 解决竟然有了大概的分析猜测，可以尝试调整nginx的keepalive timeout为15s(需要小于tomcat的超时时间)，测试了之后，故障就这样得到了解决。 参考文章 nginx错误分析 104: Connection reset by peer Nginx: Connection reset by peer 错误定位 https://www.digitalreborn.com/fix-nginx-connection-reset-by-peer-upstream/","link":"/2021/12/08/nginx/nginx-connection-reset-by-peer/"},{"title":"nginx header-connection","text":"ref: https://datatracker.ietf.org/doc/html/rfc7230#section-6 The “Connection” header field allows the sender to indicate desiredcontrol options for the current connection. In order to avoidconfusing downstream recipients, a proxy or gateway MUST remove orreplace any received connection options before forwarding themessage. nginx转发,设置 Connection: close proxy_set_header Connection &quot;&quot;; By default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the $proxy_host variable, and “Connection” is set to close. 而且 其中一个配置： 1234Syntax: proxy_http_version 1.0 | 1.1;Default: proxy_http_version 1.0;Context: http, server, locationThis directive appeared in version 1.1.4. 所以其实 nginx 到后端 例如 tomcat 之间的连接是 http1.0的协议 所以解决 方法很简单： 1234567891011121314upstream http_backend { server 127.0.0.1:8080;}server { ... location /http/ { proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; ... }} 参考文章 nginx优化——包括https、keepalive等 解决nginx到后端服务器Connection: close问题 Nginx 对 Connection 头的处理过程 nginx http header [Connection: keep-alive]的实现原理 nginx中开启keepalive后应答反而为close的原因","link":"/2021/12/09/nginx/nginx-connection/"},{"title":"windows下nginx的安装及使用","text":"12345678910111213141516# 打开cmd命令窗口，切换到nginx解压目录下# start nginx./nginx.exe start nginx.exe# 检查80端口是否被占用的命令是：netstat -ano | findstr 0.0.0.0:80 netstat -ano | findstr &quot;80&quot;./nginx.exe -s reload# 快速停止nginx./nginx.exe -s stoptaskkill /f /t /im nginx.exe# 完整有序的停止nginx./nginx.exe -s quit 下载nginxhttp://nginx.org/en/download.html 下载后解压，解压后如下 启动nginx有很多种方法启动nginx (1)直接双击nginx.exe，双击后一个黑色的弹窗一闪而过 (2)打开cmd命令窗口，切换到nginx解压目录下，输入命令 nginx.exe 或者 start nginx ，回车即可 检查nginx是否启动成功直接在浏览器地址栏输入网址 http://localhost:80，回车，出现以下页面说明启动成功 参考文章 windows下nginx的安装及使用","link":"/2021/12/09/nginx/nginx-install-on-windows/"},{"title":"使用logrotate工具实现nginx日志切割","text":"12345678910111213141516171819/usr/local/nginx/logs/*.log { # 指定转储周期为每天 daily # 使用当期日期作为命名格式 dateext # 如果日志丢失，不报错继续滚动下一个日志 missingok # 保留 31 个备份 rotate 31 # 不压缩 nocompress # 整个日志组运行一次的脚本 sharedscripts # 转储以后需要执行的命令 postrotate # 重新打开日志文件 [ ! -f /usr/local/nginx/nginx.pid ] || kill -USR1 `cat /usr/local/nginx/nginx.pid` endscript} 安装 logrotate:1$ yum install logrotate logrotate 命令参数123456logrotate [OPTION...] &lt;configfile&gt;-d, --debug ：debug模式，测试配置文件是否有错误。-f, --force ：强制转储文件。-m, --mail=command ：压缩日志后，发送日志到指定邮箱。-s, --state=statefile ：使用指定的状态文件。-v, --verbose ：显示转储过程。 手动执行 logrotate12345678910111213141516171819202122232425262728293031323334353637# '-d' 调试模式（不切分日志文件），并输出详细处理过程日志$ logrotate -d -f /etc/logrotate.d/nginx# '-f' 强制切分日志，'-v' 输出详细信息$ logrotate -vf /etc/logrotate.d/nginxreading config file nginxAllocating hash table for state file, size 15360 BHandling 1 logsrotating pattern: /usr/local/nginx/logs/*.log forced from command line (100 rotations)empty log files are rotated, old logs are removedconsidering log /usr/local/nginx/logs/access.loglog needs rotatingconsidering log /usr/local/nginx/logs/error.loglog needs rotatingrotating log /usr/local/nginx/logs/access.log, log-&gt;rotateCount is 100dateext suffix '-20201121'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding old rotated logs failedrotating log /usr/local/nginx/logs/error.log, log-&gt;rotateCount is 100dateext suffix '-20201121'glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'glob finding old rotated logs failedrenaming /usr/local/nginx/logs/access.log to /usr/local/nginx/logs/access.log-20201121renaming /usr/local/nginx/logs/error.log to /usr/local/nginx/logs/error.log-20201121running postrotate script# 切分后的日志文件$ ls -lt /usr/local/nginx/logs总用量 0-rw-r--r-- 1 nginx root 0 11月 21 18:58 access.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 access.log-20201121-rw-r--r-- 1 nginx root 0 11月 21 18:58 error.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 error.log-20201121-rw-r--r-- 1 nginx root 0 11月 21 18:58 images.log-rw-r--r-- 1 nginx root 0 11月 21 18:57 images.log-20201121 参考文章 Nginx 使用 logrotate 进行日志滚动 linux环境下使用logrotate工具实现nginx日志切割 Nginx使用Logrotate工具实现日志切割","link":"/2021/12/23/nginx/nginx-logrotate-d/"},{"title":"nginx keepalive","text":"keepalive是在TCP中一个可以检测死连接的机制，可以保持tcp长连接不被断开，属于tcp层功能。http1.1协议默认开启keepa-live保持长连接，主要作用是提高对tcp连接的复用率，减少创建连接过程给系统带来的性能损耗。 keepalive与keep-alive区别？keepalive是tcp层长连接探活机制； keep-alive是应用层http协议使用，在其头部Connection字段中的一个值，只是代表客户端与服务之间需要保持长连接，可以理解为通过此字段来告诉nginx此连接需要维持长连接，处理完别直接关闭连接。 nginx的keepalive会做哪些事情？当使用nginx作为代理服务器时，这两点必然要满足： client到nginx的连接是长连接 nginx到server的连接是长连接nginx与keepalive相关的配置介绍场景1,配置TCP层keepalive探活机制的三个参数1234567891011121314case1:http {server { listen 127.0.0.1:3306 so_keepalive=on;//开启keepalive探活，探测策略走系统默认 }}case2:http {server { listen 127.0.0.1:3306 so_keepalive=7m:75s:9;//把空闲时长从系统默认的5分钟改为了7分钟 }} 其中so_keepalive有如下选择配置，官方文档：so_keepalive123456so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]* on: 开启，探测参数更加系统默认值* off: 关闭* keepidle: 连接空闲等待时间 * keepintvl: 发送探测报文间隔时间* keepcent: 探测报文重试次数 每个参数主要是覆盖linux系统针对keepalive的默认配置，如果nginx未设置so_keepalive配置，则走系统默认的探活策略 场景2、nginx与客户端（一般为浏览器、APP等）保持的长连接进行限制管理；1234http { keepalive_timeout 120s 120s; keepalive_requests 100;} 客户端请求header头： 123GET /uri HTTP/1.1 #版本为1.1及以上，Connection:为空也开启长连接，但Connection:close时不开启Host: www.baidu.comConnection: keep-alive #Connection:keep-alive 时均开启长连接，HTTP是否为1.1以上无影响 keepalive_timeout： 第一个参数：客户端连接在服务器端空闲状态下保持的超时值（默认75s）；值为0会禁用keep-alive，也就是说默认不启用长连接；第二个参数：响应的header域中设置“Keep-Alive: timeout=time”；告知浏览器对长连接的维持时间；官方文档：keepalive_timeout keepalive_requests：默认100，某个长连接连续处理请求次数限制，超过次数则该长连接被关闭；如果需要释放某个连接占用的内存，必须关闭该链接，内存不大的情况下，不建议开大该配置；在QPS较高的场景，则有必要加大这个参数；官方文档：keepalive_requests 场景3、nginx与上游server保持长连接12345678910111213141516http { upstream BACKEND { server 127.0.0.1:8000; server 127.0.0.1:8001; server 127.0.0.1:8002; keepalive 300; //空闲连接数 keepalive_timeout 120s;//与上游空闲时间 keepalive_requests 100;//与上游请求处理最大次数 } server{ listen 8080; location /{ proxy_pass http://BACKEND; } }} keepalive：限制nginx某个worker最多空闲连接数，此处不会限制worker与上游服务长连接的总数,官方文档：keepalive keepalive_timeout：nginx与上游长连接最大空闲时间，默认值为60s；官方文档： keepalive_timeout keepalive_requests：nginx与上游长连接最大交互请求的次数，默认值为100；官方文档： keepalive_requests 除此之外，nginx与上游通信，http协议默认是走的http1.0，对客户端header头不会直接转发，且会把头部中Connection字段置为默认的”close”，要与上游保持长连接还需要加如下配置： 1234567891011http { keepalive_timeout 120s 120s; keepalive_requests 100; server { location / { proxy_http_version 1.1; //设置与上游通信的 proxy_set_header Connection &quot;&quot;; proxy_pass http://BACKEND; } }} nginx的开启长连接会带来什么问题？nginx上下游针对请求处理的超时时间配置不合理，导致报connection reset by peer问题，即低频502 此类问题主要原因为，客户端在对上游长连接fd读写时，正好此fd被上游服务器关闭了，此时会报connection reset by peer，所以需要尽量避免上游服务器主动断开连接； 参考文章 nginx优化——包括https、keepalive等 nginx的keepalive Nginx 对客户端和server端长连接控制 keepalive Nginx 支持 keepalive 长连接 nginx优化——包括https、keepalive等 Nginx——Nginx的connection、request、keepalive、pipe（pipeline）、lingering_close","link":"/2021/12/08/nginx/nginx-keep-alive/"},{"title":"nginx documentation","text":"https://nginx.org/en/docs/ngx_http_core_module client_body_buffer_size 参考文章 https://nginx.org/en/docs/ ngx_http_core_module","link":"/2021/12/27/nginx/nginx-documentation/"},{"title":"forward_proxy &amp; reverse_proxy","text":"正向代理正向代理（forward proxy）：是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。 这种代理其实在生活中是比较常见的，比如访问外国网站技术，其用到的就是代理技术。 有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。 这个过程其实和租房子很像。 租房子的时候，一般情况下，我们很难联系到房东，因为有些房东为了图方便，只把自己的房屋信息和钥匙交给中介了。而房客想要租房子，只能通过中介才能联系到房东。而对于房东来说，他可能根本不知道真正要租他的房子的人是谁，他只知道是中介在联系他。 这里面一共有三个角色，租客（用户）、中介（代理服务器）和房东（国外网站，目标服务器）。引入中介（代理服务器）的原因是用户无法联系上房东（用户无法访问国外网站）。 所以，正向代理，其实是”代理服务器”代理了”客户端”，去和”目标服务器”进行交互。 通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的，甚至不知道访问自己的是一个代理（有时候中介也直接冒充租客）。 正向代理的用途 突破访问限制 通过代理服务器，可以突破自身IP访问限制，访问国外网站，教育网等。即，租客可以通过中介，来解决无法联系上房东的问题。 提高访问速度通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。即，中介手里留存了很多房源信息和钥匙，可以直接带租客去看房。 隐藏客户端真实IP上网者也可以通过这种方法隐藏自己的IP，免受攻击。 即，房东并不知道租客的真实身份。PS：但是中介知道了，可能骚扰更多…. 反向代理反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 我们在租房子的过程中，除了有些房源需要通过中介以外，还有一些是可以直接通过房东来租的。用户直接找到房东租房的这种情况就是我们不使用代理直接访问国内的网站的情况。 还有一种情况，就是我们以为我们接触的是房东，其实有时候也有可能并非房主本人，有可能是他的亲戚、朋友，甚至是二房东。但是我们并不知道和我们沟通的并不是真正的房东。这种帮助真正的房主租房的二房东其实就是反向代理服务器。这个过程就是反向代理。 对于常用的场景，就是我们在Web开发中用到的负载均衡服务器（二房东），客户端（租客）发送请求到负载均衡服务器（二房东）上，负载均衡服务器（二房东）再把请求转发给一台真正的服务器（房东）来执行，再把执行结果返回给客户端（租客）。所以，反向代理，其实是”代理服务器”代理了”目标服务器”，去和”客户端”进行交互。通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的，甚至不知道自己访问的是一个代理。 反向代理的用途 隐藏服务器真实IP 使用反向代理，可以对客户端隐藏服务器的IP地址。 即，租客并不房东知道的真实身份。 负载均衡 反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。即，二房东发现房主本人很忙，于是找到房主的妻子帮忙处理租房事宜。 提高访问速度 反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。即，二房东同样有房屋信息和钥匙。 提供安全保障 反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。即，二房东可以有效的保护房东的安全。 正向代理和反向代理的区别虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。 1、正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。 2、正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。 3、正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。 4、正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。 代理配置项 配置语法 12345678语法：proxy_buffering on | off;默认值：proxy_buffering on;可配置段：http, server, location作用：配置proxy缓冲区。扩展：proxy_buffer_size：设置缓冲区大小（内存页大小）proxy_buffers：设置缓冲区数量和大小（内存页数量和大小）proxy_busy_buffers_size：设置最大缓冲区大小 12345语法：proxy_redirect default; proxy_redirect off; proxy_redirect redirect replacement;默认值：proxy_redirect default;可配置段：http, server, location作用：配置proxy重定向。扩展： 12345语法：proxy_buffering on | off;默认值：proxy_buffering on;可配置段：http, server, location作用：配置proxy缓冲区。扩展： 1234567语法：proxy_set_header field value;默认值：proxy_set_header Host $proxy_host; proxy_set_header Connection close;可配置段：http, server, location作用：配置proxy头信息。扩展：proxy_hide_header：设置隐藏头信息字段；proxy_set_body：设置请求体返回信息。 1234567语法：proxy_connect_timeout time;默认值：proxy_connect_timeout 60s;可配置段：http, server, location作用：配置proxy超时。扩展：proxy_hide_header：设置隐藏头信息字段；proxy_set_body：设置请求体返回信息。 配置正向代理12345678910111213141516171819202122232425262728293031323334353637[root@proxy ~]# vi /etc/nginx/conf.d/reverse.confserver{ resolver 8.8.8.8; #配置DNS解析IP地址 resolver_timeout 30s; #超时时间（5秒） listen 82; access_log /var/log/nginx/reverse.access.log main; error_log /var/log/nginx/reverse.error.log warn; location / { proxy_pass http://$http_host$request_uri; #配置正向代理参数 proxy_set_header Host $http_host; #解决如果URL中带&quot;.&quot;后Nginx 503错误 proxy_buffers 256 4k; #配置缓存大小 proxy_max_temp_file_size 0; #关闭磁盘缓存读写减少I/O proxy_connect_timeout 30; #代理连接超时时间 proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; #配置代理服务器缓存时间 }}配置释义：1、不能有hostname。2、必须有resolver, 即dns，即上面的8.8.8.8，超时时间（30秒）可选。3、配置正向代理参数，均是由 Nginx 变量组成。proxy_pass $scheme://$host$request_uri; proxy_set_header Host $http_host; 4、配置缓存大小，关闭磁盘缓存读写减少I/O，以及代理连接超时时间。proxy_buffers 256 4k; proxy_max_temp_file_size 0; proxy_connect_timeout 30; 5、配置代理服务器 Http 状态缓存时间。proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m;配置好后，重启nginx，以浏览器为例，要使用这个代理服务器，则只需将浏览器代理设置为http://+服务器ip地址+:+82（82是刚刚设置的端口号）即可使用了。 反向代理配置123456789101112131415161718192021222324252627282930313233http {# 省略了前面一般的配置，直接从负载均衡这里开始# 设置地址池，后端3台服务器 upstream http_server_pool { server 192.168.1.2:8080 weight=2 max_fails=2 fail_timeout=30s; server 192.168.1.3:8080 weight=3 max_fails=2 fail_timeout=30s; server 192.168.1.4:8080 weight=4 max_fails=2 fail_timeout=30s; }# 一个虚拟主机，用来反向代理http_server_pool这组服务器 server { listen 80;# 外网访问的域名 server_name www.test.com; location / {# 后端服务器返回500 503 404错误，自动请求转发到upstream池中另一台服务器 proxy_next_upstream error timeout invalid_header http_500 http_503 http_404; proxy_pass http://http_server_pool; proxy_set_header Host www.test.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } access_log logs/www.test.com.access.log combined; }}最简单的反向代理演示（在一台服务器上做代理服务器，将http请求转发到另一台IIS服务器上，通过二级域名形式访问。）编辑vim nginx.confserver { listen 80; server_name test.zhoumengkang.com; location / { proxy_pass http://121.199.**.*:80; }}参考：http://www.blogjava.net/xiaomage234/archive/2011/09/08/358247.html 123456789101112131415161718192021proxy_set_header X-Real-IP $remote_addr： 把源IP【$remote_addr，建立HTTP连接header里面的信息】赋值给X-Real-IP，从而通过$X-Real-IP来获取源IP；proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for： 在nginx作为代理服务器时，设置的IP列表，会把经过的机器ip，代理机器ip都记录下来，用【，】隔开。 proxy_pass：设置代理服务器的地址，可以是主机名称、IP地址加端口号等形式。proxy_pass URL提示：1：当代理的是一组服务器时可以使用 upstream 指令来设置。2：当URL中含有uri时，（例如 &quot;http://127.0.0.1:8080/&quot;、&quot;http://127.0.0.1:8080/demo.html&quot;）不管客户端访问的是地址中的uri是什么，代理服务器都会代理到URL的地址；当URL中不包含uri时（例如：&quot;http://127.0.0.1:8080&quot;），那么当客户端访问服务器时，代理服务器会根据客户端请求的uri来访问具体的URL地址。 proxy_pass_request_body on|off：用于配置是否将客户端请求的请求体发送给代理服务器。proxy_pass_request_headers on|off：用于配置是否将客户端请求的头信息发送给代理服务器。proxy_set_header field value：可以更改nginx接收到的客户端请求的请求头信息，然后将新的请求头信息发送给被代理的服务器。proxy_set_body value：ngin接收到客户端的请求后使用该指令可以修改request中的body体，然后将请求转发给代理服务器。proxy_connect_timeout time：nginx服务器与被代理服务器之间尝试建立连接的的超时时间，默认为60s。proxy_read_timeot time：nginx服务器接收被代理服务器数据时最大的等待时间，默认为60s。proxy_send_timeout time：nginx服务器发送数据至被代理服务器的最大等待时间，例如60s内没有发出一个字节则默认断开连接，默认60s。proxy_http_version 1.0|1.1：nginx服务器提供代理服务的http协议版本。proxy_method method：nginx服务器设置请求被代理服务器时使用的请求方法，一般为POST或者GET。proxy_ignore_client_abort：当客户端中断网络请求时，nginx服务是否中断对代理服务器的请求，默认off。 参考文章 终于有人把正向代理和反向代理解释的明明白白了！ Nginx反向代理和正向代理 Nginx 正向代理与反向代理解析与实战 Nginx正反代理 nginx–❤️图解及代码实现正向代理、反向代理及负载均衡（非常实用，建议收藏❤️） Nginx代理的几种模式","link":"/2021/12/08/nginx/nginx-proxy-and-reverse-proxy/"},{"title":"nginx -s reload","text":"nginx -s reload acts : nginx master process running (not restarted) nginx worker process restarted reload –重新加载，reload会重新加载配置文件，Nginx服务不会中断。而且reload时会测试conf语法等，如果出错会rollback用上一次正确配置文件保持正常运行。 restart –重启（先stop后start），会重启Nginx服务。这个重启会造成服务一瞬间的中断，如果配置文件出错会导致服务启动失败，那就是更长时间的服务中断了。所以，如果是线上的服务，修改的配置文件一定要备份。为了保证线上服务高可用，最好使用reload。 reload 只是重新加载配置文件，不会清理nginx 的一些缓存，在有些需要清理缓存的场景需要restart ，例如upstream 后端配置的集群服务地址是域名而不是ip，当后端IP 变了，就需要清除该域名的解析缓存，此时需要重启而不是reload。 参考文章 nginx reload 与 restart 的区别","link":"/2021/12/20/nginx/nginx-s-reload/"},{"title":"Nginx转发，swagger误将upstream作为base url","text":"1proxy_set_header Host $host:$server_port; nginx反向代理时配置如下： 1234proxy_set_header Host $remote_addr;proxy_set_header X-Real-IP $remote_addr;proxy_set_header REMOTE-HOST $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 这就导致获取的是客户端真实的IP地址 解决办法： 屏蔽上述配置，添加以下配置： 1proxy_set_header Host $host:$server_port; 将NGINX接收到请求头中的Host和端口继续往下传递。 参考文章 https://blog.csdn.net/surite/article/details/114120794 https://www.cnblogs.com/John-2011/p/14812449.html","link":"/2021/12/03/nginx/nginx-swagger-upstream/"},{"title":"如何在 Ubuntu 上安装 Python 3","text":"ubuntu安装python3的方法：123456789101112## remove old version apt-get remove --auto-remove #1、安装python3 -yapt-get install python3#2、安装pip3apt-get install python3-pip -y # pip3 install docker-compose python3 --version 参考文章 http://www.py.cn/faq/python/18025.html","link":"/2021/12/24/python/python-ubuntu-install/"},{"title":"nginx支持HTTP2的配置过程","text":"1./configure *** --with-http_v2_module 1listen 443 ssl http2; curl支持http2123456789101112131415161718[root@ ~]# wget https://github.com/nghttp2/nghttp2/releases/download/v1.41.0/nghttp2-1.41.0.tar.bz2[root@ ~]# tar xf nghttp2-1.41.0.tar.bz2[root@ ~]# cd nghttp2-1.41.0[root@ ~]# autoreconf -i[root@ ~]# automake[root@ ~]# autoconf [root@ ~]# ./configure --prefix=/usr/local/nghttp2-1.41.0[root@ ~]# make &amp;&amp; make install[root@ ~]# wget http://curl.haxx.se/download/curl-7.46.0.tar.bz2[root@ ~]# tar xf curl-7.46.0.tar.bz2[root@ ~]# cd curl-7.46.0[root@ ~]# ./configure --with-nghttp2=/usr/local/nghttp2-1.41.0/ --with-ssl --prefix=/usr/local/curl-7.46.0/[root@ ~]# make &amp;&amp; make install[root@ ~]# /usr/local/curl-7.46.0/bin/curl --versioncurl 7.46.0 (x86_64-pc-linux-gnu) libcurl/7.46.0 OpenSSL/1.0.2k zlib/1.2.7 nghttp2/1.41.0Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftpFeatures: IPv6 Largefile NTLM NTLM_WB SSL libz HTTP2 UnixSockets 参考文章 https://www.cnblogs.com/wshenjin/p/13522388.html https://www.cnblogs.com/bugutian/p/6628455.html","link":"/2021/12/03/nginx/nginx-suppport-http2/"},{"title":"如何在 CentOS 上安装 Python 3","text":"Installing Python 3 on CentOS 8To install Python 3 on CentOS 8 run the following command as root or sudo user in your terminal: 123456789101112131415161718192021sudo dnf install python3 -y#该命令还会安装 pip 。#To verify the installation, check the Python version by typing:python3 --versionpip3 --version#Python 3 模块包的名称以“python3”为前缀。例如，要安装paramiko 模块，您将运行：sudo dnf install python3-paramiko -y# To be able to install and build Python modules with pip, you need to install the Development toolssudo yum install python3-devel -ysudo yum groupinstall 'development tools' -y install python3.8 on centos8https://computingforgeeks.com/how-to-install-python-3-python-2-7-on-rhel-8/ https://linuxize.com/post/how-to-install-python-3-8-on-centos-8/ 123456789101112131415161718192021222324252627282930313233# sudo dnf install python3# preparesudo dnf groupinstall 'development tools' -ysudo dnf install bzip2-devel expat-devel gdbm-devel \\ ncurses-devel openssl-devel readline-devel wget \\ sqlite-devel tk-devel xz-devel zlib-devel libffi-devel -y## download VERSION=3.8.1wget https://www.python.org/ftp/python/${VERSION}/Python-${VERSION}.tgztar -xf Python-${VERSION}.tgz# 该--enable-optimizations选项通过运行多个测试来优化 Python 二进制文件。这会使构建过程变慢。cd Python-${VERSION}./configure --enable-optimizations# 通过运行以下命令启动 Python 3.8 构建过程：make -j 4# 修改-j以对应于处理器中的内核数。您可以通过键入 找到该号码nproc。# 构建过程完成后，安装 Python 二进制文件：sudo make altinstallpython3.8 --versionsudo alternatives --set python /usr/bin/python3python -m pip install --upgrade pip 创建虚拟环境 or 配置Python默认版本为3.8.0创建虚拟环境Python 虚拟环境是一个独立的目录树，其中包括 Python 安装和许多附加包。它允许您将 Python 模块安装在特定项目的隔离位置，而不是全局安装。这样，您就不必担心影响其他 Python 项目。 在此示例中，我们将my_app在用户主目录中创建一个名为的新 Python 3.8 项目。 首先，创建项目目录并切换 到它： 12mkdir ~/my_app &amp;&amp; cd ~/my_app 从项目根目录内部运行以下命令以创建一个名为的虚拟环境my_app_venv： 12python3.8 -m venv my_app_venv 激活环境： 12source my_app_venv/bin/activate 激活后，shell 提示符将以环境名称为前缀。从 Python 3.4 开始，在创建虚拟环境pip 时， 默认安装 Python 的包管理器。 在虚拟环境中，您可以使用pip代替pip3.8和python代替python3.8： 12python -v Python 3.8.1完成停用环境的工作后，键入deactivate，您将返回到正常的 shell。 1deactivate 配置Python默认版本为3.8.0 https://www.jianshu.com/p/aca71ba154b6 1234ln -s /usr/local/bin/python3.8 /usr/bin/pythonpython -m pip install --upgrade pip centos 7Start by updating the repository:12sudo yum update -y 通过在终端窗口中运行以下命令来安装 Python 3：12sudo yum install -y python3 验证您是否已成功安装 Python 3：python3 --version 参考文章 https://www.liquidweb.com/kb/how-to-install-python-3-on-centos-7/ https://phoenixnap.com/kb/how-to-install-python-3-centos-7 https://linuxize.com/post/how-to-install-python-on-centos-8/ https://linuxize.com/post/how-to-install-pip-on-centos-8/","link":"/2021/12/24/python/python-centos-install/"},{"title":"spring @Scheduled","text":"参考文章 The @Scheduled Annotation in Spring","link":"/2022/04/13/spring/spring-Scheduled/"},{"title":"spring 事务","text":"spring 事务传播属性 常量 解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。默认的传播属性。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 前六个策略类似于EJB CMT，第七个（PROPAGATION_NESTED）是Spring所提供的一个特殊变量。它要求事务管理器或者使用JDBC 3.0 Savepoint API提供嵌套事务行为（如Spring的DataSourceTransactionManager） 事务的传播机制事务的传播性一般用在事务嵌套的场景，比如一个事务方法里面调用了另外一个事务方法，那么两个方法是各自作为独立的方法提交还是内层的事务合并到外层的事务一起提交，这就是需要事务传播机制的配置来确定怎么样执行。常用的事务传播机制如下： PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务 Spring默认的传播机制。 如果外层有事务，则当前事务加入到外层事务，一块提交，一块回滚。如果外层没有事务，新建一个事务执行 explain:123456789ServiceA { void methodA() { //外部事务 ServiceB.methodB(); } } ServiceB { void methodB() { //内部事务 } } ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED, 那么由于执行ServiceA.methodA的时候1、如果ServiceA.methodA已经起了事务，这时调用ServiceB.methodB，ServiceB.methodB看到自己已经运行在ServiceA.methodA的事务内部，就不再起新的事务。这时只有外部事务并且他们是共用的，所以这时ServiceA.methodA或者ServiceB.methodB无论哪个发生异常methodA和methodB作为一个整体都将一起回滚。2、如果ServiceA.methodA没有事务，ServiceB.methodB就会为自己分配一个事务。这样，在ServiceA.methodA中是没有事务控制的。只是在ServiceB.methodB内的任何地方出现异常，ServiceB.methodB将会被回滚，不会引起ServiceA.methodA的回滚 PROPAGATION_REQUES_NEW该事务传播机制是每次都会新开启一个事务，同时把外层事务挂起，当当前事务执行完毕，恢复上层事务的执行。如果外层没有事务，执行当前新开启的事务即可 新建的事务和挂起的事务是两个独立的事务。1.标志REQUIRES_NEW会新开启事务，外层事务不会影响内部事务的提交/回滚2.标志REQUIRES_NEW的内部事务的异常，被外部事务捕获，也可以不处理回滚操作 如果设计ServiceA.methodA事务级别定义为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED_NEW,那么，当执行到ServiceB.methodB的时候, ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会发起一个新事务， 等待 ServiceB.methodB的事务完成以后，挂起的事务才会继续执行。 它与PROPAGATION_REQUIRED的区别在于事务的回滚程度。因为ServiceB.methodB新发起一个事务，存在两个不同的事务。如果ServiceB.methodB 已经提交，那么 ServiceA.methodA 回滚失败时 ServiceB.methodB 是不会回滚的。 如果ServiceB.methodB 回滚失败，他抛出的异常被ServiceA.methodA 捕获，ServiceA.methodA的事务任然可能提交（主要看ServiceB.methodB抛出的异常是不是ServiceA.methodA会回滚的异常 ）。 PROPAGATION_SUPPORTS如果当前在事务中，即以事务的形式运行，如果当前不再一个事务中，那么就以非事务的形式运行 PROPAGATION_NOT_SUPPORT该传播机制不支持事务，如果外层存在事务则挂起，执行完当前代码，则恢复外层事务，无论是否异常都不会回滚当前的代码 当前不支持事务。比如ServiceA.methodA的事务级别是PROPAGATION_REQUIRED ，而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时，ServiceA.methodA的事务挂起，而他以非事务的状态运行完，再继续ServiceA.methodA的事务。 PROPAGATION_NEVER该传播机制不支持外层事务，即如果外层有事务就抛出异常 不能在事务中运行。假设ServiceA.methodA的事务级别是PROPAGATION_REQUIRED， 而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。 PROPAGATION_MANDATORY必须在一个事务中运行。也就是说，他只能被一个父事务调用。否则，他就要抛出异常 PROPAGATION_NESTED如果有活动的事务，则运行在一个嵌套的事务中。如果没有活动事务，则按required属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器有效。 该传播机制的特点是可以保存状态保存点，当前事务回滚到某一个点，从而避免所有的嵌套事务都回滚，即各自回滚各自的，如果子事务没有把异常吃掉，基本还是会引起全部回滚的。 比如我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_NESTED，那么当执行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会起一个新的子事务并设置savepoint，等待ServiceB.methodB的事务完成以后，他才继续执行。。因为ServiceB.methodB是外部事务的子事务，那么1、如果ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚，ServiceB.methodB也将回滚。2、如果ServiceB.methodB失败回滚，如果他抛出的异常被ServiceA.methodA的try..catch捕获并处理，ServiceA.methodA事务仍然可能提交；如果他抛出的异常未被ServiceA.methodA捕获处理，ServiceA.methodA事务将回滚。 理解Nested的关键是savepoint。他与PROPAGATION_REQUIRES_NEW的区别是：PROPAGATION_REQUIRES_NEW 完全是一个新的事务,它与外部事务相互独立；而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 嵌套事务也会被 commit, 这个规则同样适用于 roll back. 在 spring 中使用 PROPAGATION_NESTED的前提： 我们要设置 transactionManager 的 nestedTransactionAllowed 属性为 true, 注意, 此属性默认为 false!!! java.sql.Savepoint 必须存在, 即 jdk 版本要 1.4+ Connection.getMetaData().supportsSavepoints() 必须为 true, 即 jdbc drive 必须支持 JDBC 3.0 确保以上条件都满足后, 你就可以尝试使用 PROPAGATION_NESTED 了. 事务的隔离级别事务的隔离级别定义一个事务可能受其他并发务活动活动影响的程度，可以把事务的隔离级别想象为这个事务对于事物处理数据的自私程度。 在一个典型的应用程序中，多个事务同时运行，经常会为了完成他们的工作而操作同一个数据。并发虽然是必需的，但是会导致以下问题： 脏读（Dirty read）脏读发生在一个事务读取了被另一个事务改写但尚未提交的数据时。如果这些改变在稍后被回滚了，那么第一个事务读取的数据就会是无效的。 不可重复读（Nonrepeatable read）不可重复读发生在一个事务执行相同的查询两次或两次以上，但每次查询结果都不相同时。这通常是由于另一个并发事务在两次查询之间更新了数据。不可重复读重点在修改。 幻读（Phantom reads）幻读和不可重复读相似。当一个事务（T1）读取几行记录后，另一个并发事务（T2）插入了一些记录时，幻读就发生了。在后来的查询中，第一个事务（T1）就会发现一些原来没有的额外记录。幻读重点在新增或删除。 在理想状态下，事务之间将完全隔离，从而可以防止这些问题发生。然而，完全隔离会影响性能，因为隔离经常涉及到锁定在数据库中的记录（甚至有时是锁表）。完全隔离要求事务相互等待来完成工作，会阻碍并发。因此，可以根据业务场景选择不同的隔离级别。 隔离级别 含义 ISOLATION_DEFAULT 使用后端数据库默认的隔离级别 ISOLATION_READ_UNCOMMITTED 允许读取尚未提交的更改。可能导致脏读、幻读或不可重复读。 ISOLATION_READ_COMMITTED （Oracle 默认级别） 允许从已经提交的并发事务读取。可防止脏读，但幻读和不可重复读仍可能会发生。 ISOLATION_REPEATABLE_READ （MYSQL默认级别） 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻读仍可能发生。 ISOLATION_SERIALIZABLE 完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。 只读如果一个事务只对数据库执行读操作，那么该数据库就可能利用那个事务的只读特性，采取某些优化措施。通过把一个事务声明为只读，可以给后端数据库一个机会来应用那些它认为合适的优化措施。由于只读的优化措施是在一个事务启动时由后端数据库实施的， 因此，只有对于那些具有可能启动一个新事务的传播行为（PROPAGATION_REQUIRES_NEW、PROPAGATION_REQUIRED、 ROPAGATION_NESTED）的方法来说，将事务声明为只读才有意义。 事务超时为了使一个应用程序很好地执行，它的事务不能运行太长时间。因此，声明式事务的下一个特性就是它的超时。 假设事务的运行时间变得格外的长，由于事务可能涉及对数据库的锁定，所以长时间运行的事务会不必要地占用数据库资源。这时就可以声明一个事务在特定秒数后自动回滚，不必等它自己结束。 由于超时时钟在一个事务启动的时候开始的，因此，只有对于那些具有可能启动一个新事务的传播行为（PROPAGATION_REQUIRES_NEW、PROPAGATION_REQUIRED、ROPAGATION_NESTED）的方法来说，声明事务超时才有意义。 回滚规则在默认设置下，事务只在出现运行时异常（runtime exception）时回滚，而在出现受检查异常（checked exception）时不回滚（这一行为和EJB中的回滚行为是一致的）。不过，可以声明在出现特定受检查异常时像运行时异常一样回滚。同样，也可以声明一个事务在出现特定的异常时不回滚，即使特定的异常是运行时异常。 Spring声明式事务配置参考事物配置中有哪些属性可以配置?以下只是简单的使用参考 事务的传播性：@Transactional(propagation=Propagation.REQUIRED) 事务的隔离级别：@Transactional(isolation = Isolation.READ_UNCOMMITTED) 读取未提交数据(会出现脏读, 不可重复读) 基本不使用 只读：@Transactional(readOnly=true) 该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false。 事务的超时性：@Transactional(timeout=30) 回滚： 指定单一异常类：@Transactional(rollbackFor=RuntimeException.class) 指定多个异常类：@Transactional(rollbackFor={RuntimeException.class, Exception.class})","link":"/2021/10/19/spring/spring-affairs/"},{"title":"spring batch","text":"案例一Ref: Spring Boot With Spring Batch How to Trigger and Stop a Scheduled Spring Batch Jobdemo https://github.com/eugenp/tutorials/tree/master/spring-batch-2 案例二 Creating a Batch Service demo 案例三 demo: https://github.com/EalenXie/springboot-batch 案例四 Spring Boot 整合——Spring batch基本使用 demo 参考文章 Introduction to Spring Batch Spring Boot下Spring Batch入门实例 SpringBoot整合SpringBatch实用简例","link":"/2022/04/13/spring/spring-batch/"},{"title":"lettuce","text":"12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; standalone properties code 12345## redisspring.redis.database=0spring.redis.host=wslspring.redis.port=6379spring.redis.password=summer123!@# cluster properties code12spring.redis.cluster.nodes=192.168.50.28:6379,192.168.50.28:6381,192.168.50.28:6383spring.redis.cluster.max-redirects=3 测试123456789101112131415161718192021222324252627import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;@Servicepublic class SimpleService { static Logger logger = LoggerFactory.getLogger(SimpleService.class) ; @Autowired StringRedisTemplate stringRedisTemplate ; public void run(){ logger.info(&quot;redis连接工厂：{}&quot;,stringRedisTemplate.getConnectionFactory()); //添加key stringRedisTemplate.opsForValue().set(&quot;user&quot;,&quot;张三&quot;); //获取key logger.info(&quot;从redis中获取key=user的值为：{}&quot;,stringRedisTemplate.opsForValue().get(&quot;user&quot;)); //删除key stringRedisTemplate.delete(&quot;user&quot;); }} 123456789101112131415161718192021222324252627282930313233import java.util.Locale;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.SpringApplication;import org.springframework.boot.actuate.autoconfigure.metrics.MeterRegistryCustomizer;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.Bean;import com.example.summermetrics.service.SimpleService;import io.micrometer.core.instrument.MeterRegistry;@SpringBootApplicationpublic class SummerMetricsApplication { static { Locale.setDefault(Locale.CHINA); } public static void main(String[] args) { // SpringApplication.run(SummerMetricsApplication.class, args); ApplicationContext ctx = SpringApplication.run(SummerMetricsApplication.class, args); SimpleService simpleService = ctx.getBean(SimpleService.class) ; simpleService.run(); } @Bean MeterRegistryCustomizer&lt;MeterRegistry&gt; configurer( @Value(&quot;${spring.application.name}&quot;) String applicationName) { return (registry) -&gt; registry.config().commonTags(&quot;application&quot;, applicationName); }} 参考文章 Spring boot - data-redis与jedis关系","link":"/2022/04/13/spring/spring-data-redis-luttuce/"},{"title":"spring-data-redis jedis","text":"123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt; redis standalone config jedis- redis_standalone123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisStandaloneConfiguration;import org.springframework.data.redis.connection.jedis.JedisClientConfiguration;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import lombok.Getter;import lombok.Setter;import lombok.extern.slf4j.Slf4j;import redis.clients.jedis.JedisPoolConfig;@Getter@Setter@Slf4j@Configuration@ConfigurationProperties(prefix = &quot;summer.redis&quot;)public class RedisConfig { private String seedAddress; private String password; JedisClientConfiguration clientConfiguration() { JedisPoolConfig poolConfig = getJedisPoolConfig(); JedisClientConfiguration.JedisClientConfigurationBuilder builder = JedisClientConfiguration.builder(); return builder .usePooling() .poolConfig(poolConfig) .build(); } public JedisPoolConfig getJedisPoolConfig() { JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(100); poolConfig.setMaxIdle(100); poolConfig.setMinIdle(10); poolConfig.setTestOnBorrow(false); poolConfig.setTestOnReturn(false); poolConfig.setTestOnCreate(true); poolConfig.setBlockWhenExhausted(true); poolConfig.setMaxWaitMillis(1000); return poolConfig; } @Bean JedisConnectionFactory jedisConnectionFactory() { RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setHostName(&quot;wsl&quot;); redisStandaloneConfiguration.setPort(6379); redisStandaloneConfiguration.setPassword(&quot;summer123!@#&quot;); JedisClientConfiguration clientConfiguration = clientConfiguration(); JedisConnectionFactory factory = new JedisConnectionFactory(redisStandaloneConfiguration, clientConfiguration); factory.afterPropertiesSet(); return factory; } @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate() { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(jedisConnectionFactory()); return template; }} jedis redis-cluster config code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.example.summermetrics.config;import java.util.Arrays;import java.util.List;import java.util.Objects;import java.util.Optional;import java.util.stream.Collectors;import org.apache.commons.collections4.CollectionUtils;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisClusterConfiguration;import org.springframework.data.redis.connection.RedisNode;import org.springframework.data.redis.connection.jedis.JedisClientConfiguration;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import lombok.Getter;import lombok.Setter;import lombok.extern.slf4j.Slf4j;import redis.clients.jedis.JedisPoolConfig;@Getter@Setter@Slf4j@Configurationpublic class RedisConfig { public JedisClientConfiguration clientConfiguration() { JedisPoolConfig poolConfig = getJedisPoolConfig(); JedisClientConfiguration.JedisClientConfigurationBuilder builder = JedisClientConfiguration.builder(); return builder .usePooling() .poolConfig(poolConfig) .build(); } public JedisPoolConfig getJedisPoolConfig() { JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(100); poolConfig.setMaxIdle(100); poolConfig.setMinIdle(10); poolConfig.setTestOnBorrow(false); poolConfig.setTestOnReturn(false); poolConfig.setTestOnCreate(true); poolConfig.setBlockWhenExhausted(true); poolConfig.setMaxWaitMillis(1000); return poolConfig; } public static final String SEED_ADDRESS = &quot;192.168.50.28:6379,192.168.50.28:6381,192.168.50.28:6383&quot;; public List&lt;RedisNode&gt; getRedisNodes(String seedAddress) { List&lt;RedisNode&gt; redisNodes = Arrays.stream(seedAddress.split(&quot;,&quot;)) .map(s -&gt; { String[] seed = Optional.ofNullable(s).orElse(&quot;&quot;).split(&quot;:&quot;); if (seed.length &lt; 2) { log.error(&quot;[RedisConnectionFactory] Add Cluster Seed. seed: {}&quot;, s); return null; } String host = seed[0]; int port = Integer.parseInt(seed[1]); log.info(&quot;[RedisConnectionFactory] Add Cluster Seed. host: {}, port: {}&quot;, host, port); return RedisNode.newRedisNode().listeningAt(host, port).build(); }).filter(Objects::nonNull).collect(Collectors.toList()); if (CollectionUtils.isEmpty(redisNodes)) { throw new RuntimeException(&quot;[RedisConnectionFactory] Add Cluster Seed failed.&quot;); } return redisNodes; } @Bean public JedisConnectionFactory jedisConnectionFactory() { RedisClusterConfiguration redisClusterConfiguration = new RedisClusterConfiguration(); getRedisNodes(SEED_ADDRESS).forEach(redisClusterConfiguration::addClusterNode); // redisClusterConfiguration.setPassword(&quot;&quot;); JedisClientConfiguration clientConfiguration = clientConfiguration(); JedisConnectionFactory factory = new JedisConnectionFactory(redisClusterConfiguration, clientConfiguration); factory.afterPropertiesSet(); return factory; } @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate() { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(jedisConnectionFactory()); return template; }} test123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.util.UUID;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseStatus;import org.springframework.web.bind.annotation.RestController;import com.example.summermetrics.domain.SummerMetricsHeader;import com.example.summermetrics.domain.redis.Student;import com.example.summermetrics.repository.StudentRepository;import io.swagger.v3.oas.annotations.Operation;import lombok.RequiredArgsConstructor;import lombok.extern.slf4j.Slf4j;@RestController@RequestMapping(value = &quot;/summer&quot;)@RequiredArgsConstructor@Slf4jpublic class RedisController { @Autowired private StringRedisTemplate stringRedisTemplate; @Autowired StudentRepository studentRepository; @Operation @GetMapping(&quot;/redis/cluster&quot;) @ResponseStatus(HttpStatus.OK) public void redisTest(SummerMetricsHeader summerMetricsHeader) { String id = UUID.randomUUID().toString(); Student student = new Student(id, summerMetricsHeader.getMemberNo(), Student.Gender.MALE, 1); studentRepository.save(student); Student retrievedStudent = studentRepository.findById(id).get(); log.info(student.toString()); retrievedStudent.setName(&quot;Richard Watson&quot;); studentRepository.save(student); log.info(student.toString()); //添加key stringRedisTemplate.opsForValue().set(&quot;user&quot;, &quot;张三&quot;); //获取key log.info(&quot;从redis中获取key=user的值为：{}&quot;, stringRedisTemplate.opsForValue().get(&quot;user&quot;)); ((JedisConnectionFactory)stringRedisTemplate.getConnectionFactory()).destroy(); }} 参考文章 Introduction to Spring Data Redis Spring boot - data-redis与jedis关系","link":"/2022/04/13/spring/spring-data-redis-jedis/"},{"title":"webflux lettuce redis","text":"123456789 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-pool2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12# Connect redis cluster nodes with – C parameter: redis cli – C – H 172.17.0.1 – P 6391redis-cli –c -h 172.17.0.1 –p 6391 code1234summer: redis: password: seed-address: 192.168.50.28:6379,192.168.50.28:6380,192.168.50.28:6381 RedisConfig1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@ConfigurationProperties(prefix = &quot;summer.redis&quot;)public class RedisConfig { private String seedAddress; private String password; private LettuceClientConfiguration getLettuceClientConfiguration() { ClusterTopologyRefreshOptions topologyRefreshOptions = ClusterTopologyRefreshOptions.builder() .dynamicRefreshSources(true) .enablePeriodicRefresh(Duration.ofSeconds(30)) .enableAdaptiveRefreshTrigger(ClusterTopologyRefreshOptions.RefreshTrigger.UNKNOWN_NODE) .adaptiveRefreshTriggersTimeout(Duration.ofSeconds(25)) .build(); return LettucePoolingClientConfiguration.builder() .clientOptions(ClusterClientOptions.builder().topologyRefreshOptions(topologyRefreshOptions).build()) .build(); } private RedisClusterConfiguration getRedisClusterConfiguration(String seedAddress) { RedisClusterConfiguration clusterConfig = new RedisClusterConfiguration(); getRedisNodes(seedAddress).forEach(clusterConfig::addClusterNode); clusterConfig.setPassword(RedisPassword.of(password)); return clusterConfig; } private List&lt;RedisNode&gt; getRedisNodes(String seedAddress) { return Arrays.stream(seedAddress.split(&quot;,&quot;)) .map(s -&gt; { String[] seed = s.split(&quot;:&quot;); String host = seed[0]; int port = Integer.parseInt(seed[1]); log.info(&quot;[RedisConnectionFactory] Add Cluster Seed. host: {}, port: {}&quot;, host, port); return RedisNode.newRedisNode().listeningAt(host, port).build(); }).collect(Collectors.toList()); } @Bean public ReactiveRedisConnectionFactory reactiveRedisConnectionFactory() { return new LettuceConnectionFactory(getRedisClusterConfiguration(seedAddress), getLettuceClientConfiguration()); } @Bean ReactiveRedisTemplate&lt;String, String&gt; stringReactiveRedisTemplate(ReactiveRedisConnectionFactory reactiveRedisConnectionFactory) { return new ReactiveRedisTemplate&lt;&gt;(reactiveRedisConnectionFactory, RedisSerializationContext.string()); }} test12345678910111213141516171819202122232425@RestController@Tag(name = &quot;Redis APIs&quot;, description = &quot;Redis APIs &quot;)public class StrignRedisController { @Autowired @Qualifier(&quot;stringReactiveRedisTemplate&quot;) private ReactiveRedisTemplate&lt;String, String&gt; stringRedisTemplate; @Operation(description = &quot;Get data from redis&quot;, parameters = { @Parameter(name = &quot;key&quot;, in = ParameterIn.QUERY, required = true, description = &quot;redis key&quot;) }) @GetMapping(&quot;redis&quot;) public Mono&lt;String&gt; getRedisData(final @RequestParam String key) { return stringRedisTemplate.opsForValue().get(key); } @PostMapping(&quot;redis&quot;) @Operation(description = &quot;save data to redis&quot;, requestBody = @io.swagger.v3.oas.annotations.parameters.RequestBody()) public Mono&lt;Boolean&gt; postRedisData(@Valid @RequestBody PostRedisRequest redisRequest) { final Mono&lt;Boolean&gt; set = stringRedisTemplate.opsForValue().set(redisRequest.getKey(), redisRequest.getValue()); return set; }} demo my demo https://github.com/ufukhalis/spring-webflux-reactive-redis-example https://github.com/daggerok/reactive-webflux-spring-data-redis 参考文章 https://hantsy.github.io/spring-reactive-sample/data/data-redis.html An Introduction to Spring Data Redis Reactive https://developer.redis.com/develop/java/spring/rate-limiting/fixed-window/reactive/ https://github.com/spring-projects/spring-data-redis/blob/main/src/main/asciidoc/reference/reactive-redis.adoc Reactive API Service — Using Spring Webflux and Reactive Data Redis https://www.vinsguru.com/spring-webflux-redis/","link":"/2022/04/13/spring/spring-data-redis-reactive-lettuce/"},{"title":"将 Spring Boot 应用程序 Docker 化","text":"参考文章 将 Spring Boot 应用程序 Docker 化 在 Docker Compose 中使用 PostgreSQL 运行 Spring Boot springboot 简单优雅的通过docker-compose 构建 Docker-compose setup and Dockerize a Spring Boot Microservice using docker-compose in Linux Mint 使用 Docker 的 Spring Boot","link":"/2021/12/28/spring/spring-dockerize/"},{"title":"BeanFactory和ApplicationContext的区别","text":"接口 BeanFactory 和 ApplicationContext 都是用来从容器中获取 Spring beans 的，但是，他们二者有很大不同 什么是 Spring BeanSpring beans 就是被 Spring 容器所管理的 Java 对象，来看一个简单的例子 12345678910package com.zoltanraffai; public class HelloWorld { private String message; public void setMessage(String message){ this.message = message; } public void getMessage(){ System.out.println(&quot;My Message : &quot; + message); } } 什么是 Spring 容器Spring 容器负责实例化，配置和装配 Spring beans，下面来看如何为 IoC 容器配置我们的 HelloWorld POJO 123456789&lt;?xml version = &quot;1.0&quot; encoding = &quot;UTF-8&quot;?&gt;&lt;beans xmlns = &quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi = &quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation = &quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd&quot;&gt; &lt;bean id = &quot;helloWorld&quot; class = &quot;com.zoltanraffai.HelloWorld&quot;&gt; &lt;property name = &quot;message&quot; value = &quot;Hello World!&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 现在，它已经被 Spring 容器管理了，接下来的问题是：我们怎样获取它？ BeanFactory 和 ApplicationContext 的不同点BeanFactory 接口这是一个用来访问 Spring 容器的 root 接口，要访问 Spring 容器，我们将使用 Spring 依赖注入功能，使用 BeanFactory 接口和它的子接口特性： Bean 的实例化/串联 通常情况，BeanFactory 的实现是使用懒加载的方式，这意味着 beans 只有在我们通过 getBean() 方法直接调用它们时才进行实例化实现 BeanFactory 最常用的 API 是 XMLBeanFactory这里是如何通过 BeanFactory 获取一个 bean 的例子： 1234567891011package com.zoltanraffai; import org.springframework.core.io.ClassPathResource; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.xml.XmlBeanFactory; public class HelloWorldApp{ public static void main(String[] args) { XmlBeanFactory factory = new XmlBeanFactory (new ClassPathResource(&quot;beans.xml&quot;)); HelloWorld obj = (HelloWorld) factory.getBean(&quot;helloWorld&quot;); obj.getMessage(); }} ApplicationContext 接口ApplicationContext 是 Spring 应用程序中的中央接口，用于向应用程序提供配置信息它继承了 BeanFactory 接口，所以 ApplicationContext 包含 BeanFactory 的所有功能以及更多功能！它的主要功能是支持大型的业务应用的创建特性： Bean instantiation/wiring Bean 的实例化/串联 自动的 BeanPostProcessor 注册 自动的 BeanFactoryPostProcessor 注册 方便的 MessageSource 访问（i18n） ApplicationEvent 的发布 与 BeanFactory 懒加载的方式不同，它是预加载，所以，每一个 bean 都在 ApplicationContext 启动之后实例化这里是 ApplicationContext 的使用例子： 1234567891011package com.zoltanraffai; import org.springframework.core.io.ClassPathResource; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.xml.XmlBeanFactory; public class HelloWorldApp{ public static void main(String[] args) { ApplicationContext context=new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); HelloWorld obj = (HelloWorld) context.getBean(&quot;helloWorld&quot;); obj.getMessage(); }} 总结ApplicationContext 包含 BeanFactory 的所有特性，通常推荐使用前者。但是也有一些限制情形，比如移动应用内存消耗比较严苛，在那些情景中，使用更轻量级的 BeanFactory 是更合理的。然而，在大多数企业级的应用中，ApplicationContext 是你的首选。 参考文章 面试还不知道BeanFactory和ApplicationContext的区别？","link":"/2021/11/03/spring/spring-diff-of-BeanFactory-and-ApplicationContext/"},{"title":"Spring Boot Embedded Tomcat Configuration","text":"12345678# HTTP Access Loggingapplication.propertiesserver.tomcat.accesslog.enabled=trueserver.tomcat.accesslog.directory=logsserver.tomcat.accesslog.file-date-format=yyyy-MM-ddserver.tomcat.accesslog.prefix=access_logserver.tomcat.accesslog.suffix=.logserver.tomcat.accesslog.rotate=true Remote Connection Properties12345678910application.propertiesserver.connection-timeout=10sserver.max-http-header-size=8KBserver.tomcat.accept-count=100server.tomcat.max-connections=10000server.tomcat.max-threads=200server.tomcat.min-spare-threads=10server.tomcat.max-swallow-size=2MBserver.tomcat.max-http-post-size=2MB server.connection-timeout Time that connectors wait for another HTTP request before closing the connection. When not set, the connector’s container-specific default is used. Use a value of -1 to indicate infinite timeout. server.max-http-header-size Maximum size of the HTTP message header. server.tomcat.accept-count Maximum queue length for incoming connection requests when all possible request processing threads are in use. server.tomcat.max-connections Maximum number of connections that the server accepts and processes at any given time. server.tomcat.max-threads Maximum amount of worker threads in server under top load. In other words, maximum number of simultaneous requests that can be handled. server.tomcat.min-spare-threads The minimum number of threads always kept running. This includes both active and idle threads. server.tomcat.max-swallow-size The maximum number of request body bytes (excluding transfer encoding overhead) that will be swallowed by Tomcat for an aborted upload. An aborted upload is when Tomcat knows that the request body is going to be ignored but the client still sends it.If Tomcat does not swallow the body the client is unlikely to see the response. If not specified the default of 2097152 (2 megabytes) will be used. A value of less than zero indicates that no limit should be enforced. server.tomcat.max-http-post-size Maximum size of the HTTP post content. HTTP Access Logging1234567application.propertiesserver.tomcat.accesslog.enabled=trueserver.tomcat.accesslog.directory=logsserver.tomcat.accesslog.file-date-format=yyyy-MM-ddserver.tomcat.accesslog.prefix=access_logserver.tomcat.accesslog.suffix=.logserver.tomcat.accesslog.rotate=true server.tomcat.accesslog.enabled – Enable access logging or not. server.tomcat.accesslog.directory – Directory in which log files are created. Can be absolute or relative to the Tomcat base dir. server.tomcat.accesslog.file-date-format – Date format to place in the log file name. server.tomcat.accesslog.prefix – Log file name prefix. server.tomcat.accesslog.suffix – Log file name suffix. server.tomcat.accesslog.rotate – Whether to enable access log rotation. 参考文章 Spring Boot Embedded Tomcat Configuration Tomcat Access Log配置","link":"/2021/12/27/spring/spring-embeded-tomcat-configruation/"},{"title":"Grafana","text":"使用Docker下载和运行Grafana###下载Grafana 1docker run -d --name=grafana -p 3000:3000 grafana/grafana 可以访问http://192.168.50.28:3000，并且使用默认的账户名(admin)密码(admin)来登录Grafana import dashboard spring boot template: 10280 jvm template: 4701 参考文章 Spring Boot Metrics监控之Prometheus&amp;Grafana 实战搭建Prometheus监控系统 Grafana入门使用 Grafana 介绍和使用","link":"/2022/04/13/spring/spring-grafana/"},{"title":"Spring Boot Customize Whitelabel Error Page","text":"123456789@Controllerpublic class MyErrorController implements ErrorController { @RequestMapping(&quot;/error&quot;) public String handleError() { //do something like logging return &quot;error&quot;; }} ref: https://www.baeldung.com/spring-boot-custom-error-page How to use Thymeleaf with Spring Boot 参考文章 Spring Boot: Customize Whitelabel Error Page","link":"/2021/12/21/spring/spring-embeded-tomcat-custom-error-page/"},{"title":"spring log4j jdbc","text":"jdbc.sqlonly : 仅记录 SQL jdbc.sqltiming ：记录 SQL 以及耗时信息 jdbc.audit ：记录除了 ResultSet 之外的所有 JDBC 调用信息，会产生大量的记录，有利于调试跟踪具体的 JDBC 问题 jdbc.resultset ：会产生更多的记录信息，因为记录了 ResultSet 的信息 jdbc.connection ：记录连接打开、关闭等信息，有利于调试数据库连接相关问题 jdbc.sqlonlyLogs only SQL. SQL executed within a prepared statement is automaticallyshown with it’s bind arguments replaced with the data bound at that position, for greatlyincreased readability. jdbc.sqltimingLogs the SQL, post-execution, including timing statistics on how long the SQLtook to execute. jdbc.auditLogs ALL JDBC calls except for ResultSets. This is a very voluminous output, andis not normally needed unless tracking down a specific JDBC problem. jdbc.resultsetEven more voluminous, because all calls to ResultSet objects are logged. jdbc.connectionLogs connection open and close events as well as dumping all open connectionnumbers. This is very useful for hunting down connection leak problems. 参考文章 Logging with log4jdbc 如何有效地记录 Java SQL 日志？ sqlonly,sqltiming,audit,resultset,connection Spring Boot 入门之整合 log4jdbc 篇（六）","link":"/2021/12/28/spring/spring-log4j-jdbc/"},{"title":"java&#x2F;spring 内存数据库","text":"H2数据库H2是一个由java实现的开源内存数据库，它可以支持内存模式和独立模式。 如果要使用H2数据库，需要添加如下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;1.4.194&lt;/version&gt;&lt;/dependency&gt; 我们可以在配置文件中设置更多的H2数据库的连接信息： 1234driverClassName=org.h2.Driverurl=jdbc:h2:mem:myDb;DB_CLOSE_DELAY=-1username=sapassword=sa 默认情况下H2数据库当没有连接的时候会自动关闭，我们可以通过添加DB_CLOSE_DELAY=-1来禁止掉这个功能。 如果我们需要使用Hibernate， 我们需要设置如下内容: hibernate.dialect=org.hibernate.dialect.H2Dialect HSQLDBHSQLDB是一个开源项目，java写的关系型数据库。它可以支持基本的SQL操作，存储过程和触发器。同样嵌入式或者单独使用。 12345&lt;dependency&gt; &lt;groupId&gt;org.hsqldb&lt;/groupId&gt; &lt;artifactId&gt;hsqldb&lt;/artifactId&gt; &lt;version&gt;2.3.4&lt;/version&gt;&lt;/dependency&gt; 下面是HSQLDB的配置文件： 1234driverClassName=org.hsqldb.jdbc.JDBCDriverurl=jdbc:hsqldb:mem:myDbusername=sapassword=sa 同样的如果使用hibernate需要配置如下属性： hibernate.dialect=org.hibernate.dialect.HSQLDialect Apache DerbyApache Derby 是由Apache基金会维护的开源项目。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.derby&lt;/groupId&gt; &lt;artifactId&gt;derby&lt;/artifactId&gt; &lt;version&gt;10.13.1.1&lt;/version&gt;&lt;/dependency&gt; 1234driverClassName=org.apache.derby.jdbc.EmbeddedDriverurl=jdbc:derby:memory:myDb;create=trueusername=sapassword=sa 对应的hibernate配置： hibernate.dialect=org.hibernate.dialect.DerbyDialect SQLiteSQLite也是一种内存数据库，我们这样添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.xerial&lt;/groupId&gt; &lt;artifactId&gt;sqlite-jdbc&lt;/artifactId&gt; &lt;version&gt;3.16.1&lt;/version&gt;&lt;/dependency&gt; 配置文件如下： 1234driverClassName=org.sqlite.JDBCurl=jdbc:sqlite:memory:myDbusername=sapassword=sa 使用Spring Boot可以很方便的使用上面提到的内存数据库 postgreSQL参考文章 在Spring Boot中使用内存数据库 Java内存数据库-H2介绍及实例（SpringBoot）","link":"/2022/04/13/spring/spring-memory-db/"},{"title":"spring mybatis-plus","text":"pom.xml12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;/dependency&gt; properties123456# DataSource ConfigMYSQL_HOST=192.168.50.28spring.datasource.url=jdbc:mysql://${MYSQL_HOST:localhost}:13306/summer?allowPublicKeyRetrieval=true&amp;useSSL=falsespring.datasource.username=rootspring.datasource.password=summerspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver Application add @MapperScan({&quot;com.example.summermetrics.mapper&quot;}) User.java12345678@Datapublic class User { private Long id; private String name; private Integer age; private String email;} UerMapper.java12345678@Datapublic class User { private Long id; private String name; private Integer age; private String email;} unit test123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 目录结构 123456789101112131415.├── java│ └── com│ └── example│ └── summermetrics│ ├── SummerMetricsApplicationTests.java│ └── mapper│ └── MybatisPlusSampleTest.java└── resources ├── application-test.properties ├── db │ ├── data-h2.sql │ └── schema-h2.sql └── log4j2-test.xml application-test.properties 123456789logging.config=classpath:log4j2-test.xml# DataSource Configspring.datasource.url=jdbc:h2:mem:testspring.datasource.username=rootspring.datasource.password=testspring.sql.init.schema-locations=classpath:db/schema-h2.sqlspring.sql.init.data-locations=classpath:db/data-h2.sqlspring.datasource.driver-class-name=org.h2.Driver MybatisPlusSampleTest 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.example.summermetrics.mapper;import java.util.List;import org.junit.FixMethodOrder;import org.junit.internal.MethodSorter;import org.junit.jupiter.api.MethodOrderer;import org.junit.jupiter.api.Order;import org.junit.jupiter.api.Test;import org.junit.jupiter.api.TestMethodOrder;import org.junit.runner.OrderWith;import org.junit.runner.RunWith;import org.junit.runners.MethodSorters;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.autoconfigure.jdbc.AutoConfigureTestDatabase;import org.springframework.test.annotation.Rollback;import org.springframework.test.context.junit4.SpringRunner;import com.baomidou.mybatisplus.test.autoconfigure.MybatisPlusTest;import com.example.summermetrics.domain.User;@RunWith(SpringRunner.class)@MybatisPlusTest@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)@TestMethodOrder(MethodOrderer.OrderAnnotation.class)class MybatisPlusSampleTest { @Autowired private UserMapper userMapper; @Test @Rollback @Order(0) void testInsert() { User user = User.builder().id(1111L).name(&quot;test&quot;).age(3).email(&quot;email&quot;).build(); userMapper.insert(user); User user1 = userMapper.selectById(1111L); assert user1.getName().equals(&quot;test&quot;); } @Test @Order(1) void testGetUser() { List&lt;User&gt; users = userMapper.selectList(null); assert users.size() == 5; }} 参考文章 官方文档 Spring boot Mybatis-Plus数据库单测实战（三种方式） my demo","link":"/2022/04/13/spring/spring-mybatis-plus/"},{"title":"springboot metrics config","text":"SpringBoot配置Actuator metrics的监控 Actuator 是 Spring Boot 提供的对应用系统的自省和监控功能。通过 Actuator，可以使用数据化的指标去度量应用的运行情况，比如查看服务器的磁盘、内存、CPU等信息，系统的线程、gc、运行状态等等。Prometheus指标只是其中之一，也是本次流量监控用到的主体。Actuator 通常通过使用 HTTP 和 JMX 来管理和监控应用，大多数情况使用 HTTP 的方式。 Maven引入Actuator和Prometheus12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; yml上配置信息123456management: endpoints: web: exposure: # 开启所有端点 include: '*' 123456spring.application.name=springboot2demo# 打开所有 Actuator 服务management.endpoints.web.exposure.include=*# 将应用名称添加到计量器的 tag 中去# 以便 Prometheus 根据应用名区分不同服务management.metrics.tags.application=${spring.application.name} 在启动类中添加Bean，用于监控JVM性能指标：1234567891011121314151617181920import io.micrometer.core.instrument.MeterRegistry;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.SpringApplication;import org.springframework.boot.actuate.autoconfigure.metrics.MeterRegistryCustomizer;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;@SpringBootApplicationpublic class Springboot2demoApplication { public static void main(String[] args) { SpringApplication.run(Springboot2demoApplication.class, args); } @Bean MeterRegistryCustomizer&lt;MeterRegistry&gt; configurer( @Value(&quot;${spring.application.name}&quot;) String applicationName) { return (registry) -&gt; registry.config().commonTags(&quot;application&quot;, applicationName); }} 然后就可以在项目中查看运行的指标了。Actuator指标：localhost:8080/actuator/metricsPrometheus指标：localhost:8080/actuator/prometheus Actuator对应Prometheus的监控指标 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205# HELP tomcat_sessions_rejected_sessions_total # TYPE tomcat_sessions_rejected_sessions_total countertomcat_sessions_rejected_sessions_total 0.0# HELP tomcat_sessions_alive_max_seconds # TYPE tomcat_sessions_alive_max_seconds gaugetomcat_sessions_alive_max_seconds 0.0# HELP jvm_buffer_count_buffers An estimate of the number of buffers in the pool# TYPE jvm_buffer_count_buffers gaugejvm_buffer_count_buffers{id=&quot;direct&quot;,} 97.0jvm_buffer_count_buffers{id=&quot;mapped&quot;,} 0.0# HELP process_cpu_usage The &quot;recent cpu usage&quot; for the Java Virtual Machine process# TYPE process_cpu_usage gaugeprocess_cpu_usage 0.0# HELP tomcat_servlet_error_total # TYPE tomcat_servlet_error_total countertomcat_servlet_error_total{name=&quot;default&quot;,} 0.0tomcat_servlet_error_total{name=&quot;jsp&quot;,} 0.0tomcat_servlet_error_total{name=&quot;dispatcherServlet&quot;,} 0.0tomcat_servlet_error_total{name=&quot;cn.taqu.core.web.filter.ApiDispatcherServlet&quot;,} 0.0# HELP tomcat_global_request_seconds # TYPE tomcat_global_request_seconds summarytomcat_global_request_seconds_count{name=&quot;http-nio-8906&quot;,} 82.0tomcat_global_request_seconds_sum{name=&quot;http-nio-8906&quot;,} 3.117# HELP tomcat_cache_access_total # TYPE tomcat_cache_access_total countertomcat_cache_access_total 0.0# HELP process_uptime_seconds The uptime of the Java virtual machine# TYPE process_uptime_seconds gaugeprocess_uptime_seconds 88.809# HELP tomcat_global_request_max_seconds # TYPE tomcat_global_request_max_seconds gaugetomcat_global_request_max_seconds{name=&quot;http-nio-8906&quot;,} 1.246# HELP tomcat_sessions_active_max_sessions # TYPE tomcat_sessions_active_max_sessions gaugetomcat_sessions_active_max_sessions 0.0# HELP tomcat_sessions_created_sessions_total # TYPE tomcat_sessions_created_sessions_total countertomcat_sessions_created_sessions_total 0.0# HELP process_start_time_seconds Start time of the process since unix epoch.# TYPE process_start_time_seconds gaugeprocess_start_time_seconds 1.610695930801E9# HELP jvm_threads_live_threads The current number of live threads including both daemon and non-daemon threads# TYPE jvm_threads_live_threads gaugejvm_threads_live_threads 343.0# HELP logback_events_total Number of error level events that made it to the logs# TYPE logback_events_total counterlogback_events_total{level=&quot;warn&quot;,} 0.0logback_events_total{level=&quot;debug&quot;,} 0.0logback_events_total{level=&quot;error&quot;,} 0.0logback_events_total{level=&quot;trace&quot;,} 0.0logback_events_total{level=&quot;info&quot;,} 19.0# HELP tomcat_threads_config_max_threads # TYPE tomcat_threads_config_max_threads gaugetomcat_threads_config_max_threads{name=&quot;http-nio-8906&quot;,} NaN# HELP jvm_threads_states_threads The current number of threads having NEW state# TYPE jvm_threads_states_threads gaugejvm_threads_states_threads{state=&quot;runnable&quot;,} 117.0jvm_threads_states_threads{state=&quot;blocked&quot;,} 0.0jvm_threads_states_threads{state=&quot;waiting&quot;,} 209.0jvm_threads_states_threads{state=&quot;timed-waiting&quot;,} 17.0jvm_threads_states_threads{state=&quot;new&quot;,} 0.0jvm_threads_states_threads{state=&quot;terminated&quot;,} 0.0# HELP system_cpu_count The number of processors available to the Java virtual machine# TYPE system_cpu_count gaugesystem_cpu_count 12.0# HELP http_server_requests_seconds # TYPE http_server_requests_seconds summaryhttp_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/index&quot;,} 2.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/index&quot;,} 0.8098944http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;root&quot;,} 1.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;root&quot;,} 0.0271729http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/**&quot;,} 73.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/**&quot;,} 0.4981964http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/common/getLanguageList&quot;,} 2.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/common/getLanguageList&quot;,} 0.0204194http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/dataGrid&quot;,} 1.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/dataGrid&quot;,} 1.2461368http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;REDIRECTION&quot;,status=&quot;302&quot;,uri=&quot;REDIRECTION&quot;,} 1.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;REDIRECTION&quot;,status=&quot;302&quot;,uri=&quot;REDIRECTION&quot;,} 0.1364228http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/manager&quot;,} 1.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/manager&quot;,} 0.1832796http_server_requests_seconds_count{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/user/addServiceSystemLog&quot;,} 1.0http_server_requests_seconds_sum{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/user/addServiceSystemLog&quot;,} 0.0549094# HELP http_server_requests_seconds_max # TYPE http_server_requests_seconds_max gaugehttp_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/index&quot;,} 0.6628419http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;root&quot;,} 0.0271729http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/**&quot;,} 0.0253742http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/common/getLanguageList&quot;,} 0.0133106http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/dataGrid&quot;,} 1.2461368http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;REDIRECTION&quot;,status=&quot;302&quot;,uri=&quot;REDIRECTION&quot;,} 0.1364228http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;GET&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/inspectRule/manager&quot;,} 0.1832796http_server_requests_seconds_max{exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/user/addServiceSystemLog&quot;,} 0.0549094# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next# TYPE jvm_gc_memory_allocated_bytes_total counterjvm_gc_memory_allocated_bytes_total 2.345259752E9# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool# TYPE jvm_buffer_total_capacity_bytes gaugejvm_buffer_total_capacity_bytes{id=&quot;direct&quot;,} 712848.0jvm_buffer_total_capacity_bytes{id=&quot;mapped&quot;,} 0.0# HELP jvm_gc_memory_promoted_bytes_total Count of positive increases in the size of the old generation memory pool before GC to after GC# TYPE jvm_gc_memory_promoted_bytes_total counterjvm_gc_memory_promoted_bytes_total 4.7747424E7# HELP jvm_buffer_memory_used_bytes An estimate of the memory that the Java virtual machine is using for this buffer pool# TYPE jvm_buffer_memory_used_bytes gaugejvm_buffer_memory_used_bytes{id=&quot;direct&quot;,} 712849.0jvm_buffer_memory_used_bytes{id=&quot;mapped&quot;,} 0.0# HELP jvm_gc_pause_seconds Time spent in GC pause# TYPE jvm_gc_pause_seconds summaryjvm_gc_pause_seconds_count{action=&quot;end of major GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 1.0jvm_gc_pause_seconds_sum{action=&quot;end of major GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 0.136jvm_gc_pause_seconds_count{action=&quot;end of minor GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 1.0jvm_gc_pause_seconds_sum{action=&quot;end of minor GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 0.013jvm_gc_pause_seconds_count{action=&quot;end of minor GC&quot;,cause=&quot;Allocation Failure&quot;,} 6.0jvm_gc_pause_seconds_sum{action=&quot;end of minor GC&quot;,cause=&quot;Allocation Failure&quot;,} 0.069# HELP jvm_gc_pause_seconds_max Time spent in GC pause# TYPE jvm_gc_pause_seconds_max gaugejvm_gc_pause_seconds_max{action=&quot;end of major GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 0.136jvm_gc_pause_seconds_max{action=&quot;end of minor GC&quot;,cause=&quot;Metadata GC Threshold&quot;,} 0.013jvm_gc_pause_seconds_max{action=&quot;end of minor GC&quot;,cause=&quot;Allocation Failure&quot;,} 0.023# HELP tomcat_threads_current_threads # TYPE tomcat_threads_current_threads gaugetomcat_threads_current_threads{name=&quot;http-nio-8906&quot;,} NaN# HELP tomcat_global_error_total # TYPE tomcat_global_error_total countertomcat_global_error_total{name=&quot;http-nio-8906&quot;,} 0.0# HELP jvm_threads_daemon_threads The current number of live daemon threads# TYPE jvm_threads_daemon_threads gaugejvm_threads_daemon_threads 237.0# HELP tomcat_cache_hit_total # TYPE tomcat_cache_hit_total countertomcat_cache_hit_total 0.0# HELP tomcat_threads_busy_threads # TYPE tomcat_threads_busy_threads gaugetomcat_threads_busy_threads{name=&quot;http-nio-8906&quot;,} NaN# HELP tomcat_servlet_request_max_seconds # TYPE tomcat_servlet_request_max_seconds gaugetomcat_servlet_request_max_seconds{name=&quot;default&quot;,} 0.0tomcat_servlet_request_max_seconds{name=&quot;jsp&quot;,} 0.0tomcat_servlet_request_max_seconds{name=&quot;dispatcherServlet&quot;,} 1.246tomcat_servlet_request_max_seconds{name=&quot;cn.taqu.core.web.filter.ApiDispatcherServlet&quot;,} 0.0# HELP jvm_threads_peak_threads The peak live thread count since the Java virtual machine started or peak was reset# TYPE jvm_threads_peak_threads gaugejvm_threads_peak_threads 345.0# HELP jvm_classes_unloaded_classes_total The total number of classes unloaded since the Java virtual machine has started execution# TYPE jvm_classes_unloaded_classes_total counterjvm_classes_unloaded_classes_total 3.0# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use# TYPE jvm_memory_committed_bytes gaugejvm_memory_committed_bytes{area=&quot;heap&quot;,id=&quot;PS Survivor Space&quot;,} 3.2505856E7jvm_memory_committed_bytes{area=&quot;heap&quot;,id=&quot;PS Old Gen&quot;,} 2.36453888E8jvm_memory_committed_bytes{area=&quot;heap&quot;,id=&quot;PS Eden Space&quot;,} 4.97549312E8jvm_memory_committed_bytes{area=&quot;nonheap&quot;,id=&quot;Metaspace&quot;,} 9.76896E7jvm_memory_committed_bytes{area=&quot;nonheap&quot;,id=&quot;Code Cache&quot;,} 2.0709376E7jvm_memory_committed_bytes{area=&quot;nonheap&quot;,id=&quot;Compressed Class Space&quot;,} 1.1976704E7# HELP tomcat_sessions_active_current_sessions # TYPE tomcat_sessions_active_current_sessions gaugetomcat_sessions_active_current_sessions 0.0# HELP tomcat_sessions_expired_sessions_total # TYPE tomcat_sessions_expired_sessions_total countertomcat_sessions_expired_sessions_total 0.0# HELP tomcat_global_sent_bytes_total # TYPE tomcat_global_sent_bytes_total countertomcat_global_sent_bytes_total{name=&quot;http-nio-8906&quot;,} 2920966.0# HELP jvm_gc_live_data_size_bytes Size of old generation memory pool after a full GC# TYPE jvm_gc_live_data_size_bytes gaugejvm_gc_live_data_size_bytes 4.3797632E7# HELP jvm_memory_max_bytes The maximum amount of memory in bytes that can be used for memory management# TYPE jvm_memory_max_bytes gaugejvm_memory_max_bytes{area=&quot;heap&quot;,id=&quot;PS Survivor Space&quot;,} 3.2505856E7jvm_memory_max_bytes{area=&quot;heap&quot;,id=&quot;PS Old Gen&quot;,} 2.841116672E9jvm_memory_max_bytes{area=&quot;heap&quot;,id=&quot;PS Eden Space&quot;,} 1.344274432E9jvm_memory_max_bytes{area=&quot;nonheap&quot;,id=&quot;Metaspace&quot;,} -1.0jvm_memory_max_bytes{area=&quot;nonheap&quot;,id=&quot;Code Cache&quot;,} 2.5165824E8jvm_memory_max_bytes{area=&quot;nonheap&quot;,id=&quot;Compressed Class Space&quot;,} 1.073741824E9# HELP tomcat_global_received_bytes_total # TYPE tomcat_global_received_bytes_total countertomcat_global_received_bytes_total{name=&quot;http-nio-8906&quot;,} 118.0# HELP jvm_gc_max_data_size_bytes Max size of old generation memory pool# TYPE jvm_gc_max_data_size_bytes gaugejvm_gc_max_data_size_bytes 2.841116672E9# HELP jvm_memory_used_bytes The amount of used memory# TYPE jvm_memory_used_bytes gaugejvm_memory_used_bytes{area=&quot;heap&quot;,id=&quot;PS Survivor Space&quot;,} 3.2479312E7jvm_memory_used_bytes{area=&quot;heap&quot;,id=&quot;PS Old Gen&quot;,} 6.7252472E7jvm_memory_used_bytes{area=&quot;heap&quot;,id=&quot;PS Eden Space&quot;,} 4.5849296E7jvm_memory_used_bytes{area=&quot;nonheap&quot;,id=&quot;Metaspace&quot;,} 9.2626808E7jvm_memory_used_bytes{area=&quot;nonheap&quot;,id=&quot;Code Cache&quot;,} 2.063232E7jvm_memory_used_bytes{area=&quot;nonheap&quot;,id=&quot;Compressed Class Space&quot;,} 1.1170784E7# HELP system_cpu_usage The &quot;recent cpu usage&quot; for the whole system# TYPE system_cpu_usage gaugesystem_cpu_usage 0.3472113977877134# HELP tomcat_servlet_request_seconds # TYPE tomcat_servlet_request_seconds summarytomcat_servlet_request_seconds_count{name=&quot;default&quot;,} 0.0tomcat_servlet_request_seconds_sum{name=&quot;default&quot;,} 0.0tomcat_servlet_request_seconds_count{name=&quot;jsp&quot;,} 0.0tomcat_servlet_request_seconds_sum{name=&quot;jsp&quot;,} 0.0tomcat_servlet_request_seconds_count{name=&quot;dispatcherServlet&quot;,} 83.0tomcat_servlet_request_seconds_sum{name=&quot;dispatcherServlet&quot;,} 3.0tomcat_servlet_request_seconds_count{name=&quot;cn.taqu.core.web.filter.ApiDispatcherServlet&quot;,} 0.0tomcat_servlet_request_seconds_sum{name=&quot;cn.taqu.core.web.filter.ApiDispatcherServlet&quot;,} 0.0# HELP jvm_classes_loaded_classes The number of classes that are currently loaded in the Java virtual machine# TYPE jvm_classes_loaded_classes gaugejvm_classes_loaded_classes 15999.0 Actuator 端点说明 auditevents：获取当前应用暴露的审计事件信息 beans：获取应用中所有的 Spring Beans 的完整关系列表 caches：获取公开可以用的缓存 conditions：获取自动配置条件信息，记录哪些自动配置条件通过和没通过的原因 configprops：获取所有配置属性，包括默认配置，显示一个所有 @ConfigurationProperties 的整理列版本 env：获取所有环境变量 flyway：获取已应用的所有Flyway数据库迁移信息，需要一个或多个 Flyway Bean liquibase：获取已应用的所有Liquibase数据库迁移。需要一个或多个 Liquibase Bean health：获取应用程序健康指标（运行状况信息） httptrace：获取HTTP跟踪信息（默认情况下，最近100个HTTP请求-响应交换）。需要 HttpTraceRepository Bean info：获取应用程序信息 integrationgraph：显示 Spring Integration 图。需要依赖 spring-integration-core loggers：显示和修改应用程序中日志的配置 logfile：返回日志文件的内容（如果已设置logging.file.name或logging.file.path属性） metrics：获取系统度量指标信息 mappings：显示所有@RequestMapping路径的整理列表 scheduledtasks：显示应用程序中的计划任务 sessions：允许从Spring Session支持的会话存储中检索和删除用户会话。需要使用Spring Session的基于Servlet的Web应用程序 shutdown：关闭应用，要求endpoints.shutdown.enabled设置为true，默认为 false threaddump：获取系统线程转储信息 heapdump：返回hprof堆转储文件 jolokia：通过HTTP公开JMX bean（当Jolokia在类路径上时，不适用于WebFlux）。需要依赖 jolokia-core prometheus：以Prometheus服务器可以抓取的格式公开指标。需要依赖 micrometer-registry-prometheus Prometheus/Metrics 端点说明 序号 参数 参数说明 是否监控 监控手段 重要度 — JVM — 1 jvm.memory.max JVM最大内存 2 jvm.memory.committed JVM可用内存 是 展示并监控堆内存和Metaspace 重要 3 jvm.memory.used JVM已用内存 是 展示并监控堆内存和Metaspace 重要 4 jvm.buffer.memory.used JVM缓冲区已用内存 5 jvm.buffer.count 当前缓冲区数 6 jvm.threads.daemon JVM守护线程数 是 显示在监控页面 7 jvm.threads.live JVM当前活跃线程数 是 显示在监控页面；监控达到阈值时报警 重要 8 jvm.threads.peak JVM峰值线程数 是 显示在监控页面 9 jvm.classes.loaded 加载classes数 10 jvm.classes.unloaded 未加载的classes数 11 jvm.gc.memory.allocated GC时，年轻代分配的内存空间 12 jvm.gc.memory.promoted GC时，老年代分配的内存空间 13 jvm.gc.max.data.size GC时，老年代的最大内存空间 14 jvm.gc.live.data.size FullGC时，老年代的内存空间 15 jvm.gc.pause GC耗时 是 显示在监控页面 — TOMCAT — 16 tomcat.sessions.created tomcat已创建session数 17 tomcat.sessions.expired tomcat已过期session数 18 tomcat.sessions.active.current tomcat活跃session数 19 tomcat.sessions.active.max tomcat最多活跃session数 是 显示在监控页面，超过阈值可报警或者进行动态扩容 重要 20 tomcat.sessions.alive.max.second tomcat最多活跃session数持续时间 21 tomcat.sessions.rejected 超过session最大配置后，拒绝的session个数 是 显示在监控页面，方便分析问题 22 tomcat.global.error 错误总数 是 显示在监控页面，方便分析问题 23 tomcat.global.sent 发送的字节数 24 tomcat.global.request.max request最长时间 25 tomcat.global.request 全局request次数和时间 26 tomcat.global.received 全局received次数和时间 27 tomcat.servlet.request servlet的请求次数和时间 28 tomcat.servlet.error servlet发生错误总数 29 tomcat.servlet.request.max servlet请求最长时间 30 tomcat.threads.busy tomcat繁忙线程 是 显示在监控页面，据此检查是否有线程夯住 31 tomcat.threads.current tomcat当前线程数（包括守护线程） 是 显示在监控页面 重要 32 tomcat.threads.config.max tomcat配置的线程最大数 是 显示在监控页面 重要 33 tomcat.cache.access tomcat读取缓存次数 34 tomcat.cache.hit tomcat缓存命中次数 — CPU… — 35 system.cpu.count CPU数量 36 system.load.average.1m load average 是 超过阈值报警 重要 37 system.cpu.usage 系统CPU使用率 38 process.cpu.usage 当前进程CPU使用率 是 超过阈值报警 39 http.server.requests http请求调用情况 是 显示10个请求量最大，耗时最长的URL；统计非200的请求量 重要 40 process.uptime 应用已运行时间 是 显示在监控页面 41 process.files.max 允许最大句柄数 是 配合当前打开句柄数使用 42 process.start.time 应用启动时间点 是 显示在监控页面 43 process.files.open 当前打开句柄数 是 监控文件句柄使用率，超过阈值后报警 重要 参考文章 Spring Boot Actuator:健康检查、审计、统计和监控 Spring Boot Metrics监控之Prometheus&amp;Grafana [Prometheus]实战：SpringBoot + Actuator metrics + Prometheus 实战搭建Prometheus监控系统，看完不信你还不会","link":"/2022/04/13/spring/spring-metrics/"},{"title":"Object Storage","text":"ibm-cos-sdk-java12345&lt;dependency&gt; &lt;groupId&gt;com.ibm.cos&lt;/groupId&gt; &lt;artifactId&gt;ibm-cos-java-sdk&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt; &lt;/dependency&gt; https://github.com/IBM/ibm-cos-sdk-java 参考文章 Getting started with IBM Cloud Object Storage cloud-object-storage-java","link":"/2022/04/13/spring/spring-object-storage/"},{"title":"Reactive WebSockets with Spring 5","text":"参考文章 Reactive WebSockets with Spring 5","link":"/2022/04/13/spring/spring-reactive-websockets/"},{"title":"spring中的@PostConstruct注解的用法","text":"@PostConstruct是java5的时候引入的注解，指的是在项目启动的时候执行这个方法，也可以理解为在spring容器启动的时候执行，可作为一些数据的常规化加载，比如数据字典之类的。 @PostConstruct注解使用简介简单起见，我们准备一个springboot项目快速启动。项目目录结构如下： 下面我们在cn.lay.postconstruct目录下创建一个类，并添加一个@PostConstruct的方法，如 最后，我们执行PostConstructApplication的main方法，启动项目。在控制台里，我们会看到 到这里，我们可以知道@PostConstruct注解的用途了。当一个class被注解为一个Bean，那么class上被@PostConstruct注解的方法将会在程序启动的时候执行。 知道了如何使用@PostConstruct以后，我们会产生疑问。为什么@PostConstruct注解的方法会在程序启动的时候执行呢？后续的内容将为你解开疑惑。 @PostConstruct原理 ref: https://www.cnblogs.com/lay2017/p/11735802.html 转载自：https://www.cnblogs.com/mark5/p/12767120.html被@PostConstruct修饰的方法会在服务器加载Servle的时候运行，并且只会被服务器执行一次。PostConstruct在构造函数之后执行也就是加载顺序 服务器加载Servlet -&gt; servlet 构造函数的加载 -&gt; postConstruct -&gt;init（init是在service 中的初始化方法. 创建service 时发生的事件.） -&gt;Service-&gt;destory-&gt;predestory-&gt;服务器卸载serlvet 那么问题：spring中Constructor、@Autowired、@PostConstruct的顺序 Constructor &gt;&gt; @Autowired &gt;&gt; @PostConstruct 依赖注入的字面意思就可以知道，要将对象p注入到对象a，那么首先就必须得生成对象p与对象a，才能执行注入。所以，如果一个类A中有个成员变量p被@Autowired注解，那么@Autowired注入是发生在A的构造方法执行完之后的。 @PostConstruct应用场景：如果想在生成对象时候完成某些初始化操作，而偏偏这些初始化操作又依赖于依赖注入，那么就无法在构造函数中实现。为此，可以使用@PostConstruct注解一个方法来完成初始化，@PostConstruct注解的方法将会在依赖注入完成后被自动调用。 参考文章 https://www.cnblogs.com/mark5/p/12767120.html https://www.cnblogs.com/lay2017/p/11735802.html","link":"/2021/11/03/spring/spring-postconstruct/"},{"title":"jedis&#x2F;lettuce timeout","text":"LettuceWhen we use Lettuce, we don’t need to configure the RedisConnectionFactory. Spring Boot does it for us. All we have left, then, is to specify a few properties in our application.properties file: 123456spring.redis.database=0spring.redis.host=localhostspring.redis.port=16379spring.redis.password=mypass# timeout establishes the connection timeoutspring.redis.timeout=60000 jedis JedisConnectionFactory.setTimeoutref: https://www.tabnine.com/code/java/methods/org.springframework.data.redis.connection.jedis.JedisConnectionFactory/setTimeout12345678910111213141516@Beanpublic RedisConnectionFactory factory() { JedisConnectionFactory factory = new JedisConnectionFactory(); factory.setDatabase(dateBase); factory.setHostName(host); factory.setPort(port); factory.setPassword(password); JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxIdle(maxIdle); poolConfig.setMinIdle(minIdle); poolConfig.setMaxWaitMillis(maxWait); poolConfig.setMaxTotal(maxTotal); factory.setPoolConfig(poolConfig); factory.setTimeout(timeout); return factory;} JedisPool 优化 JedisPool 优化 Parameter Description Default value Recommended settings maxTotal The maximum number of connections that are supported by the pool. 8 For more information, see Recommended settings. maxIdle The maximum number of idle connections in the pool. 8 For more information, see Recommended settings. minIdle The minimum number of idle connections in the pool. 0 For more information, see Recommended settings. blockWhenExhausted Specifies whether the client must wait when the resource pool is exhausted. Only when this parameter is set to true, the maxWaitMillis parameter takes effect. true We recommend that you use the default value. maxWaitMillis The maximum number of milliseconds that the client must wait when no connection is available. A value of -1 specifies that the connection never times out. We recommend that you do not use the default value. testOnBorrow Specifies whether to validate connections by using the PING command before the connections are borrowed from the pool. Invalid connections are removed from the pool. false testOnReturn Specifies whether to validate connections by using the PING command before the connections are returned to the pool. Invalid connections are removed from the pool. false jmxEnabled Specifies whether to enable Java Management Extensions (JMX) monitoring. true We recommend that you enable JMX monitoring. Take note that you must also enable the feature for your application. 参考文章 Spring Data Redis’s Property-Based Configuration JedisPool 优化 开发中常见的redis异常总结","link":"/2022/04/13/spring/spring-redis-read-timeout/"},{"title":"Prometheus &amp; Grafana","text":"preparespringboot metrics config 使用Docker下载和运行Prometheus 下载Prometheus1docker pull prom/prometheus Prometheus配置（prometheus.yml）1234567891011121314151617181920212223242526# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['127.0.0.1:9090'] - job_name: 'spring-actuator' metrics_path: '/actuator/prometheus' scrape_interval: 5s static_configs: - targets: ['192.168.50.93:9093'] 上面中比较重要的配置项是spring-actuator job中的scrape_configs选项。 metrics_path是Actuator中prometheus endpoint中的路径。targes包含了Spring Boot应用的HOST和PORT。 请确保替换HOST_IP为你Spring Boot应用运行的电脑的IP地址。值得注意的是，localhost将不起作用，因为我们将从docker container中连接HOST机器。你必须设置网络IP地址。 使用Docker运行Prometheus1234docker run -d --name=prometheus -p 9090:9090 -v /root/apps/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml# docker stop prometheus# docker rm prometheus 在Prometheus仪表盘中可视化Spring Boot Metrics1http://192.168.50.28:9090 使用Docker下载和运行Grafana###下载Grafana 1docker run -d --name=grafana -p 3000:3000 grafana/grafana 可以访问http://192.168.50.28:3000，并且使用默认的账户名(admin)密码(admin)来登录Grafana 参考文章&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Prometheus + Grafana 监控 SpringBoot Spring Boot+Prometheus+Grafana实现应用监控和报警 441437f02726b1601719b05c01afe7c337e92018 Spring Boot Actuator:健康检查、审计、统计和监控 Spring Boot Metrics监控之Prometheus&amp;Grafana Spring Boot Metrics监控之Prometheus&amp;Grafana SpringBoot - Actuator应用监控使用详解3 [Prometheus]实战：SpringBoot + Actuator metrics + Prometheus 实战搭建Prometheus监控系统，看完不信你还不会 Prometheus 快速入门教程（一）：Prometheus 快速入门 SpringBoot初始教程之SpringBoot-Metrics监控(十)","link":"/2022/04/13/spring/spring-prometheus/"},{"title":"Spring — Dynamically register beans in 4 ways At Run-Time","text":"使用 GenericBeanDefinition 进行动态 Bean 注册GenericBeanDefinition 是用于标准 bean 定义目的的一站式商店。像任何 bean 定义一样，它允许指定一个类以及可选的构造函数参数值和属性值。此外，可以通过“ parentName ”属性灵活地配置从父 bean 定义派生。通常，使用这个GenericBeanDefinition类来注册用户可见的 bean 定义（后处理器可能会对其进行操作，甚至可能重新配置父名称）。使用RootBeanDefinition / ChildBeanDefinition，其中父/子关系恰好是预先确定的。 123456789public class MyBean { private Date date; public void doSomething () { System.out.println(&quot;from my bean, date: &quot; + date); } public void setDate (Date date) { this.date = date; }} 注册上面的，使用GenericBeanDefinition动态创建的 bean 。 12345678910111213141516public class GenericBeanDefinitionExample { public static void main (String[] args) { DefaultListableBeanFactory context = new DefaultListableBeanFactory(); GenericBeanDefinition gbd = new GenericBeanDefinition(); gbd.setBeanClass(MyBean.class); MutablePropertyValues mpv = new MutablePropertyValues(); mpv.add(&quot;date&quot;, new Date()); //alternatively we can use: // gbd.getPropertyValues().addPropertyValue(&quot;date&quot;, new Date()); gbd.setPropertyValues(mpv); context.registerBeanDefinition(&quot;myBeanName&quot;, gbd); MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 1from my bean, date: Wed Jult 23 12:20:58 EDT 2019 使用 BeanDefinitionBuilder 动态注册 Bean使用构建器模式构建BeanDefinitions 的编程方法。主要用于在实现 Spring 2.0 NamespaceHandlers 时使用。这里唯一的区别是， BeanDefinitionBuilder 使用Builder Pattern。 创建另一个 bean 类。 123456789public class MyBean { private String str; public void setStr (String str) { this.str = str; } public void doSomething () { System.out.println(&quot;from MyBean &quot; + str); }} 使用BeanDefinitionBuilder动态注册 bean 的示例。 123456789101112public class BeanDefinitionBuilderExample { public static void main (String[] args) { DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); BeanDefinitionBuilder b = BeanDefinitionBuilder.rootBeanDefinition(MyBean.class) .addPropertyValue(&quot;str&quot;, &quot;myStringValue&quot;); beanFactory.registerBeanDefinition(&quot;myBean&quot;, b.getBeanDefinition()); MyBean bean = beanFactory.getBean(MyBean.class); bean.doSomething(); }} Output: 12from MyBean myStringValue 使用 BeanDefinitionBuilder 注入其他 bean 引用Creating Bean 1 123456789public class Bean1 { private Bean2 otherBean; public void setOtherBean (Bean2 otherBean) { this.otherBean = otherBean; } public void doSomething () { otherBean.doSomething(); }} Creating Bean 2 12345public class Bean2 { public void doSomething () { System.out.println(&quot;from other bean &quot;); }} Setting the Bean2 in Bean1 1234567891011121314151617181920public class InjectingOtherBeans { public static void main (String[] args) { DefaultListableBeanFactory context = new DefaultListableBeanFactory(); //define and register MyOtherBean GenericBeanDefinition beanOtherDef = new GenericBeanDefinition(); beanOtherDef.setBeanClass(Bean2.class); context.registerBeanDefinition(&quot;other&quot;, beanOtherDef); //definine and register myBean GenericBeanDefinition beanDef = new GenericBeanDefinition(); beanDef.setBeanClass(Bean1.class); MutablePropertyValues mpv = new MutablePropertyValues(); mpv.addPropertyValue(&quot;otherBean&quot;, context.getBean(&quot;other&quot;)); beanDef.setPropertyValues(mpv); context.registerBeanDefinition(&quot;myBean&quot;, beanDef); //using MyBean instance MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 1from other bean Dynamic Bean Registration With BeanFactoryPostProcessor一个BeanFactoryPostProcessor的可交互和修改bean定义，但从来没有bean实例。允许自定义修改应用程序上下文的 bean 定义，调整上下文底层 bean 工厂的 bean 属性值。应用程序上下文可以在它们的 bean 定义中自动检测BeanFactoryPostProcessor bean，并在创建任何其他 bean 之前应用它们。 创建配置1234567@Configuration public class MyConfig { @Bean MyConfigBean myConfigBean () { return new MyConfigBean(); } } BeanFactoryPostProcessor允许客户端代码自定义 bean 定义。方法BeanFactoryPostProcessor.postProcessBeanFactory在所有 bean 定义加载后由 Spring 启动过程调用，但尚未实例化任何 bean。 123456789101112public class MyConfigBean implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory ( ConfigurableListableBeanFactory beanFactory) throws BeansException { GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setBeanClass(MyBean.class); bd.getPropertyValues().add(&quot;strProp&quot;, &quot;my string property&quot;); ((DefaultListableBeanFactory) beanFactory) .registerBeanDefinition(&quot;myBeanName&quot;, bd); }} BeanFactoryPostProcessor 示例的主类。 123456789public class MyBean { private String strProp; public void setStrProp (String strProp) { this.strProp = strProp; } public void doSomething () { System.out.println(&quot;from MyBean: &quot; + strProp); }} Main class for BeanFactoryPostProcessor Example. 12345678public class BeanFactoryPostProcessorExample { public static void main (String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); MyBean bean = context.getBean(MyBean.class); bean.doSomething(); }} Output: 123from MyBean: my string propertyWARNING: @Bean method MyConfig.myConfigBean is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details. 使用 BeanFactoryPostProcessor 动态注册 Bean对标准BeanFactoryPostProcessor SPI 的扩展，允许在常规 BeanFactoryPostProcessor 检测开始之前注册进一步的 bean 定义。特别是，BeanDefinitionRegistryPostProcessor可以注册进一步的 bean 定义，进而定义BeanFactoryPostProcessor实例。 Creating another config class. 1234567@Configurationpublic class MyConfig { @Bean MyConfigBean myConfigBean () { return new MyConfigBean(); }} 这是BeanFactoryPostProcessor的子接口（最后一个例子）。它允许注册 bean 定义。它的方法postProcessBeanDefinitionRegistry在BeanFactoryPostProcessor#postProcessBeanFactory之前被调用。该接口更侧重于 BeanDefinition 注册而不是通用BeanFactoryPostProcessor。为 BeanDefinitionRegistryPostProcessor 创建实现类。 123456789101112131415public class MyConfigBean implements BeanDefinitionRegistryPostProcessor { @Override public void postProcessBeanDefinitionRegistry (BeanDefinitionRegistry registry) throws BeansException { GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setBeanClass(MyBean.class); bd.getPropertyValues().add(&quot;strProp&quot;, &quot;my string property&quot;); registry.registerBeanDefinition(&quot;myBeanName&quot;, bd); } @Override public void postProcessBeanFactory (ConfigurableListableBeanFactory beanFactory) throws BeansException { //no op }} Creating a brand new Bean class. 123456789public class MyBean { private String strProp; public void setStrProp (String strProp) { this.strProp = strProp; } public void doSomething () { System.out.println(&quot;from MyBean: &quot; + strProp); }} Main class for BeanDefinitionRegistryPostProcessor Example. 12345678public class BeanDefinitionRegistryPostProcessorExample { public static void main (String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); MyBean bean = (MyBean) context.getBean(&quot;myBeanName&quot;); bean.doSomething(); }} Output: 123from MyBean: my string propertyWARNING: Cannot enhance @Configuration bean definition 'beanDefinitionRegistryPostProcessorExample.MyConfig' since its singleton instance has been created too early. The typical cause is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor return type: Consider declaring such methods as 'static'. Unregistering the Bean at run timeIf we need to remove registered beans at runtime, we can do the same as below.To remove or unregister the bean from spring context. 1beanRegistry.removeBeanDefinition(&quot;bean&quot;) To delete/clear the singleton bean from context. 1beanRegistry.destroySingleton(&quot;bean&quot;) 参考文章 https://medium.com/@venkivenki4b6/spring-dynamically-register-beans-in-4-ways-at-run-time-c1dc45dcbeb9 https://www.jianshu.com/p/25939d9ce832 https://www.cnblogs.com/monument/p/12933915.html SpringBoot基础篇Bean之动态注册","link":"/2021/11/03/spring/spring-register-bean-at-run-time/"},{"title":"spring_boot2.0_release_notes","text":"参考文章","link":"/2022/01/05/spring/spring-spring-boot2-0-release-notes/"},{"title":"webflux springdoc-openapi","text":"12345&lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webflux-ui&lt;/artifactId&gt; &lt;version&gt;1.6.7&lt;/version&gt;&lt;/dependency&gt; code123456789@SpringBootApplication@OpenAPIDefinition(info = @Info(title = &quot;APIs&quot;, version = &quot;1.0&quot;, description = &quot;Documentation APIs v1.0&quot;))public class ApisApplication { public static void main(String[] args) { SpringApplication.run(ApisApplication.class, args); }} 12345678910111213141516171819202122232425@RestController@Tag(name = &quot;Test APIs&quot;, description = &quot;Test APIs for demo purpose&quot;)public class TestController { @GetMapping(&quot;test&quot;) @Operation(description = &quot;Get a test model demo&quot;, parameters = { @Parameter(name = &quot;name&quot;, in = ParameterIn.QUERY, required = true, description = &quot;name parameter&quot;) }) public Mono&lt;TestDto&gt; getTestDto(final @RequestParam String name, final ServerWebExchange exchange) { TestDto testDto = new TestDto(); testDto.setName(name); testDto.setAge(0); testDto.setName(&quot;Welcome &quot;+name); return Mono.just(testDto); } @PostMapping(&quot;test&quot;) @Operation(description = &quot;Create a test model demo&quot;, requestBody = @io.swagger.v3.oas.annotations.parameters.RequestBody()) public Mono&lt;TestDto&gt; postTestDto(@Valid @RequestBody final TestDto testDto, final ServerWebExchange exchange) { return Mono.just(testDto); }} my demo spring-boot-webflux RestController demo github demos springdoc-openapi-webflux springdoc-openapi-demos springdoc-openapi demo springdoc-openapi-demos 参考文章 Swagger Implementation for Webflux functional programming model ❤ Spring Webflux Swagger UI and Open API 3 API specifications","link":"/2022/04/13/spring/spring-spring-doc-webflux/"},{"title":"springboot springdoc-openapi-ui","text":"my demo spring-boot-web springdoc github demos springdoc-openapi-webflux springdoc-openapi-demos springdoc-openapi demo springdoc-openapi-demos 参考文章 官方文档 Documenting a Spring REST API Using OpenAPI 3.0 Spring REST Docs vs OpenAPI https://www.baeldung.com/spring-rest-openapi-documentation Hiding Endpoints From Swagger Documentation in Spring Boot Swagger @Api Description Is Deprecated","link":"/2022/04/13/spring/spring-spring-doc/"},{"title":"springfox","text":"github demos webflux - springfox demo 参考文章","link":"/2022/04/13/spring/spring-springfox/"},{"title":"Set a Timeout in Spring 5 Webflux WebClient","text":"idle timeout: 闲置 超时时间 Response TimeoutThe response timeout is the time we wait to receive a response after sending a request. connection timeout:The connection timeout is a period within which a connection between a client and a server must be established. read &amp; write timeout:A read timeout occurs when no data was read within a certain period of time, while the write timeout when a write operation cannot finish at a specific time. Configuring Timeouts via HTTP ClientResponse Timeout 响应超时响应超时是我们 在发送请求后等待接收响应的时间。我们可以使用responseTimeout()方法为客户端配置 The response timeout is the time we wait to receive a response after sending a request. We can use the responseTimeout() method to configure it for the client:In this example, we configure the timeout for 1 second. Netty doesn’t set the response timeout by default. After that, we can supply the HttpClient to the Spring WebClient: 123456HttpClient client = HttpClient.create() .responseTimeout(Duration.ofSeconds(1));WebClient webClient = WebClient.builder().clientConnector(new ReactorClientHttpConnector(httpClient)).build(); After doing that, the WebClient inherits all the configurations provided by the underlying HttpClient for all requests sent.这样做之后，WebClient 继承了底层HttpClient 为发送的所有请求提供的所有配置。 Connection Timeout连接超时是必须在客户端和服务器之间建立连接的时间段。 The connection timeout is a period within which a connection between a client and a server must be established. We can use different channel options keys and the option() method to perform the configuration: 12HttpClient client = HttpClient.create() .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000); 提供的值以毫秒为单位，因此我们将超时配置为 10 秒。默认情况下，Netty 将该值设置为 30 秒。 此外，我们可以配置keep-alive选项，它会在连接空闲时发送TCP检查探测： 123456HttpClient client = HttpClient.create().option(ChannelOption.SO_KEEPALIVE, true).option(EpollChannelOption.TCP_KEEPIDLE, 300).option(EpollChannelOption.TCP_KEEPINTVL, 60).option(EpollChannelOption.TCP_KEEPCNT, 8);// create WebClient... 因此，我们启用了保持活动检查以在空闲 5 分钟后以 60 秒的间隔进行探测。我们还将连接下降之前的最大探测数设置为 8。 当在给定时间内未建立连接或断开连接时，将抛出ConnectTimeoutException。 Read and Write TimeoutA read timeout occurs when no data was read within a certain period of time, while the write timeout when a write operation cannot finish at a specific time. The HttpClient allows to configure additional handlers to configure those timeouts: 读超时是指在一定时间内没有读到数据，写超时是写操作无法在特定时间完成。该HttpClient的允许配置更多的处理器配置这些超时： 123456HttpClient client = HttpClient.create() .doOnConnected(conn -&gt; conn .addHandler(new ReadTimeoutHandler(10, TimeUnit.SECONDS)) .addHandler(new WriteTimeoutHandler(10)));// create WebClient... 在这种情况下，我们通过doOnConnected()方法配置了一个连接的回调，我们在其中创建了额外的处理程序。为了配置超时，我们添加了ReadTimeOutHandler 和WriteTimeOutHandle r实例。我们将它们都设置为 10 秒。 这些处理程序的构造函数接受两种参数变体。对于第一个，我们提供了一个TimeUnit规范的数字，而第二个将给定的数字转换为秒。 底层 Netty 库相应地提供ReadTimeoutException和WriteTimeoutException类来处理错误。 参考文章 Set a Timeout in Spring 5 Webflux WebClient Configure timeout for Spring WebFlux WebClient","link":"/2021/12/23/spring/spring-webflux-webclient-set-timeout/"},{"title":"How to use Thymeleaf with Spring Boot","text":"Thymeleaf是一种流行的服务器端模板引擎，适用于 Web 和独立 Java 应用程序。 它被开发用于处理不同类型的文件，如 HTML、XML、JavaScript、CSS 和纯文本。 使用 Thymeleaf 的最大优势是它为您的开发工作流程带来了自然模板——HTML模板可以直接在浏览器中打开并仍然正确呈现为网页。这为快速开发静态原型提供了极大的灵活性，而无需在创建后端服务器上浪费时间。 与其他著名的模板引擎（如 JavaServer Pages (JSP)）相比，Thymeleaf 使整个开发过程变得非常简单和快速。在本文中，您将学习如何将 Thymeleaf 模板引擎与 Spring Boot 结合使用来提供动态 Web 内容。 依赖关系Spring Boot 对 Thymeleaf 模板引擎提供了极好的支持，使得整个集成过程非常简单明了。您需要做的只是将Thymeleaf 的Spring Boot starter包含到您的应用程序依赖项中。Spring Boot 将自动配置您使用 Thymeleaf 引擎所需的一切。要激活 Spring Boot Web 支持，请确保同时包含 Spring Boot Web starter 依赖项 ( spring-boot-starter-web)。 对于 Gradle 项目，将以下依赖项包含到您的build.gradle文件中： 12implementation 'org.springframework.boot:spring-boot-starter-thymeleaf'implementation 'org.springframework.boot:spring-boot-starter-web' 对于 Maven，将以下依赖项添加到pom.xml文件中： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 如果您是从头开始，只需使用Spring Initializr Web 工具或Spring Boot CLI即可使用上述依赖项快速引导一个新的 Spring Boot 项目。 模板Thymeleaf 模板只是HTML 静态文件（.html扩展名），可在浏览器和 Web 应用程序中使用。默认情况下，这些模板存储在src/main/resources/templates/文件夹中。Spring Boot 会在需要时自动选择并呈现这些 HTML 文件。 让我们创建我们的第一个 Thymeleaf 模板index.html，并将其放入src/main/resources/templates文件夹中： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Spring Boot Thymeleaf Web Application&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to Spring Boot Thymeleaf&lt;/h1&gt;&lt;p&gt; Hey there! &lt;th:block th:text=&quot;${message}&quot;&gt;message&lt;/th:block&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; Thymeleaf 引擎将解析上述index.html文件，评估th:text表达式并替换${message}为 Spring Boot Web 控制器类提供的实际值。 Spring Boot 控制器现在让我们定义一个名为 Spring Boot 控制器类IndexController.java，它处理端点上的所有 HTTP GET请求/并返回需要作为响应呈现的视图的名称： 12345678910111213141516171819package com.attacomsian.getstarted.controllers;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;@Controllerpublic class IndexController { @GetMapping(&quot;/&quot;) public String index(Model model) { // add `message` attribute model.addAttribute(&quot;message&quot;, &quot;Thank you for visiting.&quot;); // return view name return &quot;index&quot;; }} 正如你在上面看到的，我们定义了一个简单的 Spring 控制器，它只接受端点上的GET请求/。所述@Controller注释指示注解的类是“控制器”（例如一个网络控制器）。 该@GetMapping注释被用于映射HTTP GET请求到特定的控制器的方法。在上面的例子中，它将/端点映射到index()方法上。Model是一个特殊的接口，用于在 Spring Boot 中的控制器和视图之间共享数据。我们已将message属性添加到Model视图模板中所需的对象 —index.html文件。 该index()方法以字符串形式返回视图模板的名称。Thymeleaf 将在默认文件夹 ( src/main/resources/templates/) 中搜索此模板并进行渲染。 运行和测试应用程序12345678910111213package com.attacomsian.getstarted;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 应用程序启动后，在 Web 浏览器中打开http://localhost:8080/以查看输出。这是它的样子： 更改 Thymeleaf 默认属性Spring Boot 为 Thymeleaf 模板引擎提供了默认配置。要覆盖默认属性值，您可以在application.properties或application.yml配置文件中定义属性。 更改模板文件夹位置要更改 HTML 模板的默认文件夹位置，您需要覆盖以下属性： 12# change location from `templates` to `views`spring.thymeleaf.prefix=classpath:/views/ 禁用模板缓存默认情况下，Spring Boot 会缓存 Thymeleaf 模板以提高性能。如果您希望模板在修改时自动更新，请覆盖以下属性（不推荐在生产中使用）： 12spring.thymeleaf.cache=false 参考文章 https://attacomsian.com/blog/spring-boot-thymeleaf-example","link":"/2021/12/03/spring/spring-use-thymeleaf/"},{"title":"webflux","text":"参考文章 Spring 5 WebFlux 指南","link":"/2022/04/13/spring/spring-webflux/"},{"title":"study plan","text":"github BigData-Notes Hadoop Hive Spark Storm Flink HBase Kafka Zookeeper Flume Sqoop Azkaban Scalahttps://github.com/heibaiying/BigData-Notes/tree/master/notes 参考文章","link":"/2021/12/16/study/study-plan/"},{"title":"reactive webclient","text":"12345678WebClient.create().get() .uri(&quot;https://example.org/path&quot;) .httpRequest(httpRequest -&gt; { HttpClientRequest reactorRequest = httpRequest.getNativeRequest(); reactorRequest.responseTimeout(Duration.ofSeconds(2)); }) .retrieve() .bodyToMono(String.class); WebClient &amp; HttpClient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MyWebClient { public static void main(String[] args) throws IOException { Mono&lt;ClientResponse&gt; clientResponseMono = createWebClient(createHttpClient(&quot;webClient-pool&quot;, 30)) .get() .uri(&quot;http://localhost:8089/&quot;) // .headers(httpHeaders -&gt; httpHeaders.add(&quot;Connection&quot;, &quot;keep-alive&quot;)) .httpRequest(httpRequest -&gt; { HttpClientRequest reactorRequest = httpRequest.getNativeRequest(); reactorRequest.responseTimeout(Duration.ofSeconds(2)); }) .exchange() .doOnDiscard(PooledDataBuffer.class, DataBufferUtils::release); clientResponseMono.block(); /* ServerRequest request; createWebClient(createHttpClient(&quot;webClient-pool&quot;, 30)) .method(HttpMethod.GET) .uri(&quot;Url&quot;) .body(BodyInserters.fromDataBuffers(request.body(BodyExtractors.toDataBuffers()))) .headers(httpHeaders -&gt; httpHeaders.addAll(request.headers().asHttpHeaders())) .exchange() .doOnError(throwable -&gt; log.error(&quot;&quot;)) .doOnSuccess(clientResponse -&gt; log.info(&quot;success&quot;)) .doFinally(signalType -&gt; log.info(&quot;do on finally&quot;)) .doOnDiscard(PooledDataBuffer.class, DataBufferUtils::release); */ } private static WebClient createWebClient(HttpClient httpClient) { return WebClient.builder() .filter(new LogFilter()) .clientConnector(new ReactorClientHttpConnector(httpClient)) .exchangeStrategies(ExchangeStrategies.builder().codecs(configurer -&gt; configurer.defaultCodecs().maxInMemorySize(-1)).build()) .uriBuilderFactory(new MyUriBuilderFactory()) .build(); } private static HttpClient createHttpClient(String poolName, int timeoutSec) { return HttpClient .create(ConnectionProvider.builder(poolName) .maxConnections(20480) .maxIdleTime(Duration.of(600, ChronoUnit.SECONDS)) .build() ) .tcpConfiguration(tcpClient -&gt; tcpClient .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, (int)TimeUnit.SECONDS.toMillis(10)) .option(ChannelOption.SO_KEEPALIVE, false) .doOnConnected(connection -&gt; connection .addHandlerLast(new ReadTimeoutHandler(timeoutSec)) .markPersistent(false) ) ) .followRedirect(false) .keepAlive(false) .compress(true); }} 123456789101112131415161718192021222324import java.net.URI;import java.util.Optional;import org.springframework.web.reactive.function.client.ClientRequest;import org.springframework.web.reactive.function.client.ClientResponse;import org.springframework.web.reactive.function.client.ExchangeFilterFunction;import org.springframework.web.reactive.function.client.ExchangeFunction;import lombok.extern.slf4j.Slf4j;import reactor.core.publisher.Mono;@Slf4jpublic class LogFilter implements ExchangeFilterFunction { @Override public Mono&lt;ClientResponse&gt; filter(ClientRequest request, ExchangeFunction next) { URI url = request.url(); Optional&lt;String&gt; traceIdOption = Optional.ofNullable(request.headers().getFirst(&quot;trace-id&quot;)); log.info(&quot;{} Request: {} {}&quot;, traceIdOption.orElse(request.logPrefix()), request.method(), url); return next.exchange(request).flatMap(response -&gt; { log.info(&quot;{} Response:{} {} {}&quot;, traceIdOption.orElse(response.logPrefix()), request.method(), url, response.statusCode()); return Mono.just(response); }); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.example.demo.reactorclient;import java.io.UnsupportedEncodingException;import java.net.URI;import java.net.URISyntaxException;import java.net.URLDecoder;import java.util.Map;import java.util.function.Supplier;import org.apache.commons.codec.Charsets;import org.springframework.web.util.UriBuilderFactory;import org.springframework.web.util.UriComponentsBuilder;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class MyUriBuilderFactory implements UriBuilderFactory { public UriComponentsBuilder uriString(String uriTemplate) { return UriComponentsBuilder.fromUriString(uriTemplate); } @Override public UriComponentsBuilder builder() { return UriComponentsBuilder.newInstance(); } @Override public URI expand(String uriTemplate, Map&lt;String, ?&gt; uriVariables) { return expand(uriTemplate, () -&gt; uriVariables); } @Override public URI expand(String uriTemplate, Object... uriVariables) { return expand(uriTemplate, () -&gt; uriVariables); } public &lt;T&gt; URI expand(String uriTemplate, Supplier&lt;T&gt; uriVariablesSupplier) { T uriVariables = uriVariablesSupplier.get(); try { return new URI(UriComponentsBuilder.fromHttpUrl(uriTemplate).build().expand(uriVariables).toUriString()); } catch (URISyntaxException e) { try { String decode = URLDecoder.decode(uriTemplate, Charsets.UTF_8.name()); String encodeUrl = UriComponentsBuilder.fromHttpUrl(decode).build().expand(uriVariables).encode().toUriString(); log.warn(&quot;Url encode:[{},{}]&quot;, uriTemplate, encodeUrl); return new URI(encodeUrl); } catch (URISyntaxException | IllegalArgumentException | UnsupportedEncodingException exception) { log.error(exception.getMessage() + &quot;:&quot; + uriTemplate, exception); // log error for monitor throw new RuntimeException(&quot;bad request&quot;); } } }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;reactor-netty.version&gt;0.9.12.RELEASE&lt;/reactor-netty.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-reactor-netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;${reactor-netty.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/io.netty/netty-all --&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.69.Final&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; HttpClient keepalive configref: https://projectreactor.io/docs/netty/snapshot/api/index.html?reactor/netty/http/client/HttpClient.html 1234567891011121314151617181920private static HttpClient createHttpClient(String poolName, int timeoutSec) { return HttpClient .create(ConnectionProvider.builder(poolName) .maxConnections(20480) .maxIdleTime(Duration.of(600, ChronoUnit.SECONDS)) .build() ) .tcpConfiguration(tcpClient -&gt; tcpClient .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, (int)TimeUnit.SECONDS.toMillis(10)) .option(ChannelOption.SO_KEEPALIVE, false) .doOnConnected(connection -&gt; connection .addHandlerLast(new ReadTimeoutHandler(timeoutSec)) .markPersistent(false) ) ) .followRedirect(false) .keepAlive(false) .compress(true);} note如果 httpClient.keepalive = false,可以通过 添加 header: &quot;Connection&quot;,&quot;keep-alive&quot;, 启用 keepalive 参考文章 reactive web client Spring 5 WebClient reactor netty httpclient","link":"/2021/12/08/reactive/reactive-webclient/"},{"title":"zookeeper windows install","text":"下载zookeeperhttps://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/ 配置zookeeper解压到三个目录我们想要在单机上搭建3个server的伪集群，需要将下载好的zookeeper压缩包解压到三个目录下。 123server1 : D:\\zookeeper\\server1server2 : D:\\zookeeper\\server3server3 : D:\\zookeeper\\server3 创建配置文件（cfg文件）解压之后，分别进入conf目录，可以看到zoo_sample.cfg，log4j.properties和configuration.xsl三个文件。 在该目录下创建一个zoo.cfg文件（也可以直接使用zoo_sample.cfg），配置如下： 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server1\\\\datadataLogDir=D:\\\\zookeeper\\\\server1\\\\logs# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 以上就是zookeeper伪集群中server1的配置文件。同理在其他两个解压路径的conf目录下创建server2和server3的配置文件zoo.cfg。参数区别仅在于dataDir、dataLogDir和clientPort server2的zoo.cfg 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server2\\\\datadataLogDir=D:\\\\zookeeper\\\\server2\\\\logs# the port at which the clients will connectclientPort=2182# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 server3的zoo.cfg 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper\\\\server3\\\\datadataLogDir=D:\\\\zookeeper\\\\server3\\\\logs# the port at which the clients will connectclientPort=2183# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# （伪集群zookeeper的server1标识）server.1=localhost:2887:3887 # （伪集群zookeeper的server2标识）server.2=localhost:2888:3888 # （伪集群zookeeper的server3标识）server.3=localhost:2889:3889 创建myid文件在上个步骤中，我们在dataDir中指定了快照存放目录，切换到各目录下，分别创建一个文件名为myid的文件（没有后缀名）。文件内容为一个整型数。 在server1的data目录下的myid文件，其内容为1。在server2的data目录下的myid文件，其内容为2。在server3的data目录下的myid文件，其内容为3。 启动zookeeper分别切换到三个解压路径下的bin目录，在cmd上输入zkServer.cmd启动服务，可以同时用三个cmd窗口分别启动三个server，启动顺序是server1 -&gt; server2 -&gt; server3。启动的过程中是会报错的，信息如下： 进入cmd，切换目录到 /server1/bin/，执行命令 zkServer.cmd（此时会打印错误日志，别急，这是心跳检查连接其他zk服务，等启动集群数量一半以上的zk服务后，就不报错了）进入cmd，切换目录到 /server2/bin/，执行命令 zkServer.cmd进入cmd，切换目录到 /server3/bin/，执行命令 zkServer.cmd 验证zookeeper服务是否启动cmd，切换目录到 /server1/bin，执行命令 zkCli.cmd -server localhost:2181 参考文章 ZooKeeper集群搭建 https://www.cnblogs.com/yangzhenlong/p/8270835.html https://blog.csdn.net/sinat_34596644/article/details/78289842","link":"/2021/10/28/zookeeper/zookeeper-windows-install/"},{"title":"如何在Ubuntu 18.04上安装Node和npm","text":"从NodeSource安装Node.js和npm 要从NodeSource存储库安装Node.js和npm，请按照以下步骤操作。通过以root或者具有sudo权限的用户运行以下curl命令来启用NodeSource存储库： 12345678910111213curl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -## Run `sudo apt-get install -y nodejs` to install Node.js 16.x and npm## You may also need development tools to build native addons: sudo apt-get install gcc g++ make -y ## To install the Yarn package manager, run: curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg &gt;/dev/null echo &quot;deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main&quot; | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt-get update &amp;&amp; sudo apt-get install yarn 该命令会将NodeSource签名密钥添加到您的系统，创建apt源存储库文件，安装所有必需的软件包并刷新apt缓存。如果需要安装其他版本，例如14.x，只需将setup_16.x更改为setup_14.x。 一旦启用NodeSource存储库，请输入以下命令来安装Node.js和npm： 1sudo apt-get install -y nodejs nodejs软件包同时包含node和npm二进制文件。通过打印其版本来验证Node.js和npm是否已成功安装： 12node --version 1npm --version 参考文章 如何在Ubuntu 18.04上安装Node.js和npm 如何在 Ubuntu 20.04 上安装 Node.js 和 npm","link":"/2021/12/30/wsl/ubuntu-nodejs/"},{"title":"WSL2 + Docker + IDEA","text":"参考文章 WSL2 + Docker + IDEA","link":"/2021/09/27/wsl/wsl-idea-docker/"},{"title":"wsl install centos","text":"参考文章 https://zhuanlan.zhihu.com/p/347461016 install centosWindows的应用商店中有一些不错的linux发行版，包括很多同学都很喜欢的ubuntu，但是个人比较熟悉使用centos，而应用商店中的centos是要收费的，不过好在github上面有CENTOS官方开源的安装包，我们这里使用github上的安装包进行安装。 如果使用应用商店中的发行版直接点击安装即可。随后便可以跳过下面的centos的安装部分。 首先我们去centos的GitHub页面下载对应的安装包：https://github.com/CentOS/sig-cloud-instance-images/blob/CentOS-8-x86_64/docker/centos-8-x86_64.tar.xz 接着我们以管理员身份打开一个powershell窗口： 1234# 安装 ChocolateySet-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))# 安装 LxRunOfflinechoco install lxrunoffline 注意这里安装完成之后需要重启powershell来进行下一步的安装 LxRunOffline.exe install -n centos -d D:\\wsl\\centos -f D:\\wsl\\centos-8-x86_64.tar.xz 12345LxRunOffline install -n 自定义系统名称 -d 安装目录路径 -f tar.xz安装包路径# 注意windows系统命令行中的文件路径和linux系统差别很大# 比如我这里的安装命令就是LxRunOffline.exe install -n centos -d D:/centos -f .\\centos-7-x86_64-docker.tar.xz# 将centos安装到D盘的centos文件夹下，并且命名为centos 接下来就可以使用下述两种方式尝试启动 12LxRunOffline run -n 自定义系统名称wsl -d 自定义系统名称 升级centos为wsl2123456# 列出已经安装的wsl的信息wsl -l -v# 将对应的wsl设为wsl2，注意&lt;Distro&gt;要和上面查询到的信息一致wsl --set-version &lt;Distro&gt; 2# 设置默认使用的发行版wsl -s &lt;Distro&gt;","link":"/2021/09/27/wsl/wsl-centos/"},{"title":"wsl常用命令","text":"参考文章 https://docs.microsoft.com/zh-cn/windows/wsl/reference 设置默认版本wsl --set-default-version 2 检查分配给每个已安装的 Linux 分发版的 WSL 版本wsl -l -vwsl --list --verbose 将分发版设置为受某一 WSL 版本支持wsl --set-version &lt;distribution name&gt; &lt;versionNumber&gt; 运行/停止Ubuntu子系统wsl -l 列出了系统中安装的子系统名称，可以是一个或多个，本文中的子系统名称是Ubuntu-18.04-20190707，接下来针对这个默认子系统进行操作： 运行子系统wsl --distribution Ubuntu-18.04-20190707或者wsl -d Ubuntu-18.04-20190707 查看运行中的子系统-l --running12 适用于 Linux 的 Windows 子系统:Ubuntu-18.04-20190707 (默认) 停止子系统wsl -t Ubuntu-18.04-20190707或者wsl --terminate Ubuntu-18.04-20190707 备份/删除/还原子系统备份子系统非常简单，但一定要先停止子系统之后再备份wsl --export Ubuntu-18.04-20190707 c:\\temp\\Ubuntu-18.04-20190707.tar等待完成即可。备份成功后，子系统会被打包成命令中指定的tar文件。 删除子系统也是一个命令即可：wsl --unregister Ubuntu-18.04-20190707这样WSL子系统就从Windows中删除的干干净净了。 还原子系统删除了没关系，刚才做了备份，也是一个命令还原：wsl --import Ubuntu-18.04-20190707 c:\\WSL c:\\temp\\Ubuntu-18.04-20190707.tar这里注意指定还原的路径。成功后，子系统又回来了，可以用wsl -l确认一下。 用于运行 Linux 命令的参数 不带参数 如果未提供命令行，wsl.exe 将启动默认 shell。 –exec, -e 执行指定的命令，但不使用默认的 Linux shell。 按原样传递剩余的命令行。 上述命令也接受以下选项： –distribution, -d 运行指定的分发版。 –user, -u 以指定用户的身份运行。 用于管理适用于 Linux 的 Windows 子系统的参数 –export 将分发版导出到 tar 文件。 在标准输出中，文件名可以是 -。 –import 导入指定的 tar 文件作为新的分发版。 在标准输入中，文件名可以是 -。 –list、-l [选项] 列出分发版。 选项： –all 列出所有分发版，包括当前正在安装或卸载的分发版。 –verbose, -v 显示命令的附加信息或展开的详细信息。 –running 仅列出当前正在运行的分发版。 –set-default, -s 将分发版设置为默认值。 –terminate, -t 终止指定的分发版。 –unregister 注销分发版。 –help 显示用法信息。","link":"/2021/09/27/wsl/wsl-cmd/"},{"title":"wsl install ubuntu","text":"参考文章 https://blog.csdn.net/weixin_45883933/article/details/106085184 安装前配置ref: 适用于 Linux 的 Windows 子系统安装指南 (Windows 10) 1. 启用 Windows 功能搜索并打开“启用或关闭 Windows 功能”，然后选择“适用于Linux的Windows子系统”复选框。 在windows功能中重新勾选hyper-v然后开启hyper-v模式在管理员powershell中执行 1bcdedit /set hypervisorlaunchtype auto 如果禁用了组策略里面的Device Guard虚拟化安全设置，需要打开组策略管理，本地计算机策略 &gt; 计算机配置 &gt; 管理模板&gt;系统 &gt; Device Guard打开 基于虚拟化的安全设置为“已开启”或者“未设置”随后重新开启wsl2，若不行，重启计算机。 启用虚拟机平台可选组件在 powerShell 中以管理员身份运行下面命令 1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 1dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 运行完成之后，请重启电脑完成安装. 设置WSL发行版如果想要将默认的WSL发行版设置成 WSL 2，在 powerShell 中使用下面命令 wsl --set-default-version 2如果想要设置某一个发行版为WSL2，在 powerShell 中使用下面命令，将 换成你想要设置的发行版即可，例如 Ubuntu-18.04 wsl --set-version &lt;Distro&gt; 2 wsl --set-version Ubuntu-20.04 2验证使用的WSL版本 wsl -l -v 下载安装 Ubuntu-20.04 (Windows 应用商店里)更新包目录，并使用分发版的首选包管理器升级已安装的包sudo apt update &amp;&amp; sudo apt upgrade Windows不会自动更新或升级Linux发行版：Linux用户经常意外自行控制此任务。123456789101112131415161718192021222324252627ubuntu@kylin：〜$ wslfetch ./+o+- Windows 10 Linux Subsystem yyyyy. 'yyyyyy+ root@kylin .;//+/h yyyyyyo BUILD: 19624 .++ .:/++++++/-.`sss/` BRANCH: rs_prerelease .:++o: `\\++++++++/:---:/- RELEASE: Ubuntu 20.04 LTS o:+o+:++. `````'-/ooo+++++\\ KERNEL: Linux 4.19.104-microsoft-standard .:+o:+o/. `+sssooo+\\ UPTIME: 0d 0h 2m .++/+ +oo+o:` \\sssooo; /+++//+: oo+o \\+/+o+++ o++o ydddhh+ .++.o+ +oo+:` /dddhhh; .+.o+oo:. oddhhhh+ \\+.++o+o` -,,,,.:ohdhhhhh+ `:o+++ ohhhhhhhhyo++os: .o: .syhhhhhhh'.oo++o. /osyyyyyyy.oooo+++\\ `````+oo+++o:/ `oo++'`root@kylin:~# lsb_release -a | lolcatNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 20.04 LTSRelease: 20.04Codename: focalubuntu @ kylin:/ $ sudo apt install lolcat sudo apt install lolcat lsb_release -a | lolcat wsl ubuntu config修改 默认的源 (更换国内源)cp /etc/apt/sources.list /etc/apt/sourses.list.bak 更换默认源为阿里源, 使用 sudo vim /etc/apt/sources.list 命令编辑，删除原来的内容，添加下面的阿里源信息 12345678910deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 更换源之后，使用下面的命令更新一下 12sudo apt-get update -ysudo apt-get upgrade -y Windows 10 WSL Ubuntu 系统的 root 密码Ubuntu 的默认 root 密码是随机的，即每次开机都有一个新的 root 密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码，终端会提示我们输入新的密码并确认，此时的密码就是 root 新密码。修改成功后，输入命令 su root，再输入新的密码就 ok 了。 Linux 的 Windows10 子系统 ubuntu 设置默认用户 Linux 的 Windows10 子系统 ubuntu 设置默认用户 修改Wsl为root登录，并修改root密码 123ubuntu1804 /?ubuntu1804 config --default-user root ssh 连接 配置在WSL Ubuntu系统中安装ssh server当对Linux实现文件操作时，使用WinScp更为方便。因此需要使用ssh远程登陆 安装ssh serversudo apt-get install openssh-server 配置ssh使用 cp 命令将 SSH 相关配置备份sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak 使用 vim 编辑 sshd_config 文件 sudo vim /etc/ssh/sshd_config调整一下设置： 12345Port 22ListenAddress 0.0.0.0PermitRootLogin yesStrictModes yesPasswordAuthentication yes 12345678910111213141516171819root@summer:/# service ssh status * sshd is not runningroot@summer:/# service ssh start * Starting OpenBSD Secure Shell server sshd sshd: no hostkeys available -- exiting.root@summer:/# sshd -Tsshd: no hostkeys available -- exiting.root@summer:/# ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_keyroot@summer:/# ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_keyroot@summer:/etc/ssh# sshd -Troot@summer:/etc/ssh# service ssh start * Starting OpenBSD Secure Shell server sshd [ OK ] ＃Ubuntu的防火墙状态检测，防火墙可能限制SSH端口22root@summer:~# service ufw status * Firewall is not running... [fail]root@kylin:~# 重启ssh service 1sudo service ssh restart sshd: no hostkeys available — exiting在开启SSHD服务时报错.sshd re-exec requires execution with an absolute path用绝对路径启动,也报错如下:Could not load host key: /etc/ssh/ssh_host_keyCould not load host key: /etc/ssh/ssh_host_rsa_keyCould not load host key: /etc/ssh/ssh_host_dsa_keyDisabling protocol version 1. Could not load host keyDisabling protocol version 2. Could not load host keysshd: no hostkeys available — exiting解决过程: 123ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_keyssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key/usr/sbin/sshd 如果上述两个文件存在，仍然出现这个错误，那么试试 chmod 600 上述两个文件。之后应该可以解决。 ssh login登陆 SSH使用 SSH 指令登陆 ssh root@127.0.0.1 -p 22 运行/停止Ubuntu子系统wsl -l 列出了系统中安装的子系统名称，可以是一个或多个，本文中的子系统名称是Ubuntu-18.04-20190707，接下来针对这个默认子系统进行操作： 运行子系统wsl --distribution Ubuntu-18.04-20190707或者wsl -d Ubuntu-18.04-20190707 查看运行中的子系统-l --running12 适用于 Linux 的 Windows 子系统:Ubuntu-18.04-20190707 (默认) 停止子系统wsl -t Ubuntu-18.04-20190707或者wsl --terminate Ubuntu-18.04-20190707 备份/删除/还原子系统备份子系统非常简单，但一定要先停止子系统之后再备份wsl --export Ubuntu-18.04-20190707 c:\\temp\\Ubuntu-18.04-20190707.tar等待完成即可。备份成功后，子系统会被打包成命令中指定的tar文件。 删除子系统也是一个命令即可：wsl --unregister Ubuntu-18.04-20190707这样WSL子系统就从Windows中删除的干干净净了。 还原子系统删除了没关系，刚才做了备份，也是一个命令还原：wsl --import Ubuntu-18.04-20190707 c:\\WSL c:\\temp\\Ubuntu-18.04-20190707.tar这里注意指定还原的路径。成功后，子系统又回来了，可以用wsl -l确认一下。 install docker-engines under ubuntu.refer to: https://docs.docker.com/engine/install/ubuntu/ 12345#启动docker sudo service docker startservice --status-allsudo service docker start #WSL2下能使用 systemctl, 参考：https://www.cnblogs.com/a5idc/p/13752839.htmlsudo usermod -aG docker {$USER}，$user是linux os你创建的用户，参考：https://docs.docker.com/engine/install/linux-postinstall/docker run hello-world #检查是否安装成功 install docker-compose under ubuntu.参考： https://docs.docker.com/compose/install/ 1sudo chmod +x /usr/local/bin/docker-compose 在ubuntu下git checkout docker-compose目录，运行mysql等服务。在windows下，可直接使用localhost连接123docker-compose up #启动并运行docker-compose up -d #在后台运行docker-compose down apt-get install telnetapt-get -y install netcat-traditional","link":"/2021/09/27/wsl/wsl-ubuntu/"},{"title":"24小时之内，如何找到有毒的那瓶水？","text":"你带着手表被关在小房子里，找到有毒的瓶子，毒药十小时后发作，只有24消失时间 重要条件： 10 小时后,毒药 发作 每隔一小时 喂一瓶毒药发作时，十小时前喝的那瓶就是有毒的。 参考文章","link":"/2021/11/01/algorithm/algorithm/algorithm-2/"},{"title":"wsl ubuntu static ip &amp; service init","text":"参考文章 https://www.cnblogs.com/sinicheveen/p/13636248.html https://blog.csdn.net/u012809062/article/details/118424682 开机启动 dockerhttps://blog.csdn.net/l229568441/article/details/106968306/ 12vim /etc/init_myservice.shchmod u+x /etc/init_myservice.sh /etc/init_myservice.sh 12ip addr add 192.168.50.28/24 broadcast 192.168.50.255 dev eth0 label eth0:1service docker start wsl_ip.bat 1234567891011121314151617181920212223242526272829@echo off:: 获取管理员权限setlocalset uac=~uac_permission_tmp_%random%md &quot;%SystemRoot%\\system32\\%uac%&quot; 2&gt;nulif %errorlevel%==0 ( rd &quot;%SystemRoot%\\system32\\%uac%&quot; &gt;nul 2&gt;nul ) else ( echo set uac = CreateObject^(&quot;Shell.Application&quot;^)&gt;&quot;%temp%\\%uac%.vbs&quot; echo uac.ShellExecute &quot;%~s0&quot;,&quot;&quot;,&quot;&quot;,&quot;runas&quot;,1 &gt;&gt;&quot;%temp%\\%uac%.vbs&quot; echo WScript.Quit &gt;&gt;&quot;%temp%\\%uac%.vbs&quot; &quot;%temp%\\%uac%.vbs&quot; /f del /f /q &quot;%temp%\\%uac%.vbs&quot; &amp; exit )endlocal :: 给WSL Ubuntu和Win10添加固定ipwsl -d Ubuntu-18.04 -u root /etc/init_myservice.shnetsh interface ip add address &quot;vEthernet (WSL)&quot; 192.168.50.93 255.255.255.0 因为netsh interface ip add address &quot;vEthernet (WSL)&quot; 192.168.50.88 255.255.255.0这条命令必须以管理员身份运行，所以此脚本的上边一段代码是首先获取管理员运行权限，然后才开始执行设置ip相关的命令； 因为此脚本放在启动目录下，所以Win10启动的时候会自动运行此脚本设置ip，就可以用Xshell通过192.168.50.28访问WSL Ubuntu了； 通过BatToExeConverter.exe把上述脚本转换成wsl_ip.exe，然后放入启动目录下，开机之后就不会弹出黑窗了，比较完美。","link":"/2021/09/27/wsl/wsl_ubuntu_static_ip/"},{"title":"1000瓶酒找1毒酒","text":"某酒主人要宴请客人，他共有1000瓶酒，其中1瓶有毒。一旦喝了毒酒后，会在一天后发作，现在如果我们用小白鼠进行检测，问一天内最少需要多少只小白鼠才可以检测出哪瓶有毒？ 此题的常规思路是10只老鼠按从左到右的顺序一字排好，每桶酒也编上号1到1000，并把编号转换成二进制形式(也就是只有0和1的二进制，但是为了方便，每个二进制都写满10位，不够十位数的前面添0补满(比如1100110就写成0001100110)，数位和老鼠的位置一一对应，把酒给相应位置上是1的老鼠喝(每一桶都要喝)。最后按死掉的老鼠是哪几只，然后排成二进制，再转成十进制就是第几桶酒。比如:第70桶酒，70转换成二进制就是0001000110，那么就给第四、八、九只老鼠喝。如果最后死掉第三、七、八只老鼠，那么就是0010001100，转换成十进制就是140，即140桶酒有毒。理论上这10只老鼠可以检测1024桶酒。 并行二分法 简单理解（8瓶为例） 黄色的 取一点混在一起喂给 第一只小白鼠 蓝色的 取一点混在一起喂给 第二只小白鼠 红色的 取一点混在一起喂给 第三只小白鼠 1000瓶 python 1234567891011121314151617181920212223242526272829303132333435363738394041x=int(input('请输入哪瓶酒有毒:'))if x%2 in range(1,2): print(&quot;1dead&quot;)else: print(&quot;1alive&quot;)if x%4 in range(1,3): print(&quot;2dead&quot;)else: print(&quot;2alive&quot;)if x%8 in range(1,5): print(&quot;3dead&quot;)else: print(&quot;3alive&quot;)if x%16 in range(1,9): print(&quot;4dead&quot;)else: print(&quot;4alive&quot;)if x%32 in range(1,17): print(&quot;5dead&quot;)else: print(&quot;5alive&quot;)if x%64 in range(1,33): print(&quot;6dead&quot;)else: print(&quot;6alive&quot;)if x%128 in range(1,65): print(&quot;7dead&quot;)else: print(&quot;7alive&quot;)if x%250 in range(1,126): print(&quot;8dead&quot;)else: print(&quot;8alive&quot;)if x%500 in range(1,251): print(&quot;9dead&quot;)else: print(&quot;9alive&quot;)if x%1000 in range(1,501): print(&quot;10dead&quot;)else: print(&quot;10alive&quot;) 相关文章 8瓶酒一瓶有毒 参考文章 https://zhuanlan.zhihu.com/p/268350907","link":"/2021/11/01/algorithm/algorithm/algorithm-1/"},{"title":"找出数组中超过一半的数","text":"给你一个有N（N是奇数 &amp;&amp; 1&lt;=N&lt;=999999）个数的序列，而且保证这N个数中有一个数M的数量 &gt;= （N + 1)/2 ，让你找出这个数M。Sample Input:51 3 2 3 3Sample Output:3 一、DP思想：1、把一个大的问题分解成一个一个的子问题。2、如果得到了这些子问题的解，然后经过一定的处理，就可以得到原问题的解。3、如果这些子问题与原问题有着结构相同，即小问题还可以继续的分解。4、这样一直把大的问题一直分下去，问题的规模不断地减小，直到子问题小到不能再小，最终会得到最小子问题。5、最小子问题的解显而易见，这样递推回去，就可以得到原问题的解。 二、DP的具体实现：1、分析问题，得到状态转换方程（递推方程）。2、根据状态转换方程，从原子问题开始，不断的向上求解，知道得到原问题的解。3、在通过递推方程不断求解的过程，实际上是一个填表的过程。 按照DP的思想，把这个大问题先分解成若干个小问题。所以呢当N为N时，至少有（N + 1）/ 2个M，另外的数就先不管他； ……然后当N为5得时候，依据题意那么一定至少有3个M，另外两个数就先不管他；当N为3的时候，根据题意得，一定有两个数为M，另外一个数就先不管他；先 来看当N为1的时候，那么这个数一定是M。所以就可以把这个序列中得两个不同的数删去（只要有两个数不同就删去），最后剩下的一定是M；举个栗子：intput: 93 6 9 3 3 3 8 6 3loc ： 1 2 3 4 5 6 7 8 91、2位置删去 3、4位置删去 6、7位置删去 8、9位置删去，，还剩一个5位置，那么5位置的 3 就是要找的M . 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;string&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;using namespace std;int arr[1000006];int dp[1000006];int main(){ int n; while(scanf(&quot;%d&quot;, &amp;n) != EOF){ memset(arr, 0, sizeof(arr)); memset(dp, 0, sizeof(dp)); for(int i = 0; i &lt; n; i++) scanf(&quot;%d&quot;, &amp;arr[i]); int i = 0, j = 1; while(j &lt; n){ if(dp[i] == 1){ while(dp[i] == 1) i++; } if(arr[i] != arr[j]){ i++; dp[j++] = 1; } else if(arr[i] == arr[j]){ while(arr[i] == arr[j]) j++; } } while(dp[i] == 1) i++; printf(&quot;%d\\n&quot;, arr[i]); } return 0;} 参考文章 https://blog.csdn.net/ltrbless/article/details/81318935","link":"/2021/11/24/algorithm/algorithm/algorithm-7/"},{"title":"二分查找","text":"给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。 递归123456789101112131415161718192021class Solution { public int search(int[] nums, int target) { return searchTarget(nums, 0, nums.length - 1, target); } public static int searchTarget(int[] nums, int from, int to, int target) { int mid = (to + from) / 2; if (target &lt; nums[from] || target &gt; nums[to] || to &lt; from) { return -1; } if (nums[mid] == target) { return mid; } if (nums[mid] &lt; target) { return searchTarget(nums, mid + 1, to, target); } else { return searchTarget(nums, from, mid - 1, target); } }} while循环123456789101112131415161718class Solution { public int search(int[] nums, int target) { int low = 0, high = nums.length - 1; while (low &lt;= high) { int mid = (high - low) / 2 + low; int num = nums[mid]; if (num == target) { return mid; } else if (num &gt; target) { high = mid - 1; } else { low = mid + 1; } } return -1; }} 相关题目你是产品经理，目前正在带领一个团队开发新的产品。不幸的是，你的产品的最新版本没有通过质量检测。由于每个版本都是基于之前的版本开发的，所以错误的版本之后的所有版本都是错的。 假设你有 n 个版本 [1, 2, …, n]，你想找出导致之后所有版本出错的第一个错误的版本。 你可以通过调用 bool isBadVersion(version) 接口来判断版本号 version 是否在单元测试中出错。实现一个函数来查找第一个错误的版本。你应该尽量减少对调用 API 的次数。 示例 1： 输入：n = 5, bad = 4输出：4解释：调用 isBadVersion(3) -&gt; false调用 isBadVersion(5) -&gt; true调用 isBadVersion(4) -&gt; true所以，4 是第一个错误的版本。 示例 2： 输入：n = 1, bad = 1输出：1 123456789101112131415161718192021/* The isBadVersion API is defined in the parent class VersionControl. boolean isBadVersion(int version); */public class Solution extends VersionControl { public int firstBadVersion(int n) { int left = 1, right = n; while (left &lt; right) { // 循环直至区间左右端点相同 int mid = left + (right - left) / 2; // 防止计算时溢出 if (isBadVersion(mid)) { right = mid; // 答案在区间 [left, mid] 中 } else { left = mid + 1; // 答案在区间 [mid+1, right] 中 } } // 此时有 left == right，区间缩为一个点，即为答案 return left; } } 相关题目ref: https://leetcode-cn.com/problems/search-insert-position/给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 请必须使用时间复杂度为 O(log n) 的算法。 示例 1: 输入: nums = [1,3,5,6], target = 5输出: 2 示例 2: 输入: nums = [1,3,5,6], target = 2输出: 1 示例 3: 输入: nums = [1,3,5,6], target = 7输出: 4 示例 4: 输入: nums = [1,3,5,6], target = 0输出: 0 示例 5: 输入: nums = [1], target = 0输出: 0 1234567891011121314151617class Solution { public int searchInsert(int[] nums, int target) {int low = 0, high = nums.length - 1; while (low &lt;= high) { int mid = (high - low) / 2 + low; int num = nums[mid]; if (num == target) { return mid; } else if (num &gt; target) { high = mid - 1; } else { low = mid + 1; } } return nums[Math.min(low, nums.length - 1)] &lt; target ? Math.min(low, nums.length - 1) + 1 : low; }} 参考文章 https://leetcode-cn.com/problems/binary-search/","link":"/2021/11/04/algorithm/algorithm/algorithm-3/"},{"title":"有序数组的平方","text":"给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。 示例 1：1234输入：nums = [-4,-1,0,3,10]输出：[0,1,9,16,100]解释：平方后，数组变为 [16,1,0,9,100]排序后，数组变为 [0,1,9,16,100] 示例 2：12输入：nums = [-7,-3,2,3,11]输出：[4,9,9,49,121] 暴力排序最直观的相反，莫过于：每个数平方之后，排个序 12345678910class Solution {public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) { for (int i = 0; i &lt; A.size(); i++) { A[i] *= A[i]; } sort(A.begin(), A.end()); // 快速排序 return A; }}; 这个时间复杂度是 O(n + nlogn)， 可以说是O(nlogn)的时间复杂度，但为了和下面双指针法算法时间复杂度有鲜明对比，我记为 O(n + nlogn)。 双指针法数组其实是有序的， 只不过负数平方之后可能成为最大数了。 那么数组平方的最大值就在数组的两端，不是最左边就是最右边，不可能是中间。 此时可以考虑双指针法了，i指向起始位置，j指向终止位置。 定义一个新数组result，和A数组一样的大小，让k指向result数组终止位置。 如果A[i] * A[i] &lt; A[j] * A[j] 那么result[k–] = A[j] * A[j]; 。 如果A[i] * A[i] &gt;= A[j] * A[j] 那么result[k–] = A[i] * A[i]; 。 如动画所示： ref 12345678910111213141516171819202122232425262728293031323334class Solution { public int[] sortedSquares(int[] nums) { int right = nums.length - 1; int left = 0; int[] result = new int[nums.length]; int index = result.length - 1; while (left &lt;= right) { if (nums[left] * nums[left] &gt; nums[right] * nums[right]) { result[index--] = nums[left] * nums[left]; ++left; } else { result[index--] = nums[right] * nums[right]; --right; } } return result; }}class Solution { public int[] sortedSquares(int[] nums) { int l = 0; int r = nums.length - 1; int[] res = new int[nums.length]; int j = nums.length - 1; while(l &lt;= r){ if(nums[l] * nums[l] &gt; nums[r] * nums[r]){ res[j--] = nums[l] * nums[l++]; }else{ res[j--] = nums[r] * nums[r--]; } } return res; }} 12345678910111213141516class Solution { public int[] sortedSquares(int[] nums) { int start = 0, end = nums.length - 1; int[] result = new int[nums.length]; for (int i = nums.length - 1; i &gt;= 0; i--) { if (Math.pow(nums[start], 2) &gt; Math.pow(nums[end], 2) ) { result[i] = (int)Math.pow(nums[start], 2) ; start++; } else { result[i] = (int)Math.pow(nums[end], 2) ; end--; } } return result; }} 参考文章 https://leetcode-cn.com/problems/squares-of-a-sorted-array/submissions/","link":"/2021/11/05/algorithm/algorithm/algorithm-4/"},{"title":"骆驼运输香蕉问题","text":"总共有3000只香蕉，有一只骆驼每一次只能带1000只香蕉，每1公里吃1只香蕉，没有香蕉吃它是不肯走的，A-B 点距离1000公里， 如果这个骆驼要从A点到B点有什么办法可以让更多的香蕉剩下来？如何做到？如何最有效率的运最多的香蕉到B点？ 思路如果直接运送 1000只 香蕉， 从 A 到 B 点， 到达后， 剩余香蕉为 ０.设置一个中转站， 从Ａ到中转站需要消耗５００个香蕉，再回到A点又消耗了５００个， －－＞ 至少需要２个中转站 中转站 把香蕉放到中转站，再回去取香蕉 中转站越少越好 （每多设置一个中转站，消耗越多，骆驼吃的越多） 中转站至少两个 设置两个中转站， 每次从A 到中转站 M， 运送1000只， 需要走3次， 返回A点需要2 次 ，一共走五次。此时M中转站，应该有 2000 只香蕉。为什么？ A 到 M 的距离未知，是变化的， 设为 x. 为了让骆驼物尽其用，每一次都需要运送1000 只香蕉。 M中转站 可能有 1000 或 2000 香蕉 （损耗多少是不知道的） 假设M 有 1000 只 香蕉， 直接从M到B点就可以了。 但是此时只有一个中转站，已分析过，一个中转站是不行的。 所以，M 剩余 2000 是最划算的。 从M 到 N , 需要2次， 返回 1 次, 总共 3次.中转站N,剩余1000 香蕉是最划算的， 可一次从N 到 B. 计算x + y + z = 10005x=1000 –&gt; x=2003y=100 —&gt; x=333.3剩余距离：z=1000-x-y=467 转载https://blog.csdn.net/guanliangliang/article/details/6534761分析这个问题，我们先从初始情况开始，假设走X公里后停下，将剩余香蕉运输过来。 则可以得出剩余香蕉数量为 3000 – 5X，为什么是5呢，因为骆驼往返，总共需要走5次。 同时，由于骆驼一次运输1000只香蕉，所以这个5，只有在剩余香蕉超过2000只的时候才成立，那很容易得出一个不等式，就是3000-5X&lt;2000，求出X=200,。 也就是说，骆驼拖着香蕉，走了200公里，还剩2000只。 等到只剩2000只的时候，骆驼只要一个来回就可以把香蕉全部拖走，所以，走X公里后，剩余香蕉数量为 2000 – 3X，2000-3X &gt; 1000 得出 X = 333 还剩1000只的时候，骆驼一直拖着就行了，目前已经走了200+333=533公里，剩余距离为1000-533=447，所需再消耗447只香蕉，就能到达目的地，剩余香蕉数量为553. 参考文章 https://blog.csdn.net/guanliangliang/article/details/6534761","link":"/2021/10/29/algorithm/algorithm/algorithm-camel-banana/"},{"title":"轮转数组","text":"给你一个数组，将数组中的元素向右轮转 k 个位置，其中 k 是非负数。 12345678910111213141516示例 1:输入: nums = [1,2,3,4,5,6,7], k = 3输出: [5,6,7,1,2,3,4]解释:向右轮转 1 步: [7,1,2,3,4,5,6]向右轮转 2 步: [6,7,1,2,3,4,5]向右轮转 3 步: [5,6,7,1,2,3,4]示例 2:输入：nums = [-1,-100,3,99], k = 2输出：[3,99,-1,-100]解释: 向右轮转 1 步: [99,-1,-100,3]向右轮转 2 步: [3,99,-1,-100] 方法一：使用额外的数组我们可以使用额外的数组来将每个元素放至正确的位置。用 nn 表示数组的长度，我们遍历原数组，将原数组下标为 ii 的元素放至新数组下标为 (i+k)\\bmod n(i+k)modn 的位置，最后将新数组拷贝至原数组即可。 1234567891011class Solution { public void rotate(int[] nums, int k) { int n = nums.length; int[] newArr = new int[n]; for (int i = 0; i &lt; n; ++i) { newArr[(i + k) % n] = nums[i]; } System.arraycopy(newArr, 0, nums, 0, n); }} 复杂度分析 时间复杂度： O(n)O(n)，其中 nn 为数组的长度。空间复杂度： O(n)O(n)。 方法二：环状替换方法一中使用额外数组的原因在于如果我们直接将每个数字放至它最后的位置，这样被放置位置的元素会被覆盖从而丢失。因此，从另一个角度，我们可以将被替换的元素保存在变量 \\textit{temp}temp 中，从而避免了额外数组的开销。 我们从位置 00 开始，最初令 \\textit{temp}=\\textit{nums}[0]temp=nums[0]。根据规则，位置 00 的元素会放至 (0+k)\\bmod n(0+k)modn 的位置，令 x=(0+k)\\bmod nx=(0+k)modn，此时交换 \\textit{temp}temp 和 \\textit{nums}[x]nums[x]，完成位置 xx 的更新。然后，我们考察位置 xx，并交换 \\textit{temp}temp 和 \\textit{nums}[(x+k)\\bmod n]nums[(x+k)modn]，从而完成下一个位置的更新。不断进行上述过程，直至回到初始位置 00。 容易发现，当回到初始位置 00 时，有些数字可能还没有遍历到，此时我们应该从下一个数字开始重复的过程，可是这个时候怎么才算遍历结束呢？我们不妨先考虑这样一个问题：从 00 开始不断遍历，最终回到起点 00 的过程中，我们遍历了多少个元素？ 由于最终回到了起点，故该过程恰好走了整数数量的圈，不妨设为 aa 圈；再设该过程总共遍历了 bb 个元素。因此，我们有 an=bkan=bk，即 anan 一定为 n,kn,k 的公倍数。又因为我们在第一次回到起点时就结束，因此 aa 要尽可能小，故 anan 就是 n,kn,k 的最小公倍数 \\text{lcm}(n,k)lcm(n,k)，因此 bb 就为 \\text{lcm}(n,k)/klcm(n,k)/k。 这说明单次遍历会访问到 \\text{lcm}(n,k)/klcm(n,k)/k 个元素。为了访问到所有的元素，我们需要进行遍历的次数为其中 \\text{gcd}gcd 指的是最大公约数。 我们用下面的例子更具体地说明这个过程： 12nums = [1, 2, 3, 4, 5, 6]k = 2 如果读者对上面的数学推导的理解有一定困难，也可以使用另外一种方式完成代码：使用单独的变量 \\textit{count}count 跟踪当前已经访问的元素数量，当 \\textit{count}=ncount=n 时，结束遍历过程。 12345678910111213141516171819202122class Solution { public void rotate(int[] nums, int k) { int n = nums.length; k = k % n; int count = gcd(k, n); for (int start = 0; start &lt; count; ++start) { int current = start; int prev = nums[start]; do { int next = (current + k) % n; int temp = nums[next]; nums[next] = prev; prev = temp; current = next; } while (start != current); } } public int gcd(int x, int y) { return y &gt; 0 ? gcd(y, x % y) : x; }} 复杂度分析 时间复杂度：O(n)O(n)，其中 nn 为数组的长度。每个元素只会被遍历一次。空间复杂度：O(1)O(1)。我们只需常数空间存放若干变量。 方法三：数组翻转该方法基于如下的事实：当我们将数组的元素向右移动 kk 次后，尾部 k\\bmod nkmodn 个元素会移动至数组头部，其余元素向后移动 k\\bmod nkmodn 个位置。 该方法为数组的翻转：我们可以先将所有元素翻转，这样尾部的 k\\bmod nkmodn 个元素就被移至数组头部，然后我们再翻转 [0, k\\bmod n-1][0,kmodn−1] 区间的元素和 [k\\bmod n, n-1][kmodn,n−1] 区间的元素即能得到最后的答案。 我们以 n=7n=7，k=3k=3 为例进行如下展示： 123456789101112131415161718class Solution { public void rotate(int[] nums, int k) { k %= nums.length; reverse(nums, 0, nums.length - 1); reverse(nums, 0, k - 1); reverse(nums, k, nums.length - 1); } public void reverse(int[] nums, int start, int end) { while (start &lt; end) { int temp = nums[start]; nums[start] = nums[end]; nums[end] = temp; start += 1; end -= 1; } }} 复杂度分析 时间复杂度：O(n)O(n)，其中 nn 为数组的长度。每个元素被翻转两次，一共 nn 个元素，因此总时间复杂度为 O(2n)=O(n)O(2n)=O(n)。空间复杂度：O(1)O(1)。 动画演示 ## 参考文章","link":"/2021/11/10/algorithm/algorithm/algorithm-reverse-array/"},{"title":"16辆摩托车，每辆最多可以跑100km，如果他们可以相互配合，朝同一个方向直线行驶，那么一起最多可以跑多远？","text":"1 辆车 100 km. 2 辆车假设只有两辆车， 最多行驶 100 * 1/2 + 100 = 150 km (两辆车同时出发，行驶50 km后， 将一辆车的油加到另一辆，则这辆车可以在行使100 km) 3 辆车假设有a,b,c三辆车， 行驶 1/3 * 100后， 三辆车都剩下 2/3 的油， 将C的油加到a,b, 则 a,b 满状态，重新出发（问题转化为两辆车）。总路程为： 100 * 1/3 + 100 * 1/2 + 100 4 辆车a, b, c, d 4辆车， 行驶 1/4 后， d 的油加到 a,b,c, 转化为 3辆车。总路程为：100 * 1/4 + 100 * 1/3 + 100 * 1/2 + 100 16 辆车总路程为：100 * （1/16 + 1/15 +…+ 1/3 + 1/2 + 1 ） 转载 https://www.zhihu.com/question/494793411/answer/2192292359这应该是一个程序算法题，按照算法去写逻辑列式子比较费劲。我是这样思考的，一辆车可以用绳子牵引着其余车子行驶，直到这辆车的燃油耗尽，接着是下一辆继续按照这个模式行驶。 这样就出现了，可以每次都用1辆车去牵引剩余的车，也可以同时2辆、3辆。。。去牵引剩余的车，但是只要出现有2辆以上车在同一段路上同时耗费燃油行驶，那必然有一段路程是重复行走的，也就是说有燃油浪费在了“不必要”的路程上，那么从能量转化的角度，路程必然不是最大化的。 所以答案就只能是每次都是1辆车去牵引剩余的车。最多可以行驶：（1/16+1/15+…+1/3+1/2+1）*100=338.07km 参考文章 https://www.zhihu.com/question/494793411/answer/2192292359","link":"/2021/10/29/algorithm/algorithm/algorithm-motorcycles/"},{"title":"最长上升子序列问题（LIS）","text":"给定n个整数A1,A2….An,按从左到右的顺序选出尽量多的整数，组成一个上升子序列（子序列可以理解为：删除0或多个数，其他树的顺序不变）。 例如： 序列1，6，2，3，7，5，可以选出1，2，3，5，也可以选出1，6，7，但是前者更长。 选出的上升子序列中相邻元素不能相等。 关于求LIS有两种常用的算法： 暴力找a[j] O（n2） 用二分来找a[j] O（nlogn） 视频图解 最长上升子序列 视频图解 最长上升子序列 动态规划表格 力扣官方分析 1234567891011121314151617181920class Solution { public int lengthOfLIS(int[] nums) { if (nums.length == 0) { return 0; } int[] dp = new int[nums.length]; dp[0] = 1; int maxans = 1; for (int i = 1; i &lt; nums.length; i++) { dp[i] = 1; for (int j = 0; j &lt; i; j++) { if (nums[i] &gt; nums[j]) { dp[i] = Math.max(dp[i], dp[j] + 1); } } maxans = Math.max(maxans, dp[i]); } return maxans; }} 123456789101112131415161718192021222324252627282930public class Test7 { public static void main(String[] args) { int[] a = {0, 1, 6, 2, 3, 7, 5}; maxIncreaseList(a); int[] b = {0, 10, 9, 2, 5, 3, 7, 101, 18}; maxIncreaseList(b); } private static void maxIncreaseList(int[] a) { int[] dp = new int[a.length]; dp[1] = 1; // dp[i] = max{dp[j] + 1} 0 &lt;= j&lt; i for (int i = 2; i &lt;= a.length - 1; i++) { dp[i] = 1; for (int j = 1; j &lt; i; j++) { if (a[i] &gt; a[j]) { dp[i] = Math.max(dp[j] + 1, dp[i]); } } } int max = 1; for (int i = 1; i &lt;= a.length - 1; i++) { if (dp[i] &gt; max) { max = dp[i]; } } System.out.println(max); }} 最长不下降子序列 https://www.pianshen.com/article/6551264924/ https://www.cnblogs.com/itlqs/p/5743114.html 参考文章 https://blog.csdn.net/ltrbless/article/details/81318935 https://blog.csdn.net/weixin_43731933/article/details/96179727 https://www.cnblogs.com/GodA/p/5180560.html","link":"/2021/11/22/algorithm/algorithm_dynamic/algorithm-dynamic-lis/"},{"title":"【动态规划】 n个矩阵连乘问题","text":"递归算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.example.demo;public class Test5 { static int[] r = {0, 5, 20, 50, 1, 100}; //r1,r2,r3,r4,r5 static int[][] dp = new int[30][30]; // dp[i][j] --&gt; 矩阵 Mi * Mi+1 * Mi+2 ... * Mj (i&lt;j) static int[][] com = new int[30][30]; // dp[i][j] --&gt; 矩阵 Mi ~ Mj 相乘的组合点 k. 即： Mij = Mi * ... Mk + Mk+1 * ... Mj static int n = 4;// public static void main(String[] args) { System.out.println(minValue(1, 4)); for (int i = 1; i &lt;= n; i++) { System.out.println(); for (int j = 1; j &lt;= n; j++) System.out.printf(com[i][j] + &quot; &quot;); } System.out.println(); combine(1, 4); } static int minValue(int i, int j) { if (i == j) { dp[i][j] = 0; return 0; } if (dp[i][j] != 0) { return dp[i][j]; } if (j == i + 1) { com[i][j] = i; dp[i][i + 1] = r[i] * r[i + 1] * r[i + 2]; return r[i] * r[i + 1] * r[i + 2]; } // i&lt; j int min = Integer.MAX_VALUE; for (int k = i; k &lt; j; k++) { int currentValue = minValue(i, k) + minValue(k + 1, j) + r[i] * r[k + 1] * r[j + 1]; if (min &gt; currentValue) { min = currentValue; com[i][j] = k; } } dp[i][j] = min; return min; } //输出算法 static void combine(int i, int j) { if (i == j) return; combine(i, com[i][j]); combine(com[i][j] + 1, j); System.out.printf(&quot;M[&quot; + i + com[i][j] + &quot;]&quot;); System.out.printf(&quot; and M[&quot; + (com[i][j] + 1) + &quot;&quot; + j + &quot;]&quot;); System.out.println(); }} 输出： 非递归算法123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.demo;public class Test5 { static int[] r = {0, 5, 20, 50, 1, 100}; //r1,r2,r3,r4,r5 static int[][] m = new int[30][30]; // static int[][] com = new int[30][30]; // static int n = 4;// public static void main(String[] args) { for (int i = 1; i &lt; n; i++) { m[i][i] = 0; com[i][i + 1] = i; m[i][i + 1] = r[i] * r[i + 1] * r[i + 2]; } for (int s = 2; s &lt; n; s++) { for (int i = 1; i &lt; n - s + 1; i++) { int j = i + s; // i: 起始位置 j:终点位置 m[i][j] = m[i][i] + m[i + 1][j] + r[i] * r[i + 1] * r[j + 1]; com[i][i] = i; for (int k = i + 1; k &lt; j; k++) { int t = m[i][k] + m[k + 1][j] + r[i] * r[k + 1] * r[j + 1]; if (t &lt; m[i][j]) { m[i][j] = t; com[i][j] = k; } } } } System.out.println(m[1][n]); for (int i = 1; i &lt;= 4; i++) { for (int j = 1; j &lt;= 4; j++) { System.out.printf(com[i][j] + &quot; &quot;); } System.out.println(); } }} 参考文章","link":"/2021/11/19/algorithm/algorithm_dynamic/algorithm-dynamic-matrix-multiplication/"},{"title":"【动态规划】最大子段和","text":"一般思维 1234567891011121314151617181920212223242526public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int N = 6; public static void main(String[] args) { int maxSum = 0; for (int i = 1; i &lt;= N; i++) { //i : 表示每个子段的个数 for (int j = 1; j + i - 1 &lt;= N; j++) { //j : 起始位置 end: 结束位置 int end = i + j - 1; if (end &lt;= N) { // 计算 从j 开始， 包含i个元素的 字段 的 和 int temp = 0; for (int k = j; k &lt;= end; k++) { temp += a[k]; } maxSum = Math.max(maxSum, temp); } } } System.out.println(maxSum); }} 充分利用已经得到的结果，避免重复计算，节省计算时间 123456789101112131415161718192021222324252627public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int[][] dp = new int[MAX][MAX]; //保存从 j 到 i+j-1 子段的和； j :开始位置， i: 子段的长度 static int N = 6; public static void main(String[] args) { int maxSum = 0; for (int i = 1; i &lt;= 6; i++) { dp[1][i] = a[i]; } for (int i = 2; i &lt;= N; i++) { for (int j = 1; j &lt;= N; j++) { int k = i + j - 1; if (k &lt;= N) { dp[i][j] = dp[i - 1][j] + a[k]; if (dp[i][j] &gt; maxSum) { maxSum = dp[i][j]; } } } } System.out.println(maxSum); }} 动态规划解决： Kadane算法 （ref: https://zhuanlan.zhihu.com/p/107503435） 扫描一次整个数列的所有数值，在每一个扫描点计算以该点数值为结束点的子数列的最大和（ 正数和 ）。 该子数列由两部分组成：以前一个位置为结束点的最大子数列、该位置的数值。 因为该算法用到了“最佳子结构”（以每个位置为终点的最大子数列都是基于其前一位置的最大子数列计算得出）， 该算法可看成动态规划的一个例子。 将长度为n的目标序列存储在一个数组中,设为a。设数组b为如下 当b[j-1] &gt; 0时 b[j] = b[j-1] + a[j],否则b[j] = a[j]。由此可得计算b[j]的动态规划递归方程 b[j] = max{b[j - 1] + a[j],a[j]}, 1 &lt;= j &lt;= n 123456789101112131415161718192021public class Test6 { static int MAX = 10; static int[] a = {0, -2, 11, -4, 13, -5, -2}; static int N = 6; public static void main(String[] args) { int sum = 0; int this_sum = 0; for (int i = 1; i &lt;= N; i++) { if (this_sum &gt; 0) this_sum = this_sum + a[i]; else this_sum = a[i]; sum = Math.max(this_sum, sum); } System.out.println(sum); }} 参考文章 https://blog.csdn.net/weixin_40170902/article/details/80585218 https://blog.csdn.net/qq_38538733/article/details/76579602","link":"/2021/11/22/algorithm/algorithm_dynamic/algorithm-dynamic-max-sub-sum/"},{"title":"有一栋100层高楼,从某一层开始扔下的玻璃球刚好摔坏,现有两个玻璃球,试用最简便的方法确定这个恰好摔坏玻璃球的那层.","text":"二分法第一颗玻璃球： 从50层开始尝试， 75 -&gt; 87 -&gt; 93 -&gt; 96 -&gt; 98 -&gt; 99 -&gt; 100第二颗： 若在50层碎了，需要从第一层开始一层一层的尝试 粗调，细调 第一颗玻璃球： 从10层开始尝试， 20 , 30 ,40, 50, 60, 70, 80, 90. 第二颗： 第一层开始一层一层的尝试 最优算法：第一颗玻璃球： 14 27 39 50 60 69 77 84 90 95 99 100第二颗： 第一层开始一层一层的尝试 A:这个形象一点就像显微镜的两个调焦螺旋，一个粗调确定大范围，一个微调确定具体楼层。 B：不管什么情况，最终粗调微调的次数总和不变。 我们用①号球确定范围，②号球确定楼层。 (一)假设第一次范围为k层且①号碎了，那么①号球1次，②号球k-1次，合计1+k-1=k次。(二)假设①号球第二次才碎，那么①号球2次，为保证总次数不变②号球要丢k-2次，相当于这个范围有k-1层，情况以此类推。最糟糕情况就是要把100层都覆盖，那么所有次的范围之和加上最后的微调次数要≥98(第一层没高度，无意义，第100层也不用丢，所以是100-2)k+(k-1)+(k-2)+(k-3)+……+3+2+1≥98等差数列求和得k*(k+1)/2≥98，解得k=14，也就是最多14次，也就是第一个范围内有14层。 注意:k在这里即是总次数，也是第一次的层数。①号球具体丢的层数就是15层，28层，40层…… 参考文章 https://www.zhihu.com/question/31855632","link":"/2021/11/15/algorithm/algorithm/alogrithm-5/"},{"title":"最长递增子序列的个数","text":"最长递增子序列 的进阶版本 参考文章 https://leetcode-cn.com/problems/number-of-longest-increasing-subsequence/","link":"/2021/11/24/algorithm/algorithm_dynamic/algorithm-lis-2/"},{"title":"动态规划","text":"基本思想动态规划方法的基本思想是，把求解的问题分成许多阶段或多个子问题，然后按顺序求解各子问题。最后一个子问题就是初始问题的解。 由于动态规划的问题有重叠子问题的特点，为了减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 动态规划=贪婪策略+递推(降阶)+存储递推结果 空间换取时间 递归算法效率低的主要原因是因为进行了大量的重复计算。而动态规划的基本动机就是充分利用重叠子问题(Overlapping subproblems)。 因为动态规划将以前（子问题）计算过的结果都记录下来，遇到使用子问题结果的时候只需查表。 动态规划是一种用空间换取时间的方法。 因此，动态规划常常因为空间消耗太大而难以实现。 主要概念 阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节即称为阶段。 状态：某一阶段的出发位置称为状态。通俗地说状态是对问题在某一时刻的进展情况的数学描述。 决策：从某阶段的一个状态演变到下一个阶段某状态的选择。 状态转移方程：根据上一阶段的状态和决策导出本阶段的状态。这就像是“递推”。 例: 数塔问题 从顶部出发，在每一结点可以选择向左走或是向右走，一直走到底层，要求找出一条路径，使路径上的数值和最大。 阶段：每行就是一个阶段； 状态：d[i][j]，即取第i行，第j个数能够达到的最大值； 决策：取第i行第j个数，则可以有两种方案：取第i-1行第j-1个数或取第i-1行第j个数后再取第i行第j个数； 状态转移方程：d[i][j] = max (d[i+1][j]，d[i+1][j+1]) + data[i][j]；表示取第i行第j个数所能达到的最大和； 123456789int a[100][100], f[100][100];int max(int i,int j,int n){ int left,right; if ((i==n)||(j==n)) f[i][j] =a[i][j]; if (f[i][j] != -1) return f[i][j]; left=max(i+1,j,n); //左边 right=max(i+1,j+1,n); //右边 return (f[i][j] = (left&gt;right)? (left+a[i][j]):(right+a[i][j]));} 适合解决的问题的性质 动态规划算法的问题及决策应该具有两个性质：最优化原理、无后向性。 最优化原理(或称为最佳原则、最优子结构)； 无后向性(无后效性)：某阶段状态一旦确定以后，就不受这个状态以后决策的影响。即某状态以后的过程不会影响以前的状态，只与当前状态有关。 能够体现动态规划优点的性质： 子问题重叠性质； 动态规划用空间换取时间，在有大量重叠子问题的时候其优势才能充分体现出来。 例：数塔问题 最优化原理(最优子结构)9-&gt;12-&gt;10-&gt;18-&gt;10显然12-&gt;10-&gt;18-&gt;10也是12到最后一层的最大和…… 无后效性如，计算到12的最大和只要考虑到10的最大和与到6的最大和哪个更大，而不要考虑到10的最大和或者到6的最大和具体是哪几个数构成的。设计步骤设计动态规划算法的基本步骤设计一个标准的动态规划算法的步骤： 划分阶段； 选择状态； 确定决策并写出状态转移方程。实际应用当中的简化步骤： 分析最优解的性质，并刻划其结构特征。 递推地定义最优值。 以自底向上的方式或自顶向下的记忆化方法(备忘录法)计算出最优值。 根据计算最优值时得到的信息，构造问题的最优解。 例题： 数塔问题 //从顶部出发，在每一结点可以选择向左走或是向右走，一直走到底层，要求找出一条路径，使路径上的数值和最大。 12345678910111213141516171819public class Test1 { static int[][] result = new int[5][5]; public static int maxSum(int i, int j, int[][] data) { if (i == data.length - 1 || j == data.length - 1) { result[i][j] = data[i][j]; } if (result[i][j] != 0) { return result[i][j]; } return result[i][j] = Math.max(maxSum(i + 1, j, data), maxSum(i + 1, j + 1, data)) + data[i][j]; } public static void main(String[] args) { int[][] data = {{9}, {12, 15}, {10, 6, 8}, {2, 18, 9, 5}, {19, 7, 10, 4, 16}}; maxSum(0, 0, data); System.out.println(result[0][0]); }} 12345678910111213141516171819202122232425262728293031323334353637383940public class Test1 { static int[][] dp = new int[5][5]; static int n = 5; public static void maxSum(int[][] data) { // dp初始化 for (int i = 0; i &lt; n; ++i) { dp[n - 1][i] = data[n - 1][i]; } int temp_max; for (int i = n - 2; i &gt;= 0; --i) { for (int j = 0; j &lt;= i; ++j) { // 使用递推公式计算dp的值 temp_max = Math.max(dp[i + 1][j], dp[i + 1][j + 1]); dp[i][j] = temp_max + data[i][j]; } } } private static void printPath(int[][] data) { System.out.printf(&quot;最大路径： &quot; + data[0][0] + &quot;&quot;); int j = 0; for (int i = 1; i &lt; 5; ++i) { int node_value = dp[i - 1][j] - data[i - 1][j]; /* 如果node_value == dp[i][j]则说明下一步应该是data[i][j]；如果node_value == dp[i][j + 1]则说明下一步应该是data[i][j + 1]*/ if (node_value == dp[i][j + 1]) ++j; System.out.printf(&quot;-&gt;&quot; + data[i][j]); } System.out.println(); } public static void main(String[] args) { int[][] data = {{9}, {12, 15}, {10, 6, 8}, {2, 18, 9, 5}, {19, 7, 10, 4, 16}}; maxSum(data); System.out.println(&quot;最大路径和： &quot; + dp[0][0]); printPath(data); }} 资源分配问题设有资源n(n为整数),分配给m个项目,gi(x)为第i个项目分得资源x(x为整数)所得到的利润。 求总利润最大的资源分配方案，也就是解下列问题： 12max z=g1(x1)+ g2(x2)+……gm(xm)x1+x2+x3+……xm = n，0≤xi≤n，i=1,2,3,……,m 函数gi(x)以数据表的形式给出。 例如：现有7万元投资到A，B，C 三个项目，利润见表,问题：求总利润最大的资源分配方案。 划分阶段或找到子问题；每个阶段增加一个项目，考察投资利润情况。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Test2 { static double[][] v = { {0, 0.11, 0.13, 0.15, 0.21, 0.24, 0.3, 0.35}, {0, 0.12, 0.16, 0.21, 0.23, 0.25, 0.24, 0.34}, {0, 0.08, 0.12, 0.2, 0.24, 0.26, 0.3, 0.35}}; static int m = 3; static int n = 7; public static void main(String[] args) { double[] q = new double[10]; //原始数据（逐行使用） double[] f = new double[10];//当前最大收益情况 double[] temp = new double[10]; //正在计算的最大收益 int[][] a = new int[10][10]; //前i个项目投资j获得最大利润时，给第i个项目分配的资源数(m*(n+1)维) int[] gain = new int[10];//在不同投资数下获最大利润时第i个工程所得资源数。 // 全部资源用于A(第一个项目) q = f = v[0]; for (int j = 0; j &lt;= n; j++) { a[1][j] = j; } // 第二阶段： 全部资源用于两个项目 // 第三阶段： 全部资源用于三个项目 for (int k = 2; k &lt;= m; k++) { for (int j = 0; j &lt;= n; j++) { temp[j] = q[j]; a[k][j] = 0; } //赋值， 第二/三个项目的收益情况 (数组下标从0开始，故此处k-1) q = v[k - 1]; for (int j = 0; j &lt;= n; j++) { for (int i = 0; i &lt;= j; i++) { if (f[j - i] + q[i] &gt; temp[j]) { temp[j] = f[j - i] + q[i]; a[k][j] = i; } } } // 更新 当前最大收益情况 for (int j = 0; j &lt;= n; j++) f[j] = temp[j]; } int rest = n; for (int i = m; i &gt;= 1; i--) { gain[i] = a[i][rest]; rest = rest - gain[i]; } for (int i = 1; i &lt;= m; i++) { System.out.print(gain[i] + &quot; &quot;); } System.out.println((f[n])); }} 资源分配问题二资源分配问题是将数量一定的一种或若干种资源(原木料、资金、设备或劳动力等)合理地分配给若干个使用者,使总收益最大。 例如,某公司有3个商店A、B、C，拟将新招聘的5名员工分配给这3个商店，各商店得到新员工后每年的赢利情况如表所示,求分配给各商各多少员工才能使公司的赢利最大?解析： 其实就是完全背包的变形 用dp[i][j]表示为前i个商店共分配j个人时盈利的最大值，状态转移方程如下（k表示为i商店分配的人数）： dp[i][j] = max(dp[i][j], dp[i-1][j-k] + c[i][k]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.example.demo;public class Test3 { public static void main(String[] args) { int[][] data = { {0, 3, 7, 9, 12, 13}, {0, 5, 10, 11, 11, 11}, {0, 4, 6, 11, 12, 12} }; int m = 3; int n = 5; int[] q = new int[10]; //原始数据（逐行使用） int[] f = new int[10];//当前最大收益情况 int[] temp = new int[10]; //正在计算的最大收益 int[][] a = new int[10][10]; //前i个项目投资j获得最大利润时，给第i个项目分配的资源数(m*(n+1)维) int[] gain = new int[10];//在不同投资数下获最大利润时第i个工程所得资源数。 // 只分配 A // k =1 q = data[0]; f = data[0]; for (int k = 2; k &lt;= 3; k++) { q = data[k - 1]; for (int j = 0; j &lt;= n; j++) { temp[j] = q[j]; } for (int j = 0; j &lt;= n; j++) { for (int i = 0; i &lt;= j; i++) { if (f[j - i] + q[i] &gt; temp[j]) { temp[j] = f[j - i] + q[i]; } } } for (int i = 0; i &lt;= n; i++) { f[i] = temp[i]; } } System.out.println(f[n]); }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.example.demo;public class Test3 { static int MAX = 30; static int[][] c = new int[MAX][MAX]; static int[][] dp = new int[MAX][MAX]; // dp[i][j]表示前i个车间共分配j个人 static int[][] pnum = new int[MAX][MAX]; static int n = 3, m = 5; public static void main(String[] args) { int[][] data = { {3, 7, 9, 12, 13}, {5, 10, 11, 11, 11}, {4, 6, 11, 12, 12} }; for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= m; j++) c[i][j] = data[i - 1][j - 1]; System.out.printf(&quot;max = %d\\n&quot;, DP_source()); print_allocate(); } static int DP_source() { // 初始化 for (int i = 0; i &lt;= n; i++) dp[i][0] = 0; for (int i = 0; i &lt;= m; i++) dp[0][i] = 0; int sel_num = 0; // 记录第i个车间分配j人时应分配的人数 for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= m; j++) { sel_num = 0; // 枚举当前车间分配k人时的最大值 for (int k = 0; k &lt;= j; k++) { if (dp[i][j] &lt; dp[i - 1][j - k] + c[i][k]) { // 更新答案 dp[i][j] = dp[i - 1][j - k] + c[i][k]; sel_num = k; } } // 循环结束后找到为前i个车间共分配j人时第i个车间应分配的人数 pnum[i][j] = sel_num; } } return dp[n][m]; } static void print_allocate() // 输出每个车间应分配的人数 { int r, s; s = pnum[n][m]; // 最后一个车间应该选择的人数 r = m - s; // 剩余人数 for (int i = n; i &gt;= 1; i--) { System.out.printf(&quot;%d 商店分配 %d 人\\n&quot;, i, s); s = pnum[i - 1][r]; r -= s; } }} 0-1背包问题（knapsack problem） 一个小偷面前有一堆（n个）财宝，每个财宝有重量w和价值v两种属性，而他的背包只能携带一定重量的财宝（Capacity），在已知所有财宝的重量和价值的情况下，如何选取财宝，可以最大限度的利用当前的背包容量，取得最大价值的财宝（或求出能够获取财宝价值的最大值）。 “填二维表”的动态规划方法1234567891011121314151617181920212223242526public class Test4 { static int MAX = 20; static int[] value = {0, 1, 6, 18, 22, 28}; //物品价值 static int[] weight = {0, 1, 2, 5, 6, 7}; //物品重量 static int[][] dp = new int[MAX][MAX]; // dp[i][j]表示容量为j, 前i个物品的总价值。 static int[] result = new int[MAX]; // 选择哪些物品 static int n = 5;//五种物品 static int C = 11; //背包容量 public static void main(String[] args) { //背包容量从 1 开始递增 到 11 for (int i = 1; i &lt;= 5; i++) { for (int j = 1; j &lt;= C; j++) { if (weight[i] &gt; j) { dp[i][j] = dp[i - 1][j]; } else { dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]); } } } System.out.println(dp[n][C]); }} 空间优化 / 填一维表”的动态规划方法 https://blog.csdn.net/weixin_41162823/article/details/87878853 dp[j] = max(dp[j], dp[j−w[i]]+v[i]) 上述状态表示，我们需要用二维数组，但事实上我们只需要一维的滚动数组就可以递推出最终答案。考虑到用dp[j]来保存每层递归的值，由于我们求dp[i][j] 的时候需要用到的是dp[ i-1 ][j] 和 dp[i-1][j-w[i]] 于是可以知道，只要我们在求 dp[j] 时不覆盖 dp[ j - w[i] ]，那么就可以不断递推至所求答案。所以我们采取倒序循环，即 v = m（m为背包总容积）伪代码如下： 123 for i = 1..N for v = V..0 f[ v ] = max{ f[ v ],f[ v-w[i] ]+val[ i ] }; ref: https://zhuanlan.zhihu.com/p/30959069 完全背包问题: 完全背包（unbounded knapsack problem）与01背包不同就是每种物品可以有无限多个：一共有N种物品，每种物品有无限多个，第i（i从1开始）种物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限 W 的情况下，能够装入背包的最大价值是多少？ 分析一 ref: https://www.cnblogs.com/mfrank/p/10803417.html 跟01背包一样，完全背包也是一个很经典的动态规划问题，不同的地方在于01背包问题中，每件物品最多选择一件，而在完全背包问题中，只要背包装得下，每件物品可以选择任意多件。从每件物品的角度来说，与之相关的策略已经不再是选或者不选了，而是有取0件、取1件、取2件…直到取⌊T/Vi⌋（向下取整）件。 12345# k为装入第i种物品的件数, k &lt;= j/w[i]dp[i][j] = max{(dp[i-1][j-k*w[i]] + k*v[i]) } ( 0 &lt;= k*v[i] &lt;= W)dp[0][j] = 0dp[i][0] = 0 我们通过对0/1背包的思路加以改进，就得到了完全背包的一种解法，这种解法时间复杂度为O（n^3），空间复杂度为O（n^2）。 时间优化时间优化：根据上述 dp[i][j] 的定义，其为前 i 种物品恰好放入容量为 v 的背包的最大权值。根据上述状态转移方程可知，我们假设的是子结果dp[i-1][j-k*w[i]] 中并没有选入第 i 种物品，所以我们需要逆序遍历（像0/1背包一样）来确保该前提；但是我们现在考虑“加选一件第 i 种物品”这种策略时，正需要一个可能已经选入第 i 种物品的子结果dp[i-1][j-k*w[i]]，于是当我们顺序遍历时，就刚好达到该要求。这种做法，使我们省去了一层循环，即第 i 种物品放入的件数k，从而时间复杂度优化为O（n^2）。 空间优化：正如0/1背包的空间优化，上述状态转移方程已经优化为：dp[i][j] = max{dp[i-1][j], (dp[i][j-k*w[i]] + k*v[i]) } ( 0 &lt;= k*v[i] &lt;= W) dp[i][j]表示将前i种物品装进限重为j的背包可以获得的最大价值, 0&lt;=i&lt;=N, 0&lt;=j&lt;=W 初始状态也是一样的，我们将dp[0][0…W]初始化为0，表示将前0种物品（即没有物品）装入书包的最大价值为0。那么当 i &gt; 0 时dp[i][j]也有两种情况： 不装入第i种物品，即dp[i−1][j]，同01背包； 装入第i种物品，此时和01背包不太一样，因为每种物品有无限个（但注意书包限重是有限的），所以此时不应该转移到dp[i−1][j−w[i]]而应该转移到dp[i][j−w[i]]，即装入第i种商品后还可以再继续装入第种商品。 所以状态转移方程为dp[i][j] = max(dp[i−1][j], dp[i][j−w[i]] + v[i]) // j &gt;= w[i] 多重背包： 第i（i从1开始）种物品的重量为w[i]，价值为v[i]。第i种物品最多有Mi件可用在总重量不超过背包承载上限 W 的情况下，能够装入背包的最大价值是多少？ // dp[i][j] : 前i种物品放入一个容量为 j 的背包获得的最大价值//对于第i种物品，我们有k种选择，0 &lt;= k &lt;= M[i] &amp;&amp; 0 &lt;= k * w[i] &lt;= j，即可以选择0、1、2…M[i]个第i种物品，所以递推表达式为：dp[i][j] = max(dp[i][j− k * w[i]]+ k * v[i]) // 0 &lt;= k &lt;= M[i] &amp;&amp; 0 &lt;= k * w[i] &lt;= j 视频： https://www.bilibili.com/video/BV18x411V7fm?from=search&seid=5454260386958297352 https://www.bilibili.com/video/BV1X741127ZM?from=search&seid=17606712350225562747 参考文章 动态规划–资源分配问题 动态规划应用举例—资源分配问题 动态规划之背包问题系列 背包问题九讲 pdf 背包问题-笔记整理 动态规划之背包问题系列 动态规划之01背包问题 0-1背包问题的动态规划算法 背包问题总结（上） 背包问题总结（下） 五大常用算法之二：动态规划算法 经典算法系列：动态规划 经典中的经典算法:动态规划(详细解释,从入门到实践,逐步讲解) 【常见笔试面试算法题12】动态规划算法案例分析 动态规划十大经典案例 常见动态规划题目详解 动态规划算法详解及经典例题 【动态规划】一次搞定三种背包问题 【动态规划】多重背包问题 【动态规划】01背包问题 【动态规划】01背包问题【续】 【动态规划】完全背包问题 动态规划–01背包模型","link":"/2021/11/18/algorithm/algorithm_dynamic/algorithm-dynamic-programming/"},{"title":"求两个字符序列的最长公共字符子序列。","text":"字符序列的子序列是指从给定字符序列中随意地（不一定连续）去掉若干个字符（可能一个也不去掉）后所形成的字符序列。 令给定的字符序列X=“x0,x1,…,xm-1”,序列Y=“y0,y1,…,yk-1”是X的子序列，存在X的一个严格递增下标序列i=i0,i1,…,ik-1,使得对所有的j=0,1,…,k-1,有xi＝yj。 例如，X=“ABCBDAB”,Y=“BCDB”是X的一个子序列。 递归123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.example.demo;public class Test8 { static String[] a = {&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;}; static String[] b = {&quot;B&quot;, &quot;D&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A&quot;}; static int n = a.length; static int m = b.length; static String[] str = new String[n]; static int[][] dp = new int[n + 1][m + 1]; public static void main(String[] args) { int k = lcs_len(n, m); build_lcs(k, n, m); for (String s : str) { System.out.println(s); } } static int lcs_len(int i, int j) { int t1, t2; if (i == 0 || j == 0) { dp[i][j] = 0; } else if (a[i - 1].equals(b[j - 1])) { dp[i][j] = lcs_len(i - 1, j - 1) + 1; } else { t1 = lcs_len(i, j - 1); t2 = lcs_len(i - 1, j); dp[i][j] = Math.max(t1, t2); } return dp[i][j]; } static void build_lcs(int k, int i, int j) { if (i == 0 || j == 0) { return; } if (dp[i][j] == dp[i - 1][j]) { build_lcs(k, i - 1, j); } else if (dp[i][j] == dp[i][j - 1]) { build_lcs(k, i, j - 1); } else { str[k] = a[i - 1]; build_lcs(k - 1, i - 1, j - 1); } }} 非递归1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.demo;public class Test8 { static String[] a = {&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;}; static String[] b = {&quot;B&quot;, &quot;D&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A&quot;}; static int n = a.length; static int m = b.length; static String[] str = new String[n]; static int[][] dp = new int[n + 1][m + 1]; public static void main(String[] args) { int k = lcs_len(); build_lcs(k); for (String s : str) { System.out.println(s); } } static void build_lcs(int k) { int i = n; int j = m; while (k &gt; 0) { if (dp[i][j] == dp[i - 1][j]) { i = i - 1; } else if (dp[i][j] == dp[i][j - 1]) { j = j - 1; } else { k = k - 1; i = i - 1; j = j - 1; str[k] = a[i]; } } } static int lcs_len() { for (int i = 0; i &lt;= n; i++) dp[i][0] = 0; for (int j = 0; j &lt;= m; j++) dp[0][j] = 0; for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= m; j++) { if (a[i - 1].equals(b[j - 1])) { dp[i][j] = dp[i - 1][j - 1] + 1; } else { dp[i][j] = Math.max(dp[i][j - 1], dp[i - 1][j]); } } } return dp[a.length][b.length]; }} 参考文章","link":"/2021/11/25/algorithm/algorithm_dynamic/algorithm-max-pub-sub-sequence/"},{"title":"判断单链表有环","text":"双指针 穷举遍历哈希表缓存快慢指针p1, p2指针从头开始扫描链表。指针p1每次走1步，指针p2每次走2步。如果存在环，则指针p1、p2会相遇；如果不存在环，指针fast遇到NULL退出。 步骤演示： ref: https://blog.csdn.net/mucaoyx/article/details/81395782 原理分析：Q1: 求入环点。Q2: 求环的长度。求环长：从首次相遇节点继续循环前进，直到两个指针第2次相遇。此时，统计出来的前进次数就是环长。 求入环点：首次相遇时，指针p1每次只走一步，走过的距离 D+S1指针p2每次走两步，比p1多走一圈，做过的距离 D + S1 + S2 + S1p2的速度是p1的两倍，p2走过的距离也是p1的两倍，===&gt; 2(D+S1) = D + 2S1 + S2===&gt; D = S2 只要把其中一个指针放回到头节点位置，另一个指针在首次相遇的节点，两个指针每次向前走一步，最终归相遇的节点，就是入环节点。 12345678public class Node { int data; Node next; public Node(int data) { this.data = data; }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class TestLinked { public boolean isCycle(Node head) { if (head.next == null) { return false; } return getSameNode(head) != null; } public Integer getLengthOfCycle(Node head) { if (!isCycle(head)) { return 0; } Node slowNode = getSameNode(head); Node first = slowNode.next; Node second = slowNode.next.next; int i = 1; while (first != second) { i++; first = first.next; second = second.next.next; } return i; } private Node getSameNode(Node node) { Node fastNode = node; Node slowNode = node; while (fastNode != null) { if (fastNode.next != null) { fastNode = fastNode.next.next; } else { fastNode = null; } slowNode = slowNode.next; if (slowNode == fastNode) { return slowNode; } } return null; } public Node getEntranceOfCycle(Node head) { Node fastNode = head; Node slowNode = head; while (fastNode != null) { if (fastNode.next != null) { fastNode = fastNode.next.next; } else { fastNode = null; } slowNode = slowNode.next; if (slowNode == fastNode) { fastNode = head; while (fastNode != slowNode) { fastNode = fastNode.next; slowNode = slowNode.next; } return slowNode; } } return null; } @Test public void testIsCycle() { System.out.println(isCycle(Util.createList())); } @Test public void testGetLengthOfCycle() { System.out.println(getLengthOfCycle(Util.createList())); } @Test public void testGetEntranceOfCycle() { System.out.println(getEntranceOfCycle(Util.createList()).data); }} 1234567891011121314151617181920public class Util { public static Node createList() { Node node1 = new Node(5); Node node2 = new Node(3); Node node3 = new Node(7); Node node4 = new Node(2); Node node5 = new Node(6); Node node6 = new Node(8); Node node7 = new Node(1); node1.next = node2; node2.next = node3; node3.next = node4; node4.next = node5; node5.next = node6; node6.next = node7; node7.next = node4; return node1; }} 参考文章","link":"/2021/11/24/algorithm/algorithm_linkedlist/alogrithm-judge-linkedList-cycle/"},{"title":"dijkstra &amp; 弗洛伊德算法","text":"1 参考文章 图最短路径算法之迪杰斯特拉算法（Dijkstra） 迪杰斯特拉算法 弗洛伊德算法详解及C语言实现","link":"/2021/11/16/algorithm/algorithm_graph/algorithm-dijkstra/"},{"title":"Kruskal","text":"某省调查城镇交通状况，得到现有城镇道路统计表，表中列出了每条道路直接连通的城镇。省政府“畅通工程”的目标是使全省任何两个城镇间都可以实现交通（但不一定有直接的道路相连，只要互相间接通过道路可达即可）。问最少还需要建设多少条道路？ 测试输入包含若干测试用例。每个测试用例的第1行给出两个正整数，分别是城镇数目N ( &lt; 1000 )和道路数目M；随后的M行对应M条道路，每行给出一对正整数，分别是该条道路直接连通的两个城镇的编号。为简单起见，城镇从1到N编号。注意:两个城市之间可以有多条道路相通,也就是说3 31 21 22 1这种输入也是合法的当N为0时，输入结束，该用例不被处理。 对每个测试用例，在1行里输出最少还需要建设的道路数目。 4 21 34 33 31 21 32 35 21 23 5999 00output 102998Huge input, scanf is recommended. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.io.*;import java.util.*;public class Main{ public static int pre[]; public static int m,n; public static Edge []edges; static class Edge implements Comparable&lt;Edge&gt;{ public int u,v,w; public int compareTo(Edge e){ return this.w-e.w; } } public static int find(int x){ int r = x; while(pre[r]!=r) r=pre[r]; int j=x,tmp; while(j!=r) { tmp = pre[j]; pre[j] = r; j = tmp; } return r; } public static int kruskal(){ int tot=1,sum=0; for(int i=1;i&lt;=m&amp;&amp;tot&lt;=n;i++) //i代表边，toto代表已经连接的村庄数量 { int a = find(edges[i].u); int b = find(edges[i].v); if(a!=b){ sum+=edges[i].w; pre[a] = b; tot++; } } return sum; } //解决javaIO读取过慢的方法，利用该类读取输入数据，不要用Scanner！！！ static class InputReader { public BufferedReader reader; public StringTokenizer tokenizer; public InputReader(InputStream stream) { reader = new BufferedReader(new InputStreamReader(stream), 32768); tokenizer = null; } public String next() { while (tokenizer == null || !tokenizer.hasMoreTokens()) { try { tokenizer = new StringTokenizer(reader.readLine()); } catch (IOException e) { throw new RuntimeException(e); } } return tokenizer.nextToken(); } public int nextInt() { return Integer.parseInt(next()); } } public static void main(String []args) { InputReader sc = new InputReader(System.in); //用它来代替Scanner。 while(true){ n = sc.nextInt(); m = n*(n-1)/2; if(n==0) break; pre = new int[n+1]; for(int i=1;i&lt;=n;i++) pre[i] = i; edges = new Edge[m+1]; for(int i=1;i&lt;=m;i++) edges[i] = new Edge(); int c; for(int i=1;i&lt;=m;i++) { edges[i].u = sc.nextInt(); edges[i].v = sc.nextInt(); edges[i].w = sc.nextInt(); c = sc.nextInt(); if(c==1) edges[i].w = 0; } Arrays.sort(edges,1,edges.length); System.out.println(kruskal()); } }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 import java.util.Scanner; public class Demo1 { static class Union{ private int parent[];//当前节点给的父节点 private int count;//连通分量中节点的个数 public Union(int count){ parent = new int[count+1]; this.count = count; for (int i = 1; i &lt;= count; i++) { parent[i] = i;//使每个节点指向自己，即不再任何集合中 } } int find(int p){ return p == parent[p] ? p : find(parent[p]); } void unionElements(int p,int q){ int pRoot = find(p); int qRoot = find(q); if (pRoot==qRoot){ return; } parent[pRoot] = qRoot; } } public static void main(String[] args) { Scanner sc = new Scanner(System.in); int count = 0; while (sc.hasNext()){ count = 0; int n = sc.nextInt();//代表多少个城镇 if (n==0) break; int m = sc.nextInt();//代表有多少条路 Union union = new Union(n);//城市下标从1开始 //接下来输入道路，并连接城市 for (int i = 0; i &lt; m; i++) { int x = sc.nextInt(); int y = sc.nextInt(); union.unionElements(x,y);//连接城市 } for (int i = 1; i &lt;= n; i++) { if (union.parent[i]==i){//父节点没有变的，就是未接通的 count++; } } System.out.println(count-1); } } } 参考文章 继续畅通工程 java实现 java畅通工程 最小生成树之Kruskal算法","link":"/2021/11/16/algorithm/algorithm_graph/algorithm-Kruskal/"},{"title":"分割等和子集","text":"思路：本题可以看成是0-1背包问题，给一个可装载重量为 sum / 2 的背包和 N 个物品，每个物品的重量记录在 nums 数组中，问是否在一种装法，能够恰好将背包装满？dp[i][j]表示前i个物品是否能装满容积为j的背包，当dp[i][j]为true时表示恰好可以装满。每个数都有放入背包和不放入两种情况，分析方法和0-1背包问题一样。 复杂度：时间复杂度O(n*sum)，n是nums数组长度，sum是nums数组元素的和。空间复杂度O(n * sum)，状态压缩之后是O(sum) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class Solution { //可以看成是0-1背包问题，给一个可装载重量为 sum / 2 的背包和 N 个物品， //每个物品的重量记录在 nums 数组中，问是否在一种装法，能够恰好将背包装满？ public boolean canPartition(int[] nums) { int len = nums.length; int sum = 0; for (int num : nums) { sum += num; } if ((sum &amp; 1) == 1) {//如果是奇数，那么分割不了，直接返回false return false; } int target = sum / 2; //dp[i][j]表示前i个物品是否能装满容积为j的背包，当dp[i][j]为true时表示恰好可以装满 //最后求的是 dp[n][sum] 表示前n个物品能否把容量为sum的背包恰好装满 //dp数组长度是n+1，而且是二维数组，第一维表示物品的索引，第二个维度表示背包大小 boolean[][] dp = new boolean[len][target + 1]; //dp数组初始化，dp[..][0] = true表示背包容量为0，这时候就已经装满了， //dp[0][..] = false 表示没有物品，肯定装不满 for (int i = 0; i &lt; n; i++) { dp[i][0] = true; } //当 i==0 时，只有一个正整数 nums[0] 可以被选取，因此 dp[0][nums[0]]==true。 if (nums[0] &lt;= target) { dp[0][nums[0]] = true; } for (int i = 1; i &lt; len; i++) { for (int j = 0; j &lt;= target; j++) { if (nums[i] &lt;= j) { //dp[i - 1][j]表示不装入第i个物品 //dp[i - 1][j-num]表示装入第i个，此时需要向前看前i - 1是否能装满j-num //和背包的区别，这里只是返回true和false 表示能否装满，不用计算价值 dp[i][j] = dp[i - 1][j] || dp[i - 1][j - nums[i]]; } else { //背包容量不足 不能放入背包 //dp[i][j]取决于前i-1个物品是否能前好装满j的容量 dp[i][j] = dp[i - 1][j]; } } if (dp[i][target]) { return true; } } return dp[len - 1][target]; }}//状态压缩public class Solution { public boolean canPartition(int[] nums) { int len = nums.length; int sum = 0; for (int num : nums) { sum += num; } if ((sum &amp; 1) == 1) { return false; } int target = sum / 2; boolean[] dp = new boolean[target + 1]; dp[0] = true; if (nums[0] &lt;= target) { dp[nums[0]] = true; } for (int i = 1; i &lt; len; i++) { for (int j = target; nums[i] &lt;= j; j--) { if (dp[target]) { return true; } dp[j] = dp[j] || dp[j - nums[i]]; } } return dp[target]; }} 参考文章 分割等和子集 0-1背包问题&amp;416. 分割等和子集 https://www.bilibili.com/video/BV1fY411x7pg?p=16 https://www.bilibili.com/video/BV1fY411x7pg?p=17 https://xiaochen1024.com/courseware/60b4f11ab1aa91002eb53b18/61963bcdc1553b002e57bf13","link":"/2021/11/25/algorithm/algorithm_dynamic/dynamic-sum-equal-sub-set/"},{"title":"优先队列和堆","text":"什么是二叉堆二叉堆本质上是一种完全二叉树，它分为两个类型： 1.最大堆 任何一个父节点的值，都大于等于它左右孩子节点的值。 2.最小堆 任何一个父节点的值，都小于等于它左右孩子节点的值。 二叉堆的根节点叫做堆顶。 最大堆和最小堆的特点，决定了在最大堆的堆顶是整个堆中的最大元素；最小堆的堆顶是整个堆中的最小元素。 堆的代码实现二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。 用数组来表示堆不仅不会浪费空间还具有一定的优势： 每个结点的左孩子为下标i的2倍：left child(i) = i * 2；每个结点的右孩子为下标i的2倍加1：right child(i) = i * 2 + 1 每个结点的父亲结点为下标的二分之一：parent(i) = i / 2，注意这里是整数除，2和3除以2都为1，大家可以验证一下； 注意：这里是把下标为0的地方空出来了的，主要是为了方便理解，如果0不空出来只需要在计算的时候把i值往右偏移一个位置就行了（也就是加1，大家可以试试，下面的演示也采取这样的方式）； 堆的自我调整对于二叉堆，如下有几种操作： 插入节点 删除节点 构建二叉堆 堆的基本结构1234567891011121314151617181920212223242526272829303132333435363738public class MaxHeap&lt;E extends Comparable&lt;E&gt;&gt; { private Array&lt;E&gt; data; public MaxHeap(int capacity) { data = new Array&lt;&gt;(capacity); } public MaxHeap() { data = new Array&lt;&gt;(); } // 返回堆中的元素个数 public int size() { return data.getSize(); } // 返回一个布尔值, 表示堆中是否为空 public boolean isEmpty() { return data.isEmpty(); } // 返回完全二叉树的数组表示中，一个索引所表示的元素的父亲节点的索引 private int parent(int index) { if (index == 0) throw new IllegalArgumentException(&quot;index-0 doesn't have parent.&quot;); return (index - 1) / 2; } // 返回完全二叉树的数组表示中，一个索引所表示的元素的左孩子节点的索引 private int leftChild(int index) { return index * 2 + 1; } // 返回完全二叉树的数组表示中，一个索引所表示的元素的右孩子节点的索引 private int rightChild(int index) { return index * 2 + 2; }} 1.向堆中添加元素和Sift Up当插入一个元素到堆中时，它可能不满足堆的性质，在这种情况下，需要调整堆中元素的位置使之重新变成堆，这个过程称为堆化（heapifying）；在最大堆中，要堆化一个元素，需要找到它的父亲结点，如果不满足堆的基本性质则交换两个元素的位置，重复该过程直到每个结点都满足堆的性质为止，下面我们来模拟一下这个过程： 下面我们在该堆中插入一个新的元素26：我们通过索引（上面的公式）可以很容易地找到新插入元素的父亲结点，然后比较它们的大小，如果新元素更大则交换两个元素的位置，这个操作就相当于把该元素上浮了一下：重复该操作直到26到了一个满足堆条件的位置，此时就完成了插入的操作： 123456789101112// 向堆中添加元素public void add(E e){ data.addLast(e); siftUp(data.getSize()-1);}private void siftUp(int k){ while(k&gt;0&amp;&amp;data.get(parent(k)).compareTo(data.get(k))&lt;0){ data.swap(k,parent(k)); k=parent(k); }} 2.取出堆中的最大元素和Sift Down如果理解了上述的过程，那么取出堆中的最大元素（堆顶元素）将变得容易，不过这里运用到一个小技巧，就是用最后一个元素替换掉栈顶元素，然后把最后一个元素删除掉，这样一来元素的总个数也满足条件，然后只需要把栈顶元素依次往下调整就好了，这个操作就叫做Sift Down（下沉）：用最后元素替换掉栈顶元素，然后删除最后一个元素：然后比较其孩子结点的大小：如果不满足堆的条件，那么就跟孩子结点中较大的一个交换位置：重复该步骤，直到16到达合适的位置：完成取出最大元素的操作： 1234567891011121314151617181920212223242526272829303132对应的代码如下：// 看堆中的最大元素public E findMax(){ if(data.getSize() == 0) throw new IllegalArgumentException(&quot;Can not findMax when heap is empty.&quot;); return data.get(0);}// 取出堆中最大元素public E extractMax(){ E ret = findMax(); data.swap(0, data.getSize() - 1); data.removeLast(); siftDown(0); return ret;}private void siftDown(int k){ while(leftChild(k) &lt; data.getSize()){ int j = leftChild(k); // 在此轮循环中,data[k]和data[j]交换位置 if( j + 1 &lt; data.getSize() &amp;&amp; data.get(j + 1).compareTo(data.get(j)) &gt; 0 ) j ++; // data[j] 是 leftChild 和 rightChild 中的最大值 if(data.get(k).compareTo(data.get(j)) &gt;= 0 ) break; data.swap(k, j); k = j; }} 3.Replace 和 HeapifyReplace这个操作其实就是取出堆中最大的元素之后再新插入一个元素，常规的做法是取出最大元素之后，再利用上面的插入新元素的操作对堆进行Sift Up操作，但是这里有一个小技巧就是直接使用新元素替换掉堆顶元素，之后再进行Sift Down操作，这样就把两次O(logn）的操作变成了一次O(logn)： 1234567// 取出堆中的最大元素，并且替换成元素epublic E replace(E e){ E ret = findMax(); data.set(0, e); siftDown(0); return ret;} Heapify翻译过来就是堆化的意思，就是将任意数组整理成堆的形状，通常的做法是遍历数组从0开始添加创建一个新的堆，但是这里存在一个小技巧就是把当前数组就看做是一个完全二叉树，然后从最后一个非叶子结点开始进行Sift Down操作就可以了，最后一个非叶子结点也很好找，就是最后一个结点的父亲结点，大家可以验证一下：从22这个节点开始，依次开始Sift Down操作：重复该过程直到堆顶元素：完成堆化操作：将n个元素逐个插入到一个空堆中，算法复杂度是O(nlogn)，而heapify的过程，算法复杂度为O(n)，这是有一个质的飞跃的，下面是代码： 12345public MaxHeap(E[] arr){ data = new Array&lt;&gt;(arr); for(int i = parent(arr.length - 1) ; i &gt;= 0 ; i --) siftDown(i);} 什么是优先队列？优先队列也是一种队列，只不过不同的是，优先队列的出队顺序是按照优先级来的；在有些情况下，可能需要找到元素集合中的最小或者最大元素，可以利用优先队列ADT来完成操作，优先队列ADT是一种数据结构，它支持插入和删除最小值操作（返回并删除最小元素）或删除最大值操作（返回并删除最大元素）； 这些操作等价于队列的enQueue和deQueue操作，区别在于，对于优先队列，元素进入队列的顺序可能与其被操作的顺序不同，作业调度是优先队列的一个应用实例，它根据优先级的高低而不是先到先服务的方式来进行调度；如果最小键值元素拥有最高的优先级，那么这种优先队列叫作升序优先队列（即总是先删除最小的元素），类似的，如果最大键值元素拥有最高的优先级，那么这种优先队列叫作降序优先队列（即总是先删除最大的元素）；由于这两种类型时对称的，所以只需要关注其中一种，如升序优先队列； 优先队列ADT下面操作组成了优先队列的一个ADT； 1.优先队列的主要操作 优先队列是元素的容器，每个元素有一个相关的键值； insert(key, data)：插入键值为key的数据到优先队列中，元素以其key进行排序； deleteMin/deleteMax：删除并返回最小/最大键值的元素； getMinimum/getMaximum：返回最小/最大剑指的元素，但不删除它； 2.优先队列的辅助操作 第k最小/第k最大：返回优先队列中键值为第k个最小/最大的元素； 大小（size）：返回优先队列中的元素个数； 堆排序（Heap Sort）：基于键值的优先级将优先队列中的元素进行排序； 优先队列的应用 数据压缩：赫夫曼编码算法； 最短路径算法：Dijkstra算法； 最小生成树算法：Prim算法； 事件驱动仿真：顾客排队算法； 选择问题：查找第k个最小元素； 等等等等…. 优先队列的实现比较 实现 插入 删除 寻找最小值 无序数组 1 n n 无序链表 1 n n 有序数组 n 1 1 有序链表 n 1 1 二叉搜索树 logn(平均) logn(平均) logn(平均) 平衡二叉搜索树 logn logn logn 二叉堆 logn logn 1 参考文章 漫画：什么是二叉堆 数据结构与算法(4)——优先队列和堆 漫画：什么是优先队列？ 漫画：什么是堆排序？","link":"/2021/11/16/algorithm/algorithm_tree/algorithm-maxheap/"},{"title":"根据层序遍历构造二叉树","text":"1层序遍历： [10,5,15,3,7,13,18,1,null,6] 123456789101112131415161718192021222324252627//层序遍历的数组构造 二叉树static TreeNode buildTree(Object[] result, int index) { if (result[index] == null) { return null; } // 根结点 root 初始化 TreeNode root = new TreeNode((Integer)result[index]); root.left = null; root.right = null; int left = 2 * index + 1; int right = 2 * index + 2; //构造左子树 if (left &gt; result.length - 1) { root.left = null; } else { root.left = buildTree(result, left); } //构造右子树 if (right &gt; result.length - 1) { root.right = null; } else { root.right = buildTree(result, right); } return root;} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.example.demo;import java.util.LinkedList;public class Main { static class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int val) { this.val = val; } TreeNode() { } } //层序遍历的数组构造 二叉树 static TreeNode buildTree(Object[] result, int index) { if (result[index] == null) { return null; } TreeNode root = new TreeNode((Integer)result[index]); root.left = null; root.right = null; int left = 2 * index + 1; int right = 2 * index + 2; if (left &gt; result.length - 1) { root.left = null; } else { root.left = buildTree(result, left); } if (right &gt; result.length - 1) { root.right = null; } else { root.right = buildTree(result, right); } return root; } //先序遍历 打印 static void preOrderTraverse(TreeNode root) { //已经完成了对n件物品的选择（递归边界--死胡同） if (root == null) { return; } System.out.print(root.val + &quot; &quot;); preOrderTraverse(root.left); preOrderTraverse(root.right); } //层序遍历 打印 static void levelOrderTraverse(TreeNode root) { LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if (root == null) { return; } queue.addLast(root); while (!queue.isEmpty()) { TreeNode temp = queue.getFirst(); System.out.print(temp.val + &quot; &quot;); queue.removeFirst(); if (temp.left != null) { queue.addLast(temp.left); } if (temp.right != null) { queue.addLast(temp.right); } } } public static void main(String[] args) { Object[] result1 = {10, 5, 15, 3, 7, 13, 18, 1, null, 6}; preOrderTraverse(buildTree(result1, 0)); System.out.println(); levelOrderTraverse(buildTree(result1, 0)); System.out.println(); }} 参考文章","link":"/2021/11/16/algorithm/algorithm_tree/algorithm-construct-binary-tree/"},{"title":"hexo_guide","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. install1npm install -g hexo-cli hexo Quick Start1hexo clean &amp;&amp; hexo g &amp;&amp; hexo server Create a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo clean &amp;&amp; hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/09/23/frontend/hexo/hexo-guide/"},{"title":"string","text":"参考文章 http://data.biancheng.net/intro/ 经典Leetcode算法题分享(字符串) 几道 BAT 算法面试中经常问的「字符串」问题 [算法总结] 13 道题搞定 BAT 面试——字符串 从头到尾彻底理解KMP（2014年8月22日版） 【算法题型总结】–5、字符串【欢迎留言补充其他题目】","link":"/2021/11/16/algorithm/alogirthm_string/algorithm-string/"},{"title":"hexo icarus 配置 Gitalk 评论系统","text":"登录GitHub并点此注册一个新的OAuth应用 第一个 Application name 是应用名称 第二个 Homepage URL 是主页地址 第三个 是描述 第四个 是回调地址！！这个最重要！！写你博客的地址就可以了 打开对应hexo主题的_config.yml添加如下内容：12345678gitalk:enable: truegithubID: github帐号 # 例：asdfv1929repo: 仓库名称 # 例：blogClientID: Client IDClientSecret: Client SecretadminUser: github帐号 #指定可初始化评论账户distractionFreeMode: true 12345678910111213141516comment: type: gitalk client_id: xxxxxxxxxxxxxxxxxxxx client_secret: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx repo: Some-of-Your-GitHub-Repo owner: you_github_name admin: - you_github_name per_page: 20 # 可选填 distraction_free_mode: false # 可选填 pager_direction: last # 可选填 create_issue_manually: false # 可选填 proxy: # 可选填 flip_move_options: # 可选填 enable_hotkey: true # 可选填 ref: https://blog.csdn.net/qq_36537546/article/details/90730412 https://www.jianshu.com/p/09c1bced3a1f https://blog.csdn.net/qq_23452385/article/details/105936095","link":"/2021/10/14/frontend/hexo/hexo-comment/"},{"title":"深度优先搜索（DFS）","text":"深度优先搜索是一种枚举所有完整路径以遍历所有情况的搜索方法。 从根节点开始，尽可能深的搜索每一个分支，把一个分支的结果搜索完，再去看另一个分支。形象来说：“一条路走到底，不撞南墙不回头”。 二叉搜索树的范围和题目描述给定二叉搜索树的根结点 root，返回值位于范围 [low, high] 之间的所有结点的值的和。 注意哦，根节点的值大于左子树，并且根节点的值小于右子树 detail 示例1： 12输入：root = [10,5,15,3,7,null,18], low = 7, high = 15输出：32 示例2： 12输入：root = [10,5,15,3,7,13,18,1,null,6], low = 6, high = 10输出：23 123456789101112131415161718static int rangeSumBST(TreeNode root, int low, int high) { //方法1：DFS //找递归边界（死胡同） if (root == null) { return 0; } //岔道口 //如果根节点的值大于high，那么右子树的值一定不满足，此时只需要判断左子树即可 if (root.val &gt; high) { return rangeSumBST(root.left, low, high); } //如果根节点的值小于low，那么左子树的值一定不满足，此时只需要判断右子树即可 if (root.val &lt; low) { return rangeSumBST(root.right, low, high); } //否则根节点的值在low和high之间，则根节点、左子树、右子树这三者都要判断 return root.val + rangeSumBST(root.left, low, high) + rangeSumBST(root.right, low, high);} 递归 1234567891011121314151617static int rangeSumBST2(TreeNode root, int low, int high) { //方法1：DFS //找递归边界（死胡同） if (root == null) { return 0; } //左子树 int leftSum = rangeSumBST(root.left, low, high); //右子树 int rightSum = rangeSumBST(root.right, low, high); int result = leftSum + rightSum; //判断根节点是否满足 if(root.val &gt;= low &amp;&amp; root.val &lt;= high){ result += root.val; } return result;} 岛屿数量给你一个由 ‘1’（陆地）和 ‘0’（水）组成的的二维网格，请你计算网格中岛屿的数量。 岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。 此外，你可以假设该网格的四条边均被水包围。 示例1： 1234567输入：grid = [ [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;]]输出：1 示例2： 1234567输入：grid = [ [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;]]输出：3 为了求出岛屿的数量，我们可以扫描整个二维网格。如果一个位置为 1，则以其为起始节点开始进行深度优先搜索。在深度优先搜索的过程中，每个搜索到的 1 都会被重新标记为 0,也就是说将1周围出现（上下左右）的1全部同化成0 12345678910111213141516171819202122232425262728293031int numIslands(char** grid, int gridSize, int* gridColSize){ //考虑特殊情况 if(grid == NULL || gridSize == 0){ return 0; } int row = gridSize;//行数 int col = *gridColSize;//列数 int count = 0;//用于计数 for(int i = 0; i &lt; row; i++){ for(int j = 0; j &lt; col; j++){ if(grid[i][j] == '1'){ count++; } dfs(grid, i, j, row, col); } } return count;} void dfs(char** grid, int x, int y, int row, int col){ //找递归边界（死胡同） if(x &lt; 0 || x &gt;= row || y &lt; 0 || y &gt;= col || grid[x][y] == '0'){ return; } grid[x][y] = '0'; //岔道口 dfs(grid, x - 1, y, row, col); dfs(grid, x + 1, y, row, col); dfs(grid, x, y - 1, row, col); dfs(grid, x, y + 1, row, col);} 0-1 背包问题有n件物品，每件物品的重量为w[i], 价值为c[i]。现在需要选出若干件物品放入一个容量为v的背包中，使得在选入背包的物品重量和不超过容量v的前提下，让背包中物品的价格之和最大，求最大价值。 123输入：物品重量：3 5 1 2 2 物品价值：4 5 2 1 3 输出：10 code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main { static int maxValue = 0;//最大价值 //下面四组数据可以自己设定，由于想简化题目所以在这里直接以全局变量的形式给出 static int n = 5;//物品数目 static int v = 8;//背包容量 static int w[] = {3, 5, 1, 2, 2};//w[i]为每件物品重量 static int c[] = {4, 5, 2, 1, 3};//c[i]为每件物品价值 static int result[] = {0, 0, 0, 0, 0}; static void DFS(int index, int sumW, int sumC, int[] list) { //已经完成了对n件物品的选择（递归边界--死胡同） if (index == n) { return; } //岔道口 int[] list1 = list.clone(); list1[index] = 0; DFS(index + 1, sumW, sumC, list);//不选第index件物品 //只有加入第index件物品后未超出容量v,才能继续执行（注意这个限制条件） if (sumW + w[index] &lt;= v) { int[] list2 = list.clone(); list2[index] = 1; //注意哦，如果加入第index件物品后总价值大于最大价值maxValue时记得要更新最大价值 if (sumC + c[index] &gt; maxValue) { maxValue = sumC + c[index];//更新最大价值maxValue result = list2; } DFS(index + 1, sumW + w[index], sumC + c[index], list2);//选择第index件物品 } } public static void main(String[] args) { int[] list = {0, 0, 0, 0, 0}; DFS(0, 0, 0, list);//初始时为第0件物品、当前总重量和总价值均为0 System.out.println(&quot;满足条件的最大价值为：&quot; + maxValue); for (Integer integer : result) { System.out.print(integer); } System.out.println(); }} 参考文章 https://blog.csdn.net/weixin_57544072/article/details/121262172","link":"/2021/11/16/algorithm/algorithm_tree/algorithm-dfs/"},{"title":"hexo 加密","text":"Hexo博客文章加密hexo文章加密 插件安装npm install --save hexo-blog-encrypt 快速使用该插件的使用也很方便，这里我仅作简单介绍，详细的可以查看官方文档。 D0n9X1n/hexo-blog-encrypt: Yet, just another hexo plugin for security. 要为一篇文章添加密码查看功能，只需要在文章信息头部添加 password 字段即可： 12345---title: Hello Worlddate: 2021-04-13 21:18:02password: hello--- 全局加密配置分别为每篇文章设置密码，虽然很灵活，但是配置或者修改起来非常麻烦。为此，可以通过设置统一配置来实现全局加密。 通过添加指定 tag 的方式，可以为所有需要加密的文章添加统一加密操作。只需要在需要加密的文章中，添加设置的 tag值 即可。 在Hexo主配置文件 _config.yml 中添加如下配置： 12345678910# Securityencrypt: # hexo-blog-encryptsilent: trueabstract: 这是一篇加密文章，需要密码才能继续阅读。message: 当前文章暂不对外可见，请输入密码后查看！tags:- {name: private, password: hello} wrong_pass_message: 抱歉，您输入的密码错误，请检查后重新输入。 wrong_hash_message: 抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。 之后，需要清除缓存后重新生成 hexo clean &amp;&amp; hexo s -g。 其中的 tag 部分： 12tags:- {name: private, password: hello} 表示当在文章中指定了 private 这个 tag 后，该文章就会自动加密并使用对应的值 hello 作为密码，输入密码后才可查看。 相应的文章头部设置： 123456---title: Password Testdate: 2019-12-21 11:54:07tags:- private--- 在全局加密配置下禁用某些文章的加密可能有这样的情况，属于 private 标签下的某篇文章在一段时间内想要开放访问。如果在描述中加上密码提示： 当前文章密码为xxx，请输入密码后查看 ，来让用户每次查看时都要先输入密码后再查看，这样的操作又会给访客带来不便。 这时可以单独设置允许某篇文章不设置密码。 只需要在使用 加密tag 的前提下，结合 password 来实现即可。在博客文章的头部添加 password 并设置为 “” 就能取消当前文章的 Tag 加密。 相应的设置示例如下： 1234567---title: No Password Testdate: 2019-12-21 11:54:07tags:- privatepassword: &quot;&quot;--- 在全局加密配置下设置非全局密码在全局加密配置下，我们可以通过设置多个 加密tag 来为多篇不同类型的文章设置相同的查看密码： 1234tags:- {name: private, password: hello}- {name: jiami, password: world}- {name: 加密, password: jiesuo} 那么可能有这样的场景： 属于 private 标签下的某篇文章想要设置成不一样的密码，防止用户恶意通过一个密码来查看同标签下的所有文章。此时，仍可以通过 password 参数来实现： 1234567---title: Password Testdate: 2019-12-21 11:54:07tags:- privatepassword: &quot;buyiyang&quot;--- 说明： 该文章通过tag值 private 做了加密，按说密码应该为 hello ，但是又在信息头中设置了 password ，因为配置的优先级是 文章信息头 &gt; 按标签加密，所以最后的密码为 buyiyang 。","link":"/2021/09/23/frontend/hexo/hexo-encrypt/"},{"title":"hexo icarus","text":"install123456# cd /d/WorkPlace/myHexo# git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarusgit clone git@github.com:luochunhai/my_hexo_icarus.git themes/icarusnpm install hexo-theme-icarushexo config theme icarus 添加头像1 更改主题配置文件 12cd 博客目录vim _config.icarus.yml 找到下面这行，取消注释即可。 12avatar: /images/avatar_2.gif 上传自定义的图片到下列目录： 12博客目录/themes/icarus/source/images/ 然后在上面的主题配置文件中更改相应路径即可。 调整整体宽度ref: https://blog.csdn.net/ye17186/article/details/111564883 在node_modules\\hexo-theme-icarus\\include\\style目录下，找到responsive.styl，将widescreen样式中： 12345widescreen() .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap 改成： 1234+widescreen() .is-1-column .container, .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap 修改 hexo-theme-icarus/layout/layout.jsxref: https://github.com/ppoffice/hexo-theme-icarus/issues/696ref: https://github.com/ppoffice/hexo-theme-icarus/blob/master/layout/layout.jsx#L29-L30 Ref https://www.jianshu.com/p/7331b2774109 https://gitee.com/liqiujiong/hexo-theme-icarus https://github.com/ppoffice/hexo-theme-icarus hexo笔记四：next主题添加作者头像","link":"/2021/09/23/frontend/hexo/hexo-icarus/"},{"title":"burp suit 简单使用","text":"拦截，修改request启动burpsuite–切换到“Proxy”选项卡–选择“Options”菜单–往下看到“Intercept Client Requests”节区在该节区中我们可以看到这个位置可以配置拦截条件，我们以只拦截“www.baidu.com”为例 点击“Add”–布尔运算选择“And”–匹配类型选择“Domain name”–匹配关系选择“Matches”–匹配条件输入“www.baidu.com”--点击“OK” 切换回“Intercept”，此时“Intercept is on”但只会拦截百度的数据包，其他网站的数据包都直接放行了其实在“Intercept Client Requests”节区还可以配置各式各样的过滤条件自己随意发挥。 修改参数后继续请求API 设置 proxy -&gt; HTTP history response:如果要配置Respone的过滤，要到再下边一点的“Intercept Server Respones”节区进行配置。 参考文章 https://blog.csdn.net/weixin_34267123/article/details/86130311","link":"/2021/10/29/frontend/fiddler/burp-suit/"},{"title":"nodejs httpserver","text":"1touch time.js 1234567891011121314151617181920212223242526272829303132333435var http = require(&quot;http&quot;);var sleep = require('system-sleep');var server = http.createServer(function (req, res) { var requestBody = &quot;&quot;; req.on('data', function(chunk) { requestBody += chunk; }); req.on('end', function() { var request = req.method + &quot; &quot; + req.url + &quot;\\n\\n&quot;; var hrTime = process.hrtime(); request += (hrTime[0] * 1000000 + hrTime[1] / 1000); request += &quot;\\n\\n&quot;; res.setHeader('Content-Type', 'application/json'); res.setHeader('X-QUOTA', '100'); res.setHeader('Access-Control-Allow-Origin','*'); if (req.url != &quot;/&quot;) { console.log(request); } if (req.url != &quot;/no-end-response&quot;){ res.end(request); } }); req.on('error', function(err) { console.log(err); });});server.listen(9999);server.timeout = 400000 12touch run_time_server.sh 1234#!/bin/shpkill nodenode --max-old-space-size=2048 time.js &amp; 12## run time server./run_time_server.sh 参考文章","link":"/2021/11/17/frontend/javascript/nodejs-httpserver/"},{"title":"hexo 隐藏文章","text":"Hexo 如何隐藏文章 本 Hexo 插件可以在博客中隐藏指定的文章，并使它们仅可通过链接访问。 当一篇文章被设置为「隐藏」时，它不会出现在任何列表中（包括首页、存档、分类页面、标签页面、Feed、站点地图等），也不会被搜索引擎索引（前提是搜索引擎遵守 noindex 标签）。 只有知道文章链接的人才可以访问被隐藏的文章。 Github地址：https://github.com/printempw/hexo-hide-posts 安装在站点根目录下执行 npm install hexo-hide-posts --save 配置在站点目录下的_config.yml中如下配置： 12345678910# hexo-hide-postshide_posts:# 可以改成其他你喜欢的名字filter: hidden# 指定你想要传递隐藏文章的位置，比如让所有隐藏文章在存档页面可见# 常见的位置有：index, tag, category, archive, sitemap, feed, etc.# 留空则默认全部隐藏public_generators: []# 为隐藏的文章添加 noindex meta 标签，阻止搜索引擎收录noindex: true 举个栗子：设置 filter: secret 之后，你就可以在 front-matter 中使用 secret: true 来隐藏文章了。 使用在文章的属性中定义 hidden: true 即可隐藏文章。 12345---title: 'Hidden Post'date: '2021/03/05 21:45:14'hidden: true--- 虽然首页上被隐藏了，但你仍然可以通过 https://hexo.test/lorem-ipsum/ 链接访问它。 你可以在命令行运行 hexo hidden:list 来获取当前所有的已隐藏文章列表。 插件也在 Local Variables 中添加了 all_posts 和 hidden_posts 变量，供自定义主题使用。","link":"/2021/09/23/frontend/hexo/hexo-hidden/"},{"title":"unreal intro","text":"install download 参考文章 中文文档 UE4学习笔记（一）安装与初见","link":"/2022/04/13/game_engine/unreal/unreal_intro/"},{"title":"unity intro","text":"install https://unity.com/cn/download#how-get-started点击直接下载 visualstudio dochttps://docs.microsoft.com/en-us/visualstudio/get-started/csharp/tutorial-aspnet-core?view=vs-2022 参考文章 unity 中文课堂 Unity 3D / W3Cschool教程","link":"/2022/04/13/game_engine/unity/unity_intro/"},{"title":"fiddler简单使用","text":"Fiddler 是位于客户端和服务器端的 HTTP 代理，也是目前最常用的 HTTP 抓包工具之一。（Mac OS 建议采用 Charles） Fiddler 的基本原理 过滤拦截 的 url 修改request1.Fiddler想要抓到数据包，要确保Capture Traffic是开启，在File –&gt; Capture Traffic。开启后再左下角会有显示，当然也可以直接点击左下角的图标来关闭/开启抓包功能。 2. Rules -&gt; Automatic Breakpoints -&gt; Before Requests 3. 修改 request 参考文章 https://zhuanlan.zhihu.com/p/47003094 https://www.cnblogs.com/kristin/p/8445055.html https://www.cnblogs.com/yyhh/p/5140852.html","link":"/2021/10/29/frontend/fiddler/fiddler/"},{"title":"centos install git","text":"参考文章 https://blog.csdn.net/lqlqlq007/article/details/78983879 install1234567891011121314151617181920212223242526# preparesudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc -ysudo yum install gcc perl-ExtUtils-MakeMaker -y git --versionsudo yum remove git -y# install gitcd /usr/local/src/wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.23.0.tar.xz --no-check-certificatetar -vxf git-2.23.0.tar.xzcd git-2.23.0sudo make prefix=/usr/local/git allsudo make prefix=/usr/local/git installsudo echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/profilesource /etc/profile git --version 生成SSH密钥12git config --global user.name &quot;luochunhai&quot;git config --global user.email &quot;469608976@qq.com&quot; 1ssh-keygen -t rsa -C &quot;469608976@qq.com&quot; 1cat ~/.ssh/id_rsa.pub 添加密钥到GitHub打开 Github，登录自己的账号后点击自己的头像-&gt;settings-&gt;SSH And GPG Keys-&gt;New SSH key 将本地 id_rsa.pub 中的内容粘贴到 Key 文本框中，随意输入一个 title(不要有中文)，点击 Add Key 即可 centos里测试验证 1ssh git@github.com","link":"/2021/09/27/linux/centos/centos-git/"},{"title":"cocos creator intro","text":"installhttps://docs.cocos.com/creator/manual/zh/getting-started/install/ https://www.cocos.com/creator3d 参考文章","link":"/2022/04/13/game_engine/cocos/cocos_intro/"},{"title":"centos 常用命令、常见问题","text":"收集centos常见操作 cmd not found1sudo yum install net-tools -y centos7修改hostname1234567hostnamectl set-hostname my_hostname # 使用这个命令会立即生效且重启也生效hostname # 查看下# my_hostnamevim /etc/hosts # 编辑下hosts文件， 给127.0.0.1添加hostnamecat /etc/hosts # 检查#127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 centos77.magedu.com#::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 一次删除多个路径下的文件12# 删除node1 ~ node6/data 下的文件rm -rf node{1,2,3,4,5,6}/data/* 目录结构12345678910111213141516171819├── docker-compose.yaml├── node1│ ├── data│ └── redis.conf├── node2│ ├── data│ └── redis.conf├── node3│ ├── data│ └── redis.conf├── node4│ ├── data│ └── redis.conf├── node5│ ├── data│ └── redis.conf└── node6 ├── data └── redis.conf Fix： Failed to download metadata for repo123456789101112#Step 1: Go to the /etc/yum.repos.d/ directory.cd /etc/yum.repos.d/#Step 2: Run the below commandssed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*#Step 3: Now run the yum updateyum update -y 在linux终端命令行模式中输入以下命令查看centos版本即可。1cat /etc/redhat-release #查看centos版本 相关操作命令：1234567uname -a #查看内核版本等信息cat /proc/cpuinfo | grep &quot;physical id&quot; | uniq | wc -l #查看cpu个数cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq #查看cpu核数cat /proc/cpuinfo | grep 'model name' |uniq #查看cpu型号 查看CPU情况以下是个人工作会经常使用到的服务器的信息。 查看所有CPU信息1cat /proc/cpuinfo 查看CPU处理器个数及核心数1cat /proc/cpuinfo | grep processor 查看内存情况12345cat /proc/meminfofree -m # 以M为单位显示free -h # 以人可读的方式显示，单位G 查看CPU和内存使用情况 top htop参考文章 Failed to download metadata for repo ‘AppStream’ [CentOS] centos修改主机名的正确方法 Linux查看CPU和内存情况","link":"/2022/03/21/linux/centos/centos-cmd/"},{"title":"centos install jenkins","text":"prepare: install JDKinstall1wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo 1rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key 如果不能安装就到官网下载jenkis的rmp包，官网地址（http://pkg.jenkins-ci.org/redhat-stable/）一. 官方下载地址：https://jenkins.io/download/二. 镜像下载地址：http://mirrors.jenkins-ci.org/ 123 wget http://mirror.serverion.com/jenkins/redhat-stable/jenkins-2.235.1-1.1.noarch.rpmrpm -ivh jenkins-2.222.3-1.1.noarch.rpmyum install -y jenkins-2.222.3-1.1.noarch.rpm 1yum install -y jenkins 配置jenkis的端口 1vim /etc/sysconfig/jenkins 12找到修改端口号：JENKINS_PORT=&quot;8080&quot; 此端口不冲突可以不修改 modify mirror of update centerhttps://www.jianshu.com/p/fb1bff7a21a1 vim /var/lib/Jenkins/hudson.model.UpdateCenter.xml 12345678&lt;?xml version='1.1' encoding='UTF-8'?&gt;&lt;sites&gt; &lt;site&gt; &lt;id&gt;default&lt;/id&gt; &lt;url&gt;https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json&lt;/url&gt; &lt;/site&gt;&lt;/sites&gt; config jenkins jdkvim /etc/init.d/jenkins 1/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64/bin/java 启动jenkins 1systemctl start/stop/restart jenkins 开机启动 1systemctl enable jenkins.service su jenkins1su -s /bin/bash jenkins 配置Jenkins，run webserver全局工具配置 git： /usr/local/git/bin/git Jdk: /usr/local/java/jdk1.8.0_211 maven_home : /usr/local/maven user Jenkins git ssh使用 jenkins 自动生成的账号 1su -s /bin/bash jenkins 生成ssh 公钥，私钥 1ssh-keygen -t rsa -C &quot;469608976@qq.com&quot; install plugin maven integration plugin deploy to container plugin github create Jenkins project config git maven1clean package -Dmaven.test.skip=true shellsh /usr/scripts/webserver.sh1234echo &quot;this is webserver.sh&quot;echo &quot;this is webserver&quot;chmod u=rwx,og=rwx /var/lib/jenkins/workspace/webserver/target/webserver-0.0.1-SNAPSHOT.jarnohup java -jar /var/lib/jenkins/workspace/webserver/target/webserver-0.0.1-SNAPSHOT.jar &gt;/dev/null 2&gt;&amp;1 &amp; 参考文档 总结 jenkin + git + maven centos install jenkins","link":"/2021/09/27/linux/centos/centos-jinkins/"},{"title":"centos install jdk","text":"安装之前先查看一下有无系统自带jdk12345rpm -qa |grep javarpm -qa |grep jdkrpm -qa |grep gcj 如果有就使用批量卸载命令1rpm -qa | grep java | xargs rpm -e --nodeps 直接yum安装1.8.0版本openjdk1yum install java-1.8.0-openjdk* -y 查看版本1java -version 配置JAVA_HOMEA 定位JDK安装路径1. 终端输入：1which java 输出为： 1/usr/bin/java 2. 终端输入：1ls -lr /usr/bin/java 输出为： 1/usr/bin/java -&gt; 3. 终端输入1ls -lrt /etc/alternatives/java 输出： 1/etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64/jre/bin/java 至此，我们确定java的安装目录为： /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64 B 配置JAVA_HOME1. 打开配置环境变量的文件1vim /etc/profile 2. 添加以下配置：1234export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 1:wq保存退出。 3. 让配置生效1source /etc/profile 4. 测试配置结果1echo $JAVA_HOME","link":"/2021/09/27/linux/centos/centos-jdk/"},{"title":"centos install maven","text":"1、获取安装包并解压1234cd /usr/localwget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gztar -zxvf apache-maven-3.6.3-bin.tar.gz 2、配置环境变量，添加export1vim /etc/profile 12export MAVEN_HOME=/usr/local/mavenexport PATH=${MAVEN_HOME}/bin:${PATH} 1source /etc/profile 1mvn -v 12vim ~/.bash_profile JAVA_HOME 和 M2_HOME 都设置成自己文件的位置 1source ~/.bash_profile 3、添加阿里云镜像1vim $MAVEN_HOME/conf/settings.xm 添加以下镜像配置 123456789101112131415&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;central-repository&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;http://central.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;","link":"/2021/09/27/linux/centos/centos-maven/"},{"title":"centos install mysql","text":"https://blog.csdn.net/qq_36582604/article/details/80526287","link":"/2021/09/27/linux/centos/centos-mysql/"},{"title":"centos install nginx","text":"prepare1sudo yum install -y gcc gcc-c++ 1sudo yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel root 安装PCRE库123456cd /usr/local/wget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.33/pcre-8.33.tar.gztar -zxvf pcre-8.33.tar.gzcd pcre-8.33./configuremake &amp;&amp; make install root 安装SSL库123456cd /usr/local/wget http://www.openssl.org/source/openssl-1.0.1j.tar.gztar -zxvf openssl-1.0.1j.tar.gzcd openssl-1.0.1j./configmake &amp;&amp; make install root 安装zlib库存123456 cd /usr/local/wget http://www.zlib.net/zlib-1.2.11.tar.gztar -zxvf zlib-1.2.11.tar.gz cd zlib-1.2.11./configuremake &amp;&amp; make install set up nginx123456cd /home/kubemkdir downloadscd downloadswget https://nginx.org/download/nginx-1.16.1.tar.gztar xvf nginx-1.16.1.tar.gz cd /home/kube/downloads/nginx-1.16.1 1./configure --prefix=/home/kube/apps/nginx --user=kube --group=kube --error-log-path=/home/kube/logs/nginx/error.log --http-log-path=/home/kube/logs/nginx/access.log --with-http_ssl_module --with-openssl=/usr/local/openssl-1.0.1j --with-pcre=/usr/local/pcre-8.33 --with-zlib=/usr/local/zlib-1.2.11 --with-http_stub_status_module 12makemake install 1/home/kube/apps/nginx/sbin/nginx -V login root1234567cd ~cd /home/kube/apps/nginx/sbinsudo chown root nginxsudo chmod +s nginxcd ~ kubesudo rm -rf nginx-1.16.1sudo rm nginx-1.16.1.tar.gz 或者normal account can start nginx at 80 port. 1sudo /usr/sbin/setcap 'cap_net_bind_service=+ep' /home1/irteam/apps/nginx/sbin/nginx nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465user root;worker_processes 2;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events { worker_connections 1024;}http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' # '$status $body_bytes_sent &quot;$http_referer&quot; ' # '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip off; # gzip_min_length 1k # gzip_comp_level 4 # gzip_types text/plain text/css application/json application/javascript server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://localhost:3000; } error_page 404 /404.html; location = /404.html { root html; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} commands for the Nginx process123./nginx # Start./nginx -s reload ## Reload configure./nginx -s stop ## End","link":"/2021/09/27/linux/centos/centos-nginx/"},{"title":"ansible 用法","text":"ansible的常用模块 command ansible的默认模块，不指定-m参数的时候，使用的就是command模块；常见的命令都可以使用，但命令的执行不是通过shell来执行的，所以&lt; &gt; | and &amp; z这些操作都不可以，不支持管道，没法批量执行命令 shell模块： 使用shell模块的时候默认是通过/bin/sh来执行的，所以在终端输入的各种命令都可以使用 scripts模块 使用scripts模块可以在本地写一个脚本，在远程服务器上执行 案例1：使用shell模块的案例 1ansible -i /etc/ansible/hosts web-servers -m shell -a &quot;source ~/.bash_profile &amp;&amp; df -h|head 案例2：使用script 模块 12345cat ~/test.sh#!/bin/bashdatehostnameecho &quot;hello world&quot; 1ansible -i /etc/ansible/hosts remote -m script -a &quot;~/test.sh&quot; copy模块的使用copy模块:实现主控端向目标主机拷贝文件，类似scp功能 案例1： 把ansible主机的/etc/hosts 拷贝到主机组机器中的/root/下 1ansible -i /etc/ansible/hosts remote -m copy -a &quot;src=~/test.sh dest=/root owner=root group=root mode=0777&quot; 查看是否执行成功： 1ansible -m command -a &quot;ls /root/&quot; 'remote' file模块案例5 给文件设置权限 1ansible -i /etc/ansible/hosts remote -m file -a &quot;path=/root/test.sh mode=0755&quot; 查看权限： 1ansible -m command -a &quot;ls -l /root&quot; 'remote' stat模块获取远程文件信息案例6 获取文件信息 1ansible -i /etc/ansible/hosts remote -m stat -a &quot;path=/root/test.sh&quot; get_url 模块案例7 实现远程主机下载指定的url地址，支持sha256sum文件校验 12ansible -i /etc/ansible/hosts remote -m get_url -a &quot;url=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm dest=/tmp/ mode=0440 force=yes&quot; 注：url=https://xxx 的等号=前后不能有空格扩展:查看force=yes的作用 yum模块 yum模块linux平台软件包管理。 yum模块可以提供的status状态： latest ，present，installed #这三个代表安装；removed, absent #这两个是卸载 案例8 使用yum模块安装httpd 1ansible -i /etc/ansible/hosts remote -m yum -a &quot;name=httpd state=latest&quot; cron模块远程管理主机crontab配置 案例9： 增加每30分钟执行 echo “hello summer” 1ansible -i /etc/ansible/hosts web-servers -m cron -a “name=‘list dir’ minute=’*/30’ job=‘echo hello summer”’” service 远程管理主机系统服务模块 service模块常用参数： （1）、name参数：此参数用于指定需要操作的服务名称，比如 nginx，httpd。 （2）、state参数：此参数用于指定服务的状态 比如，我们想要启动远程主机中的httpd，则可以将 state 的值设置为 started；如果想要停止远程主机中的服务，则可以将 state 的值设置为 stopped。此参数的可用值有 started、stopped、restarted（重启）、reloaded。 enabled参数：此参数用于指定是否将服务设置为开机 启动项，设置为 yes 表示将对应服务设置为开机启动，设置为 no 表示不会开机启动。 注：想使用service模块启动服务，被启动的服务，必须可以使用service 命令启动或关闭 案例10 使用service模块重启httpd 1ansible -i /etc/ansible/hosts remote -m service -a &quot;name=httpd state=restarted&quot; user模块 管理远程主机的用户 案例11： 使用user模块创建一个用户summer 1ansible -i /etc/ansible/hosts remote -m user -a &quot;name=summer state=present&quot; ansible 实战案例playbooks的介绍1） 在playbooks 中定义任务： name： task description #任务描述信息module_name: module_args #需要使用的模块名字： 模块参数2） ansible-playbook 执行 命令：ansible-playbook site.yml playbook是由一个或多个”play”组成的列表。play的主要功能在于将事先归为一组的主机装扮成事先通过ansible中的task定义好的角色。github上提供了大量的实例供大家参考: https://github.com/ansible/ansible-examples 实战一： 使用playbook 批量部署多台LAMP环境先介绍下： Playbook常用文件夹作用： files：存放需要同步到异地服务器的源码文件及配置文件； handlers：当服务的配置文件发生变化时需要进行的操作，比如：重启服务，重新加载配置文件，handlers [‘hændləz] 处理程序 meta：角色定义，可留空； tasks：需要进行的执行的任务； templates：用于执行lamp安装的模板文件，一般为脚本； vars：本次安装定义的变量 搭建思路思路：我们搭建lanp架构，大概需要: yum 安装服务 service 启动 copy 把网站拷贝过去 在playbooks 中定义任务：name： task description #任务描述信息module_name: module_args #需要使用的模块名字： github上提供了大量的实例供大家参考:https://github.com/ansible/ansible-examples 4.2 使用Playbook批量部署多台LAMP环境步骤我们可以在ansible服务器上安装LAMP环境，然后，再将配置文件通过ansible拷贝到远程主机上 第一步：安装httpd软件 1yum -y install httpd -y 第二步：安装MySQL 12345678910111213[root@ansible ~]# yum install mariadb-server mariadb -y #安装mysql服务[root@ansible ~]# mkdir -p /mysqldata/data/ #创建目录作为数据存放的位置[root@ansible ~]# chown -R mysql:mysql /mysqldata/ #授权[root@ansible ~]# vim /etc/my.cnf #改变数据存放目录改：# 2 datadir=/var/lib/mysql# 改为：2 datadir=/mydata/data/[root@ansible data]# systemctl start mariadb 第三步：安装PHP和php-mysql模块 1yum -y install php php-mysql 第四步：提供php的测试页 123456789 vim /var/www/html/index.php cat /var/www/html/index.php&lt;?php phpinfo();?&gt; systemctl reload httpd #启动httpd服务 httpd测试：http://{ip} 确保已经出现上面的测试页，而且，要看到MySQL已经被整合进来了，才能进行下一步操作 第五；定义组名 1234vim /etc/ansible/hosts #还使用之前定义好的，这里不用修改[webservers]192.168.171.136 然后，将公钥信息复制到被控制节点，ansible和两个节点间通过ssh进行连接。下面3个命令之前已经做过，不用执行了。 12ssh-keygen ssh-copy-id root@192.168.171.136 第六：使用playbook创建一个LAMP构建的任务1、创建相关文件 12[root@ansible ~]# mkdir -pv /etc/ansible/lamp/roles/{prepare,httpd,mysql,php}/{tasks,files,templates,vars,meta,default,handlers} 我们将上面搭建成功的LAMP环境的httpd和MySQL的配置文件拷贝到对应目录下 123456789101112131415161718[root@summer ~]# cd /etc/ansible/ [root@ansible ansible]# cp /etc/httpd/conf/httpd.conf lamp/roles/httpd/files/[root@summer ansible]# cp /etc/my.cnf lamp/roles/mysql/files/[root@summer ansible]# 写prepare（前期准备）角色的playbooks[root@summer ansible]# vim lamp/roles/prepare/tasks/main.yml[root@summer ansible]# cat lamp/roles/prepare/tasks/main.yml- name: delete yum config shell: rm -rf /etc/yum.repos.d/* #删除原有的yum配置文件- name: provide yumrepo file shell: wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #下载新的yum配置文件- name: clean the yum repo shell: yum clean all #清除原有的yum缓存信息- name: clean the iptables shell: iptables -F #清除原有防火墙规则，不然后可能上不了网[root@summer ansible]# 2、构建httpd的任务 123456789101112131415161718192021[root@summer ansible]# cd /etc/ansible/lamp/roles/[root@summer roles]# mv /var/www/html/index.php httpd/files/[root@summer roles]# vim httpd/tasks/main.yml[root@summer roles]# cat httpd/tasks/main.yml[root@summer roles]# cat httpd/tasks/main.yml- name: web server install yum: name=httpd state=present #安装httpd服务- name: provide test page copy: src=index.php dest=/var/www/html #提供测试页- name: delete apache config shell: rm -rf /etc/httpd/conf/httpd.conf #删除原有的apache配置文件，如果不删除，下面的copy任务是不会执行的，因为当源文件httpd.conf和目标文件一样时，copy命令是不执行的。如果copy命令不执行，那么notify将不调用handler。- name: provide configuration file copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf #提供httpd的配置文件 notify: restart httpd #当前面的copy复制成功后，通过notify通知名字为restart httpd的handlers运行 3、构建httpd的handlers 123456[root@summer roles]# vim httpd/handlers/main.yml[root@summer roles]# cat httpd/handlers/main.yml- name: restart httpd service: name=httpd enabled=yes state=restarted 4、部署我们的MariaDB数据库 创建MySQL服务的任务，需要安装MySQL服务，改变属主信息，启动MySQL 1234567891011121314[root@summer roles]# cd /etc/ansible/lamp/roles/[root@summer roles]# vim mysql/tasks/main.yml[root@summer roles]# cat mysql/tasks/main.yml-name: install the mysqlyum: name=mariadb-server state=present #安装mysql服务- name: mkdir date directory shell: mkdir -p /mydata/data #创建挂载点目录- name: provide configration file copy: src=my.cnf dest=/etc/my.cnf #提供mysql的配置文件- name: chage the owner shell: chown -R mysql:mysql /mydata/ #更改属主和属组- name: start mariadb service: name=mariadb enabled=yes state=started #启动mysql服务 5、构建PHP的任务 12345[root@summer roles]# vim php/tasks/main.yml- name: install php yum: name=php state=present #安装php- name: install php-mysql yum: name=php-mysql state=present #安装php与mysql交互的插件 6、定义整个的任务 1234567891011[root@summer roles]# cd /etc/ansible/lamp/roles/[root@summer roles]# vim site.yml[root@summer roles]# cat site.yml- name: LAMP build remote_user: root hosts: web-servers roles: - prepare - mysql - php - httpd 注：所有yml的配置文件中，空格必须严格对 开始部署： 1[root@summer roles]# ansible-playbook -i /etc/ansible/hosts /etc/ansible/lamp/roles/site.yml 然后，在浏览器中访问这两台节点主机，可以直接访问成功. 总结：做此实验室，需要准备干净环境，selinux、防火墙都要关闭 实战二： 使用ansible部署k8s及集群安装git命令 1yum install git 使用git下载相应的ansible-k8s-insatall 包： 1git clone https://github.com/lizhenliang/ansible-install-k8s 进入到ansbile-install-k8s目录修改hosts文件，根据规划修改对应IP和名称。 123cd ansible-install-k8svim hostsvim group_vars/all.yml 部署命令： 单Master版 1ansible-playbook -i hosts single-master-deploy.yml -uroot -k 多master版 12ansible-playbook -i hosts multi-master-deploy.yml -uroot -k 参考文章 太厉害了，终于有人能把Ansible讲的明明白白了，建议收藏","link":"/2022/03/21/linux/ansible/ansible-advanced-usage/"},{"title":"ansible_cmd","text":"参考文章","link":"/2022/03/21/linux/ansible/ansible-cmd/"},{"title":"ansible","text":"introref: https://docs.ansible.com/ansible/latest/index.html#Ansible is an IT automation tool. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates. Ansible conceptsref: https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html Control nodeAny machine with Ansible installed.You can run Ansible commands and playbooks by invoking the ansible or ansible-playbook command from any control node. You can use any computer that has a Python installation as a control node - laptops, shared desktops, and servers can all run Ansible.However, you cannot use a Windows machine as a control node. You can have multiple control nodes. Managed nodesThe network devices (and/or servers) you manage with Ansible. Managed nodes are also sometimes called “hosts”. Ansible is not installed on managed nodes. InventoryA list of managed nodes.An inventory file is also sometimes called a “hostfile”. Your inventory can specify information like IP address for each managed node. An inventory can also organize managed nodes, creating and nesting groups for easier scaling. To learn more about inventory, see the Working with Inventory section. example default : /etc/ansible/hosts12345678910mail.example.com[webservers]foo.example.combar.example.com[dbservers]one.example.comtwo.example.comthree.example.com yaml format:12345678910111213all: hosts: mail.example.com: children: webservers: hosts: foo.example.com: bar.example.com: dbservers: hosts: one.example.com: two.example.com: three.example.com: CollectionsCollections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. You can install and use collections through Ansible Galaxy. To learn more about collections, see Using collections. ModulesThe units of code Ansible executes. Each module has a particular use, from administering users on a specific type of database to managing VLAN interfaces on a specific type of network device. You can invoke a single module with a task, or invoke several different modules in a playbook. Starting in Ansible 2.10, modules are grouped in collections. For an idea of how many collections Ansible includes, take a look at the Collection Index. TasksThe units of action in Ansible. You can execute a single task once with an ad hoc command. PlaybooksOrdered lists of tasks, saved so you can run those tasks in that order repeatedly. Playbooks can include variables as well as tasks. Playbooks are written in YAML and are easy to read, write, share and understand. To learn more about playbooks, see Intro to playbooks. Install1. yum install on centos 12$ sudo yum install epel-release$ sudo yum install ansible 2. install and upgrade Ansible with pipConnecting to remote nodesref: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html#connecting-to-remote-nodes 1. connected by port, user, passwd123[root@ansible_master ansible]# grep -v ^# /etc/ansible/hosts |grep -v ^$[web-servers]192.168.171.136 ansible_ssh_port=22 ansible_ssh_user=root ansible_ssh_pass=summer test connecting:1234# before cmd: ping , install `sshpass `yum install sshpass -y# test connectingansible -i /etc/ansible/hosts web-servers -m ping 2. connected by ssh123456789101112# generate sshkey on `Control node`ssh-keygen# copy public key to `Managed node`ssh-copy-id root@192.168.171.136# login test ssh 192.168.1.163# test connectingansible -i /etc/ansible/hosts 'web-servers' -m ping# testansible -m command -a &quot;uptime&quot; 'web-servers' simple usageref: Ansible Getting started run shell on Managed node1ansible -i /etc/ansible/hosts web-servers -m shell -a &quot;source ~/.bash_profile &amp;&amp; df -h|head run script12345cat ~/test.sh#!/bin/bashdatehostnameecho &quot;hello world&quot; 1ansible -i /etc/ansible/hosts web-servers -m script -a &quot;~/test.sh&quot; copy file: from Control node to Managed node1234ansible -i /etc/ansible/hosts web-servers -m copy -a &quot;src=~/test.sh dest=/root owner=root group=root mode=0777&quot;# check if successansible -m command -a &quot;ls /root/&quot; 'remote' set file auth123ansible -i /etc/ansible/hosts web-servers -m file -a &quot;path=/root/test.sh mode=0755&quot;# check file authansible -m command -a &quot;ls -l /root&quot; 'remote' download source from given url12ansible -i /etc/ansible/hosts web-servers -m get_url -a &quot;url=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm dest=/tmp/ mode=0440 force=yes&quot; yum install1ansible -i /etc/ansible/hosts web-servers -m yum -a &quot;name=httpd state=latest&quot; restart httpd1ansible -i /etc/ansible/hosts web-servers -m service -a &quot;name=httpd state=restarted&quot; Action: Run your first playbookIn a directory of your choice you can create your first playbook in a file called mytask.yaml: 123456---- name: My playbook hosts: all tasks: - name: Leaving a mark command: &quot;touch /tmp/ansible_was_here&quot; You can run this command as follows: 1$ ansible-playbook mytask.yaml ansible-examples 参考文章","link":"/2022/03/22/linux/ansible/ansible-intro-en/"},{"title":"ansible_intro","text":"Ansible 概览这部分内容对所有用户均有用。 你需要了解 Ansible 的使用背景才能在各类场景下使用他的自动化功能。本页内容是你深入理解其它内容的基础。 管理机 受控节点 Inventory 仓库 Modules 模块 Tasks 任务 Playbooks 任务剧本管理机任何安装了 Ansbile 的服务器，你都可以使用 ansible or ansible-playbook 命令。 任何安装了 Ansbile 的机器都可以做为管理节点，便携式计算机，共享桌面和服务器都可以。 你可以配置多个管理节点。唯一需要注意的是，管理节点不支持 Windows 系统。 受控节点Ansbile 管理的服务器或者网络设备都称为受控节点。 受控节点有时候也叫做 “hosts” ( 主机 ). 受控节点不需要安装 Ansible. Inventory 仓库Inventory 仓库是保存受控节点信息的列表, 因为有时候也叫 “hostfile”， 类似于系统的 hosts 文件。 Inventory 仓库可以以 IP 的方式指定受控节点。 Inventory 同样可以组织管理节点、新增、嵌套组等方式，非常便于扩展。 更多请参考 the Working with Inventory Modules 模块Modules 模块是 Ansible 执行代码的最小单元。 每个模块都是特殊用途，从特殊类型的数据库用户管理，到特殊类型的网络设备 VLAN 接口管理。 你可以在通过执行单个任务调用一个模块，也可以通过 playbook 同时调用执行钓具模块。 在链接中查看 Ansible 总共包括了多少个模块。:ref: 模块列表 &lt;modules_by_category&gt;. Tasks 任务Ansible 执行操作的最小单位。 ad-hoc 更适合临时执行命令的执行场景。 Playbooks 任务剧本Playbooks 是任务列表的组合，通常会把常用的命令列表通过正确的语法写入到 playbook中。 Playbook 可以像普通 tasks 一样调用变量， 其使用 YAML 语法，便于读、写、分享、理解。更多请参考 Intro to Playbooks. install ansibleinstall python3.8 on centos8 https://luochunhai.github.io/2021/12/24/python/python-centos-install/https://computingforgeeks.com/how-to-install-python-3-python-2-7-on-rhel-8/ https://linuxize.com/post/how-to-install-python-3-8-on-centos-8/ 123456789101112131415161718192021222324252627282930313233# sudo dnf install python3# preparesudo dnf groupinstall 'development tools' -ysudo dnf install bzip2-devel expat-devel gdbm-devel \\ ncurses-devel openssl-devel readline-devel wget \\ sqlite-devel tk-devel xz-devel zlib-devel libffi-devel -y## download VERSION=3.8.1wget https://www.python.org/ftp/python/${VERSION}/Python-${VERSION}.tgztar -xf Python-${VERSION}.tgz# 该--enable-optimizations选项通过运行多个测试来优化 Python 二进制文件。这会使构建过程变慢。cd Python-${VERSION}./configure --enable-optimizations# 通过运行以下命令启动 Python 3.8 构建过程：make -j 4# 修改-j以对应于处理器中的内核数。您可以通过键入 找到该号码nproc。# 构建过程完成后，安装 Python 二进制文件：sudo make altinstallpython3.8 --versionln -s /usr/local/bin/python3.8 /usr/bin/pythonpython -m pip install --upgrade pip 安装 Ansible on CentOSpip install12345678pip install setuptools-rustpip install paramiko## 安装 Ansible [1]:pip install ansibleansible --version yum install123yum install epel-release -yyum install sshpass -yyum install ansible -y ansible的使用基于端口，用户，密码定义主机清单格式： 12ansible基于ssh连接-i （inventory）参数后指定的远程主机时，也可以写端口，用户，密码。 如：ansible_ssh_port: 指定ssh端口ansible_ssh_user:指定 ssh 用户ansible_ssh_pass: 指定 ssh 用户登录是认证密码（明文密码不安全）ansible_sudo_pass: 指明 sudo 时候的密码 添加的内容如下： 123[root@ansible_master ansible]# grep -v ^# /etc/ansible/hosts |grep -v ^$[remote]192.168.171.136 ansible_ssh_port=22 ansible_ssh_user=root ansible_ssh_pass=summer 直接添加到文件文末就可以； 测试主机的连通性 1234yum install epel-release -yyum install sshpass -yansible -i /etc/ansible/hosts remote -m ping 可能出现的问题：Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this 1234vi /etc/ansible/ansible.cfg[defaults]forks = 8 #执行时并发数host_key_checking = False #不检测host key 查看组下所有的IP： 1ansible all --list 基于ssh密钥来访问定义主机清单设置密钥 1ssh-keygen 拷贝密钥并测试 123456# 使用ssh-keygen和ssh-copy-id三步实现SSH无密码登录 和ssh常用命令 # https://blog.csdn.net/alifrank/article/details/48241699ssh-copy-id root@192.168.171.136## 登陆测试ssh 192.168.1.163 使用ping检查‘web-servers’或者ansible节点的连通性。 1234567ansible -i /etc/ansible/hosts 'remote' -m ping# 这条命令我们也可以不指定hosts,效果是一样的，我们只要指定组即可ansible 'remote' -m ping# 有时候我们为了方便阅读也把主机组名写在最后面# remote 这个组名，放在最后面ansible -m command -a &quot;uptime&quot; 'remote' 案例1： 检查节点的内存情况 1ansible -m command -a &quot;free -m &quot; 'remote' 案例2：给节点增加用户 1ansible -m command -a &quot;useradd summer&quot; 'remote' 查看是否创建用户成功 1ansible -m command -a &quot;id summer&quot; 'remote' 参考文章 非常好的Ansible入门教程 自动化运维第一步——Ansible 使用教程 ansible基本使用教程 Ansible 文档 Ansible中文权威指南 Ansible「2.9」 中文官方文档 太厉害了，终于有人能把Ansible讲的明明白白了，建议收藏","link":"/2022/03/21/linux/ansible/ansible-intro/"},{"title":"ansible ad-hoc命令","text":"我们经常会通过命令行的形式使用ansible模块，ansible自带很多模块，可以直接使用这些模块。目前ansible已经自带了200+个模块，我们可以使用ansible-doc -l显示所有自带模块，还可以使用ansible-doc 模块名，查看模块的介绍以及案例。需要注意的是，如果使用ad-hoc命令，ansible的一些插件功能就无法使用，比如loop facts功能等。命令用法：ansible &lt;host-pattern&gt; [options] ping模块ping模块的作用与其名相同，即判断远程主机的网络是否畅通示例：ansible cluster_hosts -m ping copy模块copy模块在ansible里的角色就是把ansible执行机器上的文件拷贝到远程节点上。与fetch模块相反的操作。常用模块参数 参数名 是否必须 默认值 选项 说明 src no 用于定位ansible执行的机器上的文件，需要绝对路径。如果拷贝的是文件夹，那么文件夹会整体拷贝，如果结尾是”/”,那么只有文件夹内的东西被考过去。一切的感觉很像rsync content no 用来替代src，用于将指定文件的内容，拷贝到远程文件内 dest yes 用于定位远程节点上的文件，需要绝对路径。如果src指向的是文件夹，这个参数也必须是指向文件夹 backup no no yes/no 备份远程节点上的原始文件，在拷贝之前。如果发生什么意外，原始文件还能使用。 directory_mode no 这个参数只能用于拷贝文件夹时候，这个设定后，文件夹内新建的文件会被拷贝。而老旧的不会被拷贝 follow no no yes/no 当拷贝的文件夹内有link存在的时候，那么拷贝过去的也会有link force no yes yes/no 默认为yes,会覆盖远程的内容不一样的文件（可能文件名一样）。如果是no，就不会拷贝文件，如果远程有这个文件 group no 设定一个群组拥有拷贝到远程节点的文件权限 mode no 等同于chmod，参数可以为“u+rwx or u=rw,g=r,o=r” owner no 设定一个用户拥有拷贝到远程节点的文件权限 示例：将文件copy到测试主机 1ansible testservers -m copy -a 'src=/root/install.log dest=/tmp/install.log owner=testuser group=testgroup' 示例：copy 前先备份 12echo &quot;test &quot; &gt;&gt; /root/install.logansible testservers -m copy -a 'src=/root/install.log dest=/tmp/install.log owner=testuser group=testgroup backup=yes' 1ansible testservers -m raw -a 'ls -lrth /tmp/install*' 示例：将目录copy过去 1234ansible testservers -m copy -a 'src=/etc/ansible/testdir dest=/tmp/ owner=testuser group=testgroup backup=yes'# 查看结果ansible testservers -m command -a 'tree /tmp/testdir' 注意：发现有文件的目录copy成功，空的目录没有copy过去 常用参数返回值 参数名 参数说明 返回值 返回值类型 样例 src 位于ansible执行机上的位置 changed string /home/httpd/.ansible/tmp/ansible-tmp-1423796390.97-147729857856000/source backup_file 将原文件备份 changed and if backup=yes string /path/to/file.txt.2015-02-12@22:09~ uid 在执行后，拥有者的ID success int 100 dest 远程节点的目标目录或文件 success string /path/to/file.txt checksum 拷贝文件后的checksum值 success string 6e642bb8dd5c2e027bf21dd923337cbb4214f827 md5sum 拷贝文件后的md5 checksum值 when supported string 2a5aeecc61dc98c4d780b14b330e3282 state 执行后的状态 success string file gid 执行后拥有文件夹、文件的群组ID success int 100 mode 执行后文件的权限 success string 644 owner 执行后文件所有者的名字 success string httpd group 执行后文件所有群组的名字 success string httpd size 执行后文件大小 success int 1220 shell模块它负责在被ansible控制的节点（服务器）执行命令行。shell 模块是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样。常用参数 参数 是否必须 默认值 选项 说明 chdir no 跟command一样的，运行shell之前cd到某个目录 creates no 跟command一样的，如果某个文件存在则不运行shell removes no 跟command一样的，如果某个文件不存在则不运行shell 示例1:让所有节点运行somescript.sh并把log输出到somelog.txt。ansible -i hosts all -m shell -a &quot;sh somescript.sh &gt;&gt; somelog.txt&quot;示例2:先进入somedir/ ，再在somedir/目录下让所有节点运行somescript.sh并把log输出到somelog.txt。ansible -i hosts all -m shell -a &quot;somescript.sh &gt;&gt; somelog.txt&quot; chdir=somedir/示例3:先cd到某个需要编译的目录，执行condifgure然后,编译，然后安装。ansible -i hosts all -m shell -a &quot;./configure &amp;&amp; make &amp;&amp; make insatll&quot; chdir=/xxx/yyy/ command模块command 模块用于运行系统命令。不支持管道符和变量等（”&lt;”, “&gt;”, “|”, and “&amp;”等），如果要使用这些，那么可以使用shell模块。在使用ansible中的时候，默认的模块是-m command，从而模块的参数不需要填写，直接使用即可。常用参数 参数 是否必须 默认值 选项 说明 chdir no 运行command命令前先cd到这个目录 creates no 如果这个参数对应的文件存在，就不运行command executable no 将shell切换为command执行，这里的所有命令需要使用绝对路径 removes no 如果这个参数对应的文件不存在，就不运行command 示例1：ansible 命令调用command: ansible -i hosts all -m command -a &quot;/sbin/shutdown -t now&quot;ansible命令行调用-m command模块 -a表示使用参数 “”内的为执行的command命令，该命令为关机。那么对应的节点(192.168.10.12,127.152.112.13)都会执行关机。示例2： Run the command if the specified file does not exist.ansible -i hosts all -m command -a &quot;/usr/bin/make_database.sh arg1 arg2 creates=/path/to/database&quot;利用creates参数，判断/path/to/database这个文件是否存在，存在就跳过command命令，不存在就执行command命令。 raw模块raw模块的功能与shell和command类似。但raw模块运行时不需要在远程主机上配置python环境。示例：在10.1.1.113节点上运行hostname命令ansible 10.1.1.113 -m raw-a 'hostname|tee' fetch模块文件拉取模块主要是将远程主机中的文件拷贝到本机中，和copy模块的作用刚刚相反，并且在保存的时候使用hostname来进行保存，当文件不存在的时候，会出现错误，除非设置了选项fail_on_missing为yes 常用参数 参考文章 ansible基本使用教程 ad-hoc 命令操作指引","link":"/2022/03/21/linux/ansible/ansible-module/"},{"title":"ansible_inventory","text":"主机清单inventory Inventory主机清单 ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名 默认的inventory file为/etc/ansible/hosts inventory file可以有多个，且也可以通过Dynamic inventory来动态生成 介绍在大规模的配置管理工作中我们需要管理不同业务的机器，这些机器的信息都存放在ansible的inventory组件里。在我们工作中配置部署针对的主机必须先存放在inventory里，这样才能使用ansible对它进行操作。默认ansible的inventory是一个静态的ini文件/etc/ansible/hosts。亦可通过ANSIBLE_HOSTS环境变量指定或者命令运行时用-i参数临时设置。 参考示例：定义主机和主机组123456781、100.0.0.1 ansible_ssh_pass='123456'2、100.0.0.2 ansible_ssh_pass='123456'3、[docker]4、100.0.0.1[1:3]5、[docker:vars]6、ansible_ssh_pass='123456'7、[ansible:children]8、docker 第一、二行定义一个主机，指定ssh登录密码第三行定义了一个叫docker的组第四行定义了docker组下面四个主机从100.0.0.11-100.0.0.13第五、六行定义了docker组的ssh登录密码第七、八行定义了ansible组，ansible组包含docker组 inventory内置参数参考官网http://docs.ansible.com/ansible/latest/intro_inventory.html 参考 解释 例子 ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置. ansible_ssh_host=192.169.1.123 ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置. ansible_ssh_port=5000 ansible_ssh_user 默认的 ssh 用户名 ansible_ssh_user=cxpadmin ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 –ask-pass 或 SSH 密钥) ansible_ssh_pass=’123456’ ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 –ask-sudo-pass) ansible_sudo_pass=’123456’ ansible_sudo_exe sudo 命令路径(适用于1.8及以上版本) ansible_sudo_exe=/usr/bin/sudo ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 ‘smart’,’smart’ 方式会根据是否支持 ControlPersist, 来判断’ssh’ 方式是否可行. ansible_connection=local ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况. ansible_ssh_private_key_file=/root/key ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 ‘sh’ 语法,可设置为 ‘csh’ 或 ‘fish’. ansible_shell_type=zsh ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是”/usr/bin/python”,比如 *BSD, 或者 /usr/bin/python ansible_python_interpreter=/usr/bin/python2.6 不是 2.X 版本的 Python.我们不使用 “/usr/bin/env” 机制,因为这要求远程用户的路径设置正确,且要求 “python” 可执行程序名不可为 python以外的名字(实际有可能名为python26). ansible_*_interpreter 定义其他语言解释器 ansible_*_interpreter=/usr/bin/ruby ansible_sudo 定义sudo用户 ansible_sudo=cxpadmin 注：从ansible2.0开始， ansible_ssh_user, ansible_ssh_host, ansible_ssh_port已经改变为ansible_user, ansible_host, ansible_port。 参考文章 ansible基本使用教程 Inventory 使用进阶 https://ansible-tran.readthedocs.io/en/latest/docs/intro_inventory.html","link":"/2022/03/21/linux/ansible/ansible-inventory/"},{"title":"ansible playbook","text":"参考文章 https://github.com/ceph/ceph-ansible https://github.com/ansible/ansible-examples Playbooks http://www.ansible.com.cn/docs/playbooks_intro.html https://cn-ansibledoc.readthedocs.io/zh_CN/latest/user_guide/playbooks.html","link":"/2022/03/21/linux/ansible/ansible-playbook/"},{"title":"自动同步你的 Github 仓库到 Gitee 仓库","text":"git action 巧用Github Action同步代码到Gitee 自动同步你的 Github 仓库到 Gitee 仓库 Coding同步Github仓库gitee 镜像管理 仓库镜像管理 （ Gitee &lt;-&gt; Github 双向同步）修改 git 的配置文件 修改 git 的配置文件","link":"/2021/09/27/linux/git/git-gitee/"},{"title":"git常用命令","text":"1. 常用命令git tag12345678910111213141516# create taggit tag test_tag# delete taggit tag -d test_taggit push origin :refs/tags/test_tag# push taggit push origin test_taggit push origin --tags# show taggit show test_tag# 基于某个commit id create taggit tag -a test_tag {commitId} 查看本地和远程仓库的所有分支1git branch -a 查看远程仓库的分支1git branch -r 查看项目远程地址1git remote -v git 版本回退123456789101112131415161718# git log 命令可以显示所有提交过的版本信息# --pretty=oneline，只会显示版本号和提交时的备注信息git log --pretty=oneline# git reflog 可以查看所有分支的所有操作记录（包括已经被删除的 commit 记录和 reset 的操作）git reflog # git reset –-soft：回退到某个版本，只回退了commit的信息，不会恢复到index file一级。如果还要提交，直接commit即可；# 撤销该commit，但是又不能撤销该提交包含的更改，使用git reset --soft# 可见commit取消了，代码更改并没有取消git reset --soft {commitId}# git reset -–hard：彻底回退到某个版本，本地的源码也会变为上一个版本的内容，撤销的commit中所包含的更改被冲掉；git reset --hard {commitId}git push origin HEAD --force# 用某个commit 创建一个分支git branch {branch_name} {commitId} 2. git 安装配置1、检查git是否已经安装，输入git version命令即可，如果没有显示版本号表示没有安装git2、安装git ubuntusudo apt-get install git 3、配置git全局环境12git config --global user.name &quot;用户名&quot;git config --global user.email &quot;邮箱地址&quot; 4、生成ssh密钥ssh-keygen -t rsa -C &quot;这里换上你的邮箱&quot;会在用户目录~/.ssh/下建立相应的密钥文件。 5、创建完公钥后，需要上传。使用命令cd ~/.ssh进入~/.ssh文件夹，输入cat id_rsa.pub打开id_rsa.pub文件，复制其中所有内容。接着访问git网页，点击SSH公钥，标题栏可以随意输入，公钥栏把刚才复制的内容粘贴进去。 创建一个空的目录，初始化git仓库，添加远程仓库做测试 6、测试连接ssh -T git@github.com 7、git使用命令123456789git clone 项目地址 拉项目git pull 拉代码git push 提交到仓库git init指令初始化一个git仓库git add .添加文件git commit -m &quot;注释&quot;提交至仓库。git remote add origin https://git.oschina.net/你的用户名/项目名.git，git push origin master即可完成推送git checkout master 切换到master分支","link":"/2021/09/27/linux/git/git-cmd/"},{"title":"Linux清理磁盘空间","text":"显示每个目录的大小命令：du -sh /* du参数：-a : 列出所有的文件与目录容量，因为默认仅统计目录下面的文件量而已；-h : 以人们较易读的容量格式（G/M）显示；-s : 列出总量，而不列出每个个别的目录占用了容量；-S : 不包括子目录下的总计，与-s有点差别；-k : 以KB列出容量显示；-m : 以MB列出容量显示。 参考文章 https://www.cnblogs.com/lxcy/p/10515940.html https://blog.csdn.net/luckystar92/article/details/51986685","link":"/2021/09/27/linux/linux/linux-clear-disk/"},{"title":"ubuntu install git","text":"prepare12apt-get update -yapt-get upgrade -y install 1apt install git 1git --version 生成SSH密钥12git config --global user.name &quot;luochunhai&quot;git config --global user.email &quot;469608976@qq.com&quot; 1ssh-keygen -t rsa -C &quot;469608976@qq.com&quot; 1cat ~/.ssh/id_rsa.pub 添加密钥到GitHub 打开 Github，登录自己的账号后点击自己的头像-&gt;settings-&gt;SSH And GPG Keys-&gt;New SSH key 将本地 id_rsa.pub 中的内容粘贴到 Key 文本框中，随意输入一个 title(不要有中文)，点击 Add Key 即可 centos里测试验证1ssh git@github.com","link":"/2021/09/27/linux/git/ubuntu-git/"},{"title":"Linux 组调度","text":"参考文章 Linux 组调度浅析 Linux内核之实时进程调度和组调度","link":"/2021/09/24/linux/linux/linux-cgroup/"},{"title":"Linux 网络协议栈","text":"linux虚拟网络接口 —— 环回接口 lo 参考文章 理解 Linux 网络栈（1）：Linux 网络协议栈简单总结 理解TCP/IP网络栈 Linux 网络栈剖析 Linux网络栈解剖","link":"/2021/12/30/linux/linux/linux-network-stack/"},{"title":"linux 常用命令","text":"文件分割/合并分割123$ split -b 100M -d node01.zip$ lsnode01.zip x00 x01 x02 参数详情 参 数 描述 -b 100M 分割文件大小为 100MB -d 加上该参数后，分割后的文件将使用数字后缀；反之，分割文件名将是字母后缀。详情见下表。 分割文件格式 类型 样例 数字后缀 x01 x02 x03 字母后缀 xaa xab xac 分割文件传输将分割文件传输至本地保存 合并 该步骤样例在 Windows 10 上的 CMD 运行。（ * 使用 PowerShell 可能导致运行失败） 1234567C:\\dump&gt;copy /b x* node01.zipx00x01x02Copied 1 fileC:\\dump&gt;dirnode01.zip x00 x01 x02 这样就在本地获得了服务器中的 文件 拷贝文件 SCP123456# 拷贝本地文件到远程scp xxx.txt root@{ip/hosts}:/root# 拷贝远程文件到本地scp root@{ip/hosts}:/root/xxx.txt /root top 命令1234567891011# d：指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。# p:通过指定监控进程ID来仅仅监控某个进程的状态。# q:该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。# S：指定累计模式。# s：使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。# i：使top不显示任何闲置或者僵死进程。# c:显示整个命令行而不只是显示命令名。top -H -b -d 1 -n 200 &gt; top.txt# -p : 通过监控进程ID来仅仅监控某个进程的状态top -p {pid}# -i ： 不显示任何闲置或僵死的进程 free12free -mfree -h jmap123# 查看堆内存使用情况jmap -heap {pid} netstat 123456789101112131415# -a (all)显示所有选项，默认不显示LISTEN相关# -t (tcp)仅显示tcp相关选项# -u (udp)仅显示udp相关选项# -n 拒绝显示别名，能显示数字的全部转化成数字。# -l 仅列出有在 Listen (监听) 的服務状态# -p 显示建立相关链接的程序名# -r 显示路由信息，路由表# -e 显示扩展信息，例如uid等# -s 按各个协议进行统计# -c 每隔一个固定时间，执行该netstat命令。netstat -ltnpnetstat -ano | findstr &quot;6379&quot; cat 日志查询123456789# 1. 查询日志中关键字cat -n summer.log | grep &quot;关键字&quot; | wc -l # 2.查询某段时间内的日志sed -n '/start_time/,/end_time/p' summer.log|grep &quot;key words&quot;# set -n '/2021-03-15 01:29:17/,/2021-03-15 02:29:17/p' summer.logwc -l # 统计行数wc -c # 统计字节数wc -l # 统计字数 sed查找123# sed -n '/start time/,/end time/p' aaa.log | grep &quot;keyword&quot;sed -n '/2021-03-16 01:29:17/,/2021-03-16 02:29:17/p' aa.log | grep &quot;keyword&quot; 批量替换文件内容格式: sed -i “s/查找字段/替换字段/g” grep 查找字段 -rl 路径 文件名 -i 表示inplace edit，就地修改文件 -r 表示搜索子目录 -l 表示输出匹配的文件名s表示替换，d表示删除 示例： 12345sed -i &quot;s/shan/hua/g&quot; lishan.txt#把当前目录下lishan.txt里的shan都替换为huased -i &quot;s/&lt;root level=\\&quot;DEBUG\\&quot;&gt;/&lt;root level=\\&quot;INFO\\&quot;&gt;/g&quot; log4j2.xml#引号用 `\\&quot;` 123456789101112131415161718192021222324252627### 删除行首空格sed 's/^[ ]*//g' filenamesed 's/^ *//g' filenamesed 's/^[[:space:]]*//g' filename### 行后和行前添加新行#行后：sed 's/pattern/&amp;\\n/g' filename#行前：sed 's/pattern/\\n&amp;/g' filename&amp;代表pattern### 使用变量替换(使用双引号)sed -e &quot;s/$var1/$var2/g&quot; filename### 在第一行前插入文本sed -i '1 i\\插入字符串' filename### 在最后一行插入sed -i '$ a\\插入字符串' filename### 在匹配行前插入sed -i '/pattern/ i &quot;插入字符串&quot;' filename### 在匹配行后插入sed -i '/pattern/ a &quot;插入字符串&quot;' filename### 删除文本中空行和空格组成的行以及#号注释的行grep -v ^# filename | sed /^[[:space:]]*$/d | sed /^$/d grep 查看大日志文件123456789101112# A -&gt; After# B -&gt; Before# C -&gt; Contextgrep -A5 'Time: 210607 15:[45-59]' slow3306_9110.log# 匹配多个关键字（且）# 管道符连接 多个条件 实现关键字 且关系 匹配：grep -A5 'Time: 210607 15:[45-59]' slow3306_9110.log | grep 'Query_time: (\\d[2-5])'# 同一行同时满足两个条件（Time、Query_time）才能够匹配。# grep -E 匹配多个关键字（或）grep -E &quot;word1|word2|word3&quot; file.txt# 匹配文件中 同一行包含 word1、word2、word3 之一 tar 压缩、解压123456789# -c: 打包 把 /conf/xxx.* 打包到 xxx.tar.gztar czvf xxx.tar.gz /conf/xxx.*# -x: 解压缩 tar xzvf xxx.tar.gz# -z: gzip 压缩格式# -v: 显示打包guoch# -f：显示打包名称 linux 重启hosts12sudo /etc/init.d/network restart linux 文件属性、权限123456789101112131415# 修改文件属主、组chown -R lch.lch /usr/localchgrp -R lch /usr/local# 修改 u g o 权限chomd g=rwx 1.txtchomd u=rwx 1.txtchomd o=rwx 1.txt# 增加shell 执行权限chmod +x xxx.sh# 修改用户的组usermod -g root lchuserdel -R lch useradd user123456adduser '用户名'passwd '用户名'chmod -v u+w /etc/sudoersvim /etc/sudoers centos找到Allow root to run any commands anywhere之后添加一行 1'用户名' ALL=(ALL) ALL 如需新用户使用sudo时不用输密码，把最后一个ALL改为NOPASSWD:ALL即可 ubuntu123# User privilege specificationroot ALL=(ALL:ALL) ALLsummer ALL=(ALL:ALL) ALL sudoers的权限被改了，改回来就好了。 1pkexec chmod 0440 /etc/sudoers delete user1sudo userdel '用户名' list user123less /etc/passwdcut -d: -f1 /etc/passwd. firewall1sudo systemctl status firewalld 1sudo firewall-cmd --zone=public --add-port=3306/tcp --permanent 1sudo firewall-cmd --reload 1sudo firewall-cmd --list-all 1234567891011121314151617181920212223启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed配置firewalld-cmd查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic ab testapach AB test1234# -n: 执行的请求数# -c: 并发数ab -c10 -n100 http://www.baidu.com/ cmd not found1sudo yum install net-tools -y centos7修改hostname1234567hostnamectl set-hostname my_hostname # 使用这个命令会立即生效且重启也生效hostname # 查看下# my_hostnamevim /etc/hosts # 编辑下hosts文件， 给127.0.0.1添加hostnamecat /etc/hosts # 检查#127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 centos77.magedu.com#::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 一次删除多个路径下的文件12# 删除node1 ~ node6/data 下的文件rm -rf node{1,2,3,4,5,6}/data/* 目录结构12345678910111213141516171819├── docker-compose.yaml├── node1│ ├── data│ └── redis.conf├── node2│ ├── data│ └── redis.conf├── node3│ ├── data│ └── redis.conf├── node4│ ├── data│ └── redis.conf├── node5│ ├── data│ └── redis.conf└── node6 ├── data └── redis.conf Fix： Failed to download metadata for repo123456789101112#Step 1: Go to the /etc/yum.repos.d/ directory.cd /etc/yum.repos.d/#Step 2: Run the below commandssed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*#Step 3: Now run the yum updateyum update -y 在linux终端命令行模式中输入以下命令查看centos版本即可。1cat /etc/redhat-release #查看centos版本 相关操作命令：1234567uname -a #查看内核版本等信息cat /proc/cpuinfo | grep &quot;physical id&quot; | uniq | wc -l #查看cpu个数cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq #查看cpu核数cat /proc/cpuinfo | grep 'model name' |uniq #查看cpu型号 查看CPU情况以下是个人工作会经常使用到的服务器的信息。 查看所有CPU信息1cat /proc/cpuinfo 查看CPU处理器个数及核心数1cat /proc/cpuinfo | grep processor 查看内存情况12345cat /proc/meminfofree -m # 以M为单位显示free -h # 以人可读的方式显示，单位G 查看CPU和内存使用情况 top htop参考文章 Failed to download metadata for repo ‘AppStream’ [CentOS] centos修改主机名的正确方法 Linux查看CPU和内存情况","link":"/2021/09/27/linux/linux/linux-cmd/"},{"title":"安装 VMware Tools","text":"在 Windows 虚拟机中手动安装 VMware Tools在 Linux 虚拟机中手动安装 VMware Tools在 Linux 虚拟机中手动安装 VMware Tools 16版本ZF3R0-FHED2-M80TY-8QYGC-NPKYF 123ZF3R0-FHED2-M80TY-8QYGC-NPKYFYF390-0HF8P-M81RQ-2DXQE-M2UT6ZF71R-DMX85-08DQY-8YMNC-PPHV8 参考文章 记录基于VMware中，Centos8下设置静态IP的简要步骤 VMware虚拟机下Centos8 设置静态IP地址 为VMWare中的CentOS8虚拟机设置固定IP","link":"/2022/03/25/software/vmware/vmware-tools/"},{"title":"VMware中，Centos8下设置静态IP","text":"查看VMware的IP设置 选择NAT模式，点击更改设置进行设置将使用本地DHCP服务IP地址分配给虚拟机的勾勾去掉，因为我们是要配置静态IP，如果不去掉这个，每次虚拟机开机都会动态的被分配一个IP地址。下面红色框框的IP地址表示，等会儿我们要设置的静态IP要和它的网段保持一致，也就是保持前三个网段相同即可。子网掩码用同样的。接下来我们来进行NAT设置，看看虚拟机的网关是多少，等会儿我们设置静态IP的时候需要这个。点进去我们可以看到虚拟机的网关（192.168.23.2），将他记下来，等会要用。之后点击确定退出设置。 设置虚拟机网卡点击电脑右下角的联网设置，再点击网络和Internet设置。进去之后点击更改适配器选项。找到VMware8，右键 -&gt; 属性 -&gt; Internet协议版本4（TCP/IPv4）-&gt; 属性选择使用下面的IP的地址，填写自己IP地址（只要保持前三个网段和刚才虚拟机的子网的前三个网段一致即可）。例如，我们刚才看到我的虚拟机子网为192.168.23.0，则我们可以设置为192.168.23.100。子网掩码默认。网关： 192.169.23.2DNS: 8.8.8.8点击确定。 设置Censos8的静态IP打开终端输入命令：vim /etc/sysconfig/network-scripts/ifcfg-ens33设置自己的静态IP。将BOOTPROTO改为static，ONBOOT改为yes。然后在文件后面添加IP信息。IPADDR自己随便设置，只要保持前三个网段和虚拟机的子网前三个网段一致即可；GATEWAY（网关）设置为刚才我们记下来的虚拟机网关；NETMASK（子网掩码）默认即可；DNS1（域名解析服务器）填公共的8.8.8.8即可。 操作实例1vim /etc/sysconfig/network-scripts/ifcfg-ens160 12345678910111213141516171819TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noNAME=ens160#UUID=10413ef3-a147-4364-a8b0-306ec6370a7bDEVICE=ens160ONBOOT=yesIPADDR=192.168.171.134GATEWAY=192.168.171.2NETMASK=255.255.255.0DNS1=8.8.8.8 填写完毕之后，保存并退出。重启网卡 12nmcli c reloadnmcli c up ens160 或者reboot重启。最后我们ping一下本机，看看能不能ping的通。发现能ping通。好，静态IP设置完毕。 参考文章 记录基于VMware中，Centos8下设置静态IP的简要步骤 VMware虚拟机下Centos8 设置静态IP地址 为VMWare中的CentOS8虚拟机设置固定IP","link":"/2022/03/25/software/vmware/vmware-centos8-static-ip/"},{"title":"linux内核分析——CFS（完全公平调度算法）","text":"参考文章 CFS（完全公平调度算法） Linux进程调度策略（CFS调度）详解 [Linux][Power]CFS调度策略 Linux完全公平调度算法原理与实现 Linux进程调度：完全公平调度器CFS 基本介绍 在 2.5 版本之前，Linux 内核采用传统 UNIX 调度算法。 在内核 V2.5 中，调度程序进行了大改，采用了称为 O(1) 的调度算法，它的运行时间为常量，与系统内任务数量无关。 在内核 V2.6 的开发中，调度程序再次修改；在内核 V2.6.23 的发布中，完全公平调度程序（CFS）成为默认的 Linux 调度算法。 Linux 系统的调度基于调度类。每个类都有一个特定优先级。内核针对不同的调度类，采用不同的调度算法，以便满足系统与进程的需要。Linux 标准内核实现两个调度类：采用 CFS 调度算法的 默认调度类和实时调度类。 CFS 调度程序并不采用严格规则来为一个优先级分配某个长度的时间片，而是为每个任务分配一定比例的 CPU 处理时间。每个任务分配的具体比例是根据友好值来计算的。友好值的范围从 -20 到 +19，数值较低的友好值表示较高的相对优先级。具有较低友好值的任务，与具有较高友好值的任务相比，会得到更高比例的处理器处理时间。默认友好值为 0。 友好一词源自如下想法：当一个任务增加了它的友好值，如从 0 至 +10，该任务通过降低优先级，进而对其他任务更加友好。 CFS 没有使用离散的时间片，而是采用目标延迟，这是每个可运行任务应当运行一次的时间间隔。根据目标延迟，按比例分配 CPU 时间。除了默认值和最小值外，随着系统内的活动任务数量超过了一定阈值，目标延迟可以增加。 CFS 调度程序没有直接分配优先级。相反，它通过每个任务的变量 vruntime 以便维护虚拟运行时间，进而记录每个任务运行多久。虚拟运行时间与基于任务优先级的衰减因子有关，更低优先级的任务比更高优先级的任务具有更高衰减速率。对于正常优先级的任务（友好值为 0），虚拟运行时间与实际物理运行时间是相同的。 因此，如果一个默认优先级的任务运行 200ms，则它的虚拟运行时间也为 200ms。然而，如果一个较低优先级的任务运行 200ms，则它的虚拟运行时间将大于 200ms。同样，如果一个更高优先级的任务运行 200ms，则它的虚拟运行时间将小于 200ms。当决定下步运行哪个任务时，调度程序只需选择具有最小虚拟运行时间的任务。此外，一个更高优先级的任务如成为可运行，就会抢占低优先级任务。 下面分析一下 CFS 调度程序是如何工作的。假设有两个任务，它们具有相同的友好值。一个任务是 I/O 密集型而另一个为 CPU 密集型。通常，I/O 密集型任务在运行很短时间后就会阻塞以便等待更多的 I/O；而 CPU 密集型任务只要有在处理器上运行的机会，就会用完它的时间片。 因此，I/O 密集型任务的虚拟运行时间最终将会小于 CPU 密集型任务的，从而使得 I/O 密集型任务具有更高的优先级。这时，如果 CPU 密集型任务在运行，而 I/O 密集型任务变得有资格可以运行（如该任务所等待的 I/O 已成为可用)，那么 I/O 密集型任务就会抢占 CPU 密集型任务。 Linux 也实现了实时调度。采用 SCHED_FIFO 或 SCHED_RR 实时策略来调度的任何任务，与普通（非实时的）任务相比，具有更高的优先级。 Linux 采用两个单独的优先级范围，一个用于实时任务，另一个用于正常任务。实时任务分配的静态优先级为 0〜99，而正常任务分配的优先级为 100〜139。 这两个值域合并成为一个全局的优先级方案，其中较低数值表明较高的优先级。正常任务，根据它们的友好值，分配一个优先级；这里 -20 的友好值映射到优先级 100，而 +19 的友好 1.1 CFS原理cfs定义了一种新的模型，它给cfs_rq（cfs的run queue）中的每一个进程安排一个虚拟时钟，vruntime。如果一个进程得以执行，随着时间的增长（也就是一个个tick的到来），其vruntime将不断增大。没有得到执行的进程vruntime不变。而调度器总是选择vruntime跑得最慢的那个进程来执行。这就是所谓的“完全公平”。为了区别不同优先级的进程，优先级高的进程vruntime增长得慢，以至于它可能得到更多的运行机会。 1.2 CFS基本设计思路CFS思路很简单，就是根据各个进程的权重分配运行时间(权重怎么来的后面再说)。 进程的运行时间计算公式为: 分配给进程的运行时间 = 调度周期 * 进程权重 / 所有进程权重之和 (公式1) 调度周期: 将所有处于TASK_RUNNING态进程都调度一遍的时间,差不多相当于O(1)调度算法中运行队列和过期队列切换一次的时间。 举个例子，比如只有两个进程A, B，权重分别为1和2，调度周期设为30ms，那么分配给A的CPU时间为:30ms * (1/(1+2)) = 10ms；而B的CPU时间为：30ms * (2/(1+2)) = 20ms。那么在这30ms中A将运行10ms，B将运行20ms。 公平怎么体现呢？它们的运行时间并不一样阿？其实公平是体现在另外一个量上面，叫做**virtual runtime(vruntime)**，它记录着进程已经运行的时间，但是并不是直接记录，而是要根据进程的权重将运行时间放大或者缩小一个比例。我们来看下从实际运行时间到vruntime的换算公式 vruntime = 实际运行时间 * 1024 / 进程权重 。 (公式2) 为了不把大家搞晕，这里我直接写1024，实际上它等于nice为0的进程的权重，代码中是NICE_0_LOAD。也就是说，所有进程都以nice为0的进程的权重1024作为基准，计算自己的vruntime增加速度。 还以上面AB两个进程为例，B的权重是A的2倍，那么B的vruntime增加速度只有A的一半。 现在我们把公式2中的实际运行时间用公式1来替换，可以得到这么一个结果： vruntime = (调度周期 * 进程权重 / 所有进程总权重) * 1024 / 进程权重 = 调度周期 * 1024 / 所有进程总权重 看出什么眉目没有？没错，虽然进程的权重不同，但是它们的 vruntime增长速度应该是一样的 ，与权重无关。好，既然所有进程的vruntime增长速度宏观上看应该是同时推进的， 那么就可以用这个vruntime来选择运行的进程，谁的vruntime值较小就说明它以前占用cpu的时间较短，受到了“不公平”对待，因此下一个运行进程就是它。这样既能公平选择进程，又能保证高优先级进程获得较多的运行时间。这就是CFS的主要思想了。 或者可以这么理解：CFS的思想就是让每个调度实体（没有组调度的情形下就是进程，以后就说进程了）的vruntime互相追赶，而每个调度实体的vruntime增加速度不同，权重越大的增加的越慢，这样就能获得更多的cpu执行时间。 再补充一下权重的来源，权重跟进程nice值之间有一一对应的关系，可以通过全局数组prio_to_weight来转换，nice值越大，权重越低。 1.3 CFS数据结构介绍代码之前先介绍一下CFS相关的结构第一个是调度实体sched_entity，它代表一个调度单位，在组调度关闭的时候可以把他等同为进程。每一个task_struct中都有一个sched_entity，进程的vruntime和权重都保存在这个结构中。那么所有的sched_entity怎么组织在一起呢？红黑树。所有的sched_entity以vruntime为key(实际上是以vruntime - min_vruntime为key，是为了防止溢出， 反正结果是一样的)插入到红黑树中，同时缓存树的最左侧节点，也就是vruntime最小的节点，这样可以迅速选中vruntime最小的进程。注意只有等待CPU的就绪态进程在这棵树上，睡眠进程和正在运行的进程都不在树上。 红黑树： 红黑树是自平衡的，没有路径比其它任何路径长两倍以上。树上运行按O(log n)时间发生（n是树中节点的数量），可以快速高效的插入或者删除任务。 任务存储在以时间为顺序的红黑树中（由 sched_entity 对象表示），对处理器需求最多的任务 （最低虚拟运行时）存储在树的左侧，处理器需求最少的任务（最高虚拟运行时）存储在树的右侧。为了公平，调度器然后选取红黑树最左端的节点调度为下一个以便保持公平性。任务通过将其运行时间添加到虚拟运行时，说明其占用 CPU 的时间，然后如果可运行，再插回到树中。这样，树左侧的任务就被给予时间运行了，树的内容从右侧迁移到左侧以保持公平。 因此，每个可运行的任务都会追赶其他任务以维持整个可运行任务集合的执行平衡。 1.4 Vruntime溢出问题之前说过红黑树中实际的作为key的不是vruntime而是vruntime - min_vruntime。min_vruntime是当前红黑树中最小的key。这是为什么呢，我们先看看vruntime的类型，是usigned long类型的，再看看key的类型，是signed long类型的，因为进程的虚拟时间是一个递增的正值，因此它不会是负数，但是它有它的上限，就是unsigned long所能表示的最大值，如果溢出了，那么它就会从0开始回滚，如果这样的话，结果会怎样？结果很严重啊，就是说会本末倒置的，比如以下例子，以unsigned char说明问题： 123unsigned char a = 251, b = 254;b += 5;//到此判断a和b的大小 看看上面的例子，b回滚了，导致a远远大于b，其实真正的结果应该是b比a大8，怎么做到真正的结果呢？改为以下： 12345unsigned char a = 251, b = 254;b += 5;signed char c = a - 250,d = b - 250;//到此判断c和d的大小 结果正确了，要的就是这个效果，可是进程的vruntime怎么用unsigned long类型而不处理溢出问题呢？因为这个vruntime的作用就是推进虚拟时钟，并没有别的用处，它可以不在乎，然而在计算红黑树的key的时候就不能不在乎了，于是减去一个最小的vruntime将所有进程的key围绕在最小vruntime的周围，这样更加容易追踪。运行队列的min_vruntime的作用就是处理溢出问题的。 1.5 组调度引入组调度是为了实现做一件事的一组进程与做另一件事的另一组进程的隔离。每件“事情”各自有自己的权重，而不管它需要使用多少进程来完成。在cfs中，task_group和进程是同等对待的，task_group的优先级也由用户来控制（通过cgroup文件cpu.shares）。实现上，task_group和进程都被抽象成schedule_entity（调度实体，以下简称se），上面说到的vruntime、load、等这些东西都被封装在se里面。而task_group除了有se之外，还有cfs_rq。属于这个task_group的进程就被装在它的cfs_rq中（“组”不仅是一个被调度的实体，也是一个容器）。组调度引入以后，一系列task_group的cfs_rq组成了一个树型结构。树根是cpu所对应的cfs_rq（也就是root group的cfs_rq）、树的中间节点是各个task_group的cfs_rq、 叶子节点是各个进程。在一个task_group的两头，是两个不同的世界，就像《盗梦空间》里不同层次的梦境一样。 1.6 CFS小结CFS还有一个重要特点，即调度粒度小。CFS之前的调度器中，除了进程调用了某些阻塞函数而主动参与调度之外，每个进程都只有在用完了时间片或者属于自己的时间配额之后才被抢占。而CFS则在每次tick都进行检查，如果当前进程不再处于红黑树的左边，就被抢占。在高负载的服务器上，通过调整调度粒度能够获得更好的调度性能。","link":"/2021/09/23/linux/linux/linux_cfs/"},{"title":"vmware win11","text":"【详细版】VMware上安装Windows 11虚拟机 虚拟机安装win11方法 vmware虚拟机怎么安装最新的Win11系统教程？ VMware Workstation上安装最新版本Win11 参考文章 【详细版】VMware上安装Windows 11虚拟机 虚拟机安装win11方法 vmware虚拟机怎么安装最新的Win11系统教程？ VMware Workstation上安装最新版本Win11","link":"/2022/03/25/software/vmware/vmware-win11/"},{"title":"dubbo","text":"参考文章 第一个 Dubbo 应用 https://dubbo.apache.org/docs/v3.0/ Dubbo Background Your First Dubbo Demo","link":"/2021/12/28/big_data/dubbo/dubbo/"},{"title":"RabbitMQ","text":"RabbitMQ 是一个消息代理：它接受和转发消息。 您可以将其视为邮局：当您将要投递的邮件放入邮箱时，您可以确定信件承运人最终会将邮件递送给您的收件人。 在这个比喻中，RabbitMQ 是一个邮箱、一个邮局和一个信件载体。 RabbitMQ 和邮局之间的主要区别在于它不处理纸张，而是接受、存储和转发二进制数据块 - 消息。 常见的MQ产品#ActiveMQ：基于JMS，Apache RocketMQ：（Rocket，火箭）阿里巴巴的产品，基于JMS，目前由Apache基于会维护 Kafka：分布式消息系统，亮点：吞吐量超级高，没秒中数十万的并发。 RabbitMQ：（Rabbit，兔子）由erlang语言开发，基于AMQP协议，在erlang语言特性的加持下，RabbitMQ稳定性要比其他的MQ产品好一些，而且erlang语言本身是面向高并发的编程的语言，所以RabbitMQ速度也非常快。且它基于AMQP协议，对分布式、微服务更友好。 参考文章 Downloading and Installing RabbitMQ RabbitMQ Messaging with RabbitMQ https://www.cnblogs.com/ZhuChangwu/p/14093107.html https://developer.aliyun.com/article/769883","link":"/2021/12/28/big_data/RabbitMQ/RabbitMQ/"},{"title":"filebeat","text":"Download Filebeat Filebeat 是一个轻量级的传送器，用于转发和集中日志数据。Filebeat 作为代理安装在您的服务器上，监控您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash以进行索引。 Filebeat 的工作原理如下：当您启动 Filebeat 时，它会启动一个或多个输入，这些输入会在您为日志数据指定的位置中查找。对于 Filebeat 找到的每个日志，Filebeat 都会启动一个收割机。每个收割机读取新内容的单个日志，并将新日志数据发送到 libbeat，后者聚合事件并将聚合数据发送到您为 Filebeat 配置的输出。 How Filebeat worksedit 参考文章 一篇文章搞懂filebeat（ELK） Filebeat中文指南 Filebeat 概述 Filebeat quick start: installation and configuration","link":"/2021/12/27/big_data/file_beat/filebeat/"},{"title":"elasticsearch","text":"Download Elasticsearch Install Elasticsearch with Docker docker installStarting a single node cluster with Docker1docker pull docker.elastic.co/elasticsearch/elasticsearch:7.16.2 1docker run -p 127.0.0.1:9200:9200 -p 127.0.0.1:9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.16.2 Starting a multi-node cluster with Docker ComposeCreate a docker-compose.yml file: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475version: '2.2'services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - elastic es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data networks: - elastic es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - xpack.security.enabled=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data networks: - elasticvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: elastic: driver: bridge Run docker-compose to bring up the cluster:12docker-compose up Submit a _cat/nodes request to see that the nodes are up and running:12curl -X GET &quot;localhost:9200/_cat/nodes?v=true&amp;pretty&quot; efk_elasticsearch_1 exited with code 78 when install ElasticSearch123sudo sysctl -w vm.max_map_count=262144sudo sysctl -w vm.max_map_count=524288 ref: https://techoverflow.net/2019/03/11/how-to-fix-elasticsearch-exited-with-code-78/ Download and install archive for Linux 单机修改 vm.max_map_count1sudo sysctl -w vm.max_map_count=524288 a.切换到root用户，修改sysctl.conf配置文件 12vi /etc/sysctl.conf b.添加如下配置文件 12vm.max_map_count=655360 c.执行如下脚本 12sysctl -p 创建一个非root用户ElasticSearch有个比较特殊的地方就是不能用root权限来运行，所以我们这边需要新建一个用户以及赋予对应权限。 a.新建一个elsearch用户组 12groupadd elsearch b.新建用户elsearch，并让他加入elsearch组 123useradd elsearch -g elsearch -p elsearchpasswd elsearch c.切换用户 1su elsearch d. root 权限 1234567chmod -v u+w /etc/sudoersvim /etc/sudoers# 找到Allow root to run any commands anywhere 之后添加一行'用户名' ALL=(ALL) ALL# 如需新用户使用sudo时不用输密码，把最后一个ALL改为NOPASSWD:ALL即可 创建日志文件夹12mkdir -p ~/data/logs/elasticsearchmkdir -p ~/data/elasticsearch/{data,work,plugins,scripts} 将下载的文件放在服务器如下目录: ~/apps/1234567sudo yum install -y wget vimsudo yum install perl-Digest-SHA -ywget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.2-linux-x86_64.tar.gzwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.2-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.16.2-linux-x86_64.tar.gz.sha512 tar -xzf elasticsearch-7.16.2-linux-x86_64.tar.gzcd elasticsearch-7.16.2/ 修改配置文件1234cd /home/elsearch/apps/elasticsearch-7.16.2/configvim elasticsearch.yml ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html 123456789101112131415cluster.name: summer-esnode.name: node-1network.host: 0.0.0.0 //监听访问地址为任意网段，也可以按自己的要求要设置对应的网段discovery.seed_hosts: [&quot;192.169.171.132&quot;]cluster.initial_master_nodes: [&quot;node-1&quot;] path.data: /home/elsearch/data/elasticsearch/datapath.logs: /home/elsearch/data/logs/elasticsearch #如果没有对应的插件，那么下面两个就不用配置，否则会报错#path.plugins: /data/elasticsearch/plugins#path.scripts: /data/elasticsearch/scripts 123discovery.seed_hosts：集群节点列表，每个值应采用host：port或host的形式（其中port默认为设置transport.profiles.default.port，如果未设置则返回transport.port）discovery.seed_providers：集群节点列表的提供者，作用就是获取discovery.seed_hosts，比如使用文件指定节点列表cluster.initial_master_nodes：初始化时master节点的选举列表，一般使用node.name（节点名称）配置指定，配置旨在第一次启动有效，启动之后会保存，下次启动会读取保存的数据 也可以通过如下配置来修改端口： 12http.port: 9200 完整配置 elasticsearch.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#cluster.name: summer-es## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /home/elsearch/data/elasticsearch/data## Path to log files:#path.logs: /home/elsearch/data/logs/elasticsearch## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## By default Elasticsearch is only accessible on localhost. Set a different# address here to expose this node on the network:#network.host: 0.0.0.0## By default Elasticsearch listens for HTTP traffic on the first free port it# finds starting at 9200. Set a specific HTTP port here:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.seed_hosts: [&quot;192.169.171.132&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: [&quot;node-1&quot;]## For more information, consult the discovery and cluster formation module documentation.# ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true## ---------------------------------- Security ---------------------------------- 启动任务1/home/elsearch/apps/elasticsearch-7.16.2/bin/elasticsearch 123cd /home/elsearch/apps/elasticsearch-7.16.2/bin/sh elasticsearch 或者用sh elasticsearch -d来后台启动 验证是否运行下面两者需同时满足 a. 输入如下脚本，有对应服务出现 12ps -ef|grep elasticsearch b.输入http//:ip:9200出现下图所示 1234567891011121314151617{ &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;summer-es&quot;, &quot;cluster_uuid&quot; : &quot;7PPB46ryTe-tIu2L45cM-Q&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.16.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;2b937c44140b6559905130a8650c64dbd0879cfb&quot;, &quot;build_date&quot; : &quot;2021-12-18T19:42:46.604893745Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.10.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot;} 关闭elasticsearch需要对ES节点进行重新启动或正常关机的时候，有三种方法可以关闭ES： 1.在控制台中,使用CTRL+C组合键.2.通过发送TERM信号终止服务器进程.3.使用REST APIcurl -XPOST ‘http://localhost:9200/_shutdown' 集群参考文章 Installation Elastic 快速入门 安装与启动 使用 Docker 安装 Elasticsearch ElasticSearch教程——安装 Download and install archive for Linux ElasticSearch+Kibana安装部署 ELK 架构之 Elasticsearch 和 Kibana 安装配置 Elasticsearch安装及kibana安装 ElasticSearch 7.8.1集群搭建 Elasticsearch集群搭建 【ElasticSearch】本地安装部署及集群搭建","link":"/2021/12/27/big_data/elasticsearch/elasticsearch/"},{"title":"Kafka面试题","text":"请说明什么是Apache Kafka？Apache Kafka是由Apache开发的一种发布订阅消息系统，它是一个分布式的、分区的和重复的日志服务。 如何获取 topic 主题的列表bin/kafka-topics.sh --list --zookeeper localhost:2181 生产者和消费者的命令行是什么？生产者在主题上发布消息： bin/kafka-console-producer.sh --broker-list 192.168.43.49:9092 --topicHello-Kafka 注意这里的 IP 是 server.properties 中的 listeners 的配置。接下来每个新行就是输入一条新消息。 消费者接受消息： bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topicHello-Kafka --from-beginning Kafka 都有哪些特点？高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。 可扩展性：kafka集群支持热扩展 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败） 高并发：支持数千个客户端同时读写 请简述下你在哪些场景下会选择 Kafka？日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。 消息系统：解耦和生产者和消费者、缓存消息等。 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。 流式处理：比如spark streaming和 Flink Kafka 的设计架构你知道吗？简单架构如下详细如下Kafka 架构分为以下几个部分 Producer ：消息生产者，就是向 kafka broker 发消息的客户端。 Consumer ：消息消费者，向 kafka broker 取消息的客户端。 Topic ：可以理解为一个队列，一个 Topic 又分为一个或多个分区， Consumer Group：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。 Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。 Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。 Offset：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是 00000000000.kafka。 Kafka 分区的目的？分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。 请说明什么是传统的消息传递方法？传统的消息传递方法包括两种： 队列：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人。 发布-订阅：在这个模型中，消息被广播给所有的用户。 请说明Kafka相对于传统的消息传递方法有什么优势？高性能：单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作，Kafka性能远超过传统的ActiveMQ、RabbitMQ等，而且Kafka支持Batch操作； 可扩展：Kafka集群可以透明的扩展，增加新的服务器进集群； 容错性： Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker。 解释下Kafka中位移（offset）的作用在Kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。 kafka 为什么那么快？ Cache Filesystem Cache PageCache缓存 顺序写：由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。 Zero-copy：零拷技术减少拷贝次数 Batching of Messages：批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。 Pull 拉模式：使用拉模式进行消息的获取消费，与消费端处理能力相符。 Kafka的用途有哪些？使用场景如何？ Kafka 持久化日志，这些日志可以被重复读取和无限期保留 Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性 Kafka 支持实时的流式处理 Kafka是一个分布式的消息系统，作为消息系统，他具备系统解耦，冗余存储，流量削峰，缓冲、异步通信等功能。同时他还是一个存储系统和流式处理平台，作为存储系统他能够把消息持久化到磁盘，降低数据丢失的风险；作为流式处理平台，不仅能够为各个流式处理框架提供稳定的数据来源，还提供了一些流式处理的库 在Kafka中broker的意义是什么？在Kafka集群中，broker指Kafka服务器。 Kafka服务器能接收到的最大信息是多少？Kafka服务器可以接收到的消息的最大大小是1000000字节。 在Kafka中，ZooKeeper的作用是什么？目前，Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。 “存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。“成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。“Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。KIP-500 思想，是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。 Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？Zookeeper是一个开放源码的、高性能的协调服务，它用于Kafka的分布式应用。 不可以，不可能越过Zookeeper直接联系Kafka broker，一旦Zookeeper停止工作，它就不能服务客户端请求。 Zookeeper主要用于在集群中不同节点之间进行通信，在Kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取，除此之外，它还执行其他活动，如: leader检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。 解释Kafka的用户如何消费信息？在Kafka中传递消息是通过使用sendfile API完成的。它支持将字节Socket转移到磁盘，通过内核空间保存副本，并在内核用户之间调用内核。 解释如何提高远程用户的吞吐量？如果用户位于与broker不同的数据中心，则可能需要调优Socket缓冲区大小，以对长网络延迟进行摊销。 为什么要使用 kafka？ 缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。 解耦和扩展性：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。 冗余：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。 健壮性：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。 异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 Kafka消费过的消息如何再消费？kafka消费消息的offset是定义在zookeeper中的，如果想重复消费kafka的消息，可以在redis中自己记录offset的checkpoint点（n个），当想重复消费消息时，通过读取redis中的checkpoint点进行zookeeper的offset重设，这样就可以达到重复消费消息的目的了 kafka的数据是放在磁盘上还是内存上，为什么速度会快？ kafka使用的是磁盘存储。 速度快是因为： 顺序写入：因为硬盘是机械结构，每次读写都会寻址-&gt;写入，其中寻址是一个“机械动作”，它是耗时的。所以硬盘 “讨厌”随机I/O， 喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。 Memory Mapped Files（内存映射文件）：64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。 Kafka高效文件存储设计：Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。通过索引信息可以快速定位message和确定response的 大 小。通过index元数据全部映射到memory（内存映射文件），可以避免segment file的IO磁盘操作。通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。 注： Kafka解决查询效率的手段之一是将数据文件分段，比如有100条Message，它们的offset是从0到99。假设将数据文件分成5段，第一段为0-19，第二段为20-39，以此类推，每段放在一个单独的数据文件里面，数据文件以该段中 小的offset命名。这样在查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个段中。 为数据文件建 索引数据文件分段 使得可以在一个较小的数据文件中查找对应offset的Message 了，但是这依然需要顺序扫描才能找到对应offset的Message。为了进一步提高查找的效率，Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index。 请说明Kafka 的消息投递保证（delivery guarantee）机制以及如何实现？Kafka支持三种消息投递语义： ① At most once 消息可能会丢，但绝不会重复传递② At least one 消息绝不会丢，但可能会重复传递③ Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户想要的 consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该partition下读取的消息的offset，该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。可以将consumer设置为autocommit，即consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。 读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于At most once。 读完消息先处理再commit消费状态(保存offset)。这种模式下，如果在处理完消息之后commit之前Consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了，这就对应于At least once。 如果一定要做到Exactly once，就需要协调offset和实际操作的输出。经典的做法是引入两阶段提交，但由于许多输出系统不支持两阶段提交，更为通用的方式是将offset和操作输入存在同一个地方。比如，consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现Exactly once。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）。总之，Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once，而Exactly once要求与目标存储系统协作，Kafka提供的offset可以较为容易地实现这种方式。 如何保证Kafka的消息有序 kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。 Kafka对于消息的重复、丢失、错误以及顺序没有严格的要求。 Kafka只能保证一个partition中的消息被某个consumer消费时是顺序的，事实上，从Topic角度来说，当有多个partition时，消息仍然不是全局有序的。 kafka 的 ack 机制request.required.acks 有三个值 0 1 -1 0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据 1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他不确保是否复制完成新 leader 也会导致数据丢失 -1：同样在 1 的基础上 服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的 ack，这样数据不会丢失 kafka数据丢失问题,及如何保证？首先需要弄明白消息为什么会丢失，对于一个消息队列，会有 生产者、MQ、消费者 这三个角色，在这三个角色数据处理和传输过程中，都有可能会出现消息丢失。 生产者数据传输导致的消息丢失 对于生产者数据传输导致的数据丢失主常见情况是生产者发送消息给 Kafka，由于网络等原因导致消息丢失，对于这种情况也是通过在 producer 端设置 acks=all 来处理，这个参数是要求 leader 接收到消息后，需要等到所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。 Kafka 导致的消息丢失Kafka 导致的数据丢失一个常见的场景就是 Kafka 某个 broker 宕机，，而这个节点正好是某个 partition 的 leader 节点，这时需要重新重新选举该 partition 的 leader。如果该 partition 的 leader 在宕机时刚好还有些数据没有同步到 follower，此时 leader 挂了，在选举某个 follower 成 leader 之后，就会丢失一部分数据。 对于这个问题，Kafka 可以设置如下 4 个参数，来尽量避免消息丢失： 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本； 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个参数的含义是一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 节点。 在 producer 端设置 acks=all，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了； 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了 消费者异常导致的消息丢失消费者可能导致数据丢失的情况是：消费者获取到了这条消息后，还未处理，Kafka 就自动提交了 offset，这时 Kafka 就认为消费者已经处理完这条消息，其实消费者才刚准备处理这条消息，这时如果消费者宕机，那这条消息就丢失了。 消费者引起消息丢失的主要原因就是消息还未处理完 Kafka 会自动提交了 offset，那么只要关闭自动提交 offset，消费者在处理完之后手动提交 offset，就可以保证消息不会丢失。但是此时需要注意重复消费问题，比如消费者刚处理完，还没提交 offset，这时自己宕机了，此时这条消息肯定会被重复消费一次，这就需要消费者根据实际情况保证幂等性。 kafka的balance是怎么做的？生产者将数据发布到他们选择的主题。生产者可以选择在主题中分配哪个分区的消息。这可以通过循环的方式来完成，只是为了平衡负载，或者可以根据一些语义分区功能（比如消息中的一些键）来完成。更多关于分区在一秒钟内的使用。 Kafka 消息是采用 Pull 模式，还是 Push 模式？生产者使用push模式将消息发布到Broker，消费者使用pull模式从Broker订阅消息。 push模式很难适应消费速率不同的消费者，如果push的速度太快，容易造成消费者拒绝服务或网络拥塞；如果push的速度太慢，容易造成消费者性能浪费。但是采用pull的方式也有一个缺点，就是当Broker没有消息时，消费者会陷入不断地轮询中，为了避免这点，kafka有个参数可以让消费者阻塞知道是否有新消息到达。 kafka的消费者方式？consumer采用pull（拉）模式从broker中读取数据。 push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。 而pull模式则可以根据consumer的消费能力以适当的速率消费消息。 对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的速率，同时consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞。 Kafka数据怎么保障不丢失？ 分三个点说，一个是生产者端，一个消费者端，一个broker端。 生产者数据的不丢失kafka的ack机制：在kafka发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到，其中状态有0，1，-1。 如果是同步模式：ack设置为0，风险很大，一般不建议设置为0。即使设置为1，也会随着leader宕机丢失数据。所以如果要严格保证生产端数据不丢失，可设置为-1。 如果是异步模式：也会考虑ack的状态，除此之外，异步模式下的有个buffer，通过buffer来进行控制数据的发送，有两个值来进行控制，时间阈值与消息的数量阈值，如果buffer满了数据还没有发送出去，有个选项是配置是否立即清空buffer。可以设置为-1，永久阻塞，也就数据不再生产。异步模式下，即使设置为-1。也可能因为程序员的不科学操作，操作数据丢失，比如kill -9，但这是特别的例外情况。 注：ack=0：producer不等待broker同步完成的确认，继续发送下一条(批)信息。ack=1（默认）：producer要等待leader成功收到数据并得到确认，才发送下一条message。ack=-1：producer得到follwer确认，才发送下一条数据。 消费者数据的不丢失通过offset commit 来保证数据的不丢失，kafka自己记录了每次消费的offset数值，下次继续消费的时候，会接着上次的offset进行消费。 而offset的信息在kafka0.8版本之前保存在zookeeper中，在0.8版本之后保存到topic中，即使消费者在运行过程中挂掉了，再次启动的时候会找到offset的值，找到之前消费消息的位置，接着消费，由于 offset 的信息写入的时候并不是每条消息消费完成后都写入的，所以这种情况有可能会造成重复消费，但是不会丢失消息。 唯一例外的情况是，我们在程序中给原本做不同功能的两个consumer组设置KafkaSpoutConfig.bulider.setGroupid的时候设置成了一样的groupid，这种情况会导致这两个组共享同一份数据，就会产生组A消费partition1，partition2中的消息，组B消费partition3的消息，这样每个组消费的消息都会丢失，都是不完整的。为了保证每个组都独享一份消息数据，groupid一定不要重复才行。 kafka集群中的broker的数据不丢失每个broker中的partition我们一般都会设置有replication（副本）的个数，生产者写入的时候首先根据分发策略（有partition按partition，有key按key，都没有轮询）写入到leader中，follower（副本）再跟leader同步数据，这样有了备份，也可以保证消息数据的不丢失。 采集数据为什么选择kafka？ 采集层 主要可以使用Flume, Kafka等技术。 Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展API. Kafka：Kafka是一个可持久化的分布式的消息队列。Kafka 是一个非常通用的系统。你可以有许多生产者和很多的消费者共享多个主题Topics。 相比之下,Flume是一个专用工具被设计为旨在往HDFS，HBase发送数据。它对HDFS有特殊的优化，并且集成了Hadoop的安全特性。 所以，Cloudera 建议如果数据被多个系统消费的话，使用kafka；如果数据被设计给Hadoop使用，使用Flume。 kafka 重启是否会导致数据丢失？ kafka是将数据写到磁盘的，一般数据不会丢失。 但是在重启kafka过程中，如果有消费者消费消息，那么kafka如果来不及提交offset，可能会造成数据的不准确（丢失或者重复消费）。 kafka 宕机了如何解决？ 先考虑业务是否受到影响 kafka 宕机了，首先我们考虑的问题应该是所提供的服务是否因为宕机的机器而受到影响，如果服务提供没问题，如果实现做好了集群的容灾机制，那么这块就不用担心了。 节点排错与恢复想要恢复集群的节点，主要的步骤就是通过日志分析来查看节点宕机的原因，从而解决，重新恢复节点。 为什么Kafka不支持读写分离？ 在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。 Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点: 数据一致性问题：数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。 延时问题：类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历 网络→主节点内存→网络→从节点内存 这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历 网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘 这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。 而kafka的主写主读的优点就很多了： 1.可以简化代码的实现逻辑，减少出错的可能;2.将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控;3.没有延时的影响;4.在副本稳定的情况下，不会出现数据不一致的情况。 Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么？ ISR：In-Sync Replicas 副本同步队列 AR:Assigned Replicas 所有副本 ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度，当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR，存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。 AR=ISR+OSR。 分区中的所有副本统称为**AR(Assigned Replicas)。所有与 leader副本保持一定程度同步的副本(包括 leader副本在内)组成ISR(In-Sync Replicas)**，ISR集合是AR集合中的一个子集。消息会先发送到 leader副本，然后 follower副本才能从 leader副本中拉取消息进行同步，同步期间内 follower副本相对于 leader副本而言会有一定程度的滞后。 前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。与 leader副本同步滞后过多的副本(不包括 leader副本)组成**OSR(Out-of-Sync Replicas)**，由此可见，AR=ISR+OSR。 在正常情况下，所有的 follower副本都应该与 leader副本保持一定程度的同步，即AR=ISR，OSR集合为空。 ISR的伸缩是指leader副本负责跟踪ISR集合中所有follower副本的滞后状态，有follower副本滞后太多的时候将他从ISR中剔除，OSR集合中有follower副本”追上“了leader副本将其加入ISR集合中 Kafka中的HW、LEO、LSO、LW等分别代表什么？HW是 High Watermark的缩写，俗称高水位，它标识了一个特定的消息偏移量(offset)，消费者只能拉取到这个offset之前的消息。 LEO是 Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的 offset。LEO的大小相当于当前日志分区中最后一条消息的 offset值加1。分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。LSO(Last Stable Offset) 对未完成的事务而言，LSO 的值等于事务中第一条消息的位(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同LW:Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值 Kafka中是怎么体现消息顺序性的？通过Topic和Partition来提现，Topic是消息归类的主题是逻辑概念，Topic下有多个Partition，其在存储层面可以看成是一个可追加的日志文件，消息在被追加到Partition日志文件中的时候会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，Kafka通过offset来保证消息在分区内的顺序性 Kafka 如何保证消息的顺序性在某些业务场景下，我们需要保证对于有逻辑关联的多条MQ消息被按顺序处理，比如对于某一条数据，正常处理顺序是新增-更新-删除，最终结果是数据被删除；如果消息没有按序消费，处理顺序可能是删除-新增-更新，最终数据没有被删掉，可能会产生一些逻辑错误。对于如何保证消息的顺序性，主要需要考虑如下两点： 如何保证消息在 Kafka 中顺序性； 如何保证消费者处理消费的顺序性。如何保证消息在 Kafka 中顺序性对于 Kafka，如果我们创建了一个 topic，默认有三个 partition。生产者在写数据的时候，可以指定一个 key，比如在订单 topic 中我们可以指定订单 id 作为 key，那么相同订单 id 的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。消费者从 partition 中取出来数据的时候，也一定是有顺序的。通过制定 key 的方式首先可以保证在 kafka 内部消息是有序的。 如何保证消费者处理消费的顺序性对于某个 topic 的一个 partition，只能被同组内部的一个 consumer 消费，如果这个 consumer 内部还是单线程处理，那么其实只要保证消息在 MQ 内部是有顺序的就可以保证消费也是有顺序的。但是单线程吞吐量太低，在处理大量 MQ 消息时，我们一般会开启多线程消费机制，那么如何保证消息在多个线程之间是被顺序处理的呢？对于多线程消费我们可以预先设置 N 个内存 Queue，具有相同 key 的数据都放到同一个内存 Queue 中；然后开启 N 个线程，每个线程分别消费一个内存 Queue 的数据即可，这样就能保证顺序性。当然，消息放到内存 Queue 中，有可能还未被处理，consumer 发生宕机，内存 Queue 中的数据会全部丢失，这就转变为上面提到的如何保证消息的可靠传输的问题了。 Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？分区器、序列化器、拦截器都是生产者客户端中的东西。 分区器是将消息发送给指定的分区的，如果在发送的消息中指定了Partition，就不需要分区器了，默认的分区器中对key进行哈希（采用MurmurHash2算法，具备高运算性能及低碰撞率），同时也可以自定义分区器 序列化器把消息对象转换成字节数组，这样才能够通过网络发送给Kafka。 生产者拦截器既可以用来在消息发送前做一些准备工作,比如按照某个规则过滤不符合要求的消息、修改消息的内容等,也可以用来在发送回调逻辑前做一些定制化的需求,比如统计类工作。 他们之间工作的顺序是 拦截器 -&gt; 序列化器 -&gt; 分区器 Kafka生产者客户端的整体结构是什么样子的？ Kafka生产者客户端中使用了几个线程来处理？分别是什么？使用了两个线程来进行处理：主线程和Sender线程。 主线程负责由KafkaProducer创建消息，通过拦截器、序列化器和分区器作用以后缓存到消息累加器； Sender线程负责从消息累加器中获取消息并将其发送到Kafka中 “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果正确，那么有没有什么hack的手段？是正确的，可以让多个消费线程消费同一个分区来hack，通过assign()、seek()等方法实现，这样可以打破原有的消费线程的个数不能超过分区的限制。 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?提交的是offset + 1，表示下一条需要拉取的消息的位置 有哪些情形会造成重复消费？ 位移提交动作在消费完所有拉取到的消息后才执行会造成重复消费，因为批量拉取一批消息以后，中间消费处理的过程中可能会出现异常，这样的会前面消费的消息就会再消费一次 Rebalance 的时候也会出现，一个分区在原有消费者的位移没有上传的时候分配给另外一个消费者，另外一个消费会从上一次位移的地方继续拉取消息进行消费，这样就造成了消息的重复消费，后续可以通过添加Rebalance的监听器来做一些Rebalance的工作来解决位移未提交的问题 那些情景下会造成消息漏消费？位移提交动作在消费消息之前会造成消息漏消费，因为提交新的位移以后，可能拉取到的那一批消息中间出现异常，那么那一批消息后面的那一部分消息就不会被消费到，这样就导致了消息的漏消费 KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？第一种方式：线程封闭，每个线程实例化一个KafkaConsumer对象，一个消费线程可以消费一个或者多个分区中的消息，所有的消费线程都隶属于同一个消费者组。第二种方式：多个消费线程同时消费同一个分区，通过assign()、seek()等方法实现，这样可以打破原有的消费线程的个数不能超过分区的限制，进一步提高消费能力。但是这种方式会导致位移提交和顺序控制的处理变得更加复杂。 什么是消费者组？消费者组是Kafka独有的概念，即消费者组是Kafka提供的可扩展且具有容错性的消费者机制。 但实际上，消费者组（Consumer Group）其实包含两个概念，作为队列，消费者组允许你分割数据处理到一组进程集合上（即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据），这有助于你的消费能力的动态调整；作为发布-订阅模型（publish-subscribe），Kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。 需要注意的是：在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 因此，消费者组在一定程度上也保证了消费者程序的高可用性。 简述消费者与消费组之间的关系每一个消费者都属于一个消费者组中，消费者组能够消费到一个主题中的所有消息（实现多播），然后把这些消息通过Partition负载均衡分配给具体的消费者进行消费。 Kafka 的设计是什么样的？Kafka 将消息以 topic 为单位进行归纳 将向 Kafka topic 发布消息的程序成为 producers. 将预订 topics 并消费消息的程序成为 consumer. Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker. producers 通过网络将消息发送到 Kafka 集群，集群向消费者提供消息 Kafka 如何保证高可用？副本机制Kafka 的基本架构组成是：由多个 broker 组成一个集群，每个 broker 是一个节点；当创建一个 topic 时，这个 topic 会被划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 只存放一部分数据。 这就是天然的分布式消息队列，就是说一个** topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据**。 在 Kafka 0.8 版本之前，是没有 HA 机制的，当任何一个 broker 所在节点宕机了，这个 broker 上的 partition 就无法提供读写服务，所以这个版本之前，Kafka 没有什么高可用性可言。 在 Kafka 0.8 以后，提供了 HA 机制，就是 replica 副本机制。每个 partition 上的数据都会同步到其它机器，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，消息的生产者和消费者都跟这个 leader 打交道，其他 replica 作为 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。Kafka 负责均匀的将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。 拥有了 replica 副本机制，如果某个 broker 宕机了，这个 broker 上的 partition 在其他机器上还存在副本。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从其 follower 中重新选举一个新的 leader 出来，这个新的 leader 会继续提供读写服务，这就有达到了所谓的高可用性。 写数据的时候，生产者只将数据写入 leader 节点，leader 会将数据写入本地磁盘，接着其他 follower 会主动从 leader 来拉取数据，follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。 消费数据的时候，消费者只会从 leader 节点去读取消息，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。 截断机制如果出现 Leader 故障下线的情况，就需要从所有的 Follower 中选举新的 Leader，以便继续提供服务。为了保证一致性，通常只能从 ISR 列表中选取新的 Leader (上面已经介绍，ISR 列表中的 Follower 与原 Leader 保持同步)，因此，无论 ISR 中哪个 Follower 被选为新的 Leader，它都知道 HW 之前的数据，可以保证在切换了 Leader 后，Consumer 可以继续“看到”之前已经由 Producer 提交的数据。 如下图所示，如果 Leader 宕机，Follower1 被选为新的 Leader，而新 Leader (原 Follower1 )并没有完全同步之前 Leader 的所有数据(少了一个消息 6)，之后，新 Leader 又继续接受了新的数据，此时，原本宕机的 Leader 经修复后重新上线，它将发现新 Leader 中的数据和自己持有的数据不一致，怎么办呢? 为了保证一致性，必须有一方妥协，显然旧的 Leader 优先级较低，因此， 它会将自己的数据截断到宕机之前的 HW 位置(HW 之前的数据，与 Leader 一定是相同的)，然后同步新 Leader 的数据。这便是所谓的 “截断机制”。 描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别Kafka副本当前分为领导者副本和追随者副本。只有Leader副本才能对外提供读写服务，响应Clients端的请求。Follower副本只是采用拉（PULL）的方式，被动地同步Leader副本中的数据，并且在Leader副本所在的Broker宕机后，随时准备应聘Leader副本。 加分点： 强调Follower副本也能对外提供读服务。自Kafka 2.4版本开始，社区通过引入新的Broker端参数，允许Follower副本有限度地提供读服务。 强调Leader和Follower的消息序列在实际场景中不一致。通常情况下，很多因素可能造成Leader和Follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注（秒级别），但长时间的不同步可能就需要深入排查了，因为一旦Leader所在节点异常，可能直接影响可用性。 注意：之前确保一致性的主要手段是高水位机制（HW），但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。 分区Leader选举策略有几种？分区的Leader副本选举对用户是完全透明的，它是由Controller独立完成的。你需要回答的是，在哪些场景下，需要执行分区Leader选举。每一种场景对应于一种选举策略。 OfflinePartition Leader选举：每当有分区上线时，就需要执行Leader选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区Leader选举场景。 ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。 PreferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。 ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。 这4类选举策略的大致思想是类似的，即从AR中挑选首个在ISR中的副本，作为新Leader。 Kafka的哪些场景中使用了零拷贝（Zero Copy）？在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。 先说第一个。索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。 再说第二个。TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I/O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I/O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？创建:在zk上/brokers/topics/下节点 kafkabroker会监听节点变化创建主题删除:调用脚本删除topic会在zk上将topic设置待删除标志，kafka后台有定时的线程会扫描所有需要删除的topic进行删除 Kafka 分区数可以增加或减少吗？为什么？我们可以使用 bin/kafka-topics.sh 命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂。 topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？可以 topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？不可以 创建topic时如何选择合适的分区数？根据集群的机器数量和需要的吞吐量来决定适合的分区数 Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？__consumer_offsets 以下划线开头，保存消费组的偏移 优先副本是什么？它有什么特殊的作用？优先副本 会是默认的leader副本 发生leader变化时重选举会优先选择优先副本作为leader Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理创建主题时如果不手动指定分配方式 有两种分配方式 消费组内分配 怎么解决rebalance中遇到的问题呢？要避免 Rebalance，还是要从 Rebalance 发生的时机入手。我们在前面说过，Rebalance 主要发生的时机有三个： 组成员数量发生变化 订阅主题数量发生变化 订阅主题的分区数发生变化 后两个我们大可以人为的避免，发生rebalance最常见的原因是消费组成员的变化。 消费者成员正常的添加和停掉导致rebalance，这种情况无法避免，但是时在某些情况下，Consumer 实例会被 Coordinator 错误地认为 “已停止” 从而被“踢出”Group。从而导致rebalance。 当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。如果某个 Consumer 实例不能及时地发送这些心跳请求，Coordinator 就会认为该 Consumer 已经 “死” 了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。这个时间可以通过Consumer 端的参数 session.timeout.ms进行配置。默认值是 10 秒。 除了这个参数，Consumer 还提供了一个控制发送心跳请求频率的参数，就是 heartbeat.interval.ms。这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance，因为，目前 Coordinator 通知各个 Consumer 实例开启 Rebalance 的方法，就是将 REBALANCE_NEEDED 标志封装进心跳请求的响应体中。 除了以上两个参数，Consumer 端还有一个参数，用于控制 Consumer 实际消费能力对 Rebalance 的影响，即 max.poll.interval.ms 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起 “离开组” 的请求，Coordinator 也会开启新一轮 Rebalance。 通过上面的分析，我们可以看一下那些rebalance是可以避免的： 第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被 “踢出”Group 而引发的。这种情况下我们可以设置 session.timeout.ms 和 heartbeat.interval.ms 的值，来尽量避免rebalance的出现。（以下的配置是在网上找到的最佳实践，暂时还没测试过） 设置 session.timeout.ms = 6s。设置 heartbeat.interval.ms = 2s。要保证 Consumer 实例在被判定为 “dead” 之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &gt;= 3 * heartbeat.interval.ms。将 session.timeout.ms 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer，早日把它们踢出 Group。 第二类非必要 Rebalance 是 Consumer 消费时间过长导致的。此时，max.poll.interval.ms 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。 总之，要为业务处理逻辑留下充足的时间。这样，Consumer 就不会因为处理这些消息的时间太长而引发 Rebalance 。 请谈一谈 Kafka 数据一致性原理一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。 假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。 这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。 当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。 谈一谈 Kafka 的再均衡在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。所以对于Rebalance来说，Coordinator起着至关重要的作用 参考文章 Kafka面试题有哪些 大数据面试题——Kafka面试题总结（一） Kafka 面试题整理 Kafka面试题系列之进阶篇 Kafka面试题.md Kafka面试题与答案全套整理 300道 Kafka最全面试题整理（持续更新） Kafka面试题及答案整理 110道 （持续更新） 20道经典的Kafka面试题详解 45道Kafka面试题及答案 浅析Kafka面试题 Kafka经典面试题详解 Kafka 面试题：基础 27 问，必须都会的呀！ 18道kafka高频面试题哪些你还不会？（含答案和思维导图） 32 道常见的 Kafka 面试题你都会吗？附答案 八年面试生涯，整理了一套Kafka面试题 Kafka面试题（高吞吐量必问）","link":"/2021/12/15/big_data/kafka/kafka-1/"},{"title":"在Windows下安装使用Kafka","text":"123456cd xxxx\\kafka\\bin\\windows# start zookeeper.\\zookeeper-server-start.bat ..\\..\\config\\zookeeper.properties# start kafka.\\kafka-server-start.bat ..\\..\\config\\server.properties 下载地址创建一个主题1.\\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafka-test-topic 查看创建的主题列表1.\\kafka-topics.bat --list --zookeeper localhost:2181 启动生产者：1.\\kafka-console-producer.bat --broker-list localhost:9092 --topic kafka-test-topic 启动消费者：1.\\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic kafka-test-topic --from-beginning 参考文章 在Windows下安装使用Kafka kafka quick start kafka 在windows 平台的搭建和简单实用 Kafka集群搭建","link":"/2021/12/15/big_data/kafka/kafka-windows-install/"},{"title":"基于Zookeeper搭建Kafka高可用集群","text":"install zookeeper/kafka cluster 一、Zookeeper集群搭建为保证集群高可用，Zookeeper 集群的节点数最好是奇数，最少有三个节点，所以这里搭建一个三个节点的集群。 1.1 下载 &amp; 解压下载对应版本 Zookeeper，这里我下载的版本 3.4.14。官方下载地址：https://archive.apache.org/dist/zookeeper/ 1234# 下载wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz# 解压tar -zxvf zookeeper-3.4.14.tar.gz 1.2 修改配置拷贝三份 zookeeper 安装包。分别进入安装目录的 conf 目录，拷贝配置样本 zoo_sample.cfg 为 zoo.cfg 并进行修改，修改后三份配置文件内容分别如下： zookeeper01 配置： 123456789101112tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/01dataLogDir=/usr/local/zookeeper-cluster/log/01clientPort=2181# server.1 这个1是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到dataDir目录下面myid文件里# 指名集群间通讯端口和选举端口server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 如果是多台服务器，则集群中每个节点通讯端口和选举端口可相同，IP 地址修改为每个节点所在主机 IP 即可。 zookeeper02 配置，与 zookeeper01 相比，只有 dataLogDir、dataLogDir 和 clientPort 不同： 12345678910tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/02dataLogDir=/usr/local/zookeeper-cluster/log/02clientPort=2182server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 zookeeper03 配置，与 zookeeper01，02 相比，也只有 dataLogDir、dataLogDir 和 clientPort 不同： 12345678910tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper-cluster/data/03dataLogDir=/usr/local/zookeeper-cluster/log/03clientPort=2183server.1=127.0.0.1:2287:3387server.2=127.0.0.1:2288:3388server.3=127.0.0.1:2289:3389 配置参数说明： tickTime：用于计算的基础时间单元。比如 session 超时：N*tickTime； initLimit：用于集群，允许从节点连接并同步到 master 节点的初始化连接时间，以 tickTime 的倍数来表示； syncLimit：用于集群， master 主节点与从节点之间发送消息，请求和应答时间长度（心跳机制）； dataDir：数据存储位置； dataLogDir：日志目录； clientPort：用于客户端连接的端口，默认 2181 1.3 标识节点分别在三个节点的数据存储目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 leader 节点。 创建存储目录： 123456# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/01# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/02# dataDirmkdir -vp /usr/local/zookeeper-cluster/data/03 创建并写入节点标识到 myid 文件： 123456#server1echo &quot;1&quot; &gt; /usr/local/zookeeper-cluster/data/01/myid#server2echo &quot;2&quot; &gt; /usr/local/zookeeper-cluster/data/02/myid#server3echo &quot;3&quot; &gt; /usr/local/zookeeper-cluster/data/03/myid 1.4 启动集群分别启动三个节点： 123456# 启动节点1/usr/app/zookeeper-cluster/zookeeper01/bin/zkServer.sh start# 启动节点2/usr/app/zookeeper-cluster/zookeeper02/bin/zkServer.sh start# 启动节点3/usr/app/zookeeper-cluster/zookeeper03/bin/zkServer.sh start 1.5 集群验证使用 jps 查看进程，并且使用 zkServer.sh status 查看集群各个节点状态。如图三个节点进程均启动成功，并且两个节点为 follower 节点，一个节点为 leader 节点。 二、Kafka集群搭建2.1 下载解压Kafka 安装包官方下载地址：http://kafka.apache.org/downloads ，本用例下载的版本为 2.2.0，下载命令： 1234# 下载wget https://www-eu.apache.org/dist/kafka/2.2.0/kafka_2.12-2.2.0.tgz# 解压tar -xzf kafka_2.12-2.2.0.tgz 这里解释一下 kafka 安装包的命名规则：以 kafka_2.12-2.2.0.tgz 为例，前面的 2.12 代表 Scala 的版本号（Kafka 采用 Scala 语言进行开发），后面的 2.2.0 则代表 Kafka 的版本号。 2.2 拷贝配置文件进入解压目录的 config 目录下 ，拷贝三份配置文件： 123# cp server.properties server-1.properties# cp server.properties server-2.properties# cp server.properties server-3.properties 2.3 修改配置分别修改三份配置文件中的部分配置，如下： server-1.properties： 12345678# The id of the broker. 集群中每个节点的唯一标识broker.id=0# 监听地址listeners=PLAINTEXT://hadoop001:9092# 数据的存储位置log.dirs=/usr/local/kafka-logs/00# Zookeeper连接地址zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 server-2.properties： 1234broker.id=1listeners=PLAINTEXT://hadoop001:9093log.dirs=/usr/local/kafka-logs/01zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 server-3.properties： 1234broker.id=2listeners=PLAINTEXT://hadoop001:9094log.dirs=/usr/local/kafka-logs/02zookeeper.connect=hadoop001:2181,hadoop001:2182,hadoop001:2183 这里需要说明的是 log.dirs 指的是数据日志的存储位置，确切的说，就是分区数据的存储位置，而不是程序运行日志的位置。程序运行日志的位置是通过同一目录下的 log4j.properties 进行配置的。 2.4 启动集群分别指定不同配置文件，启动三个 Kafka 节点。启动后可以使用 jps 查看进程，此时应该有三个 zookeeper 进程和三个 kafka 进程。 123bin/kafka-server-start.sh config/server-1.propertiesbin/kafka-server-start.sh config/server-2.propertiesbin/kafka-server-start.sh config/server-3.properties 2.5 创建测试主题创建测试主题： 123bin/kafka-topics.sh --create --bootstrap-server hadoop001:9092 \\ --replication-factor 3 \\ --partitions 1 --topic my-replicated-topic 创建后可以使用以下命令查看创建的主题信息： 1bin/kafka-topics.sh --describe --bootstrap-server hadoop001:9092 --topic my-replicated-topic 可以看到分区 0 的有 0,1,2 三个副本，且三个副本都是可用副本，都在 ISR(in-sync Replica 同步副本) 列表中，其中 1 为首领副本，此时代表集群已经搭建成功。 参考文章 Kafka集群搭建 基于Zookeeper搭建Kafka高可用集群","link":"/2021/12/15/big_data/kafka/kafka-cluster/"},{"title":"kibana","text":"Kibana—your window into ElasticeditInstall Kibana with Docker Run Kibana on Docker for developmenteditTo start an Elasticsearch container for development or testing, run: 123docker network create elasticdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.16.2docker run --name es01-test --net elastic -p 127.0.0.1:9200:9200 -p 127.0.0.1:9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.16.2 To start Kibana and connect it to your Elasticsearch container, run the following commands in a new terminal session: 123docker pull docker.elastic.co/kibana/kibana:7.16.2docker run --name kib01-test --net elastic -p 127.0.0.1:5601:5601 -e &quot;ELASTICSEARCH_HOSTS=http://es01-test:9200&quot; docker.elastic.co/kibana/kibana:7.16.2 To access Kibana, go to http://localhost:5601. Install Kibana with Dockerref: https://www.elastic.co/guide/en/kibana/current/docker.html#bind-mount-config 123456version: '2'services: kibana: image: docker.elastic.co/kibana/kibana:7.16.2 volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml Install Kibana from archive on Linux1234curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.16.2-linux-x86_64.tar.gzcurl https://artifacts.elastic.co/downloads/kibana/kibana-7.16.2-linux-x86_64.tar.gz.sha512 | shasum -a 512 -c - tar -xzf kibana-7.16.2-linux-x86_64.tar.gzcd kibana-7.16.2-linux-x86_64/ 修改config/kibana.yml，添加ElasticSearch的节点配置：12/home/elsearch/apps/kibana-7.16.2-linux-x86_64cd config 1234567891011# 服务端口，默认5601server.port: 5601# 启动地址，默认localhost，如果不修改，那么远程无法访问server.host: 0.0.0.0# elasticsearch集群地址，旧版本是elasticsearch.urlelasticsearch.hosts: [&quot;http://192.168.209.128:9200&quot;,&quot;http://192.168.209.129:9200&quot;,&quot;http://192.168.209.132:9200&quot;]# 如果ES有设置账号密码，则添加下面的账号密码设置#elasticsearch.username: username#elasticsearch.password: passwor 启动1/home/elsearch/apps/kibana-7.16.2-linux-x86_64/bin/kibana 访问测试在浏览器中输入http://IP:5601会有对应的kibana界面显示 参考文章 Download Kibana Quick start Deploy an Elasticstack with SIEM with docker-compose for lab Install Kibana from archive on Linux or macOS ElasticSearch+Kibana安装部署 ElasticSearch教程——安装Kibana ElasticSearch+Kibana安装部署 ELK 架构之 Elasticsearch 和 Kibana 安装配置","link":"/2021/12/27/big_data/kibana/kibana/"},{"title":"install flink &amp; IDEA Hello world","text":"1. install flink** 下载和解压 ** 从下载页下载一个二进制的包，你可以选择任何你喜欢的Hadoop/Scala组合包。如果你计划使用文件系统，那么可以使用任何Hadoop版本。进入下载目录解压下载的压缩包 123$ cd ~/Downloads # Go to download directory$ tar xzf flink-*.tgz # Unpack the downloaded archive$ cd flink-1.2.0 2. start flink cluster1$ ./bin/start-local.sh # Start Flink 通过访问http://localhost:8081检查JobManager网页,确保所有组件都已运行。网页会显示一个有效的TaskManager实例。 3. run SocketWindowWordCount现在, 我们可以运行Flink 应用程序。 这个例子将会从一个socket中读一段文本，并且每隔5秒打印每个单词出现的数量。 例如 a tumbling window of processing time, as long as words are floating in. 1$ nc -l 9000 1$ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000 单词的数量在5秒的时间窗口中进行累加（使用处理时间和tumbling窗口），并打印在stdout。监控JobManager的输出文件，并在nc写一些文本(回车一行就发送一行输入给Flink) : 1234$ nc -l 9000lorem ipsumipsum ipsum ipsumbye 译者注：mac下使用命令nc -l -p 9000来启动监听端口，如果有问题可以telnet localhost 9000看下监听端口是否已经启动，如果启动有问题可以重装netcat ，使用命令brew install netcat。 .out文件将被打印每个时间窗口单词的总数： 1234$ tail -f log/flink-*-jobmanager-*.outlorem : 1bye : 1ipsum : 4 使用以下命令来停止Flink: 1$ ./bin/stop-local.sh 4. idea -&gt; flink maven projectref: https://www.jianshu.com/p/fdc4212422f7 选择Maven 然后选中create from archetype 在列表中找flink-quickstart 找不到的话，点击右边的add archetype 在弹出框中输入： groupId：org.apache.flinkartifactId：flink-quickstart-javaversion：1.11.1repository：https://mirrors.huaweicloud.com/repository/maven/ 从flink.apache.org下载flink-1.11.1-src.tgz，(下载地址：https://www.apache.org/dyn/closer.lua/flink/flink-1.11.1/flink-1.11.1-src.tgz) 也可以从https://github.com/中搜flink，然后点击apache/flink下载源码 将flink-1.11.1-src.tgz解压缩后， 找到子目录\\flink-1.11.1-src\\flink-1.11.1\\flink-examples\\flink-examples-batch\\src\\main\\java\\org\\apache\\flink\\examples\\java\\wordcountcopy文件 将其下的WordCount.java文件及util文件夹复制到FlinkTest工程的以下子目录下 Flink-QuickStart-Java\\src\\main\\java\\org\\example 然后到IDEA,会多出两个文件 修改WordCount.java 把WordCount.java中的 1.将package org.apache.flink.examples.java.wordcount改为 package org.example; 2.将import org.apache.flink.examples.java.wordcount.util.WordCountData; 改为 import org.example.util.WordCountData; 修改util/WordCountData.java 把package org.apache.flink.examples.java.wordcount.util改为 package org.example.util; b)重新编译和打包 运行之：在 {FLINK_HOME}/examples 创建 words.txt. 1./bin/flink run -m localhost:8081 -c org.summer.WordCount examples/myflink-1.0-SNAPSHOT.jar --input examples/words.txt --output examples/result001.txt 5. run flink in Idea下载flink-1.13.0 安装包，这里面有flink网页服务用到的一个jar，地址是：https://flink.apache.org/downloads.html 下载后解压，在lib目录下有个flink-dist_2.11-1.13.0.jar文件，记住此文件的位置，稍后会用到；回到IDEA，在项目上点击右键，点击菜单Open Module Settings：设置工作已经完成，由于StreamingJob的工作是读取本机9000端口的数据，所以我们要把9000端口的服务启动起来，不然StreamingJob运行时是连不上端口的，打开一个控制台，执行命令：nc -l 9000现在可以将StreamingJob运行起来，如下图，右键点击StreamingJob，选择Run ‘StreamingJob.main()’：即可启动flink任务，如果想打断点调试，请选择Debug ‘StreamingJob.main()’ 参考文章 《Flink官方文档》Quick Start flink入门：01 构建简单运行程序 IDEA上运行Flink任务 Flink：你绕不过去的 Hello World https://www.jianshu.com/p/4a1442da2c4e","link":"/2021/10/25/big_data/flink/flink-helloworld/"},{"title":"logstash","text":"Logstash 是一个开源数据收集引擎，具有实时流水线功能。Logstash 可以动态统一来自不同来源的数据，并将数据规范化为您选择的目的地。为各种高级下游分析和可视化用例清理和民主化您的所有数据。 集中、转换和存储你的数据Logstash是一个开源的服务器端数据处理管道，可以同时从多个数据源获取数据，并对其进行转换，然后将其发送到你最喜欢的“存储”。（当然，我们最喜欢的是Elasticsearch） 输入：采集各种样式、大小和来源的数据数据往往以各种各样的形式，或分散或集中地存在于很多系统中。Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤器：实时解析和转换数据数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 Logstash 能够动态地转换和解析数据，不受格式或复杂度的影响： 利用 Grok 从非结构化数据中派生出结构 从 IP 地址破译出地理坐标 将 PII 数据匿名化，完全排除敏感字段 整体处理不受数据源、格式或架构的影响 输出：选择你的存储，导出你的数据尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 Logstash 的强大功能编辑Elasticsearch 等的摄取主力具有强大 Elasticsearch 和 Kibana 协同作用的水平可扩展数据处理管道 可插拔管道架构混合、匹配和编排不同的输入、过滤器和输出，以在管道中和谐播放 社区可扩展且对开发人员友好的插件生态系统超过 200 个可用的插件，以及创建和贡献自己的插件的灵活性 日志和指标编辑一切开始的地方。 处理所有类型的日志数据 轻松摄取大量 Web 日志（如Apache）和应用程序日志（如Java 的 log4j） 捕获许多其他日志格式，如syslog、网络和防火墙日志等 使用Filebeat享受互补的安全日志转发功能 通过TCP和UDP 从Ganglia、collectd、 NetFlow、JMX和许多其他基础设施和应用程序平台收集指标参考文章 Logstash 介绍 Logstash介绍 Elastic 技术栈之 Logstash 基础 Download Logstash 使用 Logstash 解析日志编辑","link":"/2021/12/27/big_data/logtash/logstash/"}],"tags":[{"name":"数据结构和算法","slug":"数据结构和算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"cubrid","slug":"cubrid","link":"/tags/cubrid/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"centos","slug":"centos","link":"/tags/centos/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"http-server","slug":"http-server","link":"/tags/http-server/"},{"name":"gc","slug":"gc","link":"/tags/gc/"},{"name":"jedis","slug":"jedis","link":"/tags/jedis/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"quarkus","slug":"quarkus","link":"/tags/quarkus/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"volatile","slug":"volatile","link":"/tags/volatile/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"java锁","slug":"java锁","link":"/tags/java%E9%94%81/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"二分查找","slug":"二分查找","link":"/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"reactive","slug":"reactive","link":"/tags/reactive/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"oracle","slug":"oracle","link":"/tags/oracle/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"wsl","slug":"wsl","link":"/tags/wsl/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"lettuce","slug":"lettuce","link":"/tags/lettuce/"},{"name":"webflux","slug":"webflux","link":"/tags/webflux/"},{"name":"metrics","slug":"metrics","link":"/tags/metrics/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"mybatis-plus","slug":"mybatis-plus","link":"/tags/mybatis-plus/"},{"name":"Object Storage","slug":"Object-Storage","link":"/tags/Object-Storage/"},{"name":"WebSockets","slug":"WebSockets","link":"/tags/WebSockets/"},{"name":"springdoc","slug":"springdoc","link":"/tags/springdoc/"},{"name":"springfox","slug":"springfox","link":"/tags/springfox/"},{"name":"study","slug":"study","link":"/tags/study/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"dijkstra","slug":"dijkstra","link":"/tags/dijkstra/"},{"name":"Kruskal","slug":"Kruskal","link":"/tags/Kruskal/"},{"name":"堆","slug":"堆","link":"/tags/%E5%A0%86/"},{"name":"优先队列","slug":"优先队列","link":"/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"},{"name":"树","slug":"树","link":"/tags/%E6%A0%91/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"串","slug":"串","link":"/tags/%E4%B8%B2/"},{"name":"拦截&#x2F;抓包工具","slug":"拦截-抓包工具","link":"/tags/%E6%8B%A6%E6%88%AA-%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"unreal","slug":"unreal","link":"/tags/unreal/"},{"name":"unity","slug":"unity","link":"/tags/unity/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"cocos","slug":"cocos","link":"/tags/cocos/"},{"name":"jdk","slug":"jdk","link":"/tags/jdk/"},{"name":"ansible","slug":"ansible","link":"/tags/ansible/"},{"name":"vmware","slug":"vmware","link":"/tags/vmware/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"filebeat","slug":"filebeat","link":"/tags/filebeat/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"kibana","slug":"kibana","link":"/tags/kibana/"},{"name":"flink","slug":"flink","link":"/tags/flink/"},{"name":"logstash","slug":"logstash","link":"/tags/logstash/"}],"categories":[{"name":"数据结构和算法","slug":"数据结构和算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"cubrid","slug":"cubrid","link":"/categories/cubrid/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"graph","slug":"数据结构和算法/graph","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/graph/"},{"name":"docker compose","slug":"docker/docker-compose","link":"/categories/docker/docker-compose/"},{"name":"frontend","slug":"frontend","link":"/categories/frontend/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"gc","slug":"java/gc","link":"/categories/java/gc/"},{"name":"jedis","slug":"jedis","link":"/categories/jedis/"},{"name":"jvm","slug":"java/jvm","link":"/categories/java/jvm/"},{"name":"juc","slug":"java/juc","link":"/categories/java/juc/"},{"name":"oom","slug":"java/oom","link":"/categories/java/oom/"},{"name":"quarkus","slug":"quarkus","link":"/categories/quarkus/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"并发","slug":"java/并发","link":"/categories/java/%E5%B9%B6%E5%8F%91/"},{"name":"kubernetes","slug":"kubernetes","link":"/categories/kubernetes/"},{"name":"leetcode","slug":"leetcode","link":"/categories/leetcode/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"mongodb","slug":"mongodb","link":"/categories/mongodb/"},{"name":"netty","slug":"netty","link":"/categories/netty/"},{"name":"opencv","slug":"opencv","link":"/categories/opencv/"},{"name":"network","slug":"network","link":"/categories/network/"},{"name":"oracle","slug":"oracle","link":"/categories/oracle/"},{"name":"nginx","slug":"nginx","link":"/categories/nginx/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"wsl","slug":"wsl","link":"/categories/wsl/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"metrics","slug":"spring/metrics","link":"/categories/spring/metrics/"},{"name":"batch","slug":"spring/batch","link":"/categories/spring/batch/"},{"name":"mybatis-plus","slug":"spring/mybatis-plus","link":"/categories/spring/mybatis-plus/"},{"name":"redis","slug":"spring/redis","link":"/categories/spring/redis/"},{"name":"WebSockets","slug":"spring/WebSockets","link":"/categories/spring/WebSockets/"},{"name":"docker","slug":"spring/docker","link":"/categories/spring/docker/"},{"name":"springdoc","slug":"spring/springdoc","link":"/categories/spring/springdoc/"},{"name":"centos","slug":"linux/centos","link":"/categories/linux/centos/"},{"name":"webflux","slug":"spring/webflux","link":"/categories/spring/webflux/"},{"name":"study","slug":"study","link":"/categories/study/"},{"name":"reactive","slug":"reactive","link":"/categories/reactive/"},{"name":"zookeeper","slug":"zookeeper","link":"/categories/zookeeper/"},{"name":"动态规划","slug":"数据结构和算法/动态规划","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"链表","slug":"数据结构和算法/链表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/"},{"name":"dijkstra","slug":"数据结构和算法/dijkstra","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/dijkstra/"},{"name":"string","slug":"数据结构和算法/string","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/string/"},{"name":"树","slug":"数据结构和算法/树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%A0%91/"},{"name":"hexo","slug":"frontend/hexo","link":"/categories/frontend/hexo/"},{"name":"串","slug":"数据结构和算法/串","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E4%B8%B2/"},{"name":"拦截&#x2F;抓包工具","slug":"拦截-抓包工具","link":"/categories/%E6%8B%A6%E6%88%AA-%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"name":"game engine","slug":"game-engine","link":"/categories/game-engine/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"ansible","slug":"linux/ansible","link":"/categories/linux/ansible/"},{"name":"vmware","slug":"vmware","link":"/categories/vmware/"},{"name":"大数据","slug":"大数据","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"kafka","slug":"kafka","link":"/categories/kafka/"}]}